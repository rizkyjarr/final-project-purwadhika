[0m02:01:58.167482 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f52cc44a050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f52cc9a0690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f52cc4481d0>]}


============================== 02:01:58.169998 | f30404dd-70bc-499f-b040-8dec280d234b ==============================
[0m02:01:58.169998 [info ] [MainThread]: Running with dbt=1.9.0
[0m02:01:58.171483 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt debug', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m02:01:58.194779 [info ] [MainThread]: dbt version: 1.9.0
[0m02:01:58.196604 [info ] [MainThread]: python version: 3.11.2
[0m02:01:58.199261 [info ] [MainThread]: python path: /usr/local/bin/python
[0m02:01:58.200610 [info ] [MainThread]: os info: Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.31
[0m02:01:58.202280 [info ] [MainThread]: Using profiles dir at /usr/app/dbt_project
[0m02:01:58.204031 [info ] [MainThread]: Using profiles.yml file at /usr/app/dbt_project/profiles.yml
[0m02:01:58.205188 [info ] [MainThread]: Using dbt_project.yml file at /usr/app/dbt_project/dbt_project.yml
[0m02:01:58.303120 [info ] [MainThread]: Configuration:
[0m02:01:58.304294 [info ] [MainThread]:   profiles.yml file [[31mERROR not found[0m]
[0m02:01:58.305538 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m02:01:58.306951 [info ] [MainThread]: Required dependencies:
[0m02:01:58.308008 [debug] [MainThread]: Executing "git --help"
[0m02:01:58.323742 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m02:01:58.324603 [debug] [MainThread]: STDERR: "b''"
[0m02:01:58.325333 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m02:01:58.326344 [info ] [MainThread]: Connection test skipped since no profile was found
[0m02:01:58.327995 [info ] [MainThread]: [31m1 check failed:[0m
[0m02:01:58.329152 [info ] [MainThread]: dbt looked for a profiles.yml file in /usr/app/dbt_project/profiles.yml, but did
not find one. For more information on configuring your profile, consult the
documentation:

https://docs.getdbt.com/docs/configure-your-profile


[0m02:01:58.331588 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": false, "command_wall_clock_time": 0.21399155, "process_in_blocks": "776", "process_kernel_time": 0.060459, "process_mem_max_rss": "90472", "process_out_blocks": "0", "process_user_time": 0.977432}
[0m02:01:58.332640 [debug] [MainThread]: Command `dbt debug` failed at 02:01:58.332515 after 0.22 seconds
[0m02:01:58.333781 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f52cc429c50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f52cfd6d210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f52cfd6d150>]}
[0m02:01:58.334968 [debug] [MainThread]: Flushing usage events
[0m02:01:59.648058 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:03:01.751208 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f58c3dce910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f58c42af7d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f58c3dcd990>]}


============================== 02:03:01.755328 | 7f50ea83-094b-4ed3-971d-39636c6fa73a ==============================
[0m02:03:01.755328 [info ] [MainThread]: Running with dbt=1.9.0
[0m02:03:01.756721 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'warn_error': 'None', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt debug', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m02:03:01.767470 [info ] [MainThread]: dbt version: 1.9.0
[0m02:03:01.768348 [info ] [MainThread]: python version: 3.11.2
[0m02:03:01.769784 [info ] [MainThread]: python path: /usr/local/bin/python
[0m02:03:01.770739 [info ] [MainThread]: os info: Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.31
[0m02:03:02.302614 [info ] [MainThread]: Using profiles dir at /usr/app/dbt_project
[0m02:03:02.303759 [info ] [MainThread]: Using profiles.yml file at /usr/app/dbt_project/profiles.yml
[0m02:03:02.304871 [info ] [MainThread]: Using dbt_project.yml file at /usr/app/dbt_project/dbt_project.yml
[0m02:03:02.305801 [info ] [MainThread]: adapter type: bigquery
[0m02:03:02.307297 [info ] [MainThread]: adapter version: 1.9.0
[0m02:03:02.402199 [info ] [MainThread]: Configuration:
[0m02:03:02.403292 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m02:03:02.404241 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m02:03:02.405112 [info ] [MainThread]: Required dependencies:
[0m02:03:02.406134 [debug] [MainThread]: Executing "git --help"
[0m02:03:02.408326 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m02:03:02.409631 [debug] [MainThread]: STDERR: "b''"
[0m02:03:02.410439 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m02:03:02.411349 [info ] [MainThread]: Connection:
[0m02:03:02.412438 [info ] [MainThread]:   method: service-account
[0m02:03:02.413312 [info ] [MainThread]:   database: purwadika
[0m02:03:02.414164 [info ] [MainThread]:   execution_project: purwadika
[0m02:03:02.415144 [info ] [MainThread]:   schema: rizky_dwh_hailing_source
[0m02:03:02.416415 [info ] [MainThread]:   location: None
[0m02:03:02.417588 [info ] [MainThread]:   priority: None
[0m02:03:02.418533 [info ] [MainThread]:   maximum_bytes_billed: None
[0m02:03:02.419663 [info ] [MainThread]:   impersonate_service_account: None
[0m02:03:02.420829 [info ] [MainThread]:   job_retry_deadline_seconds: None
[0m02:03:02.422152 [info ] [MainThread]:   job_retries: 1
[0m02:03:02.423846 [info ] [MainThread]:   job_creation_timeout_seconds: None
[0m02:03:02.424872 [info ] [MainThread]:   job_execution_timeout_seconds: None
[0m02:03:02.426031 [info ] [MainThread]:   timeout_seconds: None
[0m02:03:02.427484 [info ] [MainThread]:   client_id: None
[0m02:03:02.428781 [info ] [MainThread]:   token_uri: None
[0m02:03:02.430586 [info ] [MainThread]:   dataproc_region: None
[0m02:03:02.431899 [info ] [MainThread]:   dataproc_cluster_name: None
[0m02:03:02.432880 [info ] [MainThread]:   gcs_bucket: None
[0m02:03:02.434031 [info ] [MainThread]:   dataproc_batch: None
[0m02:03:02.435123 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m02:03:02.502738 [debug] [MainThread]: Acquiring new bigquery connection 'debug'
[0m02:03:02.503622 [debug] [MainThread]: On debug: select 1 as id
[0m02:03:02.504454 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:03:02.531994 [debug] [MainThread]: BigQuery adapter: Got an error when attempting to create a bigquery " "client: '[Errno 21] Is a directory: '/root/.dbt/credentials.json''
[0m02:03:02.533124 [debug] [MainThread]: BigQuery adapter: Unhandled error while running:
select 1 as id
[0m02:03:02.534054 [debug] [MainThread]: BigQuery adapter: Database Error
  [Errno 21] Is a directory: '/root/.dbt/credentials.json'
[0m02:03:02.534785 [info ] [MainThread]:   Connection test: [[31mERROR[0m]

[0m02:03:02.535672 [info ] [MainThread]: [31m1 check failed:[0m
[0m02:03:02.536718 [info ] [MainThread]: dbt was unable to connect to the specified database.
The database returned the following error:

  >'NoneType' object has no attribute 'close'

Check your database credentials and try again. For more information, visit:
https://docs.getdbt.com/docs/configure-your-profile


[0m02:03:02.538374 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": false, "command_wall_clock_time": 0.8450967, "process_in_blocks": "696", "process_kernel_time": 0.1747, "process_mem_max_rss": "207440", "process_out_blocks": "24", "process_user_time": 2.733544}
[0m02:03:02.539326 [debug] [MainThread]: Command `dbt debug` failed at 02:03:02.539222 after 0.85 seconds
[0m02:03:02.540230 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f58c3e04450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5896576250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f58c4aaf290>]}
[0m02:03:02.541443 [debug] [MainThread]: Flushing usage events
[0m02:03:03.693784 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:04:31.038959 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd596e53810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd596f60e90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd596e87090>]}


============================== 02:04:31.043418 | 81d713c9-fbc7-4523-921b-5a295ad22e3d ==============================
[0m02:04:31.043418 [info ] [MainThread]: Running with dbt=1.9.0
[0m02:04:31.044686 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'warn_error': 'None', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt debug', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m02:04:31.051027 [info ] [MainThread]: dbt version: 1.9.0
[0m02:04:31.051864 [info ] [MainThread]: python version: 3.11.2
[0m02:04:31.054054 [info ] [MainThread]: python path: /usr/local/bin/python
[0m02:04:31.055178 [info ] [MainThread]: os info: Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.31
[0m02:04:31.556857 [info ] [MainThread]: Using profiles dir at /usr/app/dbt_project
[0m02:04:31.558394 [info ] [MainThread]: Using profiles.yml file at /usr/app/dbt_project/profiles.yml
[0m02:04:31.559756 [info ] [MainThread]: Using dbt_project.yml file at /usr/app/dbt_project/dbt_project.yml
[0m02:04:31.561102 [info ] [MainThread]: adapter type: bigquery
[0m02:04:31.562446 [info ] [MainThread]: adapter version: 1.9.0
[0m02:04:31.641979 [info ] [MainThread]: Configuration:
[0m02:04:31.644292 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m02:04:31.645262 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m02:04:31.646400 [info ] [MainThread]: Required dependencies:
[0m02:04:31.647547 [debug] [MainThread]: Executing "git --help"
[0m02:04:31.649460 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m02:04:31.650135 [debug] [MainThread]: STDERR: "b''"
[0m02:04:31.650881 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m02:04:31.651960 [info ] [MainThread]: Connection:
[0m02:04:31.653391 [info ] [MainThread]:   method: service-account
[0m02:04:31.654439 [info ] [MainThread]:   database: purwadika
[0m02:04:31.655544 [info ] [MainThread]:   execution_project: purwadika
[0m02:04:31.656705 [info ] [MainThread]:   schema: rizky_dwh_hailing_source
[0m02:04:31.659063 [info ] [MainThread]:   location: None
[0m02:04:31.660554 [info ] [MainThread]:   priority: None
[0m02:04:31.661527 [info ] [MainThread]:   maximum_bytes_billed: None
[0m02:04:31.662408 [info ] [MainThread]:   impersonate_service_account: None
[0m02:04:31.663369 [info ] [MainThread]:   job_retry_deadline_seconds: None
[0m02:04:31.664496 [info ] [MainThread]:   job_retries: 1
[0m02:04:31.665590 [info ] [MainThread]:   job_creation_timeout_seconds: None
[0m02:04:31.666913 [info ] [MainThread]:   job_execution_timeout_seconds: None
[0m02:04:31.667968 [info ] [MainThread]:   timeout_seconds: None
[0m02:04:31.668867 [info ] [MainThread]:   client_id: None
[0m02:04:31.669906 [info ] [MainThread]:   token_uri: None
[0m02:04:31.670765 [info ] [MainThread]:   dataproc_region: None
[0m02:04:31.671720 [info ] [MainThread]:   dataproc_cluster_name: None
[0m02:04:31.672753 [info ] [MainThread]:   gcs_bucket: None
[0m02:04:31.673635 [info ] [MainThread]:   dataproc_batch: None
[0m02:04:31.674714 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m02:04:31.729175 [debug] [MainThread]: Acquiring new bigquery connection 'debug'
[0m02:04:31.730186 [debug] [MainThread]: On debug: select 1 as id
[0m02:04:31.731072 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:04:32.794278 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:87d88a11-3360-405e-8b46-a8ca6bbbbf3c&page=queryresults
[0m02:04:33.636786 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m02:04:33.638193 [info ] [MainThread]: [32mAll checks passed![0m
[0m02:04:33.639993 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": true, "command_wall_clock_time": 2.6463816, "process_in_blocks": "1728", "process_kernel_time": 0.200069, "process_mem_max_rss": "212840", "process_out_blocks": "1952", "process_user_time": 2.727258}
[0m02:04:33.641273 [debug] [MainThread]: Command `dbt debug` succeeded at 02:04:33.641161 after 2.65 seconds
[0m02:04:33.642154 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m02:04:33.643123 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd596ccfed0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd59a8ed810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd59a5f4b90>]}
[0m02:04:33.644089 [debug] [MainThread]: Flushing usage events
[0m02:04:35.179263 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:13:23.075436 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff40d3efc50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff40d3eed10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff40d4f9c90>]}


============================== 02:13:23.078000 | c09a6ece-1481-4071-b0cc-401b4b306eb2 ==============================
[0m02:13:23.078000 [info ] [MainThread]: Running with dbt=1.9.0
[0m02:13:23.079859 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt run', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m02:13:23.657306 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'c09a6ece-1481-4071-b0cc-401b4b306eb2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3df58ee90>]}
[0m02:13:23.701756 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'c09a6ece-1481-4071-b0cc-401b4b306eb2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3df668f10>]}
[0m02:13:23.703096 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m02:13:23.769821 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m02:13:23.772243 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m02:13:23.773545 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'c09a6ece-1481-4071-b0cc-401b4b306eb2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3df304610>]}
[0m02:13:24.778057 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c09a6ece-1481-4071-b0cc-401b4b306eb2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3df184190>]}
[0m02:13:24.848924 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m02:13:24.854999 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m02:13:24.878854 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c09a6ece-1481-4071-b0cc-401b4b306eb2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3dd7f51d0>]}
[0m02:13:24.880016 [info ] [MainThread]: Found 4 models, 4 sources, 487 macros
[0m02:13:24.881104 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c09a6ece-1481-4071-b0cc-401b4b306eb2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3df174a90>]}
[0m02:13:24.883858 [info ] [MainThread]: 
[0m02:13:24.884947 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m02:13:24.885962 [info ] [MainThread]: 
[0m02:13:24.887547 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m02:13:24.892377 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m02:13:24.893723 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:13:25.533676 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now create_purwadika_rizky_dwh_hailing_source_staging_layer)
[0m02:13:25.534636 [debug] [ThreadPool]: Creating schema "database: "purwadika"
schema: "rizky_dwh_hailing_source_staging_layer"
"
[0m02:13:25.544110 [debug] [ThreadPool]: On create_purwadika_rizky_dwh_hailing_source_staging_layer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "connection_name": "create_purwadika_rizky_dwh_hailing_source_staging_layer"} */
create schema if not exists `purwadika`.`rizky_dwh_hailing_source_staging_layer`
  
[0m02:13:25.545018 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:13:26.420654 [debug] [ThreadPool]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:ff549e3d-6554-4cfb-bd1b-ec70f66fdf2b&page=queryresults
[0m02:13:27.364350 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_purwadika_rizky_dwh_hailing_source_staging_layer, now list_purwadika_rizky_dwh_hailing_source_staging_layer)
[0m02:13:27.365587 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:13:27.962897 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c09a6ece-1481-4071-b0cc-401b4b306eb2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3df3d4a90>]}
[0m02:13:27.964146 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:13:27.968860 [debug] [Thread-1 (]: Began running node model.hailing_project.stg_customer
[0m02:13:27.969238 [debug] [Thread-2 (]: Began running node model.hailing_project.stg_driver
[0m02:13:27.969552 [debug] [Thread-3 (]: Began running node model.hailing_project.stg_ride
[0m02:13:27.969869 [debug] [Thread-4 (]: Began running node model.hailing_project.stg_vehicle
[0m02:13:27.970397 [info ] [Thread-1 (]: 1 of 4 START sql incremental model rizky_dwh_hailing_source_staging_layer.stg_customer  [RUN]
[0m02:13:27.971371 [info ] [Thread-2 (]: 2 of 4 START sql incremental model rizky_dwh_hailing_source_staging_layer.stg_driver  [RUN]
[0m02:13:27.972555 [info ] [Thread-3 (]: 3 of 4 START sql incremental model rizky_dwh_hailing_source_staging_layer.stg_ride  [RUN]
[0m02:13:27.973745 [info ] [Thread-4 (]: 4 of 4 START sql incremental model rizky_dwh_hailing_source_staging_layer.stg_vehicle  [RUN]
[0m02:13:27.974666 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source_staging_layer, now model.hailing_project.stg_customer)
[0m02:13:27.975693 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.stg_driver'
[0m02:13:27.976480 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.stg_ride'
[0m02:13:27.977492 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.stg_vehicle'
[0m02:13:27.978532 [debug] [Thread-1 (]: Began compiling node model.hailing_project.stg_customer
[0m02:13:27.979457 [debug] [Thread-2 (]: Began compiling node model.hailing_project.stg_driver
[0m02:13:27.980371 [debug] [Thread-3 (]: Began compiling node model.hailing_project.stg_ride
[0m02:13:27.981171 [debug] [Thread-4 (]: Began compiling node model.hailing_project.stg_vehicle
[0m02:13:27.990440 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.stg_customer"
[0m02:13:27.993778 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.stg_driver"
[0m02:13:27.997289 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.stg_ride"
[0m02:13:28.002557 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.stg_vehicle"
[0m02:13:28.013883 [debug] [Thread-4 (]: Began executing node model.hailing_project.stg_vehicle
[0m02:13:28.020199 [debug] [Thread-2 (]: Began executing node model.hailing_project.stg_driver
[0m02:13:28.055805 [debug] [Thread-1 (]: Began executing node model.hailing_project.stg_customer
[0m02:13:28.077280 [debug] [Thread-3 (]: Began executing node model.hailing_project.stg_ride
[0m02:13:28.094918 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.stg_driver"
[0m02:13:28.095777 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.stg_vehicle"
[0m02:13:28.098535 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.stg_customer"
[0m02:13:28.102086 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.stg_ride"
[0m02:13:28.113235 [debug] [Thread-1 (]: On model.hailing_project.stg_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source_staging_layer`.`stg_customer`
      
    
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_customer_source`
),

cleaned AS (
    SELECT
        customer_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned
    );
  
[0m02:13:28.114468 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m02:13:28.114968 [debug] [Thread-3 (]: On model.hailing_project.stg_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_ride"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source_staging_layer`.`stg_ride`
      
    
    

    OPTIONS()
    as (
      

SELECT *
FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_ride_source`
    );
  
[0m02:13:28.116441 [debug] [Thread-4 (]: On model.hailing_project.stg_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_vehicle"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source_staging_layer`.`stg_vehicle`
      
    
    

    OPTIONS()
    as (
      

SELECT *
FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_vehicle_source`
    );
  
[0m02:13:28.117278 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m02:13:28.118506 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m02:13:28.120172 [debug] [Thread-2 (]: On model.hailing_project.stg_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_driver"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source_staging_layer`.`stg_driver`
      
    
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_driver_source`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned
    );
  
[0m02:13:28.168238 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m02:13:28.521749 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:646f9616-63cc-45b6-bf88-99d73b4ed749&page=queryresults
[0m02:13:28.523204 [error] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:646f9616-63cc-45b6-bf88-99d73b4ed749&page=queryresults
[0m02:13:28.528143 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:f54b5075-3bf2-4aba-9c4a-dd2e97f5d340&page=queryresults
[0m02:13:28.529736 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:33a93330-c5ad-4749-9727-560eebeb7501&page=queryresults
[0m02:13:28.530267 [error] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:f54b5075-3bf2-4aba-9c4a-dd2e97f5d340&page=queryresults
[0m02:13:28.531426 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:33a93330-c5ad-4749-9727-560eebeb7501&page=queryresults
[0m02:13:28.541292 [debug] [Thread-4 (]: Database Error in model stg_vehicle (models/staging/stg_vehicle.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_vehicle.sql
[0m02:13:28.542367 [debug] [Thread-1 (]: Database Error in model stg_customer (models/staging/stg_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_customer.sql
[0m02:13:28.543449 [debug] [Thread-2 (]: Database Error in model stg_driver (models/staging/stg_driver.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_driver.sql
[0m02:13:28.545777 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c09a6ece-1481-4071-b0cc-401b4b306eb2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3df15de50>]}
[0m02:13:28.546575 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c09a6ece-1481-4071-b0cc-401b4b306eb2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3dcc6e4d0>]}
[0m02:13:28.547746 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c09a6ece-1481-4071-b0cc-401b4b306eb2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3dcb1f610>]}
[0m02:13:28.549150 [error] [Thread-4 (]: 4 of 4 ERROR creating sql incremental model rizky_dwh_hailing_source_staging_layer.stg_vehicle  [[31mERROR[0m in 0.57s]
[0m02:13:28.551069 [error] [Thread-1 (]: 1 of 4 ERROR creating sql incremental model rizky_dwh_hailing_source_staging_layer.stg_customer  [[31mERROR[0m in 0.57s]
[0m02:13:28.553330 [error] [Thread-2 (]: 2 of 4 ERROR creating sql incremental model rizky_dwh_hailing_source_staging_layer.stg_driver  [[31mERROR[0m in 0.57s]
[0m02:13:28.554927 [debug] [Thread-4 (]: Finished running node model.hailing_project.stg_vehicle
[0m02:13:28.556276 [debug] [Thread-1 (]: Finished running node model.hailing_project.stg_customer
[0m02:13:28.557515 [debug] [Thread-2 (]: Finished running node model.hailing_project.stg_driver
[0m02:13:28.558931 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.stg_vehicle' to be skipped because of status 'error'.  Reason: Database Error in model stg_vehicle (models/staging/stg_vehicle.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_vehicle.sql.
[0m02:13:28.561649 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.stg_customer' to be skipped because of status 'error'.  Reason: Database Error in model stg_customer (models/staging/stg_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_customer.sql.
[0m02:13:28.562905 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.stg_driver' to be skipped because of status 'error'.  Reason: Database Error in model stg_driver (models/staging/stg_driver.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_driver.sql.
[0m02:13:28.565097 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:4885aa9d-e541-4d05-bcc8-860385bcb7c1&page=queryresults
[0m02:13:28.566302 [error] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:4885aa9d-e541-4d05-bcc8-860385bcb7c1&page=queryresults
[0m02:13:28.570401 [debug] [Thread-3 (]: Database Error in model stg_ride (models/staging/stg_ride.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_ride.sql
[0m02:13:28.571656 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c09a6ece-1481-4071-b0cc-401b4b306eb2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3dd7053d0>]}
[0m02:13:28.572987 [error] [Thread-3 (]: 3 of 4 ERROR creating sql incremental model rizky_dwh_hailing_source_staging_layer.stg_ride  [[31mERROR[0m in 0.60s]
[0m02:13:28.574379 [debug] [Thread-3 (]: Finished running node model.hailing_project.stg_ride
[0m02:13:28.575882 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.stg_ride' to be skipped because of status 'error'.  Reason: Database Error in model stg_ride (models/staging/stg_ride.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_ride.sql.
[0m02:13:28.578237 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m02:13:28.581305 [debug] [MainThread]: Connection 'master' was properly closed.
[0m02:13:28.581993 [debug] [MainThread]: Connection 'model.hailing_project.stg_customer' was properly closed.
[0m02:13:28.582844 [debug] [MainThread]: Connection 'model.hailing_project.stg_driver' was properly closed.
[0m02:13:28.583559 [debug] [MainThread]: Connection 'model.hailing_project.stg_ride' was properly closed.
[0m02:13:28.584355 [debug] [MainThread]: Connection 'model.hailing_project.stg_vehicle' was properly closed.
[0m02:13:28.585086 [info ] [MainThread]: 
[0m02:13:28.586045 [info ] [MainThread]: Finished running 4 incremental models in 0 hours 0 minutes and 3.70 seconds (3.70s).
[0m02:13:28.587818 [debug] [MainThread]: Command end result
[0m02:13:28.623846 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m02:13:28.628422 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m02:13:28.637064 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m02:13:28.637811 [info ] [MainThread]: 
[0m02:13:28.638883 [info ] [MainThread]: [31mCompleted with 4 errors, 0 partial successes, and 0 warnings:[0m
[0m02:13:28.640157 [info ] [MainThread]: 
[0m02:13:28.642484 [error] [MainThread]:   Database Error in model stg_vehicle (models/staging/stg_vehicle.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_vehicle.sql
[0m02:13:28.644360 [info ] [MainThread]: 
[0m02:13:28.645843 [error] [MainThread]:   Database Error in model stg_customer (models/staging/stg_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_customer.sql
[0m02:13:28.646854 [info ] [MainThread]: 
[0m02:13:28.647998 [error] [MainThread]:   Database Error in model stg_driver (models/staging/stg_driver.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_driver.sql
[0m02:13:28.649370 [info ] [MainThread]: 
[0m02:13:28.651287 [error] [MainThread]:   Database Error in model stg_ride (models/staging/stg_ride.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_ride.sql
[0m02:13:28.652467 [info ] [MainThread]: 
[0m02:13:28.653536 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=4 SKIP=0 TOTAL=4
[0m02:13:28.655363 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 5.626566, "process_in_blocks": "2952", "process_kernel_time": 0.239406, "process_mem_max_rss": "227664", "process_out_blocks": "120", "process_user_time": 3.980132}
[0m02:13:28.656716 [debug] [MainThread]: Command `dbt run` failed at 02:13:28.656571 after 5.63 seconds
[0m02:13:28.657757 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff40d26fd50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff40d26f910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff410d3c910>]}
[0m02:13:28.659269 [debug] [MainThread]: Flushing usage events
[0m02:13:29.808444 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:18:45.087750 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f165de0af90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f165de0b3d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f165de0a810>]}


============================== 02:18:45.090624 | 4a4e9f48-a67f-4b7f-8886-913783f5298a ==============================
[0m02:18:45.090624 [info ] [MainThread]: Running with dbt=1.9.0
[0m02:18:45.091889 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt clean', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m02:18:45.170120 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '4a4e9f48-a67f-4b7f-8886-913783f5298a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f165dd4a150>]}
[0m02:18:45.236071 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.19432564, "process_in_blocks": "16", "process_kernel_time": 0.09933, "process_mem_max_rss": "90056", "process_out_blocks": "0", "process_user_time": 0.913843}
[0m02:18:45.237553 [debug] [MainThread]: Command `dbt clean` succeeded at 02:18:45.237391 after 0.20 seconds
[0m02:18:45.238719 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f165de5fc10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f165de5fc50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1661600c10>]}
[0m02:18:45.239771 [debug] [MainThread]: Flushing usage events
[0m02:18:46.409339 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:18:47.583171 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9fa9834b10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9fa988b1d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9fa9c2de50>]}


============================== 02:18:47.586327 | bdee2df0-a205-4d95-a78f-035433b48340 ==============================
[0m02:18:47.586327 [info ] [MainThread]: Running with dbt=1.9.0
[0m02:18:47.587616 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt deps', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m02:18:47.673552 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'bdee2df0-a205-4d95-a78f-035433b48340', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9fa96e7590>]}
[0m02:18:47.687732 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m02:18:47.690576 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m02:18:47.692333 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.15736815, "process_in_blocks": "224", "process_kernel_time": 0.099129, "process_mem_max_rss": "90016", "process_out_blocks": "0", "process_user_time": 1.001206}
[0m02:18:47.693464 [debug] [MainThread]: Command `dbt deps` succeeded at 02:18:47.693309 after 0.16 seconds
[0m02:18:47.694459 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9fad028c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9fad185350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9fad1850d0>]}
[0m02:18:47.695615 [debug] [MainThread]: Flushing usage events
[0m02:18:48.762707 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:18:52.308476 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f38623fb090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f38624289d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3862429210>]}


============================== 02:18:52.311249 | 995e2a61-4840-4443-befc-8244674169b3 ==============================
[0m02:18:52.311249 [info ] [MainThread]: Running with dbt=1.9.0
[0m02:18:52.312645 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt run', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m02:18:52.907063 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '995e2a61-4840-4443-befc-8244674169b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f38623fded0>]}
[0m02:18:52.955932 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '995e2a61-4840-4443-befc-8244674169b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f383885ef10>]}
[0m02:18:52.957296 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m02:18:53.026383 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m02:18:53.028816 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m02:18:53.029763 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '995e2a61-4840-4443-befc-8244674169b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f38386fdcd0>]}
[0m02:18:54.032005 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '995e2a61-4840-4443-befc-8244674169b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f38381e0890>]}
[0m02:18:54.103335 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m02:18:54.109105 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m02:18:54.126461 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '995e2a61-4840-4443-befc-8244674169b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f38381fe650>]}
[0m02:18:54.127461 [info ] [MainThread]: Found 4 models, 4 sources, 487 macros
[0m02:18:54.128376 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '995e2a61-4840-4443-befc-8244674169b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3838301450>]}
[0m02:18:54.130972 [info ] [MainThread]: 
[0m02:18:54.132065 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m02:18:54.133306 [info ] [MainThread]: 
[0m02:18:54.134660 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m02:18:54.139423 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m02:18:54.140644 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:18:54.790776 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now create_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer)
[0m02:18:54.791786 [debug] [ThreadPool]: Creating schema "database: "purwadika"
schema: "rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer"
"
[0m02:18:54.799925 [debug] [ThreadPool]: On create_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "connection_name": "create_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer"} */
create schema if not exists `purwadika`.`rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer`
  
[0m02:18:54.800625 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:18:55.669445 [debug] [ThreadPool]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:285fe163-a733-42d8-bdca-8b8d38f7b5b4&page=queryresults
[0m02:18:56.649128 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer, now list_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer)
[0m02:18:56.650897 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:18:57.247028 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '995e2a61-4840-4443-befc-8244674169b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f38385a43d0>]}
[0m02:18:57.247999 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:18:57.253541 [debug] [Thread-1 (]: Began running node model.hailing_project.stg_customer
[0m02:18:57.253984 [debug] [Thread-2 (]: Began running node model.hailing_project.stg_driver
[0m02:18:57.254370 [debug] [Thread-3 (]: Began running node model.hailing_project.stg_ride
[0m02:18:57.254750 [debug] [Thread-4 (]: Began running node model.hailing_project.stg_vehicle
[0m02:18:57.255599 [info ] [Thread-1 (]: 1 of 4 START sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer.stg_customer  [RUN]
[0m02:18:57.256713 [info ] [Thread-2 (]: 2 of 4 START sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer.stg_driver  [RUN]
[0m02:18:57.258216 [info ] [Thread-3 (]: 3 of 4 START sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer.stg_ride  [RUN]
[0m02:18:57.259397 [info ] [Thread-4 (]: 4 of 4 START sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer.stg_vehicle  [RUN]
[0m02:18:57.260814 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer, now model.hailing_project.stg_customer)
[0m02:18:57.261950 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.stg_driver'
[0m02:18:57.263136 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.stg_ride'
[0m02:18:57.264714 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.stg_vehicle'
[0m02:18:57.266058 [debug] [Thread-1 (]: Began compiling node model.hailing_project.stg_customer
[0m02:18:57.268773 [debug] [Thread-2 (]: Began compiling node model.hailing_project.stg_driver
[0m02:18:57.271434 [debug] [Thread-3 (]: Began compiling node model.hailing_project.stg_ride
[0m02:18:57.273046 [debug] [Thread-4 (]: Began compiling node model.hailing_project.stg_vehicle
[0m02:18:57.284746 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.stg_customer"
[0m02:18:57.289441 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.stg_driver"
[0m02:18:57.294893 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.stg_ride"
[0m02:18:57.299210 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.stg_vehicle"
[0m02:18:57.310739 [debug] [Thread-2 (]: Began executing node model.hailing_project.stg_driver
[0m02:18:57.317324 [debug] [Thread-1 (]: Began executing node model.hailing_project.stg_customer
[0m02:18:57.376507 [debug] [Thread-3 (]: Began executing node model.hailing_project.stg_ride
[0m02:18:57.382602 [debug] [Thread-4 (]: Began executing node model.hailing_project.stg_vehicle
[0m02:18:57.390017 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.stg_customer"
[0m02:18:57.390640 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.stg_driver"
[0m02:18:57.393482 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.stg_ride"
[0m02:18:57.397157 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.stg_vehicle"
[0m02:18:57.408477 [debug] [Thread-2 (]: On model.hailing_project.stg_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_driver"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer`.`stg_driver`
      
    
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_driver_source`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned
    );
  
[0m02:18:57.410030 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m02:18:57.410566 [debug] [Thread-3 (]: On model.hailing_project.stg_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_ride"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer`.`stg_ride`
      
    
    

    OPTIONS()
    as (
      

SELECT *
FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_ride_source`
    );
  
[0m02:18:57.411426 [debug] [Thread-4 (]: On model.hailing_project.stg_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_vehicle"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer`.`stg_vehicle`
      
    
    

    OPTIONS()
    as (
      

SELECT *
FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_vehicle_source`
    );
  
[0m02:18:57.413100 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m02:18:57.413703 [debug] [Thread-1 (]: On model.hailing_project.stg_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer`.`stg_customer`
      
    
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_customer_source`
),

cleaned AS (
    SELECT
        customer_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned
    );
  
[0m02:18:57.438615 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m02:18:57.441446 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m02:18:57.764466 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:6107e896-4330-4e03-92fd-74ee8ca3a5bf&page=queryresults
[0m02:18:57.767348 [error] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:6107e896-4330-4e03-92fd-74ee8ca3a5bf&page=queryresults
[0m02:18:57.768242 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:c7171be9-3886-4586-806c-f92482b5aba9&page=queryresults
[0m02:18:57.771344 [error] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:c7171be9-3886-4586-806c-f92482b5aba9&page=queryresults
[0m02:18:57.774681 [debug] [Thread-2 (]: Database Error in model stg_driver (models/staging/stg_driver.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_driver.sql
[0m02:18:57.777527 [debug] [Thread-4 (]: Database Error in model stg_vehicle (models/staging/stg_vehicle.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_vehicle.sql
[0m02:18:57.779421 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:2c108a5b-ad82-48ce-aaae-e21c5ac369d1&page=queryresults
[0m02:18:57.779887 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '995e2a61-4840-4443-befc-8244674169b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3831dde650>]}
[0m02:18:57.780818 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '995e2a61-4840-4443-befc-8244674169b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3831ca1250>]}
[0m02:18:57.781873 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:2c108a5b-ad82-48ce-aaae-e21c5ac369d1&page=queryresults
[0m02:18:57.783172 [error] [Thread-2 (]: 2 of 4 ERROR creating sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer.stg_driver  [[31mERROR[0m in 0.52s]
[0m02:18:57.784548 [error] [Thread-4 (]: 4 of 4 ERROR creating sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer.stg_vehicle  [[31mERROR[0m in 0.52s]
[0m02:18:57.788188 [debug] [Thread-1 (]: Database Error in model stg_customer (models/staging/stg_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_customer.sql
[0m02:18:57.789031 [debug] [Thread-2 (]: Finished running node model.hailing_project.stg_driver
[0m02:18:57.790559 [debug] [Thread-4 (]: Finished running node model.hailing_project.stg_vehicle
[0m02:18:57.792189 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '995e2a61-4840-4443-befc-8244674169b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3831c256d0>]}
[0m02:18:57.793376 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.stg_driver' to be skipped because of status 'error'.  Reason: Database Error in model stg_driver (models/staging/stg_driver.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_driver.sql.
[0m02:18:57.795166 [error] [Thread-1 (]: 1 of 4 ERROR creating sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer.stg_customer  [[31mERROR[0m in 0.53s]
[0m02:18:57.796610 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.stg_vehicle' to be skipped because of status 'error'.  Reason: Database Error in model stg_vehicle (models/staging/stg_vehicle.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_vehicle.sql.
[0m02:18:57.797827 [debug] [Thread-1 (]: Finished running node model.hailing_project.stg_customer
[0m02:18:57.800033 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.stg_customer' to be skipped because of status 'error'.  Reason: Database Error in model stg_customer (models/staging/stg_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_customer.sql.
[0m02:18:57.840670 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:703422ab-858d-4051-99c6-58851df2b19d&page=queryresults
[0m02:18:57.842184 [error] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:703422ab-858d-4051-99c6-58851df2b19d&page=queryresults
[0m02:18:57.846614 [debug] [Thread-3 (]: Database Error in model stg_ride (models/staging/stg_ride.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_ride.sql
[0m02:18:57.847909 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '995e2a61-4840-4443-befc-8244674169b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3831c30c10>]}
[0m02:18:57.849065 [error] [Thread-3 (]: 3 of 4 ERROR creating sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer.stg_ride  [[31mERROR[0m in 0.58s]
[0m02:18:57.850382 [debug] [Thread-3 (]: Finished running node model.hailing_project.stg_ride
[0m02:18:57.851855 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.stg_ride' to be skipped because of status 'error'.  Reason: Database Error in model stg_ride (models/staging/stg_ride.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_ride.sql.
[0m02:18:57.854570 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m02:18:57.857707 [debug] [MainThread]: Connection 'master' was properly closed.
[0m02:18:57.858629 [debug] [MainThread]: Connection 'model.hailing_project.stg_customer' was properly closed.
[0m02:18:57.859634 [debug] [MainThread]: Connection 'model.hailing_project.stg_driver' was properly closed.
[0m02:18:57.860714 [debug] [MainThread]: Connection 'model.hailing_project.stg_ride' was properly closed.
[0m02:18:57.861703 [debug] [MainThread]: Connection 'model.hailing_project.stg_vehicle' was properly closed.
[0m02:18:57.862721 [info ] [MainThread]: 
[0m02:18:57.863614 [info ] [MainThread]: Finished running 4 incremental models in 0 hours 0 minutes and 3.73 seconds (3.73s).
[0m02:18:57.865233 [debug] [MainThread]: Command end result
[0m02:18:57.896602 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m02:18:57.900681 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m02:18:57.908344 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m02:18:57.909181 [info ] [MainThread]: 
[0m02:18:57.910394 [info ] [MainThread]: [31mCompleted with 4 errors, 0 partial successes, and 0 warnings:[0m
[0m02:18:57.911592 [info ] [MainThread]: 
[0m02:18:57.912736 [error] [MainThread]:   Database Error in model stg_driver (models/staging/stg_driver.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_driver.sql
[0m02:18:57.913900 [info ] [MainThread]: 
[0m02:18:57.915756 [error] [MainThread]:   Database Error in model stg_vehicle (models/staging/stg_vehicle.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_vehicle.sql
[0m02:18:57.917607 [info ] [MainThread]: 
[0m02:18:57.919166 [error] [MainThread]:   Database Error in model stg_customer (models/staging/stg_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_customer.sql
[0m02:18:57.920601 [info ] [MainThread]: 
[0m02:18:57.922638 [error] [MainThread]:   Database Error in model stg_ride (models/staging/stg_ride.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_ride.sql
[0m02:18:57.924235 [info ] [MainThread]: 
[0m02:18:57.926002 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=4 SKIP=0 TOTAL=4
[0m02:18:57.929051 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 5.6718855, "process_in_blocks": "0", "process_kernel_time": 0.240604, "process_mem_max_rss": "228632", "process_out_blocks": "0", "process_user_time": 4.130384}
[0m02:18:57.930771 [debug] [MainThread]: Command `dbt run` failed at 02:18:57.930469 after 5.67 seconds
[0m02:18:57.932291 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f38627f2490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3865ee57d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3865d70850>]}
[0m02:18:57.933518 [debug] [MainThread]: Flushing usage events
[0m02:18:58.973754 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:19:43.036703 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f30f4546e90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f30f459b3d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f30f493e110>]}


============================== 02:19:43.039152 | 7f508b4b-59f7-4147-8cd6-0d08a45c1978 ==============================
[0m02:19:43.039152 [info ] [MainThread]: Running with dbt=1.9.0
[0m02:19:43.040884 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt clean', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m02:19:43.124750 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '7f508b4b-59f7-4147-8cd6-0d08a45c1978', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f30f493e4d0>]}
[0m02:19:43.174142 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.18960154, "process_in_blocks": "0", "process_kernel_time": 0.080068, "process_mem_max_rss": "90120", "process_out_blocks": "0", "process_user_time": 0.930793}
[0m02:19:43.175183 [debug] [MainThread]: Command `dbt clean` succeeded at 02:19:43.175049 after 0.19 seconds
[0m02:19:43.176197 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f30f45a3050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f30f45a3150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f30f7d10c10>]}
[0m02:19:43.177249 [debug] [MainThread]: Flushing usage events
[0m02:19:44.249420 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:19:45.393126 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5ec9d1af50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5ec9d6b610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5ec9d1ab10>]}


============================== 02:19:45.395761 | 50629c51-5b48-4916-bf16-b08f55f53855 ==============================
[0m02:19:45.395761 [info ] [MainThread]: Running with dbt=1.9.0
[0m02:19:45.397063 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt deps', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m02:19:45.475692 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '50629c51-5b48-4916-bf16-b08f55f53855', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5ec9bc6d50>]}
[0m02:19:45.485546 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m02:19:45.488201 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m02:19:45.489894 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.14864384, "process_in_blocks": "0", "process_kernel_time": 0.059938, "process_mem_max_rss": "90020", "process_out_blocks": "0", "process_user_time": 1.018951}
[0m02:19:45.490991 [debug] [MainThread]: Command `dbt deps` succeeded at 02:19:45.490853 after 0.15 seconds
[0m02:19:45.491753 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5ecd508c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5eca10e150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5ec9d19910>]}
[0m02:19:45.492620 [debug] [MainThread]: Flushing usage events
[0m02:19:46.645759 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:19:47.798072 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fced3a57b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fced3e02510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fced3e023d0>]}


============================== 02:19:47.800876 | 36b4bddf-c76d-46a3-ba6c-257ff399de47 ==============================
[0m02:19:47.800876 [info ] [MainThread]: Running with dbt=1.9.0
[0m02:19:47.802377 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'warn_error': 'None', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt run', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m02:19:48.399327 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '36b4bddf-c76d-46a3-ba6c-257ff399de47', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcea5d91d50>]}
[0m02:19:48.443383 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '36b4bddf-c76d-46a3-ba6c-257ff399de47', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fced5c7c850>]}
[0m02:19:48.444634 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m02:19:48.514047 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m02:19:48.516226 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m02:19:48.517453 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '36b4bddf-c76d-46a3-ba6c-257ff399de47', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcea5b93790>]}
[0m02:19:49.503689 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '36b4bddf-c76d-46a3-ba6c-257ff399de47', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcea57e90d0>]}
[0m02:19:49.568227 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m02:19:49.574022 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m02:19:49.589989 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '36b4bddf-c76d-46a3-ba6c-257ff399de47', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcea5887290>]}
[0m02:19:49.591258 [info ] [MainThread]: Found 4 models, 4 sources, 487 macros
[0m02:19:49.592417 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '36b4bddf-c76d-46a3-ba6c-257ff399de47', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcea5a61790>]}
[0m02:19:49.594991 [info ] [MainThread]: 
[0m02:19:49.596181 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m02:19:49.597270 [info ] [MainThread]: 
[0m02:19:49.598509 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m02:19:49.603426 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m02:19:49.604465 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:19:50.214126 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now create_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer)
[0m02:19:50.215642 [debug] [ThreadPool]: Creating schema "database: "purwadika"
schema: "rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer"
"
[0m02:19:50.229867 [debug] [ThreadPool]: On create_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "connection_name": "create_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer"} */
create schema if not exists `purwadika`.`rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer`
  
[0m02:19:50.231396 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:19:51.075076 [debug] [ThreadPool]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:eff2262a-9599-4bac-8e25-f6defc77ceb5&page=queryresults
[0m02:19:52.051860 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer, now list_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer)
[0m02:19:52.052882 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:19:52.647637 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '36b4bddf-c76d-46a3-ba6c-257ff399de47', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcea5884410>]}
[0m02:19:52.649546 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:19:52.654428 [debug] [Thread-1 (]: Began running node model.hailing_project.stg_customer
[0m02:19:52.654897 [debug] [Thread-2 (]: Began running node model.hailing_project.stg_driver
[0m02:19:52.655325 [debug] [Thread-3 (]: Began running node model.hailing_project.stg_ride
[0m02:19:52.655779 [debug] [Thread-4 (]: Began running node model.hailing_project.stg_vehicle
[0m02:19:52.656379 [info ] [Thread-1 (]: 1 of 4 START sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer.stg_customer  [RUN]
[0m02:19:52.657696 [info ] [Thread-2 (]: 2 of 4 START sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer.stg_driver  [RUN]
[0m02:19:52.659094 [info ] [Thread-3 (]: 3 of 4 START sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer.stg_ride  [RUN]
[0m02:19:52.660466 [info ] [Thread-4 (]: 4 of 4 START sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer.stg_vehicle  [RUN]
[0m02:19:52.661523 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer, now model.hailing_project.stg_customer)
[0m02:19:52.662659 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.stg_driver'
[0m02:19:52.663775 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.stg_ride'
[0m02:19:52.665131 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.stg_vehicle'
[0m02:19:52.666395 [debug] [Thread-1 (]: Began compiling node model.hailing_project.stg_customer
[0m02:19:52.667350 [debug] [Thread-2 (]: Began compiling node model.hailing_project.stg_driver
[0m02:19:52.668200 [debug] [Thread-3 (]: Began compiling node model.hailing_project.stg_ride
[0m02:19:52.669164 [debug] [Thread-4 (]: Began compiling node model.hailing_project.stg_vehicle
[0m02:19:52.678200 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.stg_customer"
[0m02:19:52.681497 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.stg_driver"
[0m02:19:52.685727 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.stg_ride"
[0m02:19:52.689378 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.stg_vehicle"
[0m02:19:52.702546 [debug] [Thread-4 (]: Began executing node model.hailing_project.stg_vehicle
[0m02:19:52.709417 [debug] [Thread-3 (]: Began executing node model.hailing_project.stg_ride
[0m02:19:52.742979 [debug] [Thread-1 (]: Began executing node model.hailing_project.stg_customer
[0m02:19:52.743343 [debug] [Thread-2 (]: Began executing node model.hailing_project.stg_driver
[0m02:19:52.782538 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.stg_vehicle"
[0m02:19:52.785044 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.stg_customer"
[0m02:19:52.785581 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.stg_ride"
[0m02:19:52.788713 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.stg_driver"
[0m02:19:52.801166 [debug] [Thread-1 (]: On model.hailing_project.stg_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer`.`stg_customer`
      
    
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_customer_source`
),

cleaned AS (
    SELECT
        customer_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned
    );
  
[0m02:19:52.802363 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m02:19:52.803163 [debug] [Thread-3 (]: On model.hailing_project.stg_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_ride"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer`.`stg_ride`
      
    
    

    OPTIONS()
    as (
      

SELECT *
FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_ride_source`
    );
  
[0m02:19:52.804698 [debug] [Thread-2 (]: On model.hailing_project.stg_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_driver"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer`.`stg_driver`
      
    
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_driver_source`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned
    );
  
[0m02:19:52.805201 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m02:19:52.807701 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m02:19:52.809056 [debug] [Thread-4 (]: On model.hailing_project.stg_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_vehicle"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer`.`stg_vehicle`
      
    
    

    OPTIONS()
    as (
      

SELECT *
FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_vehicle_source`
    );
  
[0m02:19:52.835926 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m02:19:53.069577 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:efbadefb-97fe-4c22-a6c8-b73c0fb171d7&page=queryresults
[0m02:19:53.070866 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:efbadefb-97fe-4c22-a6c8-b73c0fb171d7&page=queryresults
[0m02:19:53.076360 [debug] [Thread-1 (]: Database Error in model stg_customer (models/staging/stg_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_customer.sql
[0m02:19:53.079108 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '36b4bddf-c76d-46a3-ba6c-257ff399de47', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fce7f3e5450>]}
[0m02:19:53.080368 [error] [Thread-1 (]: 1 of 4 ERROR creating sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer.stg_customer  [[31mERROR[0m in 0.42s]
[0m02:19:53.081709 [debug] [Thread-1 (]: Finished running node model.hailing_project.stg_customer
[0m02:19:53.083138 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.stg_customer' to be skipped because of status 'error'.  Reason: Database Error in model stg_customer (models/staging/stg_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_customer.sql.
[0m02:19:53.160594 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:70c69ada-06e4-4a82-a967-4279d5e053f4&page=queryresults
[0m02:19:53.161707 [error] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:70c69ada-06e4-4a82-a967-4279d5e053f4&page=queryresults
[0m02:19:53.165304 [debug] [Thread-2 (]: Database Error in model stg_driver (models/staging/stg_driver.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_driver.sql
[0m02:19:53.166187 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '36b4bddf-c76d-46a3-ba6c-257ff399de47', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fce7f140950>]}
[0m02:19:53.167406 [error] [Thread-2 (]: 2 of 4 ERROR creating sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer.stg_driver  [[31mERROR[0m in 0.50s]
[0m02:19:53.168375 [debug] [Thread-2 (]: Finished running node model.hailing_project.stg_driver
[0m02:19:53.169604 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.stg_driver' to be skipped because of status 'error'.  Reason: Database Error in model stg_driver (models/staging/stg_driver.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_driver.sql.
[0m02:19:53.189273 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:dbf52f61-28b6-4b38-9bd0-87e904709498&page=queryresults
[0m02:19:53.190659 [error] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:dbf52f61-28b6-4b38-9bd0-87e904709498&page=queryresults
[0m02:19:53.194317 [debug] [Thread-4 (]: Database Error in model stg_vehicle (models/staging/stg_vehicle.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_vehicle.sql
[0m02:19:53.195547 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '36b4bddf-c76d-46a3-ba6c-257ff399de47', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fce7f132d90>]}
[0m02:19:53.196796 [error] [Thread-4 (]: 4 of 4 ERROR creating sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer.stg_vehicle  [[31mERROR[0m in 0.53s]
[0m02:19:53.198030 [debug] [Thread-4 (]: Finished running node model.hailing_project.stg_vehicle
[0m02:19:53.199262 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.stg_vehicle' to be skipped because of status 'error'.  Reason: Database Error in model stg_vehicle (models/staging/stg_vehicle.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_vehicle.sql.
[0m02:19:53.206344 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:9d6d5eab-a475-46fa-9d54-3c7d7e00878d&page=queryresults
[0m02:19:53.207441 [error] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:9d6d5eab-a475-46fa-9d54-3c7d7e00878d&page=queryresults
[0m02:19:53.210872 [debug] [Thread-3 (]: Database Error in model stg_ride (models/staging/stg_ride.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_ride.sql
[0m02:19:53.212108 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '36b4bddf-c76d-46a3-ba6c-257ff399de47', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fce7f3f4390>]}
[0m02:19:53.213401 [error] [Thread-3 (]: 3 of 4 ERROR creating sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer.stg_ride  [[31mERROR[0m in 0.55s]
[0m02:19:53.214467 [debug] [Thread-3 (]: Finished running node model.hailing_project.stg_ride
[0m02:19:53.215679 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.stg_ride' to be skipped because of status 'error'.  Reason: Database Error in model stg_ride (models/staging/stg_ride.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_ride.sql.
[0m02:19:53.217446 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m02:19:53.221052 [debug] [MainThread]: Connection 'master' was properly closed.
[0m02:19:53.221827 [debug] [MainThread]: Connection 'model.hailing_project.stg_customer' was properly closed.
[0m02:19:53.222608 [debug] [MainThread]: Connection 'model.hailing_project.stg_driver' was properly closed.
[0m02:19:53.223536 [debug] [MainThread]: Connection 'model.hailing_project.stg_ride' was properly closed.
[0m02:19:53.224323 [debug] [MainThread]: Connection 'model.hailing_project.stg_vehicle' was properly closed.
[0m02:19:53.225250 [info ] [MainThread]: 
[0m02:19:53.226377 [info ] [MainThread]: Finished running 4 incremental models in 0 hours 0 minutes and 3.63 seconds (3.63s).
[0m02:19:53.228128 [debug] [MainThread]: Command end result
[0m02:19:53.264122 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m02:19:53.269292 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m02:19:53.278390 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m02:19:53.279099 [info ] [MainThread]: 
[0m02:19:53.280452 [info ] [MainThread]: [31mCompleted with 4 errors, 0 partial successes, and 0 warnings:[0m
[0m02:19:53.281929 [info ] [MainThread]: 
[0m02:19:53.283440 [error] [MainThread]:   Database Error in model stg_customer (models/staging/stg_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_customer.sql
[0m02:19:53.284486 [info ] [MainThread]: 
[0m02:19:53.285700 [error] [MainThread]:   Database Error in model stg_driver (models/staging/stg_driver.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_driver.sql
[0m02:19:53.286808 [info ] [MainThread]: 
[0m02:19:53.288665 [error] [MainThread]:   Database Error in model stg_vehicle (models/staging/stg_vehicle.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_vehicle.sql
[0m02:19:53.290195 [info ] [MainThread]: 
[0m02:19:53.292798 [error] [MainThread]:   Database Error in model stg_ride (models/staging/stg_ride.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_ride.sql
[0m02:19:53.296067 [info ] [MainThread]: 
[0m02:19:53.298499 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=4 SKIP=0 TOTAL=4
[0m02:19:53.301766 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 5.559815, "process_in_blocks": "0", "process_kernel_time": 0.159599, "process_mem_max_rss": "227496", "process_out_blocks": "0", "process_user_time": 4.199452}
[0m02:19:53.304129 [debug] [MainThread]: Command `dbt run` failed at 02:19:53.303881 after 5.56 seconds
[0m02:19:53.309675 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fced3e028d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fced5b8aed0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fced3a3f190>]}
[0m02:19:53.312580 [debug] [MainThread]: Flushing usage events
[0m02:19:54.432570 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:22:59.298886 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc582de2450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc582de3d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc582de2c90>]}


============================== 02:22:59.301439 | 598de295-1704-4dee-b3ae-d4343be14bee ==============================
[0m02:22:59.301439 [info ] [MainThread]: Running with dbt=1.9.0
[0m02:22:59.304163 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt run', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m02:22:59.897242 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '598de295-1704-4dee-b3ae-d4343be14bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc559f64b50>]}
[0m02:22:59.941040 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '598de295-1704-4dee-b3ae-d4343be14bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc58505a210>]}
[0m02:22:59.942289 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m02:23:00.011330 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m02:23:00.078598 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m02:23:00.079893 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '598de295-1704-4dee-b3ae-d4343be14bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc583be4390>]}
[0m02:23:01.075126 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '598de295-1704-4dee-b3ae-d4343be14bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc558fa2d10>]}
[0m02:23:01.141482 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m02:23:01.148081 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m02:23:01.161756 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '598de295-1704-4dee-b3ae-d4343be14bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc543122a50>]}
[0m02:23:01.162979 [info ] [MainThread]: Found 4 models, 4 sources, 487 macros
[0m02:23:01.164993 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '598de295-1704-4dee-b3ae-d4343be14bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc558dea390>]}
[0m02:23:01.168040 [info ] [MainThread]: 
[0m02:23:01.169154 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m02:23:01.170684 [info ] [MainThread]: 
[0m02:23:01.172194 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m02:23:01.176700 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m02:23:01.177769 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:23:02.337608 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer)
[0m02:23:02.338814 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:23:02.888646 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '598de295-1704-4dee-b3ae-d4343be14bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc558e3d850>]}
[0m02:23:02.893292 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:23:02.898715 [debug] [Thread-1 (]: Began running node model.hailing_project.stg_customer
[0m02:23:02.899162 [debug] [Thread-2 (]: Began running node model.hailing_project.stg_driver
[0m02:23:02.899561 [debug] [Thread-3 (]: Began running node model.hailing_project.stg_ride
[0m02:23:02.899911 [debug] [Thread-4 (]: Began running node model.hailing_project.stg_vehicle
[0m02:23:02.900627 [info ] [Thread-1 (]: 1 of 4 START sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer.stg_customer  [RUN]
[0m02:23:02.902948 [info ] [Thread-2 (]: 2 of 4 START sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer.stg_driver  [RUN]
[0m02:23:02.905319 [info ] [Thread-3 (]: 3 of 4 START sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer.stg_ride  [RUN]
[0m02:23:02.907001 [info ] [Thread-4 (]: 4 of 4 START sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer.stg_vehicle  [RUN]
[0m02:23:02.908807 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer, now model.hailing_project.stg_customer)
[0m02:23:02.910166 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.stg_driver'
[0m02:23:02.911458 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.stg_ride'
[0m02:23:02.912759 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.stg_vehicle'
[0m02:23:02.914024 [debug] [Thread-1 (]: Began compiling node model.hailing_project.stg_customer
[0m02:23:02.914986 [debug] [Thread-2 (]: Began compiling node model.hailing_project.stg_driver
[0m02:23:02.915994 [debug] [Thread-3 (]: Began compiling node model.hailing_project.stg_ride
[0m02:23:02.916878 [debug] [Thread-4 (]: Began compiling node model.hailing_project.stg_vehicle
[0m02:23:02.926278 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.stg_customer"
[0m02:23:02.929758 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.stg_driver"
[0m02:23:02.933442 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.stg_ride"
[0m02:23:02.937378 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.stg_vehicle"
[0m02:23:02.943149 [debug] [Thread-3 (]: Began executing node model.hailing_project.stg_ride
[0m02:23:02.944703 [debug] [Thread-2 (]: Began executing node model.hailing_project.stg_driver
[0m02:23:02.951044 [debug] [Thread-4 (]: Began executing node model.hailing_project.stg_vehicle
[0m02:23:02.951686 [debug] [Thread-1 (]: Began executing node model.hailing_project.stg_customer
[0m02:23:03.023351 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.stg_driver"
[0m02:23:03.026136 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.stg_vehicle"
[0m02:23:03.026779 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.stg_ride"
[0m02:23:03.029786 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.stg_customer"
[0m02:23:03.038455 [debug] [Thread-4 (]: On model.hailing_project.stg_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_vehicle"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer`.`stg_vehicle`
      
    
    

    OPTIONS()
    as (
      

SELECT *
FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_vehicle_source`
    );
  
[0m02:23:03.039788 [debug] [Thread-1 (]: On model.hailing_project.stg_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer`.`stg_customer`
      
    
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_customer_source`
),

cleaned AS (
    SELECT
        customer_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned
    );
  
[0m02:23:03.040237 [debug] [Thread-2 (]: On model.hailing_project.stg_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_driver"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer`.`stg_driver`
      
    
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_driver_source`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned
    );
  
[0m02:23:03.041026 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m02:23:03.041683 [debug] [Thread-3 (]: On model.hailing_project.stg_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_ride"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer`.`stg_ride`
      
    
    

    OPTIONS()
    as (
      

SELECT *
FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_ride_source`
    );
  
[0m02:23:03.042414 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m02:23:03.043246 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m02:23:03.044854 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m02:23:03.359713 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:79e5f65c-7115-4456-8243-3c91fd64924f&page=queryresults
[0m02:23:03.361730 [error] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:79e5f65c-7115-4456-8243-3c91fd64924f&page=queryresults
[0m02:23:03.362561 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:86310e65-be7e-4ea7-b55f-428455560bc9&page=queryresults
[0m02:23:03.365437 [error] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:86310e65-be7e-4ea7-b55f-428455560bc9&page=queryresults
[0m02:23:03.369647 [debug] [Thread-4 (]: Database Error in model stg_vehicle (models/staging/stg_vehicle.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_vehicle.sql
[0m02:23:03.370817 [debug] [Thread-2 (]: Database Error in model stg_driver (models/staging/stg_driver.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_driver.sql
[0m02:23:03.372341 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '598de295-1704-4dee-b3ae-d4343be14bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc507709590>]}
[0m02:23:03.373028 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '598de295-1704-4dee-b3ae-d4343be14bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc5431e9b10>]}
[0m02:23:03.374161 [error] [Thread-4 (]: 4 of 4 ERROR creating sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer.stg_vehicle  [[31mERROR[0m in 0.46s]
[0m02:23:03.375896 [error] [Thread-2 (]: 2 of 4 ERROR creating sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer.stg_driver  [[31mERROR[0m in 0.46s]
[0m02:23:03.377233 [debug] [Thread-4 (]: Finished running node model.hailing_project.stg_vehicle
[0m02:23:03.378654 [debug] [Thread-2 (]: Finished running node model.hailing_project.stg_driver
[0m02:23:03.380169 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.stg_vehicle' to be skipped because of status 'error'.  Reason: Database Error in model stg_vehicle (models/staging/stg_vehicle.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_vehicle.sql.
[0m02:23:03.381903 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.stg_driver' to be skipped because of status 'error'.  Reason: Database Error in model stg_driver (models/staging/stg_driver.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_driver.sql.
[0m02:23:03.413141 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:a793c2ef-2f5d-41b2-a0a1-9a8012d35841&page=queryresults
[0m02:23:03.414247 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:a793c2ef-2f5d-41b2-a0a1-9a8012d35841&page=queryresults
[0m02:23:03.417566 [debug] [Thread-1 (]: Database Error in model stg_customer (models/staging/stg_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_customer.sql
[0m02:23:03.418427 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '598de295-1704-4dee-b3ae-d4343be14bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc507728cd0>]}
[0m02:23:03.419705 [error] [Thread-1 (]: 1 of 4 ERROR creating sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer.stg_customer  [[31mERROR[0m in 0.51s]
[0m02:23:03.420942 [debug] [Thread-1 (]: Finished running node model.hailing_project.stg_customer
[0m02:23:03.422227 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.stg_customer' to be skipped because of status 'error'.  Reason: Database Error in model stg_customer (models/staging/stg_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_customer.sql.
[0m02:23:03.431591 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:4f7e0877-0170-42bf-8f06-39971f85f0b7&page=queryresults
[0m02:23:03.433212 [error] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:4f7e0877-0170-42bf-8f06-39971f85f0b7&page=queryresults
[0m02:23:03.436933 [debug] [Thread-3 (]: Database Error in model stg_ride (models/staging/stg_ride.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_ride.sql
[0m02:23:03.438133 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '598de295-1704-4dee-b3ae-d4343be14bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc5432431d0>]}
[0m02:23:03.439279 [error] [Thread-3 (]: 3 of 4 ERROR creating sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer.stg_ride  [[31mERROR[0m in 0.53s]
[0m02:23:03.440640 [debug] [Thread-3 (]: Finished running node model.hailing_project.stg_ride
[0m02:23:03.442280 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.stg_ride' to be skipped because of status 'error'.  Reason: Database Error in model stg_ride (models/staging/stg_ride.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_ride.sql.
[0m02:23:03.444426 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m02:23:03.447601 [debug] [MainThread]: Connection 'master' was properly closed.
[0m02:23:03.448553 [debug] [MainThread]: Connection 'model.hailing_project.stg_customer' was properly closed.
[0m02:23:03.449372 [debug] [MainThread]: Connection 'model.hailing_project.stg_driver' was properly closed.
[0m02:23:03.450095 [debug] [MainThread]: Connection 'model.hailing_project.stg_ride' was properly closed.
[0m02:23:03.450805 [debug] [MainThread]: Connection 'model.hailing_project.stg_vehicle' was properly closed.
[0m02:23:03.451757 [info ] [MainThread]: 
[0m02:23:03.452678 [info ] [MainThread]: Finished running 4 incremental models in 0 hours 0 minutes and 2.28 seconds (2.28s).
[0m02:23:03.454381 [debug] [MainThread]: Command end result
[0m02:23:03.485186 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m02:23:03.490386 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m02:23:03.497818 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m02:23:03.498665 [info ] [MainThread]: 
[0m02:23:03.499917 [info ] [MainThread]: [31mCompleted with 4 errors, 0 partial successes, and 0 warnings:[0m
[0m02:23:03.500952 [info ] [MainThread]: 
[0m02:23:03.502062 [error] [MainThread]:   Database Error in model stg_vehicle (models/staging/stg_vehicle.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_vehicle.sql
[0m02:23:03.503073 [info ] [MainThread]: 
[0m02:23:03.504059 [error] [MainThread]:   Database Error in model stg_driver (models/staging/stg_driver.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_driver.sql
[0m02:23:03.505185 [info ] [MainThread]: 
[0m02:23:03.506282 [error] [MainThread]:   Database Error in model stg_customer (models/staging/stg_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_customer.sql
[0m02:23:03.507134 [info ] [MainThread]: 
[0m02:23:03.508120 [error] [MainThread]:   Database Error in model stg_ride (models/staging/stg_ride.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_ride.sql
[0m02:23:03.509039 [info ] [MainThread]: 
[0m02:23:03.510102 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=4 SKIP=0 TOTAL=4
[0m02:23:03.511788 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 4.2606525, "process_in_blocks": "0", "process_kernel_time": 0.212551, "process_mem_max_rss": "224192", "process_out_blocks": "0", "process_user_time": 4.078972}
[0m02:23:03.512753 [debug] [MainThread]: Command `dbt run` failed at 02:23:03.512647 after 4.26 seconds
[0m02:23:03.513724 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc582e5d5d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc582e5f9d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc58675d150>]}
[0m02:23:03.514650 [debug] [MainThread]: Flushing usage events
[0m02:23:05.016646 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:27:10.061335 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe7bafa2b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe7bb4503d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe7baff71d0>]}


============================== 02:27:10.063905 | 31c668d0-44a8-423d-9cba-07485a1d97cc ==============================
[0m02:27:10.063905 [info ] [MainThread]: Running with dbt=1.9.0
[0m02:27:10.065631 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'profiles_dir': '/usr/app/dbt_project', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt clean', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m02:27:10.142962 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '31c668d0-44a8-423d-9cba-07485a1d97cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe7bae36950>]}
[0m02:27:10.196558 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.18368678, "process_in_blocks": "0", "process_kernel_time": 0.081932, "process_mem_max_rss": "90140", "process_out_blocks": "0", "process_user_time": 0.92174}
[0m02:27:10.197709 [debug] [MainThread]: Command `dbt clean` succeeded at 02:27:10.197592 after 0.19 seconds
[0m02:27:10.198861 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe7bb39a3d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe7be8f1350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe7bafa1850>]}
[0m02:27:10.199813 [debug] [MainThread]: Flushing usage events
[0m02:27:11.381765 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:27:12.492552 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f72fb382950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f72fb3c0790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f72fb77de10>]}


============================== 02:27:12.495880 | 105f7905-72f4-4f26-b25a-0023adc54469 ==============================
[0m02:27:12.495880 [info ] [MainThread]: Running with dbt=1.9.0
[0m02:27:12.497159 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'invocation_command': 'dbt deps', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m02:27:12.581002 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '105f7905-72f4-4f26-b25a-0023adc54469', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f72fb3d5950>]}
[0m02:27:12.591820 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m02:27:12.594827 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m02:27:12.596546 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.15206721, "process_in_blocks": "0", "process_kernel_time": 0.079586, "process_mem_max_rss": "90212", "process_out_blocks": "0", "process_user_time": 0.974936}
[0m02:27:12.597503 [debug] [MainThread]: Command `dbt deps` succeeded at 02:27:12.597373 after 0.15 seconds
[0m02:27:12.598341 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f72fb77e250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f72fec6ca90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f72fecfd5d0>]}
[0m02:27:12.599115 [debug] [MainThread]: Flushing usage events
[0m02:27:13.667226 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:27:18.126541 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff9375bbed0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff9379b2610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff9379b24d0>]}


============================== 02:27:18.129205 | ed0e3112-f793-4b76-89d4-df3e53df2e2c ==============================
[0m02:27:18.129205 [info ] [MainThread]: Running with dbt=1.9.0
[0m02:27:18.130468 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m02:27:18.714561 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ed0e3112-f793-4b76-89d4-df3e53df2e2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff9097b8450>]}
[0m02:27:18.757460 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ed0e3112-f793-4b76-89d4-df3e53df2e2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff939868890>]}
[0m02:27:18.758844 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m02:27:18.827246 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m02:27:18.829601 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m02:27:18.830408 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'ed0e3112-f793-4b76-89d4-df3e53df2e2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff937615d10>]}
[0m02:27:19.666752 [error] [MainThread]: Encountered an error:
Compilation Error in model stg_customer (models/staging/stg_customer.sql)
  invalid syntax for function call expression
    line 1
      {{ config(
[0m02:27:19.668956 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.5943345, "process_in_blocks": "16", "process_kernel_time": 0.234997, "process_mem_max_rss": "211636", "process_out_blocks": "0", "process_user_time": 3.412571}
[0m02:27:19.670237 [debug] [MainThread]: Command `dbt run` failed at 02:27:19.670097 after 1.60 seconds
[0m02:27:19.671146 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff9375ea510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff937a70410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff90967fe50>]}
[0m02:27:19.672119 [debug] [MainThread]: Flushing usage events
[0m02:27:20.698749 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:29:19.756932 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb876e4fd10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb876e02a50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb876e022d0>]}


============================== 02:29:19.759598 | cfa47e46-00f7-47de-9070-f6658cefd0e9 ==============================
[0m02:29:19.759598 [info ] [MainThread]: Running with dbt=1.9.0
[0m02:29:19.763323 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'version_check': 'True', 'warn_error': 'None', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt clean', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m02:29:19.842269 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'cfa47e46-00f7-47de-9070-f6658cefd0e9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb876cc7150>]}
[0m02:29:19.857803 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.14823915, "process_in_blocks": "0", "process_kernel_time": 0.118135, "process_mem_max_rss": "90124", "process_out_blocks": "0", "process_user_time": 0.905702}
[0m02:29:19.858795 [debug] [MainThread]: Command `dbt clean` succeeded at 02:29:19.858683 after 0.15 seconds
[0m02:29:19.859609 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb876e4f7d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb876e4f8d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb876f11b10>]}
[0m02:29:19.860396 [debug] [MainThread]: Flushing usage events
[0m02:29:21.008618 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:29:36.098313 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8dfb763a50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8dfb7a7090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8dfb762b10>]}


============================== 02:29:36.100834 | ae7e7a25-d2f8-4c6c-97f2-7663699b82f7 ==============================
[0m02:29:36.100834 [info ] [MainThread]: Running with dbt=1.9.0
[0m02:29:36.102185 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'invocation_command': 'dbt deps', 'send_anonymous_usage_stats': 'True'}
[0m02:29:36.182096 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ae7e7a25-d2f8-4c6c-97f2-7663699b82f7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8dfb7dbdd0>]}
[0m02:29:36.192091 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m02:29:36.195892 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m02:29:36.197299 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.1474884, "process_in_blocks": "0", "process_kernel_time": 0.089347, "process_mem_max_rss": "89884", "process_out_blocks": "0", "process_user_time": 0.93318}
[0m02:29:36.198655 [debug] [MainThread]: Command `dbt deps` succeeded at 02:29:36.198507 after 0.15 seconds
[0m02:29:36.199593 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8dfef5cb90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8dff0e1390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8dff0e1110>]}
[0m02:29:36.200359 [debug] [MainThread]: Flushing usage events
[0m02:29:37.248158 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:29:42.747893 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff17872e790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff1793e7910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff178afe550>]}


============================== 02:29:42.750836 | f2242523-1c80-44d8-8022-7848c9aa47cc ==============================
[0m02:29:42.750836 [info ] [MainThread]: Running with dbt=1.9.0
[0m02:29:42.752017 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt compile', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m02:29:43.366137 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f2242523-1c80-44d8-8022-7848c9aa47cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff14a90e2d0>]}
[0m02:29:43.412740 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f2242523-1c80-44d8-8022-7848c9aa47cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff14a950f10>]}
[0m02:29:43.413928 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m02:29:43.485356 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m02:29:43.487673 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m02:29:43.488700 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'f2242523-1c80-44d8-8022-7848c9aa47cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff17858c590>]}
[0m02:29:44.327713 [error] [MainThread]: Encountered an error:
Compilation Error in model stg_customer (models/staging/stg_customer.sql)
  invalid syntax for function call expression
    line 1
      {{ config(
[0m02:29:44.329316 [debug] [MainThread]: Resource report: {"command_name": "compile", "command_success": false, "command_wall_clock_time": 1.6324943, "process_in_blocks": "0", "process_kernel_time": 0.18059, "process_mem_max_rss": "212028", "process_out_blocks": "0", "process_user_time": 3.551614}
[0m02:29:44.330421 [debug] [MainThread]: Command `dbt compile` failed at 02:29:44.330251 after 1.63 seconds
[0m02:29:44.331210 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff17857be10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff17857bb90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff17c07d0d0>]}
[0m02:29:44.332149 [debug] [MainThread]: Flushing usage events
[0m02:29:45.589524 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:29:53.502418 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f183ca52fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f183ca85a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f183ca86f50>]}


============================== 02:29:53.505798 | 41cb02dc-0cc4-4c1b-965c-9dc620114dec ==============================
[0m02:29:53.505798 [info ] [MainThread]: Running with dbt=1.9.0
[0m02:29:53.507274 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt run', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m02:29:54.116437 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '41cb02dc-0cc4-4c1b-965c-9dc620114dec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f183ca53490>]}
[0m02:29:54.168556 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '41cb02dc-0cc4-4c1b-965c-9dc620114dec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f183ed06250>]}
[0m02:29:54.169894 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m02:29:54.238174 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m02:29:54.240432 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m02:29:54.241225 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '41cb02dc-0cc4-4c1b-965c-9dc620114dec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f180ebe17d0>]}
[0m02:29:55.066343 [error] [MainThread]: Encountered an error:
Compilation Error in model stg_customer (models/staging/stg_customer.sql)
  invalid syntax for function call expression
    line 1
      {{ config(
[0m02:29:55.068222 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.617304, "process_in_blocks": "0", "process_kernel_time": 0.131437, "process_mem_max_rss": "211732", "process_out_blocks": "0", "process_user_time": 3.548801}
[0m02:29:55.069459 [debug] [MainThread]: Command `dbt run` failed at 02:29:55.069352 after 1.62 seconds
[0m02:29:55.070305 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f183ca98910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f180eaa7810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1840409210>]}
[0m02:29:55.071221 [debug] [MainThread]: Flushing usage events
[0m02:29:56.099082 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:30:20.664628 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f46baa52b10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f46b9343350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f46b8a49f10>]}


============================== 02:30:20.667132 | 4630e5b5-e768-46ab-8517-fec3768dbd26 ==============================
[0m02:30:20.667132 [info ] [MainThread]: Running with dbt=1.9.0
[0m02:30:20.668783 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt run', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m02:30:21.213151 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '4630e5b5-e768-46ab-8517-fec3768dbd26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f468a7f5fd0>]}
[0m02:30:21.262779 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '4630e5b5-e768-46ab-8517-fec3768dbd26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f46ba8c6250>]}
[0m02:30:21.263928 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m02:30:21.327974 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m02:30:21.330285 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m02:30:21.332570 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '4630e5b5-e768-46ab-8517-fec3768dbd26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f468a997c50>]}
[0m02:30:22.115540 [error] [MainThread]: Encountered an error:
Compilation Error in model stg_customer (models/staging/stg_customer.sql)
  invalid syntax for function call expression
    line 1
      {{ config(
[0m02:30:22.117385 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.5054442, "process_in_blocks": "0", "process_kernel_time": 0.180737, "process_mem_max_rss": "213952", "process_out_blocks": "0", "process_user_time": 3.383815}
[0m02:30:22.118554 [debug] [MainThread]: Command `dbt run` failed at 02:30:22.118408 after 1.51 seconds
[0m02:30:22.119529 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f46b86cb810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f46b86cb750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f468a6a8d90>]}
[0m02:30:22.120437 [debug] [MainThread]: Flushing usage events
[0m02:30:23.406765 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:48:46.577975 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e03cbec10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e04afbc90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e040be110>]}


============================== 03:48:46.581100 | 4b6e4011-c2d3-4c10-ba46-fe102571ed89 ==============================
[0m03:48:46.581100 [info ] [MainThread]: Running with dbt=1.9.0
[0m03:48:46.583063 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'warn_error': 'None', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt clean', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m03:48:46.673982 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '4b6e4011-c2d3-4c10-ba46-fe102571ed89', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e03d16210>]}
[0m03:48:46.691460 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.17322543, "process_in_blocks": "0", "process_kernel_time": 0.071361, "process_mem_max_rss": "90076", "process_out_blocks": "0", "process_user_time": 0.937895}
[0m03:48:46.692203 [debug] [MainThread]: Command `dbt clean` succeeded at 03:48:46.692116 after 0.17 seconds
[0m03:48:46.692904 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e03d15010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e03d14210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e074b8b90>]}
[0m03:48:46.693683 [debug] [MainThread]: Flushing usage events
[0m03:48:47.999145 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:48:49.140859 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5b8f516cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5b8f4c3250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5b8f4c2650>]}


============================== 03:48:49.143352 | 1f903d85-65ef-48f7-8c9a-aed9097531ac ==============================
[0m03:48:49.143352 [info ] [MainThread]: Running with dbt=1.9.0
[0m03:48:49.144652 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt deps', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m03:48:49.228319 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1f903d85-65ef-48f7-8c9a-aed9097531ac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5b8f402090>]}
[0m03:48:49.239323 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m03:48:49.241814 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m03:48:49.243604 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.1564101, "process_in_blocks": "0", "process_kernel_time": 0.120278, "process_mem_max_rss": "90156", "process_out_blocks": "0", "process_user_time": 0.962226}
[0m03:48:49.244668 [debug] [MainThread]: Command `dbt deps` succeeded at 03:48:49.244540 after 0.16 seconds
[0m03:48:49.245366 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5b8f516cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5b8f8be8d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5b92cb8c10>]}
[0m03:48:49.246184 [debug] [MainThread]: Flushing usage events
[0m03:48:50.258690 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:48:52.041857 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb74036e10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb74036a50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb74087950>]}


============================== 03:48:52.044630 | d45ae16e-a5ef-414b-92c4-b8dabf098e93 ==============================
[0m03:48:52.044630 [info ] [MainThread]: Running with dbt=1.9.0
[0m03:48:52.045738 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt run', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m03:48:52.628930 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd45ae16e-a5ef-414b-92c4-b8dabf098e93', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb463df5d0>]}
[0m03:48:52.674213 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd45ae16e-a5ef-414b-92c4-b8dabf098e93', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb46297490>]}
[0m03:48:52.675430 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m03:48:52.750946 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m03:48:52.753801 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m03:48:52.754901 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'd45ae16e-a5ef-414b-92c4-b8dabf098e93', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb4cc71590>]}
[0m03:48:53.740104 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.example
- models.dbt_project
[0m03:48:53.751432 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd45ae16e-a5ef-414b-92c4-b8dabf098e93', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb460d4f10>]}
[0m03:48:53.818544 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m03:48:53.824729 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m03:48:53.841886 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd45ae16e-a5ef-414b-92c4-b8dabf098e93', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb44626610>]}
[0m03:48:53.843072 [info ] [MainThread]: Found 4 models, 4 sources, 487 macros
[0m03:48:53.844252 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd45ae16e-a5ef-414b-92c4-b8dabf098e93', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb46382550>]}
[0m03:48:53.847146 [info ] [MainThread]: 
[0m03:48:53.848265 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m03:48:53.849418 [info ] [MainThread]: 
[0m03:48:53.851660 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m03:48:53.856931 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m03:48:53.858131 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m03:48:54.461050 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m03:48:54.462308 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m03:48:54.658101 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd45ae16e-a5ef-414b-92c4-b8dabf098e93', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb45f3ad10>]}
[0m03:48:54.659578 [debug] [MainThread]: Opening a new connection, currently in state init
[0m03:48:54.664912 [debug] [Thread-1 (]: Began running node model.hailing_project.stg_customer
[0m03:48:54.665303 [debug] [Thread-2 (]: Began running node model.hailing_project.stg_driver
[0m03:48:54.665665 [debug] [Thread-3 (]: Began running node model.hailing_project.stg_ride
[0m03:48:54.666059 [debug] [Thread-4 (]: Began running node model.hailing_project.stg_vehicle
[0m03:48:54.666709 [info ] [Thread-1 (]: 1 of 4 START sql incremental model rizky_dwh_hailing_source.stg_customer ....... [RUN]
[0m03:48:54.667970 [info ] [Thread-2 (]: 2 of 4 START sql incremental model rizky_dwh_hailing_source.stg_driver ......... [RUN]
[0m03:48:54.669068 [info ] [Thread-3 (]: 3 of 4 START sql incremental model rizky_dwh_hailing_source.stg_ride ........... [RUN]
[0m03:48:54.670214 [info ] [Thread-4 (]: 4 of 4 START sql incremental model rizky_dwh_hailing_source.stg_vehicle ........ [RUN]
[0m03:48:54.671678 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.stg_customer)
[0m03:48:54.676645 [debug] [Thread-1 (]: Began compiling node model.hailing_project.stg_customer
[0m03:48:54.674594 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.stg_ride'
[0m03:48:54.675816 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.stg_vehicle'
[0m03:48:54.673185 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.stg_driver'
[0m03:48:54.685826 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.stg_customer"
[0m03:48:54.686787 [debug] [Thread-3 (]: Began compiling node model.hailing_project.stg_ride
[0m03:48:54.688038 [debug] [Thread-4 (]: Began compiling node model.hailing_project.stg_vehicle
[0m03:48:54.689235 [debug] [Thread-2 (]: Began compiling node model.hailing_project.stg_driver
[0m03:48:54.694104 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.stg_ride"
[0m03:48:54.697849 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.stg_vehicle"
[0m03:48:54.702073 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.stg_driver"
[0m03:48:54.714652 [debug] [Thread-1 (]: Began executing node model.hailing_project.stg_customer
[0m03:48:54.721008 [debug] [Thread-4 (]: Began executing node model.hailing_project.stg_vehicle
[0m03:48:54.742940 [debug] [Thread-3 (]: Began executing node model.hailing_project.stg_ride
[0m03:48:54.769683 [debug] [Thread-2 (]: Began executing node model.hailing_project.stg_driver
[0m03:48:54.832074 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.stg_vehicle"
[0m03:48:54.832728 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.stg_customer"
[0m03:48:54.833474 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.stg_ride"
[0m03:48:54.836786 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.stg_driver"
[0m03:48:54.847600 [debug] [Thread-4 (]: On model.hailing_project.stg_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_vehicle"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`stg_vehicle`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_vehicle_source`
),
SELECT *
FROM source
    );
  
[0m03:48:54.848840 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m03:48:54.849350 [debug] [Thread-1 (]: On model.hailing_project.stg_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`stg_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_customer_source`
),

cleaned AS (
    SELECT
        customer_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned
    );
  
[0m03:48:54.850869 [debug] [Thread-3 (]: On model.hailing_project.stg_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_ride"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`stg_ride`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_ride_source`
),

SELECT *
FROM source
    );
  
[0m03:48:54.851760 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m03:48:54.852316 [debug] [Thread-2 (]: On model.hailing_project.stg_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_driver"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`stg_driver`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_driver_source`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned
    );
  
[0m03:48:54.854713 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m03:48:54.880104 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m03:48:55.333011 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:867609ef-42fc-4e69-bce0-062e7c18a7a4&page=queryresults
[0m03:48:55.334001 [error] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:867609ef-42fc-4e69-bce0-062e7c18a7a4&page=queryresults
[0m03:48:55.340453 [debug] [Thread-4 (]: Database Error in model stg_vehicle (models/staging/stg_vehicle.sql)
  Syntax error: Trailing comma after the WITH clause before the main query is not allowed at [19:1]
  compiled code at target/run/hailing_project/models/staging/stg_vehicle.sql
[0m03:48:55.342403 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd45ae16e-a5ef-414b-92c4-b8dabf098e93', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb444266d0>]}
[0m03:48:55.343664 [error] [Thread-4 (]: 4 of 4 ERROR creating sql incremental model rizky_dwh_hailing_source.stg_vehicle  [[31mERROR[0m in 0.67s]
[0m03:48:55.345422 [debug] [Thread-4 (]: Finished running node model.hailing_project.stg_vehicle
[0m03:48:55.346745 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.stg_vehicle' to be skipped because of status 'error'.  Reason: Database Error in model stg_vehicle (models/staging/stg_vehicle.sql)
  Syntax error: Trailing comma after the WITH clause before the main query is not allowed at [19:1]
  compiled code at target/run/hailing_project/models/staging/stg_vehicle.sql.
[0m03:48:55.383661 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:ca4ee090-40bb-4a20-bdb7-770e5b76ea45&page=queryresults
[0m03:48:55.384765 [error] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:ca4ee090-40bb-4a20-bdb7-770e5b76ea45&page=queryresults
[0m03:48:55.388337 [debug] [Thread-3 (]: Database Error in model stg_ride (models/staging/stg_ride.sql)
  Syntax error: Trailing comma after the WITH clause before the main query is not allowed at [20:1]
  compiled code at target/run/hailing_project/models/staging/stg_ride.sql
[0m03:48:55.389174 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd45ae16e-a5ef-414b-92c4-b8dabf098e93', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb446b5f50>]}
[0m03:48:55.390177 [error] [Thread-3 (]: 3 of 4 ERROR creating sql incremental model rizky_dwh_hailing_source.stg_ride .. [[31mERROR[0m in 0.71s]
[0m03:48:55.391380 [debug] [Thread-3 (]: Finished running node model.hailing_project.stg_ride
[0m03:48:55.392421 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.stg_ride' to be skipped because of status 'error'.  Reason: Database Error in model stg_ride (models/staging/stg_ride.sql)
  Syntax error: Trailing comma after the WITH clause before the main query is not allowed at [20:1]
  compiled code at target/run/hailing_project/models/staging/stg_ride.sql.
[0m03:48:56.472613 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:26f5a9d0-22b5-4fc2-b25e-72b5439fe2c8&page=queryresults
[0m03:48:56.710713 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:c86efc61-8407-4610-87cc-2fd6b7c7c6f7&page=queryresults
[0m03:48:56.802393 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:c86efc61-8407-4610-87cc-2fd6b7c7c6f7&page=queryresults
[0m03:48:56.806713 [debug] [Thread-1 (]: Database Error in model stg_customer (models/staging/stg_customer.sql)
  Unrecognized name: customer_id; Did you mean cust_id? at [22:9]
  compiled code at target/run/hailing_project/models/staging/stg_customer.sql
[0m03:48:56.807969 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd45ae16e-a5ef-414b-92c4-b8dabf098e93', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb44417d50>]}
[0m03:48:56.809454 [error] [Thread-1 (]: 1 of 4 ERROR creating sql incremental model rizky_dwh_hailing_source.stg_customer  [[31mERROR[0m in 2.14s]
[0m03:48:56.811066 [debug] [Thread-1 (]: Finished running node model.hailing_project.stg_customer
[0m03:48:56.812800 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.stg_customer' to be skipped because of status 'error'.  Reason: Database Error in model stg_customer (models/staging/stg_customer.sql)
  Unrecognized name: customer_id; Did you mean cust_id? at [22:9]
  compiled code at target/run/hailing_project/models/staging/stg_customer.sql.
[0m03:48:58.223982 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd45ae16e-a5ef-414b-92c4-b8dabf098e93', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb4441b490>]}
[0m03:48:58.225257 [info ] [Thread-2 (]: 2 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_driver .... [[32mCREATE TABLE (70.0 rows, 4.8 KiB processed)[0m in 3.55s]
[0m03:48:58.226780 [debug] [Thread-2 (]: Finished running node model.hailing_project.stg_driver
[0m03:48:58.229292 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m03:48:58.232549 [debug] [MainThread]: Connection 'master' was properly closed.
[0m03:48:58.233494 [debug] [MainThread]: Connection 'model.hailing_project.stg_customer' was properly closed.
[0m03:48:58.234578 [debug] [MainThread]: Connection 'model.hailing_project.stg_driver' was properly closed.
[0m03:48:58.235380 [debug] [MainThread]: Connection 'model.hailing_project.stg_ride' was properly closed.
[0m03:48:58.237180 [debug] [MainThread]: Connection 'model.hailing_project.stg_vehicle' was properly closed.
[0m03:48:58.238281 [info ] [MainThread]: 
[0m03:48:58.239667 [info ] [MainThread]: Finished running 4 incremental models in 0 hours 0 minutes and 4.39 seconds (4.39s).
[0m03:48:58.241893 [debug] [MainThread]: Command end result
[0m03:48:58.276224 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m03:48:58.280265 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m03:48:58.288287 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m03:48:58.289101 [info ] [MainThread]: 
[0m03:48:58.290190 [info ] [MainThread]: [31mCompleted with 3 errors, 0 partial successes, and 0 warnings:[0m
[0m03:48:58.291264 [info ] [MainThread]: 
[0m03:48:58.292355 [error] [MainThread]:   Database Error in model stg_vehicle (models/staging/stg_vehicle.sql)
  Syntax error: Trailing comma after the WITH clause before the main query is not allowed at [19:1]
  compiled code at target/run/hailing_project/models/staging/stg_vehicle.sql
[0m03:48:58.293521 [info ] [MainThread]: 
[0m03:48:58.294788 [error] [MainThread]:   Database Error in model stg_ride (models/staging/stg_ride.sql)
  Syntax error: Trailing comma after the WITH clause before the main query is not allowed at [20:1]
  compiled code at target/run/hailing_project/models/staging/stg_ride.sql
[0m03:48:58.295737 [info ] [MainThread]: 
[0m03:48:58.297045 [error] [MainThread]:   Database Error in model stg_customer (models/staging/stg_customer.sql)
  Unrecognized name: customer_id; Did you mean cust_id? at [22:9]
  compiled code at target/run/hailing_project/models/staging/stg_customer.sql
[0m03:48:58.297984 [info ] [MainThread]: 
[0m03:48:58.299187 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=3 SKIP=0 TOTAL=4
[0m03:48:58.300716 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 6.308942, "process_in_blocks": "0", "process_kernel_time": 0.217576, "process_mem_max_rss": "227536", "process_out_blocks": "0", "process_user_time": 4.11417}
[0m03:48:58.302115 [debug] [MainThread]: Command `dbt run` failed at 03:48:58.301996 after 6.31 seconds
[0m03:48:58.302959 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb740b14d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb740b3910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb779ed210>]}
[0m03:48:58.303931 [debug] [MainThread]: Flushing usage events
[0m03:48:59.325197 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:50:41.729427 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f567077a450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f567077a990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f567077a610>]}


============================== 03:50:41.731891 | 529f87d7-6afb-4e1e-8bac-84c3ff408093 ==============================
[0m03:50:41.731891 [info ] [MainThread]: Running with dbt=1.9.0
[0m03:50:41.734506 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt clean', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m03:50:41.815197 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '529f87d7-6afb-4e1e-8bac-84c3ff408093', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5670c90a50>]}
[0m03:50:41.874857 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.19473526, "process_in_blocks": "0", "process_kernel_time": 0.06868, "process_mem_max_rss": "90052", "process_out_blocks": "0", "process_user_time": 0.93209}
[0m03:50:41.875697 [debug] [MainThread]: Command `dbt clean` succeeded at 03:50:41.875599 after 0.20 seconds
[0m03:50:41.876484 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f56707d1810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f56707cfa10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f56706c2a10>]}
[0m03:50:41.877255 [debug] [MainThread]: Flushing usage events
[0m03:50:42.997065 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:50:44.109329 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdcfb372e10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdcfb76a110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdcfb853750>]}


============================== 03:50:44.112663 | 850e8d11-8c97-4829-ae46-7eb0c2df9421 ==============================
[0m03:50:44.112663 [info ] [MainThread]: Running with dbt=1.9.0
[0m03:50:44.114330 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt clean', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m03:50:44.197698 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '850e8d11-8c97-4829-ae46-7eb0c2df9421', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdcfb209650>]}
[0m03:50:44.211517 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.15543059, "process_in_blocks": "0", "process_kernel_time": 0.068863, "process_mem_max_rss": "89856", "process_out_blocks": "0", "process_user_time": 0.98377}
[0m03:50:44.212608 [debug] [MainThread]: Command `dbt clean` succeeded at 03:50:44.212482 after 0.16 seconds
[0m03:50:44.213587 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdcfb3ce2d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdcfb3cc410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdcfeb3cc50>]}
[0m03:50:44.214622 [debug] [MainThread]: Flushing usage events
[0m03:50:45.280840 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:50:46.480062 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f377e7db010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f377ebd6110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f377e80c490>]}


============================== 03:50:46.482657 | de1a6b8e-6207-4037-a5a6-884431cd32f9 ==============================
[0m03:50:46.482657 [info ] [MainThread]: Running with dbt=1.9.0
[0m03:50:46.483781 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'version_check': 'True', 'warn_error': 'None', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'invocation_command': 'dbt deps', 'send_anonymous_usage_stats': 'True'}
[0m03:50:46.570851 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'de1a6b8e-6207-4037-a5a6-884431cd32f9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f377e82e290>]}
[0m03:50:46.582813 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m03:50:46.585585 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m03:50:46.587296 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.15657125, "process_in_blocks": "0", "process_kernel_time": 0.100615, "process_mem_max_rss": "90328", "process_out_blocks": "0", "process_user_time": 1.026273}
[0m03:50:46.589094 [debug] [MainThread]: Command `dbt deps` succeeded at 03:50:46.588626 after 0.16 seconds
[0m03:50:46.590465 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f377e84d590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f377e84f990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3781fd0b90>]}
[0m03:50:46.591425 [debug] [MainThread]: Flushing usage events
[0m03:50:47.650574 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:51:37.432385 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7decb4ac90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7ded033910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7decb97dd0>]}


============================== 03:51:37.434767 | b7190cd3-1d5e-4235-9367-57ccdda45d7e ==============================
[0m03:51:37.434767 [info ] [MainThread]: Running with dbt=1.9.0
[0m03:51:37.435957 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m03:51:38.032673 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b7190cd3-1d5e-4235-9367-57ccdda45d7e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7dbee72f10>]}
[0m03:51:38.104604 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b7190cd3-1d5e-4235-9367-57ccdda45d7e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7deedf8850>]}
[0m03:51:38.105818 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m03:51:38.179653 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m03:51:38.181631 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m03:51:38.183040 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'b7190cd3-1d5e-4235-9367-57ccdda45d7e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7dc5d7ca90>]}
[0m03:51:39.129366 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.example
- models.dbt_project
[0m03:51:39.140710 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b7190cd3-1d5e-4235-9367-57ccdda45d7e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7dbd124990>]}
[0m03:51:39.203809 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m03:51:39.209147 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m03:51:39.223960 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b7190cd3-1d5e-4235-9367-57ccdda45d7e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7dbd0c3910>]}
[0m03:51:39.225159 [info ] [MainThread]: Found 4 models, 4 sources, 487 macros
[0m03:51:39.226267 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b7190cd3-1d5e-4235-9367-57ccdda45d7e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7dbea7c550>]}
[0m03:51:39.229243 [info ] [MainThread]: 
[0m03:51:39.230500 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m03:51:39.231429 [info ] [MainThread]: 
[0m03:51:39.232873 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m03:51:39.237955 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m03:51:39.239048 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m03:51:39.782113 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m03:51:39.783168 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m03:51:40.017044 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b7190cd3-1d5e-4235-9367-57ccdda45d7e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7dbeae8e90>]}
[0m03:51:40.018928 [debug] [MainThread]: Opening a new connection, currently in state init
[0m03:51:40.024765 [debug] [Thread-1 (]: Began running node model.hailing_project.stg_customer
[0m03:51:40.025121 [debug] [Thread-2 (]: Began running node model.hailing_project.stg_driver
[0m03:51:40.025509 [debug] [Thread-3 (]: Began running node model.hailing_project.stg_ride
[0m03:51:40.025865 [debug] [Thread-4 (]: Began running node model.hailing_project.stg_vehicle
[0m03:51:40.026365 [info ] [Thread-1 (]: 1 of 4 START sql incremental model rizky_dwh_hailing_source.stg_customer ....... [RUN]
[0m03:51:40.027623 [info ] [Thread-2 (]: 2 of 4 START sql incremental model rizky_dwh_hailing_source.stg_driver ......... [RUN]
[0m03:51:40.028738 [info ] [Thread-3 (]: 3 of 4 START sql incremental model rizky_dwh_hailing_source.stg_ride ........... [RUN]
[0m03:51:40.029993 [info ] [Thread-4 (]: 4 of 4 START sql incremental model rizky_dwh_hailing_source.stg_vehicle ........ [RUN]
[0m03:51:40.031309 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.stg_customer)
[0m03:51:40.032596 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.stg_driver'
[0m03:51:40.034403 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.stg_ride'
[0m03:51:40.035875 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.stg_vehicle'
[0m03:51:40.037337 [debug] [Thread-1 (]: Began compiling node model.hailing_project.stg_customer
[0m03:51:40.038363 [debug] [Thread-2 (]: Began compiling node model.hailing_project.stg_driver
[0m03:51:40.039320 [debug] [Thread-3 (]: Began compiling node model.hailing_project.stg_ride
[0m03:51:40.040346 [debug] [Thread-4 (]: Began compiling node model.hailing_project.stg_vehicle
[0m03:51:40.047996 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.stg_customer"
[0m03:51:40.051314 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.stg_driver"
[0m03:51:40.055683 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.stg_ride"
[0m03:51:40.060410 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.stg_vehicle"
[0m03:51:40.070428 [debug] [Thread-4 (]: Began executing node model.hailing_project.stg_vehicle
[0m03:51:40.077158 [debug] [Thread-3 (]: Began executing node model.hailing_project.stg_ride
[0m03:51:40.103838 [debug] [Thread-2 (]: Began executing node model.hailing_project.stg_driver
[0m03:51:40.115046 [debug] [Thread-1 (]: Began executing node model.hailing_project.stg_customer
[0m03:51:40.152124 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.stg_vehicle"
[0m03:51:40.153432 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.stg_ride"
[0m03:51:40.156050 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m03:51:40.160344 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.stg_customer"
[0m03:51:40.196248 [debug] [Thread-4 (]: On model.hailing_project.stg_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_vehicle"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`stg_vehicle`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_vehicle_source`
),
SELECT *
FROM source
    );
  
[0m03:51:40.197601 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m03:51:40.198241 [debug] [Thread-1 (]: On model.hailing_project.stg_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`stg_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_customer_source`
)

WITH cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned
    );
  
[0m03:51:40.200194 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m03:51:40.200599 [debug] [Thread-3 (]: On model.hailing_project.stg_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_ride"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`stg_ride`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_ride_source`
)

SELECT *
FROM source
    );
  
[0m03:51:40.225450 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m03:51:40.420935 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.stg_driver"
[0m03:51:40.427200 [debug] [Thread-2 (]: On model.hailing_project.stg_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_driver_source`
)

WITH cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m03:51:40.690507 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:1f357af3-36f2-458e-8d19-0edfbf4cc3da&page=queryresults
[0m03:51:40.691849 [error] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:1f357af3-36f2-458e-8d19-0edfbf4cc3da&page=queryresults
[0m03:51:40.696871 [debug] [Thread-4 (]: Database Error in model stg_vehicle (models/staging/stg_vehicle.sql)
  Syntax error: Trailing comma after the WITH clause before the main query is not allowed at [19:1]
  compiled code at target/run/hailing_project/models/staging/stg_vehicle.sql
[0m03:51:40.699082 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b7190cd3-1d5e-4235-9367-57ccdda45d7e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7dbc750090>]}
[0m03:51:40.700058 [error] [Thread-4 (]: 4 of 4 ERROR creating sql incremental model rizky_dwh_hailing_source.stg_vehicle  [[31mERROR[0m in 0.66s]
[0m03:51:40.701238 [debug] [Thread-4 (]: Finished running node model.hailing_project.stg_vehicle
[0m03:51:40.702358 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.stg_vehicle' to be skipped because of status 'error'.  Reason: Database Error in model stg_vehicle (models/staging/stg_vehicle.sql)
  Syntax error: Trailing comma after the WITH clause before the main query is not allowed at [19:1]
  compiled code at target/run/hailing_project/models/staging/stg_vehicle.sql.
[0m03:51:40.716636 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:519f6a0e-86f0-41b2-8158-7c9575306572&page=queryresults
[0m03:51:40.718019 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:519f6a0e-86f0-41b2-8158-7c9575306572&page=queryresults
[0m03:51:40.721398 [debug] [Thread-1 (]: Database Error in model stg_customer (models/staging/stg_customer.sql)
  Syntax error: Expected keyword DEPTH but got identifier "cleaned" at [20:6]
  compiled code at target/run/hailing_project/models/staging/stg_customer.sql
[0m03:51:40.722416 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b7190cd3-1d5e-4235-9367-57ccdda45d7e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7dbc750ad0>]}
[0m03:51:40.723425 [error] [Thread-1 (]: 1 of 4 ERROR creating sql incremental model rizky_dwh_hailing_source.stg_customer  [[31mERROR[0m in 0.69s]
[0m03:51:40.724598 [debug] [Thread-1 (]: Finished running node model.hailing_project.stg_customer
[0m03:51:40.725682 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.stg_customer' to be skipped because of status 'error'.  Reason: Database Error in model stg_customer (models/staging/stg_customer.sql)
  Syntax error: Expected keyword DEPTH but got identifier "cleaned" at [20:6]
  compiled code at target/run/hailing_project/models/staging/stg_customer.sql.
[0m03:51:40.772889 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:cc8dac86-73ac-48c6-85af-c1e36756a363&page=queryresults
[0m03:51:40.774108 [error] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:cc8dac86-73ac-48c6-85af-c1e36756a363&page=queryresults
[0m03:51:40.777571 [debug] [Thread-2 (]: Database Error in model stg_driver (models/staging/stg_driver.sql)
  Syntax error: Expected keyword DEPTH but got identifier "cleaned" at [21:6]
  compiled code at target/run/hailing_project/models/staging/stg_driver.sql
[0m03:51:40.778659 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b7190cd3-1d5e-4235-9367-57ccdda45d7e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7dbd1c6a90>]}
[0m03:51:40.779741 [error] [Thread-2 (]: 2 of 4 ERROR creating sql incremental model rizky_dwh_hailing_source.stg_driver  [[31mERROR[0m in 0.75s]
[0m03:51:40.780860 [debug] [Thread-2 (]: Finished running node model.hailing_project.stg_driver
[0m03:51:40.782030 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.stg_driver' to be skipped because of status 'error'.  Reason: Database Error in model stg_driver (models/staging/stg_driver.sql)
  Syntax error: Expected keyword DEPTH but got identifier "cleaned" at [21:6]
  compiled code at target/run/hailing_project/models/staging/stg_driver.sql.
[0m03:51:40.906121 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:31ba37c3-4d51-4737-87eb-4a5a8bede1c8&page=queryresults
[0m03:51:42.967413 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b7190cd3-1d5e-4235-9367-57ccdda45d7e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7dbd0e6090>]}
[0m03:51:42.968893 [info ] [Thread-3 (]: 3 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_ride ...... [[32mCREATE TABLE (70.0 rows, 6.2 KiB processed)[0m in 2.93s]
[0m03:51:42.970393 [debug] [Thread-3 (]: Finished running node model.hailing_project.stg_ride
[0m03:51:42.973070 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m03:51:42.976480 [debug] [MainThread]: Connection 'master' was properly closed.
[0m03:51:42.977315 [debug] [MainThread]: Connection 'model.hailing_project.stg_customer' was properly closed.
[0m03:51:42.978132 [debug] [MainThread]: Connection 'model.hailing_project.stg_driver' was properly closed.
[0m03:51:42.978812 [debug] [MainThread]: Connection 'model.hailing_project.stg_ride' was properly closed.
[0m03:51:42.979523 [debug] [MainThread]: Connection 'model.hailing_project.stg_vehicle' was properly closed.
[0m03:51:42.980342 [info ] [MainThread]: 
[0m03:51:42.981362 [info ] [MainThread]: Finished running 4 incremental models in 0 hours 0 minutes and 3.75 seconds (3.75s).
[0m03:51:42.983605 [debug] [MainThread]: Command end result
[0m03:51:43.019384 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m03:51:43.025356 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m03:51:43.035800 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m03:51:43.036967 [info ] [MainThread]: 
[0m03:51:43.038677 [info ] [MainThread]: [31mCompleted with 3 errors, 0 partial successes, and 0 warnings:[0m
[0m03:51:43.039925 [info ] [MainThread]: 
[0m03:51:43.041192 [error] [MainThread]:   Database Error in model stg_vehicle (models/staging/stg_vehicle.sql)
  Syntax error: Trailing comma after the WITH clause before the main query is not allowed at [19:1]
  compiled code at target/run/hailing_project/models/staging/stg_vehicle.sql
[0m03:51:43.042449 [info ] [MainThread]: 
[0m03:51:43.044025 [error] [MainThread]:   Database Error in model stg_customer (models/staging/stg_customer.sql)
  Syntax error: Expected keyword DEPTH but got identifier "cleaned" at [20:6]
  compiled code at target/run/hailing_project/models/staging/stg_customer.sql
[0m03:51:43.045395 [info ] [MainThread]: 
[0m03:51:43.046603 [error] [MainThread]:   Database Error in model stg_driver (models/staging/stg_driver.sql)
  Syntax error: Expected keyword DEPTH but got identifier "cleaned" at [21:6]
  compiled code at target/run/hailing_project/models/staging/stg_driver.sql
[0m03:51:43.047640 [info ] [MainThread]: 
[0m03:51:43.048597 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=3 SKIP=0 TOTAL=4
[0m03:51:43.050753 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 5.6623764, "process_in_blocks": "0", "process_kernel_time": 0.279745, "process_mem_max_rss": "226472", "process_out_blocks": "0", "process_user_time": 4.006348}
[0m03:51:43.052336 [debug] [MainThread]: Command `dbt run` failed at 03:51:43.052165 after 5.66 seconds
[0m03:51:43.053376 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7decf42990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7df04fd010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7decba36d0>]}
[0m03:51:43.054444 [debug] [MainThread]: Flushing usage events
[0m03:51:44.297123 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:52:34.409055 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8d14a4ef10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8d14e4a150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8d14a4ebd0>]}


============================== 03:52:34.411673 | de1a501b-b97a-415c-8de0-788dc80242eb ==============================
[0m03:52:34.411673 [info ] [MainThread]: Running with dbt=1.9.0
[0m03:52:34.412727 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'profiles_dir': '/usr/app/dbt_project', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt run', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m03:52:34.975291 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'de1a501b-b97a-415c-8de0-788dc80242eb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8d14acbd50>]}
[0m03:52:35.019882 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'de1a501b-b97a-415c-8de0-788dc80242eb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8d16cc6290>]}
[0m03:52:35.021404 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m03:52:35.084190 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m03:52:35.209905 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
[0m03:52:35.211040 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/staging/stg_vehicle.sql
[0m03:52:35.211817 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/staging/stg_customer.sql
[0m03:52:35.449778 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project
- models.dbt_project.example
[0m03:52:35.463221 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'de1a501b-b97a-415c-8de0-788dc80242eb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ce6eb2e90>]}
[0m03:52:35.534400 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m03:52:35.539796 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m03:52:35.554360 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'de1a501b-b97a-415c-8de0-788dc80242eb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ce4ef4050>]}
[0m03:52:35.555556 [info ] [MainThread]: Found 4 models, 4 sources, 487 macros
[0m03:52:35.556727 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'de1a501b-b97a-415c-8de0-788dc80242eb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ce6c35390>]}
[0m03:52:35.560001 [info ] [MainThread]: 
[0m03:52:35.561074 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m03:52:35.561965 [info ] [MainThread]: 
[0m03:52:35.563230 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m03:52:35.568495 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m03:52:35.569612 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m03:52:36.059137 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m03:52:36.059990 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m03:52:36.292422 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'de1a501b-b97a-415c-8de0-788dc80242eb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8d14a668d0>]}
[0m03:52:36.293387 [debug] [MainThread]: Opening a new connection, currently in state init
[0m03:52:36.298922 [debug] [Thread-1 (]: Began running node model.hailing_project.stg_customer
[0m03:52:36.299280 [debug] [Thread-2 (]: Began running node model.hailing_project.stg_driver
[0m03:52:36.299817 [debug] [Thread-3 (]: Began running node model.hailing_project.stg_ride
[0m03:52:36.300199 [debug] [Thread-4 (]: Began running node model.hailing_project.stg_vehicle
[0m03:52:36.301256 [info ] [Thread-1 (]: 1 of 4 START sql incremental model rizky_dwh_hailing_source.stg_customer ....... [RUN]
[0m03:52:36.302525 [info ] [Thread-2 (]: 2 of 4 START sql incremental model rizky_dwh_hailing_source.stg_driver ......... [RUN]
[0m03:52:36.303743 [info ] [Thread-3 (]: 3 of 4 START sql incremental model rizky_dwh_hailing_source.stg_ride ........... [RUN]
[0m03:52:36.304819 [info ] [Thread-4 (]: 4 of 4 START sql incremental model rizky_dwh_hailing_source.stg_vehicle ........ [RUN]
[0m03:52:36.305904 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.stg_customer)
[0m03:52:36.307093 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.stg_driver'
[0m03:52:36.308099 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.stg_ride'
[0m03:52:36.308953 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.stg_vehicle'
[0m03:52:36.309717 [debug] [Thread-1 (]: Began compiling node model.hailing_project.stg_customer
[0m03:52:36.310523 [debug] [Thread-2 (]: Began compiling node model.hailing_project.stg_driver
[0m03:52:36.311449 [debug] [Thread-3 (]: Began compiling node model.hailing_project.stg_ride
[0m03:52:36.312287 [debug] [Thread-4 (]: Began compiling node model.hailing_project.stg_vehicle
[0m03:52:36.320882 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.stg_customer"
[0m03:52:36.324058 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.stg_driver"
[0m03:52:36.328077 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.stg_ride"
[0m03:52:36.332522 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.stg_vehicle"
[0m03:52:36.337689 [debug] [Thread-1 (]: Began executing node model.hailing_project.stg_customer
[0m03:52:36.338229 [debug] [Thread-4 (]: Began executing node model.hailing_project.stg_vehicle
[0m03:52:36.349609 [debug] [Thread-3 (]: Began executing node model.hailing_project.stg_ride
[0m03:52:36.349973 [debug] [Thread-2 (]: Began executing node model.hailing_project.stg_driver
[0m03:52:36.404600 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m03:52:36.428087 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.stg_vehicle"
[0m03:52:36.429149 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.stg_customer"
[0m03:52:36.432434 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m03:52:36.463644 [debug] [Thread-1 (]: On model.hailing_project.stg_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`stg_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_customer_source`
)

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned
    );
  
[0m03:52:36.487628 [debug] [Thread-4 (]: On model.hailing_project.stg_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_vehicle"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`stg_vehicle`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_vehicle_source`
)

SELECT *
FROM source
    );
  
[0m03:52:36.488093 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m03:52:36.490382 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m03:52:36.727963 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.stg_driver"
[0m03:52:36.731604 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.stg_ride"
[0m03:52:36.736612 [debug] [Thread-2 (]: On model.hailing_project.stg_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_driver_source`
)

WITH cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m03:52:36.737835 [debug] [Thread-3 (]: On model.hailing_project.stg_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_ride_source`
)

SELECT *
FROM source
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m03:52:36.991392 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:3b14d6d9-cf1f-4053-89f3-bd4f4a87e22c&page=queryresults
[0m03:52:36.993419 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:3b14d6d9-cf1f-4053-89f3-bd4f4a87e22c&page=queryresults
[0m03:52:36.999488 [debug] [Thread-1 (]: Database Error in model stg_customer (models/staging/stg_customer.sql)
  Syntax error: Unexpected identifier "cleaned" at [20:1]
  compiled code at target/run/hailing_project/models/staging/stg_customer.sql
[0m03:52:37.002115 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'de1a501b-b97a-415c-8de0-788dc80242eb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ce4f6bf50>]}
[0m03:52:37.003624 [error] [Thread-1 (]: 1 of 4 ERROR creating sql incremental model rizky_dwh_hailing_source.stg_customer  [[31mERROR[0m in 0.70s]
[0m03:52:37.005887 [debug] [Thread-1 (]: Finished running node model.hailing_project.stg_customer
[0m03:52:37.008203 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.stg_customer' to be skipped because of status 'error'.  Reason: Database Error in model stg_customer (models/staging/stg_customer.sql)
  Syntax error: Unexpected identifier "cleaned" at [20:1]
  compiled code at target/run/hailing_project/models/staging/stg_customer.sql.
[0m03:52:37.083185 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:0c115b79-c3a8-42f3-b535-5e101cf409a9&page=queryresults
[0m03:52:37.085011 [error] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:0c115b79-c3a8-42f3-b535-5e101cf409a9&page=queryresults
[0m03:52:37.091496 [debug] [Thread-2 (]: Database Error in model stg_driver (models/staging/stg_driver.sql)
  Syntax error: Expected keyword DEPTH but got identifier "cleaned" at [21:6]
  compiled code at target/run/hailing_project/models/staging/stg_driver.sql
[0m03:52:37.092561 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'de1a501b-b97a-415c-8de0-788dc80242eb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ce4f680d0>]}
[0m03:52:37.093857 [error] [Thread-2 (]: 2 of 4 ERROR creating sql incremental model rizky_dwh_hailing_source.stg_driver  [[31mERROR[0m in 0.79s]
[0m03:52:37.094960 [debug] [Thread-2 (]: Finished running node model.hailing_project.stg_driver
[0m03:52:37.096111 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.stg_driver' to be skipped because of status 'error'.  Reason: Database Error in model stg_driver (models/staging/stg_driver.sql)
  Syntax error: Expected keyword DEPTH but got identifier "cleaned" at [21:6]
  compiled code at target/run/hailing_project/models/staging/stg_driver.sql.
[0m03:52:37.235539 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:e74471db-864e-4bd5-b7ed-e966e126058a&page=queryresults
[0m03:52:38.120191 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:1dc6c1d3-a482-46ee-af62-ac21695f3093&page=queryresults
[0m03:52:38.917728 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'de1a501b-b97a-415c-8de0-788dc80242eb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ce4eebd50>]}
[0m03:52:38.918881 [info ] [Thread-4 (]: 4 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_vehicle ... [[32mCREATE TABLE (70.0 rows, 3.8 KiB processed)[0m in 2.61s]
[0m03:52:38.920028 [debug] [Thread-4 (]: Finished running node model.hailing_project.stg_vehicle
[0m03:52:39.679385 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'de1a501b-b97a-415c-8de0-788dc80242eb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ce4f5f290>]}
[0m03:52:39.680362 [info ] [Thread-3 (]: 3 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_ride ...... [[32mMERGE (70.0 rows, 12.4 KiB processed)[0m in 3.37s]
[0m03:52:39.681451 [debug] [Thread-3 (]: Finished running node model.hailing_project.stg_ride
[0m03:52:39.683459 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m03:52:39.686098 [debug] [MainThread]: Connection 'master' was properly closed.
[0m03:52:39.686767 [debug] [MainThread]: Connection 'model.hailing_project.stg_customer' was properly closed.
[0m03:52:39.687347 [debug] [MainThread]: Connection 'model.hailing_project.stg_driver' was properly closed.
[0m03:52:39.688064 [debug] [MainThread]: Connection 'model.hailing_project.stg_ride' was properly closed.
[0m03:52:39.688677 [debug] [MainThread]: Connection 'model.hailing_project.stg_vehicle' was properly closed.
[0m03:52:39.689405 [info ] [MainThread]: 
[0m03:52:39.690190 [info ] [MainThread]: Finished running 4 incremental models in 0 hours 0 minutes and 4.13 seconds (4.13s).
[0m03:52:39.691872 [debug] [MainThread]: Command end result
[0m03:52:39.724313 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m03:52:39.728477 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m03:52:39.737091 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m03:52:39.737790 [info ] [MainThread]: 
[0m03:52:39.738825 [info ] [MainThread]: [31mCompleted with 2 errors, 0 partial successes, and 0 warnings:[0m
[0m03:52:39.739745 [info ] [MainThread]: 
[0m03:52:39.740820 [error] [MainThread]:   Database Error in model stg_customer (models/staging/stg_customer.sql)
  Syntax error: Unexpected identifier "cleaned" at [20:1]
  compiled code at target/run/hailing_project/models/staging/stg_customer.sql
[0m03:52:39.741979 [info ] [MainThread]: 
[0m03:52:39.743012 [error] [MainThread]:   Database Error in model stg_driver (models/staging/stg_driver.sql)
  Syntax error: Expected keyword DEPTH but got identifier "cleaned" at [21:6]
  compiled code at target/run/hailing_project/models/staging/stg_driver.sql
[0m03:52:39.743991 [info ] [MainThread]: 
[0m03:52:39.744993 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=2 SKIP=0 TOTAL=4
[0m03:52:39.746473 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 5.3955393, "process_in_blocks": "0", "process_kernel_time": 0.179213, "process_mem_max_rss": "228640", "process_out_blocks": "0", "process_user_time": 3.494667}
[0m03:52:39.747372 [debug] [MainThread]: Command `dbt run` failed at 03:52:39.747265 after 5.40 seconds
[0m03:52:39.748166 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8d14e4a290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8d14acbf90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8d14acba50>]}
[0m03:52:39.749218 [debug] [MainThread]: Flushing usage events
[0m03:52:40.816296 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:54:09.824353 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0d4eac2cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0d4efd8c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0d4eac2610>]}


============================== 03:54:09.826791 | dca53bf5-95ca-495c-a2d5-f385a35a5fe7 ==============================
[0m03:54:09.826791 [info ] [MainThread]: Running with dbt=1.9.0
[0m03:54:09.828128 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m03:54:10.392039 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'dca53bf5-95ca-495c-a2d5-f385a35a5fe7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0d4eac9d90>]}
[0m03:54:10.444749 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'dca53bf5-95ca-495c-a2d5-f385a35a5fe7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0d50d3a190>]}
[0m03:54:10.446382 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m03:54:10.515417 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m03:54:10.668063 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m03:54:10.669476 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/staging/stg_driver.sql
[0m03:54:10.932783 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project
- models.dbt_project.example
[0m03:54:10.945126 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'dca53bf5-95ca-495c-a2d5-f385a35a5fe7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0d24d8fa90>]}
[0m03:54:11.016954 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m03:54:11.022375 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m03:54:11.037186 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'dca53bf5-95ca-495c-a2d5-f385a35a5fe7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0d130fe950>]}
[0m03:54:11.038504 [info ] [MainThread]: Found 4 models, 4 sources, 487 macros
[0m03:54:11.040006 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'dca53bf5-95ca-495c-a2d5-f385a35a5fe7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0d24a611d0>]}
[0m03:54:11.042707 [info ] [MainThread]: 
[0m03:54:11.043862 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m03:54:11.044906 [info ] [MainThread]: 
[0m03:54:11.046330 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m03:54:11.051326 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m03:54:11.052237 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m03:54:11.620969 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m03:54:11.621871 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m03:54:11.853218 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'dca53bf5-95ca-495c-a2d5-f385a35a5fe7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0d2485e910>]}
[0m03:54:11.854570 [debug] [MainThread]: Opening a new connection, currently in state init
[0m03:54:11.858863 [debug] [Thread-1 (]: Began running node model.hailing_project.stg_customer
[0m03:54:11.859202 [debug] [Thread-2 (]: Began running node model.hailing_project.stg_driver
[0m03:54:11.859759 [debug] [Thread-3 (]: Began running node model.hailing_project.stg_ride
[0m03:54:11.860114 [debug] [Thread-4 (]: Began running node model.hailing_project.stg_vehicle
[0m03:54:11.860800 [info ] [Thread-1 (]: 1 of 4 START sql incremental model rizky_dwh_hailing_source.stg_customer ....... [RUN]
[0m03:54:11.862351 [info ] [Thread-2 (]: 2 of 4 START sql incremental model rizky_dwh_hailing_source.stg_driver ......... [RUN]
[0m03:54:11.863397 [info ] [Thread-3 (]: 3 of 4 START sql incremental model rizky_dwh_hailing_source.stg_ride ........... [RUN]
[0m03:54:11.864522 [info ] [Thread-4 (]: 4 of 4 START sql incremental model rizky_dwh_hailing_source.stg_vehicle ........ [RUN]
[0m03:54:11.865737 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.stg_customer)
[0m03:54:11.867042 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.stg_driver'
[0m03:54:11.868162 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.stg_ride'
[0m03:54:11.869546 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.stg_vehicle'
[0m03:54:11.870647 [debug] [Thread-1 (]: Began compiling node model.hailing_project.stg_customer
[0m03:54:11.871533 [debug] [Thread-2 (]: Began compiling node model.hailing_project.stg_driver
[0m03:54:11.872319 [debug] [Thread-3 (]: Began compiling node model.hailing_project.stg_ride
[0m03:54:11.873149 [debug] [Thread-4 (]: Began compiling node model.hailing_project.stg_vehicle
[0m03:54:11.881753 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.stg_customer"
[0m03:54:11.885135 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.stg_driver"
[0m03:54:11.888635 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.stg_ride"
[0m03:54:11.892817 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.stg_vehicle"
[0m03:54:11.898729 [debug] [Thread-3 (]: Began executing node model.hailing_project.stg_ride
[0m03:54:11.899191 [debug] [Thread-2 (]: Began executing node model.hailing_project.stg_driver
[0m03:54:11.910645 [debug] [Thread-1 (]: Began executing node model.hailing_project.stg_customer
[0m03:54:11.921005 [debug] [Thread-4 (]: Began executing node model.hailing_project.stg_vehicle
[0m03:54:11.943261 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m03:54:11.943612 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m03:54:11.968643 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m03:54:11.973685 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.stg_customer"
[0m03:54:12.050539 [debug] [Thread-1 (]: On model.hailing_project.stg_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`stg_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_customer_source`
)

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned
    );
  
[0m03:54:12.051715 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m03:54:12.258156 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.stg_ride"
[0m03:54:12.265814 [debug] [Thread-3 (]: On model.hailing_project.stg_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_ride_source`
)

SELECT *
FROM source
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m03:54:12.282459 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.stg_driver"
[0m03:54:12.285197 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.stg_vehicle"
[0m03:54:12.292256 [debug] [Thread-2 (]: On model.hailing_project.stg_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_driver_source`
)

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m03:54:12.293721 [debug] [Thread-4 (]: On model.hailing_project.stg_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_vehicle_source`
)

SELECT *
FROM source
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m03:54:12.497365 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:cc35f3a9-4a3c-4aa0-9e92-a8e815d27132&page=queryresults
[0m03:54:12.498647 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:cc35f3a9-4a3c-4aa0-9e92-a8e815d27132&page=queryresults
[0m03:54:12.503409 [debug] [Thread-1 (]: Database Error in model stg_customer (models/staging/stg_customer.sql)
  Syntax error: Unexpected identifier "cleaned" at [20:1]
  compiled code at target/run/hailing_project/models/staging/stg_customer.sql
[0m03:54:12.505335 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dca53bf5-95ca-495c-a2d5-f385a35a5fe7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0d131ddf10>]}
[0m03:54:12.506641 [error] [Thread-1 (]: 1 of 4 ERROR creating sql incremental model rizky_dwh_hailing_source.stg_customer  [[31mERROR[0m in 0.64s]
[0m03:54:12.507699 [debug] [Thread-1 (]: Finished running node model.hailing_project.stg_customer
[0m03:54:12.508665 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.stg_customer' to be skipped because of status 'error'.  Reason: Database Error in model stg_customer (models/staging/stg_customer.sql)
  Syntax error: Unexpected identifier "cleaned" at [20:1]
  compiled code at target/run/hailing_project/models/staging/stg_customer.sql.
[0m03:54:12.642837 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:81548928-2f7a-48f0-a02d-c57c47f1e53f&page=queryresults
[0m03:54:12.644081 [error] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:81548928-2f7a-48f0-a02d-c57c47f1e53f&page=queryresults
[0m03:54:12.647977 [debug] [Thread-2 (]: Database Error in model stg_driver (models/staging/stg_driver.sql)
  Syntax error: Unexpected identifier "cleaned" at [21:1]
  compiled code at target/run/hailing_project/models/staging/stg_driver.sql
[0m03:54:12.650207 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dca53bf5-95ca-495c-a2d5-f385a35a5fe7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0d1319d850>]}
[0m03:54:12.653167 [error] [Thread-2 (]: 2 of 4 ERROR creating sql incremental model rizky_dwh_hailing_source.stg_driver  [[31mERROR[0m in 0.78s]
[0m03:54:12.654899 [debug] [Thread-2 (]: Finished running node model.hailing_project.stg_driver
[0m03:54:12.656314 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.stg_driver' to be skipped because of status 'error'.  Reason: Database Error in model stg_driver (models/staging/stg_driver.sql)
  Syntax error: Unexpected identifier "cleaned" at [21:1]
  compiled code at target/run/hailing_project/models/staging/stg_driver.sql.
[0m03:54:12.860424 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:a9427830-3516-49dd-9eb5-a2219a516405&page=queryresults
[0m03:54:13.771075 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:e4333740-597d-4c81-a3c3-1f327fd88867&page=queryresults
[0m03:54:14.462404 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dca53bf5-95ca-495c-a2d5-f385a35a5fe7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0d131e4d90>]}
[0m03:54:14.463748 [info ] [Thread-4 (]: 4 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_vehicle ... [[32mMERGE (70.0 rows, 7.7 KiB processed)[0m in 2.59s]
[0m03:54:14.464971 [debug] [Thread-4 (]: Finished running node model.hailing_project.stg_vehicle
[0m03:54:15.705479 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dca53bf5-95ca-495c-a2d5-f385a35a5fe7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0d0bf5ed50>]}
[0m03:54:15.706518 [info ] [Thread-3 (]: 3 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_ride ...... [[32mMERGE (70.0 rows, 12.4 KiB processed)[0m in 3.84s]
[0m03:54:15.708446 [debug] [Thread-3 (]: Finished running node model.hailing_project.stg_ride
[0m03:54:15.710841 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m03:54:15.714265 [debug] [MainThread]: Connection 'master' was properly closed.
[0m03:54:15.715176 [debug] [MainThread]: Connection 'model.hailing_project.stg_customer' was properly closed.
[0m03:54:15.716248 [debug] [MainThread]: Connection 'model.hailing_project.stg_driver' was properly closed.
[0m03:54:15.717148 [debug] [MainThread]: Connection 'model.hailing_project.stg_ride' was properly closed.
[0m03:54:15.718336 [debug] [MainThread]: Connection 'model.hailing_project.stg_vehicle' was properly closed.
[0m03:54:15.719294 [info ] [MainThread]: 
[0m03:54:15.720339 [info ] [MainThread]: Finished running 4 incremental models in 0 hours 0 minutes and 4.67 seconds (4.67s).
[0m03:54:15.722362 [debug] [MainThread]: Command end result
[0m03:54:15.756474 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m03:54:15.762363 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m03:54:15.772373 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m03:54:15.773330 [info ] [MainThread]: 
[0m03:54:15.774326 [info ] [MainThread]: [31mCompleted with 2 errors, 0 partial successes, and 0 warnings:[0m
[0m03:54:15.775362 [info ] [MainThread]: 
[0m03:54:15.776403 [error] [MainThread]:   Database Error in model stg_customer (models/staging/stg_customer.sql)
  Syntax error: Unexpected identifier "cleaned" at [20:1]
  compiled code at target/run/hailing_project/models/staging/stg_customer.sql
[0m03:54:15.778073 [info ] [MainThread]: 
[0m03:54:15.779409 [error] [MainThread]:   Database Error in model stg_driver (models/staging/stg_driver.sql)
  Syntax error: Unexpected identifier "cleaned" at [21:1]
  compiled code at target/run/hailing_project/models/staging/stg_driver.sql
[0m03:54:15.780443 [info ] [MainThread]: 
[0m03:54:15.781604 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=2 SKIP=0 TOTAL=4
[0m03:54:15.783321 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 6.004255, "process_in_blocks": "0", "process_kernel_time": 0.274545, "process_mem_max_rss": "226336", "process_out_blocks": "0", "process_user_time": 3.42674}
[0m03:54:15.784707 [debug] [MainThread]: Command `dbt run` failed at 03:54:15.784406 after 6.01 seconds
[0m03:54:15.785493 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0d4eebe650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0d4eb41850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0d4eb43c50>]}
[0m03:54:15.786593 [debug] [MainThread]: Flushing usage events
[0m03:54:16.902471 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:55:09.159775 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f40a4cbfcd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f40a506a110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f40a4c726d0>]}


============================== 03:55:09.162354 | b8cac8fb-cd27-41d4-8ccc-b907ce13dd9d ==============================
[0m03:55:09.162354 [info ] [MainThread]: Running with dbt=1.9.0
[0m03:55:09.163683 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt clean', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m03:55:09.242657 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b8cac8fb-cd27-41d4-8ccc-b907ce13dd9d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f40a4ccd810>]}
[0m03:55:09.294947 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.18828923, "process_in_blocks": "0", "process_kernel_time": 0.039608, "process_mem_max_rss": "89936", "process_out_blocks": "0", "process_user_time": 0.960514}
[0m03:55:09.296131 [debug] [MainThread]: Command `dbt clean` succeeded at 03:55:09.296013 after 0.19 seconds
[0m03:55:09.297179 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f40a4c72ad0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f40a4c72190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f40a843cc10>]}
[0m03:55:09.298057 [debug] [MainThread]: Flushing usage events
[0m03:55:10.369621 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:55:24.770918 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbc383cfe10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbc383cf110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbc383ce650>]}


============================== 03:55:24.774277 | 0c7ae357-769b-49ef-8725-7187896870d1 ==============================
[0m03:55:24.774277 [info ] [MainThread]: Running with dbt=1.9.0
[0m03:55:24.775891 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt deps', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m03:55:24.863354 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '0c7ae357-769b-49ef-8725-7187896870d1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbc38302f10>]}
[0m03:55:24.872599 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m03:55:24.875455 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m03:55:24.876872 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.15382788, "process_in_blocks": "0", "process_kernel_time": 0.090793, "process_mem_max_rss": "90180", "process_out_blocks": "0", "process_user_time": 0.978553}
[0m03:55:24.877995 [debug] [MainThread]: Command `dbt deps` succeeded at 03:55:24.877857 after 0.16 seconds
[0m03:55:24.878921 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbc3841f110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbc38884310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbc3bc24b90>]}
[0m03:55:24.879873 [debug] [MainThread]: Flushing usage events
[0m03:55:26.050892 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:55:28.807178 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f777b2078d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f777a54f610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f777a8f8190>]}


============================== 03:55:28.810814 | 2963f7c2-f555-493c-bdd6-ed99d18b3bd1 ==============================
[0m03:55:28.810814 [info ] [MainThread]: Running with dbt=1.9.0
[0m03:55:28.812027 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt run', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m03:55:29.417786 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '2963f7c2-f555-493c-bdd6-ed99d18b3bd1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7753134b50>]}
[0m03:55:29.464029 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '2963f7c2-f555-493c-bdd6-ed99d18b3bd1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f775080f5d0>]}
[0m03:55:29.465558 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m03:55:29.538658 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m03:55:29.541544 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m03:55:29.542274 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '2963f7c2-f555-493c-bdd6-ed99d18b3bd1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f775086c750>]}
[0m03:55:30.548355 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.example
- models.dbt_project
[0m03:55:30.559047 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2963f7c2-f555-493c-bdd6-ed99d18b3bd1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7750557c10>]}
[0m03:55:30.623650 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m03:55:30.629340 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m03:55:30.644547 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2963f7c2-f555-493c-bdd6-ed99d18b3bd1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7750407650>]}
[0m03:55:30.645711 [info ] [MainThread]: Found 4 models, 4 sources, 487 macros
[0m03:55:30.646988 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2963f7c2-f555-493c-bdd6-ed99d18b3bd1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f775012b390>]}
[0m03:55:30.649699 [info ] [MainThread]: 
[0m03:55:30.650862 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m03:55:30.651836 [info ] [MainThread]: 
[0m03:55:30.653009 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m03:55:30.657771 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m03:55:30.658952 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m03:55:31.214619 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m03:55:31.215562 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m03:55:31.431486 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2963f7c2-f555-493c-bdd6-ed99d18b3bd1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f77505cb690>]}
[0m03:55:31.432650 [debug] [MainThread]: Opening a new connection, currently in state init
[0m03:55:31.438165 [debug] [Thread-1 (]: Began running node model.hailing_project.stg_customer
[0m03:55:31.438546 [debug] [Thread-2 (]: Began running node model.hailing_project.stg_driver
[0m03:55:31.439004 [debug] [Thread-3 (]: Began running node model.hailing_project.stg_ride
[0m03:55:31.439377 [debug] [Thread-4 (]: Began running node model.hailing_project.stg_vehicle
[0m03:55:31.440151 [info ] [Thread-1 (]: 1 of 4 START sql incremental model rizky_dwh_hailing_source.stg_customer ....... [RUN]
[0m03:55:31.441542 [info ] [Thread-2 (]: 2 of 4 START sql incremental model rizky_dwh_hailing_source.stg_driver ......... [RUN]
[0m03:55:31.442821 [info ] [Thread-3 (]: 3 of 4 START sql incremental model rizky_dwh_hailing_source.stg_ride ........... [RUN]
[0m03:55:31.443938 [info ] [Thread-4 (]: 4 of 4 START sql incremental model rizky_dwh_hailing_source.stg_vehicle ........ [RUN]
[0m03:55:31.445307 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.stg_customer)
[0m03:55:31.446572 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.stg_driver'
[0m03:55:31.448002 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.stg_ride'
[0m03:55:31.449149 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.stg_vehicle'
[0m03:55:31.450139 [debug] [Thread-1 (]: Began compiling node model.hailing_project.stg_customer
[0m03:55:31.450927 [debug] [Thread-2 (]: Began compiling node model.hailing_project.stg_driver
[0m03:55:31.451735 [debug] [Thread-3 (]: Began compiling node model.hailing_project.stg_ride
[0m03:55:31.452862 [debug] [Thread-4 (]: Began compiling node model.hailing_project.stg_vehicle
[0m03:55:31.461263 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.stg_customer"
[0m03:55:31.465636 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.stg_driver"
[0m03:55:31.469369 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.stg_ride"
[0m03:55:31.472947 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.stg_vehicle"
[0m03:55:31.486675 [debug] [Thread-3 (]: Began executing node model.hailing_project.stg_ride
[0m03:55:31.498362 [debug] [Thread-4 (]: Began executing node model.hailing_project.stg_vehicle
[0m03:55:31.522128 [debug] [Thread-1 (]: Began executing node model.hailing_project.stg_customer
[0m03:55:31.522470 [debug] [Thread-2 (]: Began executing node model.hailing_project.stg_driver
[0m03:55:31.538896 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m03:55:31.541798 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m03:55:31.567226 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m03:55:31.575318 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.stg_customer"
[0m03:55:31.669405 [debug] [Thread-1 (]: On model.hailing_project.stg_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`stg_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_customer_source`
)

WITH cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned
    );
  
[0m03:55:31.670530 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m03:55:31.918699 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.stg_ride"
[0m03:55:31.921156 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.stg_driver"
[0m03:55:31.922692 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.stg_vehicle"
[0m03:55:31.928621 [debug] [Thread-3 (]: On model.hailing_project.stg_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_ride_source`
)

SELECT *
FROM source
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m03:55:31.931728 [debug] [Thread-2 (]: On model.hailing_project.stg_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_driver_source`
)

WITH cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m03:55:31.934284 [debug] [Thread-4 (]: On model.hailing_project.stg_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_vehicle_source`
)

SELECT *
FROM source
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m03:55:32.182142 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:099f2d54-5d14-4ae4-9ffb-989e83538f9f&page=queryresults
[0m03:55:32.183346 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:099f2d54-5d14-4ae4-9ffb-989e83538f9f&page=queryresults
[0m03:55:32.187968 [debug] [Thread-1 (]: Database Error in model stg_customer (models/staging/stg_customer.sql)
  Syntax error: Expected keyword DEPTH but got identifier "cleaned" at [20:6]
  compiled code at target/run/hailing_project/models/staging/stg_customer.sql
[0m03:55:32.190308 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2963f7c2-f555-493c-bdd6-ed99d18b3bd1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7702f8f150>]}
[0m03:55:32.191747 [error] [Thread-1 (]: 1 of 4 ERROR creating sql incremental model rizky_dwh_hailing_source.stg_customer  [[31mERROR[0m in 0.74s]
[0m03:55:32.193153 [debug] [Thread-1 (]: Finished running node model.hailing_project.stg_customer
[0m03:55:32.194571 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.stg_customer' to be skipped because of status 'error'.  Reason: Database Error in model stg_customer (models/staging/stg_customer.sql)
  Syntax error: Expected keyword DEPTH but got identifier "cleaned" at [20:6]
  compiled code at target/run/hailing_project/models/staging/stg_customer.sql.
[0m03:55:32.199419 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:a8ef050e-ecc6-4976-bae6-17bd99d1396c&page=queryresults
[0m03:55:32.283921 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:9b6c3bff-c7bc-4c12-86a7-385f561c0395&page=queryresults
[0m03:55:32.285117 [error] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:9b6c3bff-c7bc-4c12-86a7-385f561c0395&page=queryresults
[0m03:55:32.289236 [debug] [Thread-2 (]: Database Error in model stg_driver (models/staging/stg_driver.sql)
  Syntax error: Expected keyword DEPTH but got identifier "cleaned" at [21:6]
  compiled code at target/run/hailing_project/models/staging/stg_driver.sql
[0m03:55:32.290314 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2963f7c2-f555-493c-bdd6-ed99d18b3bd1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f774a90fe90>]}
[0m03:55:32.291582 [error] [Thread-2 (]: 2 of 4 ERROR creating sql incremental model rizky_dwh_hailing_source.stg_driver  [[31mERROR[0m in 0.84s]
[0m03:55:32.292890 [debug] [Thread-2 (]: Finished running node model.hailing_project.stg_driver
[0m03:55:32.294284 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.stg_driver' to be skipped because of status 'error'.  Reason: Database Error in model stg_driver (models/staging/stg_driver.sql)
  Syntax error: Expected keyword DEPTH but got identifier "cleaned" at [21:6]
  compiled code at target/run/hailing_project/models/staging/stg_driver.sql.
[0m03:55:32.472294 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:5b3e4fc1-d0ad-4058-84bf-60127e0576f9&page=queryresults
[0m03:55:34.019349 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2963f7c2-f555-493c-bdd6-ed99d18b3bd1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f774a9ef2d0>]}
[0m03:55:34.020819 [info ] [Thread-4 (]: 4 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_vehicle ... [[32mMERGE (70.0 rows, 7.7 KiB processed)[0m in 2.57s]
[0m03:55:34.022224 [debug] [Thread-4 (]: Finished running node model.hailing_project.stg_vehicle
[0m03:55:34.274515 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2963f7c2-f555-493c-bdd6-ed99d18b3bd1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7702fe1090>]}
[0m03:55:34.276259 [info ] [Thread-3 (]: 3 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_ride ...... [[32mMERGE (70.0 rows, 12.4 KiB processed)[0m in 2.83s]
[0m03:55:34.278487 [debug] [Thread-3 (]: Finished running node model.hailing_project.stg_ride
[0m03:55:34.281322 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m03:55:34.285203 [debug] [MainThread]: Connection 'master' was properly closed.
[0m03:55:34.285984 [debug] [MainThread]: Connection 'model.hailing_project.stg_customer' was properly closed.
[0m03:55:34.286849 [debug] [MainThread]: Connection 'model.hailing_project.stg_driver' was properly closed.
[0m03:55:34.287649 [debug] [MainThread]: Connection 'model.hailing_project.stg_ride' was properly closed.
[0m03:55:34.288407 [debug] [MainThread]: Connection 'model.hailing_project.stg_vehicle' was properly closed.
[0m03:55:34.289540 [info ] [MainThread]: 
[0m03:55:34.290431 [info ] [MainThread]: Finished running 4 incremental models in 0 hours 0 minutes and 3.64 seconds (3.64s).
[0m03:55:34.292046 [debug] [MainThread]: Command end result
[0m03:55:34.326600 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m03:55:34.330260 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m03:55:34.337377 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m03:55:34.338364 [info ] [MainThread]: 
[0m03:55:34.339345 [info ] [MainThread]: [31mCompleted with 2 errors, 0 partial successes, and 0 warnings:[0m
[0m03:55:34.340285 [info ] [MainThread]: 
[0m03:55:34.341190 [error] [MainThread]:   Database Error in model stg_customer (models/staging/stg_customer.sql)
  Syntax error: Expected keyword DEPTH but got identifier "cleaned" at [20:6]
  compiled code at target/run/hailing_project/models/staging/stg_customer.sql
[0m03:55:34.342011 [info ] [MainThread]: 
[0m03:55:34.343022 [error] [MainThread]:   Database Error in model stg_driver (models/staging/stg_driver.sql)
  Syntax error: Expected keyword DEPTH but got identifier "cleaned" at [21:6]
  compiled code at target/run/hailing_project/models/staging/stg_driver.sql
[0m03:55:34.343830 [info ] [MainThread]: 
[0m03:55:34.344871 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=2 SKIP=0 TOTAL=4
[0m03:55:34.346684 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 5.5879216, "process_in_blocks": "0", "process_kernel_time": 0.23382, "process_mem_max_rss": "229560", "process_out_blocks": "0", "process_user_time": 4.188439}
[0m03:55:34.347840 [debug] [MainThread]: Command `dbt run` failed at 03:55:34.347695 after 5.59 seconds
[0m03:55:34.348837 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f777a57b610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f777deb5190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f777a925f50>]}
[0m03:55:34.349649 [debug] [MainThread]: Flushing usage events
[0m03:55:35.369581 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:57:01.842205 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fee18996e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fee189ebbd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fee18eb0a50>]}


============================== 03:57:01.845022 | faa07538-7d5c-40c2-b3fa-ba941cc648ea ==============================
[0m03:57:01.845022 [info ] [MainThread]: Running with dbt=1.9.0
[0m03:57:01.846405 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt clean', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m03:57:01.925705 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'faa07538-7d5c-40c2-b3fa-ba941cc648ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fee18828290>]}
[0m03:57:01.984078 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.19159567, "process_in_blocks": "0", "process_kernel_time": 0.110106, "process_mem_max_rss": "90232", "process_out_blocks": "0", "process_user_time": 0.990958}
[0m03:57:01.985043 [debug] [MainThread]: Command `dbt clean` succeeded at 03:57:01.984933 after 0.19 seconds
[0m03:57:01.985741 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fee189ef010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fee189ee250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fee1c190c10>]}
[0m03:57:01.986387 [debug] [MainThread]: Flushing usage events
[0m03:57:03.102048 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:57:04.236538 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efd5e1db990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efd5e22efd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efd60a89ed0>]}


============================== 03:57:04.239085 | 12044cc6-e7bf-4a2b-9974-6fa04b8997a3 ==============================
[0m03:57:04.239085 [info ] [MainThread]: Running with dbt=1.9.0
[0m03:57:04.240329 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt deps', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m03:57:04.321313 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '12044cc6-e7bf-4a2b-9974-6fa04b8997a3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efd5e0e3dd0>]}
[0m03:57:04.330902 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m03:57:04.333293 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m03:57:04.334731 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.14978145, "process_in_blocks": "0", "process_kernel_time": 0.050052, "process_mem_max_rss": "90192", "process_out_blocks": "0", "process_user_time": 1.02107}
[0m03:57:04.335828 [debug] [MainThread]: Command `dbt deps` succeeded at 03:57:04.335688 after 0.15 seconds
[0m03:57:04.336779 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efd5e22f110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efd5e26a310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efd61a34b90>]}
[0m03:57:04.337703 [debug] [MainThread]: Flushing usage events
[0m03:57:05.361502 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:57:10.069705 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3db55d7890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3db597e110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3db5586e50>]}


============================== 03:57:10.072220 | 69de4a25-c58b-4675-beab-b2b8eff3ef12 ==============================
[0m03:57:10.072220 [info ] [MainThread]: Running with dbt=1.9.0
[0m03:57:10.074696 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'log_format': 'default', 'invocation_command': 'dbt run', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m03:57:10.640124 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '69de4a25-c58b-4675-beab-b2b8eff3ef12', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d8cd99ad0>]}
[0m03:57:10.688109 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '69de4a25-c58b-4675-beab-b2b8eff3ef12', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3db77d8dd0>]}
[0m03:57:10.689656 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m03:57:10.758220 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m03:57:10.761682 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m03:57:10.762700 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '69de4a25-c58b-4675-beab-b2b8eff3ef12', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d877cf610>]}
[0m03:57:11.751320 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project
- models.dbt_project.example
[0m03:57:11.764502 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '69de4a25-c58b-4675-beab-b2b8eff3ef12', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d877c16d0>]}
[0m03:57:11.835931 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m03:57:11.842835 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m03:57:11.860727 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '69de4a25-c58b-4675-beab-b2b8eff3ef12', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d87396ad0>]}
[0m03:57:11.861885 [info ] [MainThread]: Found 4 models, 4 sources, 487 macros
[0m03:57:11.863283 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '69de4a25-c58b-4675-beab-b2b8eff3ef12', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d87369a10>]}
[0m03:57:11.867070 [info ] [MainThread]: 
[0m03:57:11.868330 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m03:57:11.869453 [info ] [MainThread]: 
[0m03:57:11.870892 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m03:57:11.876006 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m03:57:11.877128 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m03:57:12.483653 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m03:57:12.485001 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m03:57:12.697190 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '69de4a25-c58b-4675-beab-b2b8eff3ef12', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d8746b290>]}
[0m03:57:12.701160 [debug] [MainThread]: Opening a new connection, currently in state init
[0m03:57:12.706561 [debug] [Thread-1 (]: Began running node model.hailing_project.stg_customer
[0m03:57:12.706888 [debug] [Thread-2 (]: Began running node model.hailing_project.stg_driver
[0m03:57:12.707224 [debug] [Thread-3 (]: Began running node model.hailing_project.stg_ride
[0m03:57:12.707525 [debug] [Thread-4 (]: Began running node model.hailing_project.stg_vehicle
[0m03:57:12.708027 [info ] [Thread-1 (]: 1 of 4 START sql incremental model rizky_dwh_hailing_source.stg_customer ....... [RUN]
[0m03:57:12.708940 [info ] [Thread-2 (]: 2 of 4 START sql incremental model rizky_dwh_hailing_source.stg_driver ......... [RUN]
[0m03:57:12.709867 [info ] [Thread-3 (]: 3 of 4 START sql incremental model rizky_dwh_hailing_source.stg_ride ........... [RUN]
[0m03:57:12.710807 [info ] [Thread-4 (]: 4 of 4 START sql incremental model rizky_dwh_hailing_source.stg_vehicle ........ [RUN]
[0m03:57:12.711929 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.stg_customer)
[0m03:57:12.712899 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.stg_driver'
[0m03:57:12.713772 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.stg_ride'
[0m03:57:12.714622 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.stg_vehicle'
[0m03:57:12.715332 [debug] [Thread-1 (]: Began compiling node model.hailing_project.stg_customer
[0m03:57:12.716134 [debug] [Thread-2 (]: Began compiling node model.hailing_project.stg_driver
[0m03:57:12.716881 [debug] [Thread-3 (]: Began compiling node model.hailing_project.stg_ride
[0m03:57:12.717629 [debug] [Thread-4 (]: Began compiling node model.hailing_project.stg_vehicle
[0m03:57:12.724464 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.stg_customer"
[0m03:57:12.728563 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.stg_driver"
[0m03:57:12.732520 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.stg_ride"
[0m03:57:12.736321 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.stg_vehicle"
[0m03:57:12.748694 [debug] [Thread-2 (]: Began executing node model.hailing_project.stg_driver
[0m03:57:12.749993 [debug] [Thread-4 (]: Began executing node model.hailing_project.stg_vehicle
[0m03:57:12.794869 [debug] [Thread-1 (]: Began executing node model.hailing_project.stg_customer
[0m03:57:12.795275 [debug] [Thread-3 (]: Began executing node model.hailing_project.stg_ride
[0m03:57:12.797594 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m03:57:12.797998 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m03:57:12.822461 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m03:57:12.827901 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.stg_customer"
[0m03:57:12.927185 [debug] [Thread-1 (]: On model.hailing_project.stg_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`stg_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_customer_source`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned
    );
  
[0m03:57:12.928316 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m03:57:13.157076 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.stg_ride"
[0m03:57:13.161516 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.stg_vehicle"
[0m03:57:13.162911 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.stg_driver"
[0m03:57:13.168305 [debug] [Thread-2 (]: On model.hailing_project.stg_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_driver_source`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m03:57:13.169715 [debug] [Thread-3 (]: On model.hailing_project.stg_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_ride_source`
)

SELECT *
FROM source
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m03:57:13.173739 [debug] [Thread-4 (]: On model.hailing_project.stg_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_vehicle_source`
)

SELECT *
FROM source
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m03:57:13.347744 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:9c82e0b7-2856-4508-9a62-6e88dec4c098&page=queryresults
[0m03:57:13.452667 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:22fa7bdc-468c-48cd-8f1c-d452a15eeef1&page=queryresults
[0m03:57:13.509953 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:2034e47d-b241-441c-96b7-b0377fa7389e&page=queryresults
[0m03:57:13.798102 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:d09d99b6-dd3d-4f3b-b11a-6e5e01b7e7d3&page=queryresults
[0m03:57:15.216883 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '69de4a25-c58b-4675-beab-b2b8eff3ef12', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d45f12190>]}
[0m03:57:15.218074 [info ] [Thread-4 (]: 4 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_vehicle ... [[32mMERGE (70.0 rows, 7.7 KiB processed)[0m in 2.50s]
[0m03:57:15.219463 [debug] [Thread-4 (]: Finished running node model.hailing_project.stg_vehicle
[0m03:57:15.227541 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '69de4a25-c58b-4675-beab-b2b8eff3ef12', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d8599fc50>]}
[0m03:57:15.228867 [info ] [Thread-1 (]: 1 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_customer .. [[32mCREATE TABLE (70.0 rows, 4.8 KiB processed)[0m in 2.52s]
[0m03:57:15.230098 [debug] [Thread-1 (]: Finished running node model.hailing_project.stg_customer
[0m03:57:15.310368 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '69de4a25-c58b-4675-beab-b2b8eff3ef12', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d85957850>]}
[0m03:57:15.311608 [info ] [Thread-2 (]: 2 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_driver .... [[32mMERGE (70.0 rows, 9.4 KiB processed)[0m in 2.60s]
[0m03:57:15.312911 [debug] [Thread-2 (]: Finished running node model.hailing_project.stg_driver
[0m03:57:15.334356 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '69de4a25-c58b-4675-beab-b2b8eff3ef12', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d859c6cd0>]}
[0m03:57:15.335323 [info ] [Thread-3 (]: 3 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_ride ...... [[32mMERGE (70.0 rows, 12.4 KiB processed)[0m in 2.62s]
[0m03:57:15.336578 [debug] [Thread-3 (]: Finished running node model.hailing_project.stg_ride
[0m03:57:15.339497 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m03:57:15.342938 [debug] [MainThread]: Connection 'master' was properly closed.
[0m03:57:15.343644 [debug] [MainThread]: Connection 'model.hailing_project.stg_customer' was properly closed.
[0m03:57:15.344402 [debug] [MainThread]: Connection 'model.hailing_project.stg_driver' was properly closed.
[0m03:57:15.345062 [debug] [MainThread]: Connection 'model.hailing_project.stg_ride' was properly closed.
[0m03:57:15.346048 [debug] [MainThread]: Connection 'model.hailing_project.stg_vehicle' was properly closed.
[0m03:57:15.346926 [info ] [MainThread]: 
[0m03:57:15.347830 [info ] [MainThread]: Finished running 4 incremental models in 0 hours 0 minutes and 3.48 seconds (3.48s).
[0m03:57:15.349520 [debug] [MainThread]: Command end result
[0m03:57:15.382035 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m03:57:15.386515 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m03:57:15.395721 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m03:57:15.396571 [info ] [MainThread]: 
[0m03:57:15.397619 [info ] [MainThread]: [32mCompleted successfully[0m
[0m03:57:15.398638 [info ] [MainThread]: 
[0m03:57:15.399671 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m03:57:15.401547 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 5.3793664, "process_in_blocks": "0", "process_kernel_time": 0.191403, "process_mem_max_rss": "226976", "process_out_blocks": "0", "process_user_time": 4.200798}
[0m03:57:15.402517 [debug] [MainThread]: Command `dbt run` succeeded at 03:57:15.402401 after 5.38 seconds
[0m03:57:15.403554 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3db8d50b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d87841410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3db597e150>]}
[0m03:57:15.404425 [debug] [MainThread]: Flushing usage events
[0m03:57:16.432072 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m07:14:24.057157 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa0e02e3250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa0e02e3050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa0e02e2ed0>]}


============================== 07:14:24.062167 | 9217f315-1bb4-4d1d-a3d5-eb8a8b52fd2f ==============================
[0m07:14:24.062167 [info ] [MainThread]: Running with dbt=1.9.0
[0m07:14:24.063873 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m07:14:24.739792 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '9217f315-1bb4-4d1d-a3d5-eb8a8b52fd2f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa0b247eb10>]}
[0m07:14:24.789404 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '9217f315-1bb4-4d1d-a3d5-eb8a8b52fd2f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa0e256e0d0>]}
[0m07:14:24.790645 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m07:14:24.876192 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m07:14:25.046511 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m07:14:25.047417 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m07:14:25.053276 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project
- models.dbt_project.example
[0m07:14:25.080426 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9217f315-1bb4-4d1d-a3d5-eb8a8b52fd2f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa0e111e0d0>]}
[0m07:14:25.204505 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m07:14:25.213125 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m07:14:25.236328 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9217f315-1bb4-4d1d-a3d5-eb8a8b52fd2f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa0b233e390>]}
[0m07:14:25.237722 [info ] [MainThread]: Found 4 models, 4 sources, 487 macros
[0m07:14:25.238754 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9217f315-1bb4-4d1d-a3d5-eb8a8b52fd2f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa0e2662310>]}
[0m07:14:25.243057 [info ] [MainThread]: 
[0m07:14:25.244300 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m07:14:25.245371 [info ] [MainThread]: 
[0m07:14:25.246653 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m07:14:25.251061 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m07:14:25.252149 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:14:25.932829 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m07:14:25.934527 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m07:14:26.181470 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9217f315-1bb4-4d1d-a3d5-eb8a8b52fd2f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa0e08c53d0>]}
[0m07:14:26.183857 [debug] [MainThread]: Opening a new connection, currently in state init
[0m07:14:26.191654 [debug] [Thread-1 (]: Began running node model.hailing_project.stg_customer
[0m07:14:26.192053 [debug] [Thread-2 (]: Began running node model.hailing_project.stg_driver
[0m07:14:26.192475 [debug] [Thread-3 (]: Began running node model.hailing_project.stg_ride
[0m07:14:26.192840 [debug] [Thread-4 (]: Began running node model.hailing_project.stg_vehicle
[0m07:14:26.193442 [info ] [Thread-1 (]: 1 of 4 START sql incremental model rizky_dwh_hailing_source.stg_customer ....... [RUN]
[0m07:14:26.196094 [info ] [Thread-2 (]: 2 of 4 START sql incremental model rizky_dwh_hailing_source.stg_driver ......... [RUN]
[0m07:14:26.197379 [info ] [Thread-3 (]: 3 of 4 START sql incremental model rizky_dwh_hailing_source.stg_ride ........... [RUN]
[0m07:14:26.198742 [info ] [Thread-4 (]: 4 of 4 START sql incremental model rizky_dwh_hailing_source.stg_vehicle ........ [RUN]
[0m07:14:26.199964 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.stg_customer)
[0m07:14:26.203516 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.stg_driver'
[0m07:14:26.204699 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.stg_ride'
[0m07:14:26.206016 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.stg_vehicle'
[0m07:14:26.206896 [debug] [Thread-1 (]: Began compiling node model.hailing_project.stg_customer
[0m07:14:26.209575 [debug] [Thread-2 (]: Began compiling node model.hailing_project.stg_driver
[0m07:14:26.210992 [debug] [Thread-3 (]: Began compiling node model.hailing_project.stg_ride
[0m07:14:26.212091 [debug] [Thread-4 (]: Began compiling node model.hailing_project.stg_vehicle
[0m07:14:26.222007 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.stg_customer"
[0m07:14:26.226201 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.stg_driver"
[0m07:14:26.232466 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.stg_ride"
[0m07:14:26.237762 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.stg_vehicle"
[0m07:14:26.253551 [debug] [Thread-2 (]: Began executing node model.hailing_project.stg_driver
[0m07:14:26.255208 [debug] [Thread-3 (]: Began executing node model.hailing_project.stg_ride
[0m07:14:26.266408 [debug] [Thread-4 (]: Began executing node model.hailing_project.stg_vehicle
[0m07:14:26.289452 [debug] [Thread-1 (]: Began executing node model.hailing_project.stg_customer
[0m07:14:26.329708 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m07:14:26.331299 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m07:14:26.334154 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m07:14:26.337479 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m07:14:26.663888 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.stg_ride"
[0m07:14:26.666159 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.stg_driver"
[0m07:14:26.667965 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.stg_vehicle"
[0m07:14:26.669058 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.stg_customer"
[0m07:14:26.686209 [debug] [Thread-2 (]: On model.hailing_project.stg_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_driver_source`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m07:14:26.692104 [debug] [Thread-3 (]: On model.hailing_project.stg_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_ride_source`
)

SELECT *
FROM source
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m07:14:26.692943 [debug] [Thread-4 (]: On model.hailing_project.stg_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_vehicle_source`
)

SELECT *
FROM source
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m07:14:26.695761 [debug] [Thread-1 (]: On model.hailing_project.stg_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_customer_source`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m07:14:27.289022 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:0bb9971d-ed97-4412-8de7-1cd4eb96858a&page=queryresults
[0m07:14:27.534418 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:30b64f7e-61b1-4cc3-88a0-49449c954f94&page=queryresults
[0m07:14:27.539028 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:5f5e5bea-79f6-44ed-b2be-3149264083f8&page=queryresults
[0m07:14:28.140278 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:7df0087e-63ef-46b7-9232-2f978ab7357a&page=queryresults
[0m07:14:29.295070 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9217f315-1bb4-4d1d-a3d5-eb8a8b52fd2f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa0e08735d0>]}
[0m07:14:29.296256 [info ] [Thread-1 (]: 1 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_customer .. [[32mMERGE (70.0 rows, 9.5 KiB processed)[0m in 3.09s]
[0m07:14:29.297908 [debug] [Thread-1 (]: Finished running node model.hailing_project.stg_customer
[0m07:14:29.474888 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9217f315-1bb4-4d1d-a3d5-eb8a8b52fd2f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa0e10afa90>]}
[0m07:14:29.476368 [info ] [Thread-4 (]: 4 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_vehicle ... [[32mMERGE (70.0 rows, 7.7 KiB processed)[0m in 3.27s]
[0m07:14:29.477631 [debug] [Thread-4 (]: Finished running node model.hailing_project.stg_vehicle
[0m07:14:29.667286 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9217f315-1bb4-4d1d-a3d5-eb8a8b52fd2f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa0b2142dd0>]}
[0m07:14:29.669166 [info ] [Thread-3 (]: 3 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_ride ...... [[32mMERGE (70.0 rows, 12.4 KiB processed)[0m in 3.46s]
[0m07:14:29.671011 [debug] [Thread-3 (]: Finished running node model.hailing_project.stg_ride
[0m07:14:30.129711 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9217f315-1bb4-4d1d-a3d5-eb8a8b52fd2f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa0e02e9b90>]}
[0m07:14:30.130940 [info ] [Thread-2 (]: 2 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_driver .... [[32mMERGE (70.0 rows, 9.4 KiB processed)[0m in 3.93s]
[0m07:14:30.133340 [debug] [Thread-2 (]: Finished running node model.hailing_project.stg_driver
[0m07:14:30.135664 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m07:14:30.138650 [debug] [MainThread]: Connection 'master' was properly closed.
[0m07:14:30.139566 [debug] [MainThread]: Connection 'model.hailing_project.stg_customer' was properly closed.
[0m07:14:30.140512 [debug] [MainThread]: Connection 'model.hailing_project.stg_driver' was properly closed.
[0m07:14:30.141337 [debug] [MainThread]: Connection 'model.hailing_project.stg_ride' was properly closed.
[0m07:14:30.142170 [debug] [MainThread]: Connection 'model.hailing_project.stg_vehicle' was properly closed.
[0m07:14:30.143229 [info ] [MainThread]: 
[0m07:14:30.144330 [info ] [MainThread]: Finished running 4 incremental models in 0 hours 0 minutes and 4.90 seconds (4.90s).
[0m07:14:30.146268 [debug] [MainThread]: Command end result
[0m07:14:30.181117 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m07:14:30.186507 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m07:14:30.194413 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m07:14:30.195439 [info ] [MainThread]: 
[0m07:14:30.196633 [info ] [MainThread]: [32mCompleted successfully[0m
[0m07:14:30.197755 [info ] [MainThread]: 
[0m07:14:30.198773 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m07:14:30.200481 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 6.2747736, "process_in_blocks": "0", "process_kernel_time": 0.386009, "process_mem_max_rss": "222724", "process_out_blocks": "0", "process_user_time": 3.741319}
[0m07:14:30.201630 [debug] [MainThread]: Command `dbt run` succeeded at 07:14:30.201452 after 6.28 seconds
[0m07:14:30.202788 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa0e035f910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa0e035f690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa0e3adcb90>]}
[0m07:14:30.203700 [debug] [MainThread]: Flushing usage events
[0m07:14:31.324369 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m07:30:49.092343 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb243071950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb243073710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb243072a10>]}


============================== 07:30:49.094968 | 9728cfc1-1b6b-4ee8-80a0-6b8a1269ab91 ==============================
[0m07:30:49.094968 [info ] [MainThread]: Running with dbt=1.9.0
[0m07:30:49.096823 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m07:30:49.662161 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '9728cfc1-1b6b-4ee8-80a0-6b8a1269ab91', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb243185d50>]}
[0m07:30:49.707859 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '9728cfc1-1b6b-4ee8-80a0-6b8a1269ab91', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb2452f4e50>]}
[0m07:30:49.709238 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m07:30:49.773126 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m07:30:49.898481 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 4 files changed.
[0m07:30:49.899480 [debug] [MainThread]: Partial parsing: added file: hailing_project://macros/check_if_incremental.sql
[0m07:30:49.900583 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/staging/stg_ride.sql
[0m07:30:49.901425 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/staging/stg_driver.sql
[0m07:30:49.902315 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/staging/stg_vehicle.sql
[0m07:30:49.903057 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/staging/stg_customer.sql
[0m07:30:50.157347 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project
- models.dbt_project.example
[0m07:30:50.169781 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9728cfc1-1b6b-4ee8-80a0-6b8a1269ab91', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb218f507d0>]}
[0m07:30:50.249233 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m07:30:50.255615 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m07:30:50.270170 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9728cfc1-1b6b-4ee8-80a0-6b8a1269ab91', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb218f04450>]}
[0m07:30:50.271348 [info ] [MainThread]: Found 4 models, 4 sources, 488 macros
[0m07:30:50.272388 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9728cfc1-1b6b-4ee8-80a0-6b8a1269ab91', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb218d4e5d0>]}
[0m07:30:50.275228 [info ] [MainThread]: 
[0m07:30:50.276310 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m07:30:50.277605 [info ] [MainThread]: 
[0m07:30:50.279144 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m07:30:50.284100 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m07:30:50.285414 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:30:50.877964 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m07:30:50.879091 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m07:30:51.124803 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9728cfc1-1b6b-4ee8-80a0-6b8a1269ab91', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb218d4d4d0>]}
[0m07:30:51.126503 [debug] [MainThread]: Opening a new connection, currently in state init
[0m07:30:51.132518 [debug] [Thread-1 (]: Began running node model.hailing_project.stg_customer
[0m07:30:51.132941 [debug] [Thread-2 (]: Began running node model.hailing_project.stg_driver
[0m07:30:51.134089 [debug] [Thread-3 (]: Began running node model.hailing_project.stg_ride
[0m07:30:51.134510 [debug] [Thread-4 (]: Began running node model.hailing_project.stg_vehicle
[0m07:30:51.135150 [info ] [Thread-1 (]: 1 of 4 START sql incremental model rizky_dwh_hailing_source.stg_customer ....... [RUN]
[0m07:30:51.136590 [info ] [Thread-2 (]: 2 of 4 START sql incremental model rizky_dwh_hailing_source.stg_driver ......... [RUN]
[0m07:30:51.137744 [info ] [Thread-3 (]: 3 of 4 START sql incremental model rizky_dwh_hailing_source.stg_ride ........... [RUN]
[0m07:30:51.138924 [info ] [Thread-4 (]: 4 of 4 START sql incremental model rizky_dwh_hailing_source.stg_vehicle ........ [RUN]
[0m07:30:51.139939 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.stg_customer)
[0m07:30:51.141051 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.stg_driver'
[0m07:30:51.142063 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.stg_ride'
[0m07:30:51.142952 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.stg_vehicle'
[0m07:30:51.143863 [debug] [Thread-1 (]: Began compiling node model.hailing_project.stg_customer
[0m07:30:51.144646 [debug] [Thread-2 (]: Began compiling node model.hailing_project.stg_driver
[0m07:30:51.145421 [debug] [Thread-3 (]: Began compiling node model.hailing_project.stg_ride
[0m07:30:51.146314 [debug] [Thread-4 (]: Began compiling node model.hailing_project.stg_vehicle
[0m07:30:51.156291 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.stg_customer"
[0m07:30:51.160500 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.stg_driver"
[0m07:30:51.165748 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.stg_ride"
[0m07:30:51.169689 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.stg_vehicle"
[0m07:30:51.175006 [debug] [Thread-4 (]: Began executing node model.hailing_project.stg_vehicle
[0m07:30:51.175513 [debug] [Thread-1 (]: Began executing node model.hailing_project.stg_customer
[0m07:30:51.181812 [debug] [Thread-3 (]: Began executing node model.hailing_project.stg_ride
[0m07:30:51.192903 [debug] [Thread-2 (]: Began executing node model.hailing_project.stg_driver
[0m07:30:51.213840 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m07:30:51.216169 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m07:30:51.219998 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m07:30:51.223265 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m07:30:51.477753 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.stg_vehicle"
[0m07:30:51.486710 [debug] [Thread-4 (]: On model.hailing_project.stg_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_vehicle_source`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`stg_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m07:30:51.495854 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.stg_customer"
[0m07:30:51.501589 [debug] [Thread-1 (]: On model.hailing_project.stg_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_customer_source`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`stg_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m07:30:51.503763 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.stg_ride"
[0m07:30:51.511415 [debug] [Thread-3 (]: On model.hailing_project.stg_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_ride_source`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`stg_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m07:30:51.532187 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.stg_driver"
[0m07:30:51.538923 [debug] [Thread-2 (]: On model.hailing_project.stg_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_driver_source`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`stg_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m07:30:51.802681 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:090693f2-a77b-4dc8-a974-f80c6d37090c&page=queryresults
[0m07:30:51.866937 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:d1f396e0-69ee-46d7-be88-08796ccc7b23&page=queryresults
[0m07:30:52.912257 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:50043940-5a09-439b-8426-768bd85eb2cb&page=queryresults
[0m07:30:52.914930 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:fd6c4e65-9a9f-4e70-89dd-ccfa76572ad6&page=queryresults
[0m07:30:53.702659 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9728cfc1-1b6b-4ee8-80a0-6b8a1269ab91', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb218e9c590>]}
[0m07:30:53.703990 [info ] [Thread-4 (]: 4 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_vehicle ... [[32mMERGE (0.0 rows, 7.7 KiB processed)[0m in 2.56s]
[0m07:30:53.706127 [debug] [Thread-4 (]: Finished running node model.hailing_project.stg_vehicle
[0m07:30:53.754802 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9728cfc1-1b6b-4ee8-80a0-6b8a1269ab91', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb218ddbb90>]}
[0m07:30:53.756838 [info ] [Thread-1 (]: 1 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_customer .. [[32mMERGE (0.0 rows, 9.5 KiB processed)[0m in 2.61s]
[0m07:30:53.758693 [debug] [Thread-1 (]: Finished running node model.hailing_project.stg_customer
[0m07:30:54.561517 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9728cfc1-1b6b-4ee8-80a0-6b8a1269ab91', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb218dee910>]}
[0m07:30:54.564764 [info ] [Thread-2 (]: 2 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_driver .... [[32mMERGE (0.0 rows, 9.4 KiB processed)[0m in 3.42s]
[0m07:30:54.567154 [debug] [Thread-2 (]: Finished running node model.hailing_project.stg_driver
[0m07:30:54.798589 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9728cfc1-1b6b-4ee8-80a0-6b8a1269ab91', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb218ddc590>]}
[0m07:30:54.799938 [info ] [Thread-3 (]: 3 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_ride ...... [[32mMERGE (0.0 rows, 12.4 KiB processed)[0m in 3.66s]
[0m07:30:54.801464 [debug] [Thread-3 (]: Finished running node model.hailing_project.stg_ride
[0m07:30:54.804555 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m07:30:54.807896 [debug] [MainThread]: Connection 'master' was properly closed.
[0m07:30:54.808619 [debug] [MainThread]: Connection 'model.hailing_project.stg_customer' was properly closed.
[0m07:30:54.809528 [debug] [MainThread]: Connection 'model.hailing_project.stg_driver' was properly closed.
[0m07:30:54.810651 [debug] [MainThread]: Connection 'model.hailing_project.stg_ride' was properly closed.
[0m07:30:54.811606 [debug] [MainThread]: Connection 'model.hailing_project.stg_vehicle' was properly closed.
[0m07:30:54.812830 [info ] [MainThread]: 
[0m07:30:54.814584 [info ] [MainThread]: Finished running 4 incremental models in 0 hours 0 minutes and 4.53 seconds (4.53s).
[0m07:30:54.816849 [debug] [MainThread]: Command end result
[0m07:30:54.849859 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m07:30:54.854511 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m07:30:54.863605 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m07:30:54.864344 [info ] [MainThread]: 
[0m07:30:54.865567 [info ] [MainThread]: [32mCompleted successfully[0m
[0m07:30:54.866583 [info ] [MainThread]: 
[0m07:30:54.867577 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m07:30:54.869308 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 5.824409, "process_in_blocks": "0", "process_kernel_time": 0.194672, "process_mem_max_rss": "226324", "process_out_blocks": "0", "process_user_time": 3.463129}
[0m07:30:54.870348 [debug] [MainThread]: Command `dbt run` succeeded at 07:30:54.870241 after 5.83 seconds
[0m07:30:54.871225 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb2469f1350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb2469f10d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb2469f1250>]}
[0m07:30:54.872311 [debug] [MainThread]: Flushing usage events
[0m07:30:55.990910 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m07:42:35.533356 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fda004fad10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fda004fa310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fda004fac90>]}


============================== 07:42:35.536888 | 3b0b4895-c001-42c0-9901-b182671f7801 ==============================
[0m07:42:35.536888 [info ] [MainThread]: Running with dbt=1.9.0
[0m07:42:35.538473 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt run', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m07:42:36.138255 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '3b0b4895-c001-42c0-9901-b182671f7801', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd9d2e81450>]}
[0m07:42:36.197358 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '3b0b4895-c001-42c0-9901-b182671f7801', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fda027ae2d0>]}
[0m07:42:36.198620 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m07:42:36.276413 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m07:42:36.427590 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m07:42:36.428428 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m07:42:36.433150 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project
- models.dbt_project.example
[0m07:42:36.457172 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3b0b4895-c001-42c0-9901-b182671f7801', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd9d2807790>]}
[0m07:42:36.590853 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m07:42:36.597347 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m07:42:36.615077 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3b0b4895-c001-42c0-9901-b182671f7801', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd9d25779d0>]}
[0m07:42:36.616421 [info ] [MainThread]: Found 4 models, 4 sources, 488 macros
[0m07:42:36.617623 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3b0b4895-c001-42c0-9901-b182671f7801', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fda01d2aa50>]}
[0m07:42:36.620269 [info ] [MainThread]: 
[0m07:42:36.621304 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m07:42:36.622260 [info ] [MainThread]: 
[0m07:42:36.623673 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m07:42:36.629307 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m07:42:36.630232 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:42:37.168645 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m07:42:37.169482 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m07:42:37.359274 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3b0b4895-c001-42c0-9901-b182671f7801', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd9d29c77d0>]}
[0m07:42:37.360592 [debug] [MainThread]: Opening a new connection, currently in state init
[0m07:42:37.366038 [debug] [Thread-1 (]: Began running node model.hailing_project.stg_customer
[0m07:42:37.366422 [debug] [Thread-2 (]: Began running node model.hailing_project.stg_driver
[0m07:42:37.366910 [debug] [Thread-3 (]: Began running node model.hailing_project.stg_ride
[0m07:42:37.367290 [debug] [Thread-4 (]: Began running node model.hailing_project.stg_vehicle
[0m07:42:37.368112 [info ] [Thread-1 (]: 1 of 4 START sql incremental model rizky_dwh_hailing_source.stg_customer ....... [RUN]
[0m07:42:37.369831 [info ] [Thread-2 (]: 2 of 4 START sql incremental model rizky_dwh_hailing_source.stg_driver ......... [RUN]
[0m07:42:37.370910 [info ] [Thread-3 (]: 3 of 4 START sql incremental model rizky_dwh_hailing_source.stg_ride ........... [RUN]
[0m07:42:37.372130 [info ] [Thread-4 (]: 4 of 4 START sql incremental model rizky_dwh_hailing_source.stg_vehicle ........ [RUN]
[0m07:42:37.373291 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.stg_customer)
[0m07:42:37.374617 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.stg_driver'
[0m07:42:37.376171 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.stg_ride'
[0m07:42:37.377221 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.stg_vehicle'
[0m07:42:37.378030 [debug] [Thread-1 (]: Began compiling node model.hailing_project.stg_customer
[0m07:42:37.379097 [debug] [Thread-2 (]: Began compiling node model.hailing_project.stg_driver
[0m07:42:37.380111 [debug] [Thread-3 (]: Began compiling node model.hailing_project.stg_ride
[0m07:42:37.381012 [debug] [Thread-4 (]: Began compiling node model.hailing_project.stg_vehicle
[0m07:42:37.398034 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.stg_customer"
[0m07:42:37.401786 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.stg_driver"
[0m07:42:37.406678 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.stg_ride"
[0m07:42:37.411604 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.stg_vehicle"
[0m07:42:37.417003 [debug] [Thread-2 (]: Began executing node model.hailing_project.stg_driver
[0m07:42:37.417593 [debug] [Thread-3 (]: Began executing node model.hailing_project.stg_ride
[0m07:42:37.418344 [debug] [Thread-1 (]: Began executing node model.hailing_project.stg_customer
[0m07:42:37.436542 [debug] [Thread-4 (]: Began executing node model.hailing_project.stg_vehicle
[0m07:42:37.465613 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m07:42:37.468608 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m07:42:37.471307 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m07:42:37.475882 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m07:42:37.750408 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.stg_ride"
[0m07:42:37.752883 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.stg_driver"
[0m07:42:37.754469 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.stg_customer"
[0m07:42:37.760311 [debug] [Thread-3 (]: On model.hailing_project.stg_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_ride_source`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`stg_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m07:42:37.761455 [debug] [Thread-1 (]: On model.hailing_project.stg_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_customer_source`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`stg_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m07:42:37.763542 [debug] [Thread-2 (]: On model.hailing_project.stg_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_driver_source`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`stg_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m07:42:37.767001 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.stg_vehicle"
[0m07:42:37.775191 [debug] [Thread-4 (]: On model.hailing_project.stg_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_vehicle_source`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`stg_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m07:42:38.030298 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:48c61271-4f05-40fe-a346-89e53ea76384&page=queryresults
[0m07:42:38.038643 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:7c53dd75-39f1-4742-9386-016641bb0607&page=queryresults
[0m07:42:39.110434 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:8c792602-497d-4efe-aaf1-5997c496371b&page=queryresults
[0m07:42:39.111976 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:4eb10280-dad4-41fb-9670-9016ab9bc08e&page=queryresults
[0m07:42:39.873799 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3b0b4895-c001-42c0-9901-b182671f7801', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd9d28c1b50>]}
[0m07:42:39.874953 [info ] [Thread-3 (]: 3 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_ride ...... [[32mMERGE (15.0 rows, 13.8 KiB processed)[0m in 2.50s]
[0m07:42:39.876635 [debug] [Thread-3 (]: Finished running node model.hailing_project.stg_ride
[0m07:42:39.910703 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3b0b4895-c001-42c0-9901-b182671f7801', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd9d2535450>]}
[0m07:42:39.912022 [info ] [Thread-2 (]: 2 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_driver .... [[32mMERGE (15.0 rows, 10.5 KiB processed)[0m in 2.54s]
[0m07:42:39.913738 [debug] [Thread-2 (]: Finished running node model.hailing_project.stg_driver
[0m07:42:40.607381 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3b0b4895-c001-42c0-9901-b182671f7801', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fda00a8fe50>]}
[0m07:42:40.609295 [info ] [Thread-1 (]: 1 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_customer .. [[32mMERGE (15.0 rows, 10.5 KiB processed)[0m in 3.23s]
[0m07:42:40.610912 [debug] [Thread-1 (]: Finished running node model.hailing_project.stg_customer
[0m07:42:40.629043 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3b0b4895-c001-42c0-9901-b182671f7801', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fda0052db10>]}
[0m07:42:40.631131 [info ] [Thread-4 (]: 4 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_vehicle ... [[32mMERGE (15.0 rows, 8.5 KiB processed)[0m in 3.25s]
[0m07:42:40.633420 [debug] [Thread-4 (]: Finished running node model.hailing_project.stg_vehicle
[0m07:42:40.636556 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m07:42:40.639742 [debug] [MainThread]: Connection 'master' was properly closed.
[0m07:42:40.640702 [debug] [MainThread]: Connection 'model.hailing_project.stg_customer' was properly closed.
[0m07:42:40.641409 [debug] [MainThread]: Connection 'model.hailing_project.stg_driver' was properly closed.
[0m07:42:40.642052 [debug] [MainThread]: Connection 'model.hailing_project.stg_ride' was properly closed.
[0m07:42:40.642883 [debug] [MainThread]: Connection 'model.hailing_project.stg_vehicle' was properly closed.
[0m07:42:40.644114 [info ] [MainThread]: 
[0m07:42:40.645495 [info ] [MainThread]: Finished running 4 incremental models in 0 hours 0 minutes and 4.02 seconds (4.02s).
[0m07:42:40.647562 [debug] [MainThread]: Command end result
[0m07:42:40.684982 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m07:42:40.689692 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m07:42:40.698032 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m07:42:40.698780 [info ] [MainThread]: 
[0m07:42:40.699834 [info ] [MainThread]: [32mCompleted successfully[0m
[0m07:42:40.700859 [info ] [MainThread]: 
[0m07:42:40.701995 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m07:42:40.703611 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 5.221707, "process_in_blocks": "0", "process_kernel_time": 0.271276, "process_mem_max_rss": "222804", "process_out_blocks": "0", "process_user_time": 3.345746}
[0m07:42:40.704672 [debug] [MainThread]: Command `dbt run` succeeded at 07:42:40.704554 after 5.22 seconds
[0m07:42:40.705678 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fda03e13e10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fda03d2cc10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fda008f65d0>]}
[0m07:42:40.706704 [debug] [MainThread]: Flushing usage events
[0m07:42:41.823814 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m08:18:12.432832 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc75201efd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc75201ecd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc75201ec90>]}


============================== 08:18:12.436866 | 873b1c9b-3fbb-4208-95d5-5d3038cd76f1 ==============================
[0m08:18:12.436866 [info ] [MainThread]: Running with dbt=1.9.0
[0m08:18:12.438432 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt run', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m08:18:13.019581 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '873b1c9b-3fbb-4208-95d5-5d3038cd76f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc7281f7fd0>]}
[0m08:18:13.068481 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '873b1c9b-3fbb-4208-95d5-5d3038cd76f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc7542cc9d0>]}
[0m08:18:13.069551 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m08:18:13.133470 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m08:18:13.303393 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m08:18:13.304297 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m08:18:13.309036 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.example
- models.dbt_project
[0m08:18:13.334214 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '873b1c9b-3fbb-4208-95d5-5d3038cd76f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc728340610>]}
[0m08:18:13.454205 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m08:18:13.459718 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m08:18:13.473409 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '873b1c9b-3fbb-4208-95d5-5d3038cd76f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc730bcc350>]}
[0m08:18:13.474285 [info ] [MainThread]: Found 4 models, 4 sources, 488 macros
[0m08:18:13.475356 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '873b1c9b-3fbb-4208-95d5-5d3038cd76f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc7283d30d0>]}
[0m08:18:13.478100 [info ] [MainThread]: 
[0m08:18:13.479228 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m08:18:13.480274 [info ] [MainThread]: 
[0m08:18:13.481633 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m08:18:13.486338 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m08:18:13.487277 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:18:14.120962 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m08:18:14.123822 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:18:14.328906 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '873b1c9b-3fbb-4208-95d5-5d3038cd76f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc7298132d0>]}
[0m08:18:14.330246 [debug] [MainThread]: Opening a new connection, currently in state init
[0m08:18:14.335727 [debug] [Thread-1 (]: Began running node model.hailing_project.stg_customer
[0m08:18:14.336095 [debug] [Thread-2 (]: Began running node model.hailing_project.stg_driver
[0m08:18:14.336501 [debug] [Thread-3 (]: Began running node model.hailing_project.stg_ride
[0m08:18:14.337017 [debug] [Thread-4 (]: Began running node model.hailing_project.stg_vehicle
[0m08:18:14.337710 [info ] [Thread-1 (]: 1 of 4 START sql incremental model rizky_dwh_hailing_source.stg_customer ....... [RUN]
[0m08:18:14.339459 [info ] [Thread-2 (]: 2 of 4 START sql incremental model rizky_dwh_hailing_source.stg_driver ......... [RUN]
[0m08:18:14.340884 [info ] [Thread-3 (]: 3 of 4 START sql incremental model rizky_dwh_hailing_source.stg_ride ........... [RUN]
[0m08:18:14.342085 [info ] [Thread-4 (]: 4 of 4 START sql incremental model rizky_dwh_hailing_source.stg_vehicle ........ [RUN]
[0m08:18:14.343308 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.stg_customer)
[0m08:18:14.344823 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.stg_driver'
[0m08:18:14.345920 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.stg_ride'
[0m08:18:14.346739 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.stg_vehicle'
[0m08:18:14.347521 [debug] [Thread-1 (]: Began compiling node model.hailing_project.stg_customer
[0m08:18:14.348287 [debug] [Thread-2 (]: Began compiling node model.hailing_project.stg_driver
[0m08:18:14.348945 [debug] [Thread-3 (]: Began compiling node model.hailing_project.stg_ride
[0m08:18:14.349605 [debug] [Thread-4 (]: Began compiling node model.hailing_project.stg_vehicle
[0m08:18:14.364590 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.stg_customer"
[0m08:18:14.368731 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.stg_driver"
[0m08:18:14.373105 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.stg_ride"
[0m08:18:14.376836 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.stg_vehicle"
[0m08:18:14.382847 [debug] [Thread-2 (]: Began executing node model.hailing_project.stg_driver
[0m08:18:14.383522 [debug] [Thread-4 (]: Began executing node model.hailing_project.stg_vehicle
[0m08:18:14.389653 [debug] [Thread-1 (]: Began executing node model.hailing_project.stg_customer
[0m08:18:14.400012 [debug] [Thread-3 (]: Began executing node model.hailing_project.stg_ride
[0m08:18:14.429197 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m08:18:14.429478 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m08:18:14.432490 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m08:18:14.435631 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m08:18:14.726733 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.stg_driver"
[0m08:18:14.728540 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.stg_customer"
[0m08:18:14.729286 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.stg_vehicle"
[0m08:18:14.730515 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.stg_ride"
[0m08:18:14.735505 [debug] [Thread-2 (]: On model.hailing_project.stg_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_driver_source`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`stg_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m08:18:14.736582 [debug] [Thread-3 (]: On model.hailing_project.stg_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_ride_source`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`stg_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m08:18:14.738965 [debug] [Thread-1 (]: On model.hailing_project.stg_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_customer_source`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`stg_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m08:18:14.739581 [debug] [Thread-4 (]: On model.hailing_project.stg_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_vehicle_source`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`stg_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m08:18:15.072113 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:49718984-e9aa-404c-99c2-2a8a9ee4778a&page=queryresults
[0m08:18:15.075968 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:c27e9b31-331d-4ef1-a721-af21532687e2&page=queryresults
[0m08:18:15.078186 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:a07a28b7-71de-49a1-880d-3110dd9b5c5f&page=queryresults
[0m08:18:15.078652 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:b6fb1980-78c9-41e3-8fef-05578a1c4be1&page=queryresults
[0m08:18:16.682071 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '873b1c9b-3fbb-4208-95d5-5d3038cd76f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc728327bd0>]}
[0m08:18:16.682628 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '873b1c9b-3fbb-4208-95d5-5d3038cd76f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc720185590>]}
[0m08:18:16.682909 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '873b1c9b-3fbb-4208-95d5-5d3038cd76f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc728236210>]}
[0m08:18:16.683860 [info ] [Thread-4 (]: 4 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_vehicle ... [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.33s]
[0m08:18:16.685961 [info ] [Thread-2 (]: 2 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_driver .... [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.34s]
[0m08:18:16.687373 [info ] [Thread-3 (]: 3 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_ride ...... [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.34s]
[0m08:18:16.688659 [debug] [Thread-4 (]: Finished running node model.hailing_project.stg_vehicle
[0m08:18:16.690023 [debug] [Thread-2 (]: Finished running node model.hailing_project.stg_driver
[0m08:18:16.691368 [debug] [Thread-3 (]: Finished running node model.hailing_project.stg_ride
[0m08:18:16.925810 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '873b1c9b-3fbb-4208-95d5-5d3038cd76f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc7284a0490>]}
[0m08:18:16.928615 [info ] [Thread-1 (]: 1 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_customer .. [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.58s]
[0m08:18:16.931276 [debug] [Thread-1 (]: Finished running node model.hailing_project.stg_customer
[0m08:18:16.933597 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m08:18:16.936740 [debug] [MainThread]: Connection 'master' was properly closed.
[0m08:18:16.937819 [debug] [MainThread]: Connection 'model.hailing_project.stg_customer' was properly closed.
[0m08:18:16.938708 [debug] [MainThread]: Connection 'model.hailing_project.stg_driver' was properly closed.
[0m08:18:16.939486 [debug] [MainThread]: Connection 'model.hailing_project.stg_ride' was properly closed.
[0m08:18:16.940531 [debug] [MainThread]: Connection 'model.hailing_project.stg_vehicle' was properly closed.
[0m08:18:16.941790 [info ] [MainThread]: 
[0m08:18:16.943806 [info ] [MainThread]: Finished running 4 incremental models in 0 hours 0 minutes and 3.46 seconds (3.46s).
[0m08:18:16.945513 [debug] [MainThread]: Command end result
[0m08:18:16.989803 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m08:18:16.997847 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m08:18:17.006172 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m08:18:17.007010 [info ] [MainThread]: 
[0m08:18:17.008111 [info ] [MainThread]: [32mCompleted successfully[0m
[0m08:18:17.009185 [info ] [MainThread]: 
[0m08:18:17.010118 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m08:18:17.011798 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 4.648351, "process_in_blocks": "0", "process_kernel_time": 0.190411, "process_mem_max_rss": "223264", "process_out_blocks": "0", "process_user_time": 3.397345}
[0m08:18:17.012890 [debug] [MainThread]: Command `dbt run` succeeded at 08:18:17.012744 after 4.65 seconds
[0m08:18:17.013849 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc755874b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc7559d1190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc7559d1150>]}
[0m08:18:17.014724 [debug] [MainThread]: Flushing usage events
[0m08:18:18.388019 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m08:21:35.277834 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faa71026ed0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faa71077610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faa714229d0>]}


============================== 08:21:35.280368 | e7dbe8e6-b9b2-4380-bcf9-6a7a4dcf4949 ==============================
[0m08:21:35.280368 [info ] [MainThread]: Running with dbt=1.9.0
[0m08:21:35.282387 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt run', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m08:21:35.849786 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e7dbe8e6-b9b2-4380-bcf9-6a7a4dcf4949', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faa437f7d90>]}
[0m08:21:35.897980 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e7dbe8e6-b9b2-4380-bcf9-6a7a4dcf4949', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faa4394edd0>]}
[0m08:21:35.899081 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m08:21:35.965936 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m08:21:36.099694 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m08:21:36.101230 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/staging/sources.yml
[0m08:21:36.392563 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.hailing_project.stg_customer' (models/staging/stg_customer.sql) depends on a source named 'source.customer_data' which was not found
[0m08:21:36.394691 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.1627843, "process_in_blocks": "0", "process_kernel_time": 0.201076, "process_mem_max_rss": "215860", "process_out_blocks": "0", "process_user_time": 2.996037}
[0m08:21:36.395751 [debug] [MainThread]: Command `dbt run` failed at 08:21:36.395644 after 1.16 seconds
[0m08:21:36.396832 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faa710857d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faa714228d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faa749a1210>]}
[0m08:21:36.397751 [debug] [MainThread]: Flushing usage events
[0m08:21:37.585841 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m08:21:58.696691 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb527357190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb527357150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb527357390>]}


============================== 08:21:58.699223 | 3ac88093-f584-4fae-8042-6fc9b98c9baf ==============================
[0m08:21:58.699223 [info ] [MainThread]: Running with dbt=1.9.0
[0m08:21:58.701425 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m08:21:59.258717 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '3ac88093-f584-4fae-8042-6fc9b98c9baf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4f952b4d0>]}
[0m08:21:59.304815 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '3ac88093-f584-4fae-8042-6fc9b98c9baf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb5295aa690>]}
[0m08:21:59.306289 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m08:21:59.373130 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m08:21:59.512444 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m08:21:59.513637 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/staging/sources.yml
[0m08:21:59.686979 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project
- models.dbt_project.example
[0m08:21:59.699330 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3ac88093-f584-4fae-8042-6fc9b98c9baf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4f921f790>]}
[0m08:21:59.771445 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m08:21:59.777832 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m08:21:59.792999 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3ac88093-f584-4fae-8042-6fc9b98c9baf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4f8fc9550>]}
[0m08:21:59.794272 [info ] [MainThread]: Found 4 models, 4 sources, 488 macros
[0m08:21:59.795320 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3ac88093-f584-4fae-8042-6fc9b98c9baf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb527a60c10>]}
[0m08:21:59.798178 [info ] [MainThread]: 
[0m08:21:59.799314 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m08:21:59.800266 [info ] [MainThread]: 
[0m08:21:59.801528 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m08:21:59.806732 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m08:21:59.807705 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:22:00.404796 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m08:22:00.405806 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:22:00.625979 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3ac88093-f584-4fae-8042-6fc9b98c9baf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb5271c8490>]}
[0m08:22:00.627142 [debug] [MainThread]: Opening a new connection, currently in state init
[0m08:22:00.631898 [debug] [Thread-1 (]: Began running node model.hailing_project.stg_customer
[0m08:22:00.632440 [debug] [Thread-2 (]: Began running node model.hailing_project.stg_driver
[0m08:22:00.632851 [debug] [Thread-3 (]: Began running node model.hailing_project.stg_ride
[0m08:22:00.633224 [debug] [Thread-4 (]: Began running node model.hailing_project.stg_vehicle
[0m08:22:00.633784 [info ] [Thread-1 (]: 1 of 4 START sql incremental model rizky_dwh_hailing_source.stg_customer ....... [RUN]
[0m08:22:00.634833 [info ] [Thread-2 (]: 2 of 4 START sql incremental model rizky_dwh_hailing_source.stg_driver ......... [RUN]
[0m08:22:00.635791 [info ] [Thread-3 (]: 3 of 4 START sql incremental model rizky_dwh_hailing_source.stg_ride ........... [RUN]
[0m08:22:00.636717 [info ] [Thread-4 (]: 4 of 4 START sql incremental model rizky_dwh_hailing_source.stg_vehicle ........ [RUN]
[0m08:22:00.637766 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.stg_customer)
[0m08:22:00.638723 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.stg_driver'
[0m08:22:00.639631 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.stg_ride'
[0m08:22:00.640452 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.stg_vehicle'
[0m08:22:00.641237 [debug] [Thread-1 (]: Began compiling node model.hailing_project.stg_customer
[0m08:22:00.641989 [debug] [Thread-2 (]: Began compiling node model.hailing_project.stg_driver
[0m08:22:00.642641 [debug] [Thread-3 (]: Began compiling node model.hailing_project.stg_ride
[0m08:22:00.643469 [debug] [Thread-4 (]: Began compiling node model.hailing_project.stg_vehicle
[0m08:22:00.657714 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.stg_customer"
[0m08:22:00.661531 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.stg_driver"
[0m08:22:00.666182 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.stg_ride"
[0m08:22:00.670362 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.stg_vehicle"
[0m08:22:00.676069 [debug] [Thread-3 (]: Began executing node model.hailing_project.stg_ride
[0m08:22:00.676537 [debug] [Thread-1 (]: Began executing node model.hailing_project.stg_customer
[0m08:22:00.682740 [debug] [Thread-4 (]: Began executing node model.hailing_project.stg_vehicle
[0m08:22:00.683077 [debug] [Thread-2 (]: Began executing node model.hailing_project.stg_driver
[0m08:22:00.728513 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m08:22:00.731399 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m08:22:00.731912 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m08:22:00.735429 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m08:22:01.021917 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.stg_ride"
[0m08:22:01.031763 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.stg_customer"
[0m08:22:01.032304 [debug] [Thread-3 (]: On model.hailing_project.stg_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_ride_source`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`stg_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m08:22:01.040120 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.stg_driver"
[0m08:22:01.042016 [debug] [Thread-1 (]: On model.hailing_project.stg_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_customer_source`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`stg_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m08:22:01.044675 [debug] [Thread-2 (]: On model.hailing_project.stg_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_driver_source`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`stg_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m08:22:01.047051 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.stg_vehicle"
[0m08:22:01.055653 [debug] [Thread-4 (]: On model.hailing_project.stg_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_vehicle_source`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`stg_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m08:22:01.320422 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:bf34a7f2-05d8-4b66-8f93-38355ae08d44&page=queryresults
[0m08:22:01.331037 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:9c67940c-8b6f-440b-8c72-e95e28d6caeb&page=queryresults
[0m08:22:01.346206 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:9fcd591b-0bb1-4f74-87e7-94b821539846&page=queryresults
[0m08:22:01.587215 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:c36f477f-d378-4222-81ba-639f48b9ab5f&page=queryresults
[0m08:22:03.143042 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3ac88093-f584-4fae-8042-6fc9b98c9baf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4f86db890>]}
[0m08:22:03.143483 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3ac88093-f584-4fae-8042-6fc9b98c9baf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4f9060890>]}
[0m08:22:03.144057 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3ac88093-f584-4fae-8042-6fc9b98c9baf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4f9060fd0>]}
[0m08:22:03.144982 [info ] [Thread-3 (]: 3 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_ride ...... [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.50s]
[0m08:22:03.146513 [info ] [Thread-2 (]: 2 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_driver .... [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.50s]
[0m08:22:03.147929 [info ] [Thread-4 (]: 4 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_vehicle ... [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.50s]
[0m08:22:03.149289 [debug] [Thread-3 (]: Finished running node model.hailing_project.stg_ride
[0m08:22:03.150357 [debug] [Thread-2 (]: Finished running node model.hailing_project.stg_driver
[0m08:22:03.151275 [debug] [Thread-4 (]: Finished running node model.hailing_project.stg_vehicle
[0m08:22:03.396862 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3ac88093-f584-4fae-8042-6fc9b98c9baf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4f8696150>]}
[0m08:22:03.398466 [info ] [Thread-1 (]: 1 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_customer .. [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.76s]
[0m08:22:03.399879 [debug] [Thread-1 (]: Finished running node model.hailing_project.stg_customer
[0m08:22:03.402692 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m08:22:03.407263 [debug] [MainThread]: Connection 'master' was properly closed.
[0m08:22:03.408525 [debug] [MainThread]: Connection 'model.hailing_project.stg_customer' was properly closed.
[0m08:22:03.410677 [debug] [MainThread]: Connection 'model.hailing_project.stg_driver' was properly closed.
[0m08:22:03.411769 [debug] [MainThread]: Connection 'model.hailing_project.stg_ride' was properly closed.
[0m08:22:03.412743 [debug] [MainThread]: Connection 'model.hailing_project.stg_vehicle' was properly closed.
[0m08:22:03.414100 [info ] [MainThread]: 
[0m08:22:03.416519 [info ] [MainThread]: Finished running 4 incremental models in 0 hours 0 minutes and 3.61 seconds (3.61s).
[0m08:22:03.419113 [debug] [MainThread]: Command end result
[0m08:22:03.459681 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m08:22:03.464349 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m08:22:03.473447 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m08:22:03.474283 [info ] [MainThread]: 
[0m08:22:03.475524 [info ] [MainThread]: [32mCompleted successfully[0m
[0m08:22:03.476657 [info ] [MainThread]: 
[0m08:22:03.477740 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m08:22:03.479739 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 4.8314342, "process_in_blocks": "0", "process_kernel_time": 0.144241, "process_mem_max_rss": "222996", "process_out_blocks": "0", "process_user_time": 3.451483}
[0m08:22:03.480925 [debug] [MainThread]: Command `dbt run` succeeded at 08:22:03.480799 after 4.83 seconds
[0m08:22:03.481928 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb52ab48c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb52aca5350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb52aca5210>]}
[0m08:22:03.482989 [debug] [MainThread]: Flushing usage events
[0m08:22:04.544138 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m08:22:17.701112 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f44daecbb50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f44dae7b3d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f44dae7aa10>]}


============================== 08:22:17.703736 | b4a8c7b2-0f48-4de6-bf00-984e84d2b338 ==============================
[0m08:22:17.703736 [info ] [MainThread]: Running with dbt=1.9.0
[0m08:22:17.707145 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'version_check': 'True', 'warn_error': 'None', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt run', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m08:22:18.292096 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b4a8c7b2-0f48-4de6-bf00-984e84d2b338', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f44b1103810>]}
[0m08:22:18.337217 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b4a8c7b2-0f48-4de6-bf00-984e84d2b338', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f44b117cf10>]}
[0m08:22:18.338226 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m08:22:18.406073 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m08:22:18.534804 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
[0m08:22:18.536253 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/staging/sources.yml
[0m08:22:18.536954 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/staging/stg_customer.sql
[0m08:22:18.833272 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.hailing_project.stg_driver' (models/staging/stg_driver.sql) depends on a source named 'source.driver_data' which was not found
[0m08:22:18.835370 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.1823285, "process_in_blocks": "0", "process_kernel_time": 0.141755, "process_mem_max_rss": "215568", "process_out_blocks": "0", "process_user_time": 3.057857}
[0m08:22:18.836458 [debug] [MainThread]: Command `dbt run` failed at 08:22:18.836343 after 1.18 seconds
[0m08:22:18.837279 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f44dacf9690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f44dacfba10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f44b0cd05d0>]}
[0m08:22:18.838174 [debug] [MainThread]: Flushing usage events
[0m08:22:19.859620 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m08:22:41.760571 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd38887f150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd388c6e110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd3888c36d0>]}


============================== 08:22:41.764248 | 971611f3-095f-4bdc-adff-384ed1f3b5dd ==============================
[0m08:22:41.764248 [info ] [MainThread]: Running with dbt=1.9.0
[0m08:22:41.766273 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'version_check': 'True', 'warn_error': 'None', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m08:22:42.405008 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '971611f3-095f-4bdc-adff-384ed1f3b5dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd3888df610>]}
[0m08:22:42.454837 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '971611f3-095f-4bdc-adff-384ed1f3b5dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd38ab04a10>]}
[0m08:22:42.456489 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m08:22:42.528347 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m08:22:42.672747 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m08:22:42.673793 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/staging/stg_customer.sql
[0m08:22:43.007607 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project
- models.dbt_project.example
[0m08:22:43.020459 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '971611f3-095f-4bdc-adff-384ed1f3b5dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd35aa23810>]}
[0m08:22:43.100224 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m08:22:43.105650 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m08:22:43.121002 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '971611f3-095f-4bdc-adff-384ed1f3b5dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd35a86ff50>]}
[0m08:22:43.122311 [info ] [MainThread]: Found 4 models, 4 sources, 488 macros
[0m08:22:43.123673 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '971611f3-095f-4bdc-adff-384ed1f3b5dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd35a6d4390>]}
[0m08:22:43.126684 [info ] [MainThread]: 
[0m08:22:43.127817 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m08:22:43.128843 [info ] [MainThread]: 
[0m08:22:43.130513 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m08:22:43.136209 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m08:22:43.137209 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:22:43.637140 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m08:22:43.638417 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:22:43.886919 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '971611f3-095f-4bdc-adff-384ed1f3b5dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd35a673d50>]}
[0m08:22:43.888157 [debug] [MainThread]: Opening a new connection, currently in state init
[0m08:22:43.894076 [debug] [Thread-1 (]: Began running node model.hailing_project.stg_customer
[0m08:22:43.894455 [debug] [Thread-2 (]: Began running node model.hailing_project.stg_driver
[0m08:22:43.894891 [debug] [Thread-3 (]: Began running node model.hailing_project.stg_ride
[0m08:22:43.895213 [debug] [Thread-4 (]: Began running node model.hailing_project.stg_vehicle
[0m08:22:43.895744 [info ] [Thread-1 (]: 1 of 4 START sql incremental model rizky_dwh_hailing_source.stg_customer ....... [RUN]
[0m08:22:43.896819 [info ] [Thread-2 (]: 2 of 4 START sql incremental model rizky_dwh_hailing_source.stg_driver ......... [RUN]
[0m08:22:43.897984 [info ] [Thread-3 (]: 3 of 4 START sql incremental model rizky_dwh_hailing_source.stg_ride ........... [RUN]
[0m08:22:43.899057 [info ] [Thread-4 (]: 4 of 4 START sql incremental model rizky_dwh_hailing_source.stg_vehicle ........ [RUN]
[0m08:22:43.900200 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.stg_customer)
[0m08:22:43.901220 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.stg_driver'
[0m08:22:43.902148 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.stg_ride'
[0m08:22:43.903061 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.stg_vehicle'
[0m08:22:43.903774 [debug] [Thread-1 (]: Began compiling node model.hailing_project.stg_customer
[0m08:22:43.904853 [debug] [Thread-2 (]: Began compiling node model.hailing_project.stg_driver
[0m08:22:43.905711 [debug] [Thread-3 (]: Began compiling node model.hailing_project.stg_ride
[0m08:22:43.906540 [debug] [Thread-4 (]: Began compiling node model.hailing_project.stg_vehicle
[0m08:22:43.916133 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.stg_customer"
[0m08:22:43.920501 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.stg_driver"
[0m08:22:43.925880 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.stg_ride"
[0m08:22:43.930128 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.stg_vehicle"
[0m08:22:43.936002 [debug] [Thread-2 (]: Began executing node model.hailing_project.stg_driver
[0m08:22:43.936673 [debug] [Thread-1 (]: Began executing node model.hailing_project.stg_customer
[0m08:22:43.942979 [debug] [Thread-3 (]: Began executing node model.hailing_project.stg_ride
[0m08:22:43.953090 [debug] [Thread-4 (]: Began executing node model.hailing_project.stg_vehicle
[0m08:22:43.987034 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m08:22:43.987499 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m08:22:43.989835 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m08:22:43.992680 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m08:22:44.286333 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.stg_customer"
[0m08:22:44.288181 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.stg_driver"
[0m08:22:44.292592 [debug] [Thread-1 (]: On model.hailing_project.stg_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_customer_source`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`stg_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m08:22:44.293746 [debug] [Thread-2 (]: On model.hailing_project.stg_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_driver_source`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`stg_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m08:22:44.296363 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.stg_vehicle"
[0m08:22:44.303643 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.stg_ride"
[0m08:22:44.305470 [debug] [Thread-4 (]: On model.hailing_project.stg_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_vehicle_source`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`stg_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m08:22:44.307945 [debug] [Thread-3 (]: On model.hailing_project.stg_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_ride_source`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`stg_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m08:22:44.560086 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:898bc365-4a1b-4083-b8c1-dfc45cf4a1f1&page=queryresults
[0m08:22:44.565353 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:077de461-4221-4a1c-af9d-237cbc305ec8&page=queryresults
[0m08:22:44.731529 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:077de461-4221-4a1c-af9d-237cbc305ec8&page=queryresults
[0m08:22:44.747043 [debug] [Thread-1 (]: Database Error in model stg_customer (models/staging/stg_customer.sql)
  Unrecognized name: created_at_at; Did you mean created_at? at [35:20]
  compiled code at target/run/hailing_project/models/staging/stg_customer.sql
[0m08:22:44.749992 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '971611f3-095f-4bdc-adff-384ed1f3b5dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd358405ed0>]}
[0m08:22:44.751242 [error] [Thread-1 (]: 1 of 4 ERROR creating sql incremental model rizky_dwh_hailing_source.stg_customer  [[31mERROR[0m in 0.85s]
[0m08:22:44.752903 [debug] [Thread-1 (]: Finished running node model.hailing_project.stg_customer
[0m08:22:44.754518 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.stg_customer' to be skipped because of status 'error'.  Reason: Database Error in model stg_customer (models/staging/stg_customer.sql)
  Unrecognized name: created_at_at; Did you mean created_at? at [35:20]
  compiled code at target/run/hailing_project/models/staging/stg_customer.sql.
[0m08:22:44.836801 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:8a6a3c55-e78c-4954-9742-fd78f2485047&page=queryresults
[0m08:22:45.653035 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:ce572007-8886-46ca-9dbb-0cc80cf42a36&page=queryresults
[0m08:22:46.396178 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '971611f3-095f-4bdc-adff-384ed1f3b5dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd35a5a1d10>]}
[0m08:22:46.398178 [info ] [Thread-3 (]: 3 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_ride ...... [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.49s]
[0m08:22:46.399788 [debug] [Thread-3 (]: Finished running node model.hailing_project.stg_ride
[0m08:22:46.895988 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '971611f3-095f-4bdc-adff-384ed1f3b5dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd35842f9d0>]}
[0m08:22:46.897519 [info ] [Thread-4 (]: 4 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_vehicle ... [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.99s]
[0m08:22:46.899179 [debug] [Thread-4 (]: Finished running node model.hailing_project.stg_vehicle
[0m08:22:47.464938 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '971611f3-095f-4bdc-adff-384ed1f3b5dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd35a5a1850>]}
[0m08:22:47.466621 [info ] [Thread-2 (]: 2 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_driver .... [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 3.56s]
[0m08:22:47.468175 [debug] [Thread-2 (]: Finished running node model.hailing_project.stg_driver
[0m08:22:47.470574 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m08:22:47.473975 [debug] [MainThread]: Connection 'master' was properly closed.
[0m08:22:47.474902 [debug] [MainThread]: Connection 'model.hailing_project.stg_customer' was properly closed.
[0m08:22:47.475720 [debug] [MainThread]: Connection 'model.hailing_project.stg_driver' was properly closed.
[0m08:22:47.476571 [debug] [MainThread]: Connection 'model.hailing_project.stg_ride' was properly closed.
[0m08:22:47.477315 [debug] [MainThread]: Connection 'model.hailing_project.stg_vehicle' was properly closed.
[0m08:22:47.478392 [info ] [MainThread]: 
[0m08:22:47.479390 [info ] [MainThread]: Finished running 4 incremental models in 0 hours 0 minutes and 4.35 seconds (4.35s).
[0m08:22:47.482287 [debug] [MainThread]: Command end result
[0m08:22:47.516280 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m08:22:47.520396 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m08:22:47.528804 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m08:22:47.529804 [info ] [MainThread]: 
[0m08:22:47.531162 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m08:22:47.532243 [info ] [MainThread]: 
[0m08:22:47.533362 [error] [MainThread]:   Database Error in model stg_customer (models/staging/stg_customer.sql)
  Unrecognized name: created_at_at; Did you mean created_at? at [35:20]
  compiled code at target/run/hailing_project/models/staging/stg_customer.sql
[0m08:22:47.534328 [info ] [MainThread]: 
[0m08:22:47.535393 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=1 SKIP=0 TOTAL=4
[0m08:22:47.537137 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 5.833213, "process_in_blocks": "448", "process_kernel_time": 0.207239, "process_mem_max_rss": "228060", "process_out_blocks": "0", "process_user_time": 3.621758}
[0m08:22:47.538493 [debug] [MainThread]: Command `dbt run` failed at 08:22:47.538312 after 5.83 seconds
[0m08:22:47.539590 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd3888b5790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd34a6ba050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd3888b4790>]}
[0m08:22:47.540485 [debug] [MainThread]: Flushing usage events
[0m08:22:48.770993 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m08:23:10.006409 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f480d483bd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f480d8d84d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f480d42f050>]}


============================== 08:23:10.009479 | e8c378eb-1201-41dc-995a-5ef9097b55f0 ==============================
[0m08:23:10.009479 [info ] [MainThread]: Running with dbt=1.9.0
[0m08:23:10.010632 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt run', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m08:23:10.703903 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e8c378eb-1201-41dc-995a-5ef9097b55f0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47df546e10>]}
[0m08:23:10.757024 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e8c378eb-1201-41dc-995a-5ef9097b55f0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47e4e14f10>]}
[0m08:23:10.758564 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m08:23:10.834599 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m08:23:10.985412 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m08:23:10.986755 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/staging/stg_customer.sql
[0m08:23:11.270486 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project
- models.dbt_project.example
[0m08:23:11.286192 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e8c378eb-1201-41dc-995a-5ef9097b55f0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47df502290>]}
[0m08:23:11.362266 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m08:23:11.368632 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m08:23:11.383211 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e8c378eb-1201-41dc-995a-5ef9097b55f0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47df19ea10>]}
[0m08:23:11.384297 [info ] [MainThread]: Found 4 models, 4 sources, 488 macros
[0m08:23:11.386028 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e8c378eb-1201-41dc-995a-5ef9097b55f0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47df1a4610>]}
[0m08:23:11.389244 [info ] [MainThread]: 
[0m08:23:11.390372 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m08:23:11.391547 [info ] [MainThread]: 
[0m08:23:11.393473 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m08:23:11.398866 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m08:23:11.400111 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:23:11.874677 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m08:23:11.875625 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:23:12.104283 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e8c378eb-1201-41dc-995a-5ef9097b55f0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47df7d4b90>]}
[0m08:23:12.105692 [debug] [MainThread]: Opening a new connection, currently in state init
[0m08:23:12.112297 [debug] [Thread-1 (]: Began running node model.hailing_project.stg_customer
[0m08:23:12.112845 [debug] [Thread-2 (]: Began running node model.hailing_project.stg_driver
[0m08:23:12.113454 [debug] [Thread-3 (]: Began running node model.hailing_project.stg_ride
[0m08:23:12.114011 [debug] [Thread-4 (]: Began running node model.hailing_project.stg_vehicle
[0m08:23:12.114755 [info ] [Thread-1 (]: 1 of 4 START sql incremental model rizky_dwh_hailing_source.stg_customer ....... [RUN]
[0m08:23:12.116068 [info ] [Thread-2 (]: 2 of 4 START sql incremental model rizky_dwh_hailing_source.stg_driver ......... [RUN]
[0m08:23:12.117779 [info ] [Thread-3 (]: 3 of 4 START sql incremental model rizky_dwh_hailing_source.stg_ride ........... [RUN]
[0m08:23:12.119291 [info ] [Thread-4 (]: 4 of 4 START sql incremental model rizky_dwh_hailing_source.stg_vehicle ........ [RUN]
[0m08:23:12.121170 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.stg_customer)
[0m08:23:12.122695 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.stg_driver'
[0m08:23:12.124071 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.stg_ride'
[0m08:23:12.125413 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.stg_vehicle'
[0m08:23:12.126641 [debug] [Thread-1 (]: Began compiling node model.hailing_project.stg_customer
[0m08:23:12.127832 [debug] [Thread-2 (]: Began compiling node model.hailing_project.stg_driver
[0m08:23:12.129124 [debug] [Thread-3 (]: Began compiling node model.hailing_project.stg_ride
[0m08:23:12.130232 [debug] [Thread-4 (]: Began compiling node model.hailing_project.stg_vehicle
[0m08:23:12.144780 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.stg_customer"
[0m08:23:12.150053 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.stg_driver"
[0m08:23:12.157498 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.stg_ride"
[0m08:23:12.161654 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.stg_vehicle"
[0m08:23:12.167988 [debug] [Thread-1 (]: Began executing node model.hailing_project.stg_customer
[0m08:23:12.168905 [debug] [Thread-3 (]: Began executing node model.hailing_project.stg_ride
[0m08:23:12.174713 [debug] [Thread-4 (]: Began executing node model.hailing_project.stg_vehicle
[0m08:23:12.175104 [debug] [Thread-2 (]: Began executing node model.hailing_project.stg_driver
[0m08:23:12.211682 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m08:23:12.211969 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m08:23:12.214865 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m08:23:12.218302 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m08:23:12.538360 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.stg_driver"
[0m08:23:12.539920 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.stg_ride"
[0m08:23:12.540565 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.stg_vehicle"
[0m08:23:12.537091 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.stg_customer"
[0m08:23:12.545917 [debug] [Thread-2 (]: On model.hailing_project.stg_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_driver_source`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`stg_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m08:23:12.546812 [debug] [Thread-4 (]: On model.hailing_project.stg_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_vehicle_source`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`stg_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m08:23:12.548862 [debug] [Thread-3 (]: On model.hailing_project.stg_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_ride_source`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`stg_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m08:23:12.551573 [debug] [Thread-1 (]: On model.hailing_project.stg_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_customer_source`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`stg_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m08:23:12.794914 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:6988f829-1759-42d0-bb8d-9fadc9750f5c&page=queryresults
[0m08:23:12.795537 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:4e4cccf0-ba08-4fe6-b244-40d31183711b&page=queryresults
[0m08:23:12.812820 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:a3a3a744-253c-4f7b-b4c1-e911e23fb65b&page=queryresults
[0m08:23:12.840339 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:27a1e004-58ca-4360-83e5-3d73608b0a5d&page=queryresults
[0m08:23:14.364948 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e8c378eb-1201-41dc-995a-5ef9097b55f0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47df323a50>]}
[0m08:23:14.366262 [info ] [Thread-4 (]: 4 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_vehicle ... [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.24s]
[0m08:23:14.368496 [debug] [Thread-4 (]: Finished running node model.hailing_project.stg_vehicle
[0m08:23:14.564064 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e8c378eb-1201-41dc-995a-5ef9097b55f0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47dc75b890>]}
[0m08:23:14.568138 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e8c378eb-1201-41dc-995a-5ef9097b55f0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47dc764ed0>]}
[0m08:23:14.569354 [info ] [Thread-3 (]: 3 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_ride ...... [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.44s]
[0m08:23:14.572283 [info ] [Thread-2 (]: 2 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_driver .... [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.45s]
[0m08:23:14.574182 [debug] [Thread-3 (]: Finished running node model.hailing_project.stg_ride
[0m08:23:14.575777 [debug] [Thread-2 (]: Finished running node model.hailing_project.stg_driver
[0m08:23:14.609671 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e8c378eb-1201-41dc-995a-5ef9097b55f0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47dc74c590>]}
[0m08:23:14.610826 [info ] [Thread-1 (]: 1 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_customer .. [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.49s]
[0m08:23:14.622350 [debug] [Thread-1 (]: Finished running node model.hailing_project.stg_customer
[0m08:23:14.628976 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m08:23:14.632897 [debug] [MainThread]: Connection 'master' was properly closed.
[0m08:23:14.639967 [debug] [MainThread]: Connection 'model.hailing_project.stg_customer' was properly closed.
[0m08:23:14.641615 [debug] [MainThread]: Connection 'model.hailing_project.stg_driver' was properly closed.
[0m08:23:14.642475 [debug] [MainThread]: Connection 'model.hailing_project.stg_ride' was properly closed.
[0m08:23:14.643922 [debug] [MainThread]: Connection 'model.hailing_project.stg_vehicle' was properly closed.
[0m08:23:14.645390 [info ] [MainThread]: 
[0m08:23:14.646648 [info ] [MainThread]: Finished running 4 incremental models in 0 hours 0 minutes and 3.25 seconds (3.25s).
[0m08:23:14.648508 [debug] [MainThread]: Command end result
[0m08:23:14.699662 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m08:23:14.705466 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m08:23:14.713966 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m08:23:14.714931 [info ] [MainThread]: 
[0m08:23:14.716212 [info ] [MainThread]: [32mCompleted successfully[0m
[0m08:23:14.717633 [info ] [MainThread]: 
[0m08:23:14.718841 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m08:23:14.720861 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 4.779687, "process_in_blocks": "0", "process_kernel_time": 0.161282, "process_mem_max_rss": "224496", "process_out_blocks": "0", "process_user_time": 3.769968}
[0m08:23:14.721979 [debug] [MainThread]: Command `dbt run` succeeded at 08:23:14.721862 after 4.78 seconds
[0m08:23:14.723011 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f480d2abdd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4810ce8a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4810d787d0>]}
[0m08:23:14.724382 [debug] [MainThread]: Flushing usage events
[0m08:23:15.791846 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m08:27:30.959413 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3316be3950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3316c33f90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3316c2b7d0>]}


============================== 08:27:30.962303 | bea2439a-3348-4f55-a283-4c04192d726c ==============================
[0m08:27:30.962303 [info ] [MainThread]: Running with dbt=1.9.0
[0m08:27:30.963575 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt run', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m08:27:31.561458 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'bea2439a-3348-4f55-a283-4c04192d726c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f32ed06a950>]}
[0m08:27:31.610933 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'bea2439a-3348-4f55-a283-4c04192d726c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3318e96150>]}
[0m08:27:31.612449 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m08:27:31.682920 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m08:27:31.822084 [debug] [MainThread]: Partial parsing enabled: 4 files deleted, 4 files added, 1 files changed.
[0m08:27:31.823302 [debug] [MainThread]: Partial parsing: added file: hailing_project://models/staging/production_hailing_ride_staging.sql
[0m08:27:31.824261 [debug] [MainThread]: Partial parsing: added file: hailing_project://models/staging/production_hailing_vehicle_staging.sql
[0m08:27:31.825284 [debug] [MainThread]: Partial parsing: added file: hailing_project://models/staging/production_hailing_customer_staging.sql
[0m08:27:31.826110 [debug] [MainThread]: Partial parsing: added file: hailing_project://models/staging/production_hailing_driver_staging.sql
[0m08:27:31.826988 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/staging/sources.yml
[0m08:27:31.827802 [debug] [MainThread]: Partial parsing: deleted file: hailing_project://models/staging/stg_customer.sql
[0m08:27:31.828532 [debug] [MainThread]: Partial parsing: deleted file: hailing_project://models/staging/stg_driver.sql
[0m08:27:31.829297 [debug] [MainThread]: Partial parsing: deleted file: hailing_project://models/staging/stg_ride.sql
[0m08:27:31.830335 [debug] [MainThread]: Partial parsing: deleted file: hailing_project://models/staging/stg_vehicle.sql
[0m08:27:32.183624 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.example
- models.dbt_project
[0m08:27:32.197759 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'bea2439a-3348-4f55-a283-4c04192d726c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f32ec9e8610>]}
[0m08:27:32.277301 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m08:27:32.283668 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m08:27:32.298710 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'bea2439a-3348-4f55-a283-4c04192d726c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f32ec7f7290>]}
[0m08:27:32.299996 [info ] [MainThread]: Found 4 models, 4 sources, 488 macros
[0m08:27:32.301759 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'bea2439a-3348-4f55-a283-4c04192d726c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f33172d65d0>]}
[0m08:27:32.304783 [info ] [MainThread]: 
[0m08:27:32.306121 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m08:27:32.307523 [info ] [MainThread]: 
[0m08:27:32.309641 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m08:27:32.314422 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m08:27:32.316149 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:27:32.905040 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m08:27:32.906245 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:27:33.111609 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'bea2439a-3348-4f55-a283-4c04192d726c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f32ecf7c210>]}
[0m08:27:33.113027 [debug] [MainThread]: Opening a new connection, currently in state init
[0m08:27:33.120084 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_customer_staging
[0m08:27:33.120622 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_driver_staging
[0m08:27:33.121101 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_ride_staging
[0m08:27:33.121634 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_vehicle_staging
[0m08:27:33.123495 [info ] [Thread-1 (]: 1 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_customer_staging  [RUN]
[0m08:27:33.125415 [info ] [Thread-2 (]: 2 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_driver_staging  [RUN]
[0m08:27:33.127184 [info ] [Thread-3 (]: 3 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_ride_staging  [RUN]
[0m08:27:33.129172 [info ] [Thread-4 (]: 4 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_vehicle_staging  [RUN]
[0m08:27:33.131370 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.production_hailing_customer_staging)
[0m08:27:33.133550 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_driver_staging'
[0m08:27:33.136521 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_ride_staging'
[0m08:27:33.138106 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_vehicle_staging'
[0m08:27:33.139550 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_customer_staging
[0m08:27:33.140992 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_driver_staging
[0m08:27:33.142840 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_ride_staging
[0m08:27:33.144255 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_vehicle_staging
[0m08:27:33.154140 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_customer_staging"
[0m08:27:33.159558 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_driver_staging"
[0m08:27:33.165776 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_ride_staging"
[0m08:27:33.170662 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_vehicle_staging"
[0m08:27:33.176842 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_customer_staging
[0m08:27:33.183716 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_vehicle_staging
[0m08:27:33.211126 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_driver_staging
[0m08:27:33.216911 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_ride_staging
[0m08:27:33.273959 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_vehicle_staging"
[0m08:27:33.274959 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_customer_staging"
[0m08:27:33.277939 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_driver_staging"
[0m08:27:33.282491 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_ride_staging"
[0m08:27:33.287572 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_customer_staging: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_customer_staging"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_customer_staging`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_customer_source`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    );
  
[0m08:27:33.288961 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m08:27:33.289427 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_vehicle_staging: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_vehicle_staging"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_vehicle_staging`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_vehicle_source`
)

SELECT *
FROM source

    );
  
[0m08:27:33.290744 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_ride_staging: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_ride_staging"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_ride_staging`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_ride_source`
)

SELECT *
FROM source

    );
  
[0m08:27:33.291570 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m08:27:33.292389 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_driver_staging: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_driver_staging"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_driver_staging`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_driver_source`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    );
  
[0m08:27:33.294527 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m08:27:33.318625 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m08:27:33.706692 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:7fc33d6e-81d0-4263-95bf-1c8956f8c172&page=queryresults
[0m08:27:33.716220 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:31085e80-a3cf-4850-9b4a-0e89417e82c9&page=queryresults
[0m08:27:33.722078 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:bc8394a4-3750-4e31-b3a2-1d3aeabb0b44&page=queryresults
[0m08:27:33.726232 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:9066ce79-d874-4f6f-a75a-2e05455cc4ce&page=queryresults
[0m08:27:35.593557 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bea2439a-3348-4f55-a283-4c04192d726c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f32ecfab0d0>]}
[0m08:27:35.595426 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bea2439a-3348-4f55-a283-4c04192d726c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f32ec45b050>]}
[0m08:27:35.597305 [info ] [Thread-1 (]: 1 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_customer_staging  [[32mCREATE TABLE (85.0 rows, 5.8 KiB processed)[0m in 2.46s]
[0m08:27:35.598170 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bea2439a-3348-4f55-a283-4c04192d726c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f32ec283350>]}
[0m08:27:35.599250 [info ] [Thread-4 (]: 4 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_vehicle_staging  [[32mCREATE TABLE (85.0 rows, 4.7 KiB processed)[0m in 2.46s]
[0m08:27:35.600598 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_customer_staging
[0m08:27:35.602178 [info ] [Thread-2 (]: 2 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_driver_staging  [[32mCREATE TABLE (85.0 rows, 5.8 KiB processed)[0m in 2.46s]
[0m08:27:35.603419 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_vehicle_staging
[0m08:27:35.605232 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_driver_staging
[0m08:27:35.617693 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bea2439a-3348-4f55-a283-4c04192d726c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f32ec7f5f50>]}
[0m08:27:35.618692 [info ] [Thread-3 (]: 3 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_ride_staging  [[32mCREATE TABLE (85.0 rows, 7.6 KiB processed)[0m in 2.48s]
[0m08:27:35.619871 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_ride_staging
[0m08:27:35.622893 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m08:27:35.625989 [debug] [MainThread]: Connection 'master' was properly closed.
[0m08:27:35.626936 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_customer_staging' was properly closed.
[0m08:27:35.627933 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_driver_staging' was properly closed.
[0m08:27:35.628818 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_ride_staging' was properly closed.
[0m08:27:35.629777 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_vehicle_staging' was properly closed.
[0m08:27:35.630671 [info ] [MainThread]: 
[0m08:27:35.631722 [info ] [MainThread]: Finished running 4 incremental models in 0 hours 0 minutes and 3.32 seconds (3.32s).
[0m08:27:35.633318 [debug] [MainThread]: Command end result
[0m08:27:35.668417 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m08:27:35.673451 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m08:27:35.682040 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m08:27:35.682934 [info ] [MainThread]: 
[0m08:27:35.684269 [info ] [MainThread]: [32mCompleted successfully[0m
[0m08:27:35.686117 [info ] [MainThread]: 
[0m08:27:35.687174 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m08:27:35.688857 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 4.7852182, "process_in_blocks": "0", "process_kernel_time": 0.270995, "process_mem_max_rss": "224704", "process_out_blocks": "0", "process_user_time": 3.663454}
[0m08:27:35.690050 [debug] [MainThread]: Command `dbt run` succeeded at 08:27:35.689879 after 4.79 seconds
[0m08:27:35.691191 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3316c2b7d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3316fddf90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f331a508b10>]}
[0m08:27:35.692269 [debug] [MainThread]: Flushing usage events
[0m08:27:36.829557 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m08:39:38.577262 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff88def3350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff88def3510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff88dea2d90>]}


============================== 08:39:38.580813 | 5b5196af-75b8-4e53-bbcd-ea4035cf723e ==============================
[0m08:39:38.580813 [info ] [MainThread]: Running with dbt=1.9.0
[0m08:39:38.582552 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt run', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m08:39:39.188386 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5b5196af-75b8-4e53-bbcd-ea4035cf723e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff8647dc2d0>]}
[0m08:39:39.233777 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '5b5196af-75b8-4e53-bbcd-ea4035cf723e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff890158b10>]}
[0m08:39:39.235247 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m08:39:39.307329 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m08:39:39.446764 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m08:39:39.448612 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/staging/sources.yml
[0m08:39:39.801061 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project
- models.dbt_project.example
[0m08:39:39.812341 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5b5196af-75b8-4e53-bbcd-ea4035cf723e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff88ec64490>]}
[0m08:39:39.884185 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m08:39:39.891044 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m08:39:39.905683 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5b5196af-75b8-4e53-bbcd-ea4035cf723e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff8641aed50>]}
[0m08:39:39.906796 [info ] [MainThread]: Found 4 models, 4 sources, 488 macros
[0m08:39:39.908433 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5b5196af-75b8-4e53-bbcd-ea4035cf723e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff85fcf7d90>]}
[0m08:39:39.911366 [info ] [MainThread]: 
[0m08:39:39.912489 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m08:39:39.913568 [info ] [MainThread]: 
[0m08:39:39.914949 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m08:39:39.920109 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m08:39:39.921037 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:39:40.503687 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m08:39:40.504818 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:39:40.773147 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5b5196af-75b8-4e53-bbcd-ea4035cf723e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff88f098750>]}
[0m08:39:40.774127 [debug] [MainThread]: Opening a new connection, currently in state init
[0m08:39:40.779144 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_customer_staging
[0m08:39:40.779498 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_driver_staging
[0m08:39:40.779838 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_ride_staging
[0m08:39:40.780118 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_vehicle_staging
[0m08:39:40.780634 [info ] [Thread-1 (]: 1 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_customer_staging  [RUN]
[0m08:39:40.781653 [info ] [Thread-2 (]: 2 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_driver_staging  [RUN]
[0m08:39:40.782763 [info ] [Thread-3 (]: 3 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_ride_staging  [RUN]
[0m08:39:40.783878 [info ] [Thread-4 (]: 4 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_vehicle_staging  [RUN]
[0m08:39:40.784902 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.production_hailing_customer_staging)
[0m08:39:40.785951 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_driver_staging'
[0m08:39:40.786883 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_ride_staging'
[0m08:39:40.788751 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_vehicle_staging'
[0m08:39:40.789745 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_customer_staging
[0m08:39:40.790628 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_driver_staging
[0m08:39:40.791483 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_ride_staging
[0m08:39:40.792417 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_vehicle_staging
[0m08:39:40.800291 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_customer_staging"
[0m08:39:40.804776 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_driver_staging"
[0m08:39:40.809609 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_ride_staging"
[0m08:39:40.813770 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_vehicle_staging"
[0m08:39:40.820314 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_customer_staging
[0m08:39:40.821615 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_vehicle_staging
[0m08:39:40.827934 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_ride_staging
[0m08:39:40.848484 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_driver_staging
[0m08:39:40.905256 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_customer_staging"
[0m08:39:40.905858 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_vehicle_staging"
[0m08:39:40.910465 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_ride_staging"
[0m08:39:40.915140 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_driver_staging"
[0m08:39:40.921371 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_customer_staging: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_customer_staging"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_customer_staging`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    );
  
[0m08:39:40.923021 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_driver_staging: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_driver_staging"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_driver_staging`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    );
  
[0m08:39:40.923574 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_ride_staging: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_ride_staging"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_ride_staging`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    );
  
[0m08:39:40.924351 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m08:39:40.925255 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_vehicle_staging: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_vehicle_staging"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_vehicle_staging`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    );
  
[0m08:39:40.925913 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m08:39:40.927023 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m08:39:40.929315 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m08:39:41.431996 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:1363d983-f250-470b-82bc-904e80a950b5&page=queryresults
[0m08:39:41.439151 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:9940b5b3-c090-43f4-a64b-faa6760986a4&page=queryresults
[0m08:39:41.448901 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:54c66f7a-af0b-476e-87a8-66e5049e5903&page=queryresults
[0m08:39:41.467382 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:a16d22a3-38b6-46f5-b56a-2a38549df091&page=queryresults
[0m08:39:43.178411 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5b5196af-75b8-4e53-bbcd-ea4035cf723e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff88e599f90>]}
[0m08:39:43.178990 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5b5196af-75b8-4e53-bbcd-ea4035cf723e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff85c138210>]}
[0m08:39:43.179664 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5b5196af-75b8-4e53-bbcd-ea4035cf723e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff85c11a9d0>]}
[0m08:39:43.180781 [info ] [Thread-1 (]: 1 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_customer_staging  [[32mCREATE TABLE (85.0 rows, 5.8 KiB processed)[0m in 2.39s]
[0m08:39:43.182279 [info ] [Thread-3 (]: 3 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_ride_staging  [[32mCREATE TABLE (85.0 rows, 7.6 KiB processed)[0m in 2.39s]
[0m08:39:43.183893 [info ] [Thread-2 (]: 2 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_driver_staging  [[32mCREATE TABLE (85.0 rows, 5.8 KiB processed)[0m in 2.39s]
[0m08:39:43.187346 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_customer_staging
[0m08:39:43.188234 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5b5196af-75b8-4e53-bbcd-ea4035cf723e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff85fa78990>]}
[0m08:39:43.189308 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_ride_staging
[0m08:39:43.191172 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_driver_staging
[0m08:39:43.193714 [info ] [Thread-4 (]: 4 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_vehicle_staging  [[32mCREATE TABLE (85.0 rows, 4.7 KiB processed)[0m in 2.40s]
[0m08:39:43.197053 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_vehicle_staging
[0m08:39:43.199905 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m08:39:43.204144 [debug] [MainThread]: Connection 'master' was properly closed.
[0m08:39:43.205339 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_customer_staging' was properly closed.
[0m08:39:43.206770 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_driver_staging' was properly closed.
[0m08:39:43.207741 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_ride_staging' was properly closed.
[0m08:39:43.208462 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_vehicle_staging' was properly closed.
[0m08:39:43.209673 [info ] [MainThread]: 
[0m08:39:43.210887 [info ] [MainThread]: Finished running 4 incremental models in 0 hours 0 minutes and 3.29 seconds (3.29s).
[0m08:39:43.212824 [debug] [MainThread]: Command end result
[0m08:39:43.250261 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m08:39:43.255282 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m08:39:43.264495 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m08:39:43.265487 [info ] [MainThread]: 
[0m08:39:43.266789 [info ] [MainThread]: [32mCompleted successfully[0m
[0m08:39:43.267931 [info ] [MainThread]: 
[0m08:39:43.269090 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m08:39:43.270753 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 4.754618, "process_in_blocks": "0", "process_kernel_time": 0.178834, "process_mem_max_rss": "224996", "process_out_blocks": "0", "process_user_time": 3.646234}
[0m08:39:43.271813 [debug] [MainThread]: Command `dbt run` succeeded at 08:39:43.271665 after 4.76 seconds
[0m08:39:43.272837 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff88e38b710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff8917ba890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff8917bbe10>]}
[0m08:39:43.273980 [debug] [MainThread]: Flushing usage events
[0m08:39:44.535912 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m08:41:44.508859 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effe0015f90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effdfc1db50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effdfc6ba90>]}


============================== 08:41:44.511995 | 9e13fda7-806a-4f8c-92f7-037962eb7068 ==============================
[0m08:41:44.511995 [info ] [MainThread]: Running with dbt=1.9.0
[0m08:41:44.513392 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt run', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m08:41:45.091789 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '9e13fda7-806a-4f8c-92f7-037962eb7068', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb81d5750>]}
[0m08:41:45.139722 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '9e13fda7-806a-4f8c-92f7-037962eb7068', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effe1e91f50>]}
[0m08:41:45.141190 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m08:41:45.208456 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m08:41:45.354277 [debug] [MainThread]: Partial parsing enabled: 4 files deleted, 4 files added, 0 files changed.
[0m08:41:45.355482 [debug] [MainThread]: Partial parsing: added file: hailing_project://models/staging/production_hailing_staging_ride.sql
[0m08:41:45.356515 [debug] [MainThread]: Partial parsing: added file: hailing_project://models/staging/production_hailing_staging_customer.sql
[0m08:41:45.357617 [debug] [MainThread]: Partial parsing: added file: hailing_project://models/staging/production_hailing_staging_driver.sql
[0m08:41:45.358502 [debug] [MainThread]: Partial parsing: added file: hailing_project://models/staging/production_hailing_staging_vehicle.sql
[0m08:41:45.359555 [debug] [MainThread]: Partial parsing: deleted file: hailing_project://models/staging/production_hailing_driver_staging.sql
[0m08:41:45.360456 [debug] [MainThread]: Partial parsing: deleted file: hailing_project://models/staging/production_hailing_customer_staging.sql
[0m08:41:45.361405 [debug] [MainThread]: Partial parsing: deleted file: hailing_project://models/staging/production_hailing_ride_staging.sql
[0m08:41:45.362254 [debug] [MainThread]: Partial parsing: deleted file: hailing_project://models/staging/production_hailing_vehicle_staging.sql
[0m08:41:45.630494 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.example
- models.dbt_project
[0m08:41:45.642505 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9e13fda7-806a-4f8c-92f7-037962eb7068', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb1e46b10>]}
[0m08:41:45.720003 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m08:41:45.726872 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m08:41:45.741856 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9e13fda7-806a-4f8c-92f7-037962eb7068', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb1d9ebd0>]}
[0m08:41:45.742934 [info ] [MainThread]: Found 4 models, 4 sources, 488 macros
[0m08:41:45.744183 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9e13fda7-806a-4f8c-92f7-037962eb7068', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb1f1dd50>]}
[0m08:41:45.747599 [info ] [MainThread]: 
[0m08:41:45.748694 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m08:41:45.749705 [info ] [MainThread]: 
[0m08:41:45.750723 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m08:41:45.754864 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m08:41:45.755758 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:41:46.326346 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m08:41:46.327235 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:41:46.584013 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9e13fda7-806a-4f8c-92f7-037962eb7068', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb1f1e310>]}
[0m08:41:46.585502 [debug] [MainThread]: Opening a new connection, currently in state init
[0m08:41:46.592811 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m08:41:46.593231 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m08:41:46.593562 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m08:41:46.593910 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m08:41:46.594450 [info ] [Thread-1 (]: 1 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [RUN]
[0m08:41:46.596132 [info ] [Thread-2 (]: 2 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [RUN]
[0m08:41:46.597253 [info ] [Thread-3 (]: 3 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [RUN]
[0m08:41:46.598298 [info ] [Thread-4 (]: 4 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [RUN]
[0m08:41:46.599467 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.production_hailing_staging_customer)
[0m08:41:46.600500 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m08:41:46.601496 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m08:41:46.602530 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_vehicle'
[0m08:41:46.603243 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m08:41:46.604029 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m08:41:46.604734 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m08:41:46.605536 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m08:41:46.614089 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m08:41:46.618498 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m08:41:46.622632 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m08:41:46.626572 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m08:41:46.631751 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m08:41:46.638684 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m08:41:46.660511 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m08:41:46.666438 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m08:41:46.716323 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m08:41:46.718476 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m08:41:46.722007 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m08:41:46.727807 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m08:41:46.736683 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    );
  
[0m08:41:46.738298 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m08:41:46.739047 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    );
  
[0m08:41:46.740751 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    );
  
[0m08:41:46.741412 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    );
  
[0m08:41:46.742243 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m08:41:46.746092 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m08:41:46.768762 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m08:41:47.228720 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:cb0b32c7-6a70-428c-9c74-72a25cffcf1f&page=queryresults
[0m08:41:47.231334 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:486b0192-d722-449f-b154-09c4ef7334d7&page=queryresults
[0m08:41:47.234280 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:860fee08-ffe9-4668-8cbc-cf82af9cd63b&page=queryresults
[0m08:41:47.259504 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:05c35d65-43f5-47e1-a6c4-47b023f0b583&page=queryresults
[0m08:41:49.155470 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9e13fda7-806a-4f8c-92f7-037962eb7068', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effa1f6c750>]}
[0m08:41:49.155836 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9e13fda7-806a-4f8c-92f7-037962eb7068', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb1fab690>]}
[0m08:41:49.156142 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9e13fda7-806a-4f8c-92f7-037962eb7068', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effe099ea90>]}
[0m08:41:49.157290 [info ] [Thread-2 (]: 2 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [[32mCREATE TABLE (85.0 rows, 5.8 KiB processed)[0m in 2.55s]
[0m08:41:49.158635 [info ] [Thread-1 (]: 1 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [[32mCREATE TABLE (85.0 rows, 5.8 KiB processed)[0m in 2.56s]
[0m08:41:49.160177 [info ] [Thread-3 (]: 3 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [[32mCREATE TABLE (85.0 rows, 7.6 KiB processed)[0m in 2.55s]
[0m08:41:49.161613 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m08:41:49.162813 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m08:41:49.164114 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m08:41:49.177392 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9e13fda7-806a-4f8c-92f7-037962eb7068', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb1a1ba90>]}
[0m08:41:49.178844 [info ] [Thread-4 (]: 4 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [[32mCREATE TABLE (85.0 rows, 4.7 KiB processed)[0m in 2.57s]
[0m08:41:49.180411 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m08:41:49.182571 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m08:41:49.185888 [debug] [MainThread]: Connection 'master' was properly closed.
[0m08:41:49.186909 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m08:41:49.187942 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m08:41:49.188715 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m08:41:49.189306 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m08:41:49.190023 [info ] [MainThread]: 
[0m08:41:49.190945 [info ] [MainThread]: Finished running 4 incremental models in 0 hours 0 minutes and 3.44 seconds (3.44s).
[0m08:41:49.193114 [debug] [MainThread]: Command end result
[0m08:41:49.226359 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m08:41:49.230612 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m08:41:49.238958 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m08:41:49.239950 [info ] [MainThread]: 
[0m08:41:49.241156 [info ] [MainThread]: [32mCompleted successfully[0m
[0m08:41:49.242717 [info ] [MainThread]: 
[0m08:41:49.244169 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m08:41:49.245833 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 4.790658, "process_in_blocks": "0", "process_kernel_time": 0.242733, "process_mem_max_rss": "224756", "process_out_blocks": "0", "process_user_time": 3.499414}
[0m08:41:49.247003 [debug] [MainThread]: Command `dbt run` succeeded at 08:41:49.246894 after 4.79 seconds
[0m08:41:49.247855 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effdfc6b110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effdfc9b850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effe3438c10>]}
[0m08:41:49.248612 [debug] [MainThread]: Flushing usage events
[0m08:41:50.360982 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m08:55:53.438048 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc9bb843090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc9bbd23790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc9bb842d90>]}


============================== 08:55:53.440785 | 188f2d7a-2cad-4b2f-9d3b-318ce69a68c5 ==============================
[0m08:55:53.440785 [info ] [MainThread]: Running with dbt=1.9.0
[0m08:55:53.443792 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt clean', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m08:55:53.541592 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '188f2d7a-2cad-4b2f-9d3b-318ce69a68c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc9bb740590>]}
[0m08:55:53.616102 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.22455075, "process_in_blocks": "0", "process_kernel_time": 0.119231, "process_mem_max_rss": "89884", "process_out_blocks": "0", "process_user_time": 0.924043}
[0m08:55:53.616990 [debug] [MainThread]: Command `dbt clean` succeeded at 08:55:53.616891 after 0.23 seconds
[0m08:55:53.617840 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc9bf305850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc9bf00cb90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc9bbc3a090>]}
[0m08:55:53.618611 [debug] [MainThread]: Flushing usage events
[0m08:55:54.719266 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m08:55:55.867510 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2eccfdb250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ecd016150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2eccfdad10>]}


============================== 08:55:55.870876 | ab56964a-a0bb-4c5d-8da2-9de161090d50 ==============================
[0m08:55:55.870876 [info ] [MainThread]: Running with dbt=1.9.0
[0m08:55:55.872480 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'invocation_command': 'dbt deps', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m08:55:55.955841 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ab56964a-a0bb-4c5d-8da2-9de161090d50', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ecced5d90>]}
[0m08:55:55.967959 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m08:55:55.970791 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m08:55:55.972410 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.1555311, "process_in_blocks": "0", "process_kernel_time": 0.109292, "process_mem_max_rss": "90120", "process_out_blocks": "0", "process_user_time": 0.963762}
[0m08:55:55.973544 [debug] [MainThread]: Command `dbt deps` succeeded at 08:55:55.973423 after 0.16 seconds
[0m08:55:55.974805 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ecd04f950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ecd016150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ed07f4b90>]}
[0m08:55:55.975714 [debug] [MainThread]: Flushing usage events
[0m08:55:57.027390 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m08:55:59.333091 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff6ec212f90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff6ec257910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff6ec256f90>]}


============================== 08:55:59.336082 | 9be4d424-1a46-4f73-b13a-dc52af359668 ==============================
[0m08:55:59.336082 [info ] [MainThread]: Running with dbt=1.9.0
[0m08:55:59.337134 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m08:55:59.954350 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '9be4d424-1a46-4f73-b13a-dc52af359668', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff6be4273d0>]}
[0m08:56:00.011637 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '9be4d424-1a46-4f73-b13a-dc52af359668', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff6ee486150>]}
[0m08:56:00.013063 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m08:56:00.111993 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m08:56:00.114820 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m08:56:00.116055 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '9be4d424-1a46-4f73-b13a-dc52af359668', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff6be40c890>]}
[0m08:56:00.959452 [error] [MainThread]: Encountered an error:
Compilation Error in model dim_customer (models/facts/dim_customer.sql)
  expected token ',', got 'partition_by'
    line 6
      partition_by={
[0m08:56:00.961679 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.6971128, "process_in_blocks": "0", "process_kernel_time": 0.173183, "process_mem_max_rss": "212028", "process_out_blocks": "0", "process_user_time": 3.545171}
[0m08:56:00.962928 [debug] [MainThread]: Command `dbt run` failed at 08:56:00.962774 after 1.70 seconds
[0m08:56:00.963870 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff6ec31dc10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff6be517a50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff6ec242b90>]}
[0m08:56:00.964920 [debug] [MainThread]: Flushing usage events
[0m08:56:02.218201 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m08:56:14.289954 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f66d0d97190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f66d2ba9ed0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f66d0d96610>]}


============================== 08:56:14.293297 | 47699dbc-bf56-4bee-86af-c67e838e11b7 ==============================
[0m08:56:14.293297 [info ] [MainThread]: Running with dbt=1.9.0
[0m08:56:14.294521 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m08:56:14.927525 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '47699dbc-bf56-4bee-86af-c67e838e11b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f66a80db5d0>]}
[0m08:56:14.972869 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '47699dbc-bf56-4bee-86af-c67e838e11b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f66d300c710>]}
[0m08:56:14.974099 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m08:56:15.043632 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m08:56:15.047056 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m08:56:15.048294 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '47699dbc-bf56-4bee-86af-c67e838e11b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f66a9335c90>]}
[0m08:56:16.070617 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project
- models.dbt_project.example
[0m08:56:16.083971 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '47699dbc-bf56-4bee-86af-c67e838e11b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f66a321bd50>]}
[0m08:56:16.160529 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m08:56:16.166191 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m08:56:16.180220 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '47699dbc-bf56-4bee-86af-c67e838e11b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f66a2947010>]}
[0m08:56:16.181182 [info ] [MainThread]: Found 5 models, 4 sources, 488 macros
[0m08:56:16.182253 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '47699dbc-bf56-4bee-86af-c67e838e11b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f66a2b4c910>]}
[0m08:56:16.185224 [info ] [MainThread]: 
[0m08:56:16.186651 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m08:56:16.187777 [info ] [MainThread]: 
[0m08:56:16.189187 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m08:56:16.194044 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m08:56:16.194817 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m08:56:16.195635 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:56:16.196568 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:56:17.174266 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now create_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_facts)
[0m08:56:17.175593 [debug] [ThreadPool]: Creating schema "database: "purwadika"
schema: "rizky_dwh_hailing_source_rizky_dwh_hailing_facts"
"
[0m08:56:17.185112 [debug] [ThreadPool]: On create_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_facts: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "connection_name": "create_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_facts"} */
create schema if not exists `purwadika`.`rizky_dwh_hailing_source_rizky_dwh_hailing_facts`
  
[0m08:56:17.185993 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:56:18.033143 [debug] [ThreadPool]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:a4611c7b-5f04-4e83-a696-d54823fc335a&page=queryresults
[0m08:56:18.952582 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_facts, now list_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_facts)
[0m08:56:18.953105 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m08:56:18.954022 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:56:18.955119 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:56:19.504221 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '47699dbc-bf56-4bee-86af-c67e838e11b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f66a2fb3650>]}
[0m08:56:19.505634 [debug] [MainThread]: Opening a new connection, currently in state init
[0m08:56:19.511265 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m08:56:19.511990 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m08:56:19.512357 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m08:56:19.512797 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m08:56:19.513537 [info ] [Thread-1 (]: 1 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [RUN]
[0m08:56:19.514609 [info ] [Thread-2 (]: 2 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [RUN]
[0m08:56:19.515507 [info ] [Thread-3 (]: 3 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [RUN]
[0m08:56:19.516567 [info ] [Thread-4 (]: 4 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [RUN]
[0m08:56:19.517726 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_facts, now model.hailing_project.production_hailing_staging_customer)
[0m08:56:19.519027 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.production_hailing_staging_driver)
[0m08:56:19.520188 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m08:56:19.521117 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_vehicle'
[0m08:56:19.521991 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m08:56:19.522896 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m08:56:19.523746 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m08:56:19.524590 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m08:56:19.535354 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m08:56:19.540152 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m08:56:19.545159 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m08:56:19.549713 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m08:56:19.564158 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m08:56:19.570611 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m08:56:19.589141 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m08:56:19.608163 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m08:56:19.609444 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m08:56:19.609835 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m08:56:19.612375 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m08:56:19.617880 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m08:56:19.911915 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m08:56:19.915510 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m08:56:19.916741 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m08:56:19.918280 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m08:56:19.929276 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m08:56:19.930726 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m08:56:19.934719 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m08:56:19.937538 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m08:56:20.261435 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:d34d8f83-627d-4416-95ee-161fecb8b93d&page=queryresults
[0m08:56:20.261907 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:b945e293-6643-4419-8c69-ba34c7d4dd22&page=queryresults
[0m08:56:20.264128 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:29ebc6f8-24cf-46ca-ad87-cb0162c9c32b&page=queryresults
[0m08:56:20.266154 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:9bd397cb-b8f3-45da-a108-41ad7e513f76&page=queryresults
[0m08:56:21.808083 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '47699dbc-bf56-4bee-86af-c67e838e11b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f66a29acdd0>]}
[0m08:56:21.809431 [info ] [Thread-1 (]: 1 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.29s]
[0m08:56:21.811020 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m08:56:21.812414 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m08:56:21.813620 [info ] [Thread-1 (]: 5 of 5 START sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_facts.dim_customer  [RUN]
[0m08:56:21.814852 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_customer, now model.hailing_project.dim_customer)
[0m08:56:21.815989 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m08:56:21.820607 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m08:56:21.831710 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m08:56:21.857714 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '47699dbc-bf56-4bee-86af-c67e838e11b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f66a2937890>]}
[0m08:56:21.870866 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '47699dbc-bf56-4bee-86af-c67e838e11b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f66a16be7d0>]}
[0m08:56:21.872176 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m08:56:21.872998 [info ] [Thread-4 (]: 4 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.34s]
[0m08:56:21.874492 [info ] [Thread-3 (]: 3 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.35s]
[0m08:56:21.876872 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m08:56:21.877997 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m08:56:21.885955 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source_rizky_dwh_hailing_facts`.`dim_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
)

SELECT *
FROM source

    );
  
[0m08:56:21.887595 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m08:56:22.066828 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '47699dbc-bf56-4bee-86af-c67e838e11b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f66a1663c10>]}
[0m08:56:22.068223 [info ] [Thread-2 (]: 2 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.55s]
[0m08:56:22.069559 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m08:56:22.145883 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:27053855-795a-4b5e-a8d0-39f127d3302c&page=queryresults
[0m08:56:22.147182 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:27053855-795a-4b5e-a8d0-39f127d3302c&page=queryresults
[0m08:56:22.152102 [debug] [Thread-1 (]: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_facts was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m08:56:22.153159 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '47699dbc-bf56-4bee-86af-c67e838e11b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f66a03f1750>]}
[0m08:56:22.155106 [error] [Thread-1 (]: 5 of 5 ERROR creating sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_facts.dim_customer  [[31mERROR[0m in 0.34s]
[0m08:56:22.157201 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m08:56:22.158745 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.dim_customer' to be skipped because of status 'error'.  Reason: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_facts was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql.
[0m08:56:22.161659 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m08:56:22.165718 [debug] [MainThread]: Connection 'master' was properly closed.
[0m08:56:22.166637 [debug] [MainThread]: Connection 'model.hailing_project.dim_customer' was properly closed.
[0m08:56:22.167453 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m08:56:22.168136 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m08:56:22.168996 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m08:56:22.170079 [info ] [MainThread]: 
[0m08:56:22.171559 [info ] [MainThread]: Finished running 5 incremental models in 0 hours 0 minutes and 5.98 seconds (5.98s).
[0m08:56:22.174005 [debug] [MainThread]: Command end result
[0m08:56:22.211249 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m08:56:22.215917 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m08:56:22.225212 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m08:56:22.225981 [info ] [MainThread]: 
[0m08:56:22.226983 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m08:56:22.228025 [info ] [MainThread]: 
[0m08:56:22.229124 [error] [MainThread]:   Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_facts was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m08:56:22.230038 [info ] [MainThread]: 
[0m08:56:22.231046 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=0 TOTAL=5
[0m08:56:22.232740 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 8.001722, "process_in_blocks": "0", "process_kernel_time": 0.270523, "process_mem_max_rss": "227580", "process_out_blocks": "0", "process_user_time": 4.318353}
[0m08:56:22.233893 [debug] [MainThread]: Command `dbt run` failed at 08:56:22.233774 after 8.00 seconds
[0m08:56:22.234960 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f66d1192250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f66d1192490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f66d0e13650>]}
[0m08:56:22.235975 [debug] [MainThread]: Flushing usage events
[0m08:56:23.522471 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m09:02:51.542904 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0058c3bd10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0058fde110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0058c3bad0>]}


============================== 09:02:51.545550 | 330823d6-ff0a-4567-87ad-72d7c9342a21 ==============================
[0m09:02:51.545550 [info ] [MainThread]: Running with dbt=1.9.0
[0m09:02:51.546773 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m09:02:52.119321 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '330823d6-ff0a-4567-87ad-72d7c9342a21', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0058beac50>]}
[0m09:02:52.177202 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '330823d6-ff0a-4567-87ad-72d7c9342a21', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f005ae5a250>]}
[0m09:02:52.178567 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m09:02:52.252413 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m09:02:52.400017 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
[0m09:02:52.401572 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/staging/sources.yml
[0m09:02:52.402603 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/facts/dim_customer.sql
[0m09:02:52.733720 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.example
- models.dbt_project
[0m09:02:52.745280 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '330823d6-ff0a-4567-87ad-72d7c9342a21', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f002aa17c10>]}
[0m09:02:52.819470 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m09:02:52.825069 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m09:02:52.840761 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '330823d6-ff0a-4567-87ad-72d7c9342a21', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f002a9fea10>]}
[0m09:02:52.841995 [info ] [MainThread]: Found 5 models, 8 sources, 488 macros
[0m09:02:52.843352 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '330823d6-ff0a-4567-87ad-72d7c9342a21', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f002aa0ce90>]}
[0m09:02:52.846181 [info ] [MainThread]: 
[0m09:02:52.847420 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m09:02:52.848474 [info ] [MainThread]: 
[0m09:02:52.849960 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m09:02:52.855113 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m09:02:52.856788 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:02:53.499168 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m09:02:53.500207 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m09:02:53.728327 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '330823d6-ff0a-4567-87ad-72d7c9342a21', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f002a9d5c50>]}
[0m09:02:53.729338 [debug] [MainThread]: Opening a new connection, currently in state init
[0m09:02:53.734358 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m09:02:53.734705 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m09:02:53.735116 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m09:02:53.735495 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m09:02:53.736050 [info ] [Thread-1 (]: 1 of 5 START sql incremental model rizky_dwh_hailing_source.dim_customer ....... [RUN]
[0m09:02:53.737325 [info ] [Thread-2 (]: 2 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [RUN]
[0m09:02:53.738564 [info ] [Thread-3 (]: 3 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [RUN]
[0m09:02:53.739692 [info ] [Thread-4 (]: 4 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [RUN]
[0m09:02:53.741038 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.dim_customer)
[0m09:02:53.742016 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_customer'
[0m09:02:53.743448 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m09:02:53.744709 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m09:02:53.745860 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m09:02:53.747015 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m09:02:53.748515 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m09:02:53.749682 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m09:02:53.757780 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m09:02:53.764643 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m09:02:53.768179 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m09:02:53.772066 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m09:02:53.777580 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m09:02:53.778568 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m09:02:53.779070 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m09:02:53.779403 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m09:02:53.827489 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m09:02:53.828068 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m09:02:53.851716 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m09:02:53.858596 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m09:02:53.933183 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`dim_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
)

SELECT *
FROM source

    );
  
[0m09:02:53.934676 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m09:02:54.152322 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m09:02:54.153664 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m09:02:54.154833 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m09:02:54.159867 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m09:02:54.160491 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m09:02:54.161284 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m09:02:54.370648 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:f6923a34-c577-44dd-b997-85fd21cd509c&page=queryresults
[0m09:02:54.441687 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:293ccd08-85c5-4147-83ce-6594f1c73c86&page=queryresults
[0m09:02:54.481932 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:aa9af51f-d7d5-423b-804e-cd12e703d850&page=queryresults
[0m09:02:54.482568 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:59fc1ea1-e78f-42cd-bf0e-9d46f236fbb2&page=queryresults
[0m09:02:55.997230 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '330823d6-ff0a-4567-87ad-72d7c9342a21', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f002a799f90>]}
[0m09:02:55.998739 [info ] [Thread-3 (]: 3 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.25s]
[0m09:02:56.000818 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m09:02:56.001894 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m09:02:56.003167 [info ] [Thread-3 (]: 5 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [RUN]
[0m09:02:56.004397 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_driver, now model.hailing_project.production_hailing_staging_vehicle)
[0m09:02:56.005565 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m09:02:56.009769 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m09:02:56.016948 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m09:02:56.021384 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m09:02:56.254285 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m09:02:56.255329 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '330823d6-ff0a-4567-87ad-72d7c9342a21', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f002aa03c10>]}
[0m09:02:56.258163 [info ] [Thread-1 (]: 1 of 5 OK created sql incremental model rizky_dwh_hailing_source.dim_customer .. [[32mCREATE TABLE (85.0 rows, 5.7 KiB processed)[0m in 2.51s]
[0m09:02:56.260890 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m09:02:56.265466 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m09:02:56.308142 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '330823d6-ff0a-4567-87ad-72d7c9342a21', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f00283a4350>]}
[0m09:02:56.309167 [info ] [Thread-4 (]: 4 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.56s]
[0m09:02:56.310601 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m09:02:56.321177 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '330823d6-ff0a-4567-87ad-72d7c9342a21', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f002a7ea350>]}
[0m09:02:56.322610 [info ] [Thread-2 (]: 2 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.58s]
[0m09:02:56.324235 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m09:02:56.536349 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:d34e8e4e-03a9-4c73-8223-06ff0091a353&page=queryresults
[0m09:02:58.336631 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '330823d6-ff0a-4567-87ad-72d7c9342a21', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f00283bc6d0>]}
[0m09:02:58.337669 [info ] [Thread-3 (]: 5 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.33s]
[0m09:02:58.339068 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m09:02:58.341586 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m09:02:58.344499 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:02:58.346593 [debug] [MainThread]: Connection 'model.hailing_project.dim_customer' was properly closed.
[0m09:02:58.347619 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m09:02:58.348772 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m09:02:58.349562 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m09:02:58.350458 [info ] [MainThread]: 
[0m09:02:58.351800 [info ] [MainThread]: Finished running 5 incremental models in 0 hours 0 minutes and 5.50 seconds (5.50s).
[0m09:02:58.354845 [debug] [MainThread]: Command end result
[0m09:02:58.389635 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m09:02:58.393696 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m09:02:58.402108 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m09:02:58.402813 [info ] [MainThread]: 
[0m09:02:58.403912 [info ] [MainThread]: [32mCompleted successfully[0m
[0m09:02:58.404872 [info ] [MainThread]: 
[0m09:02:58.405898 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
[0m09:02:58.407909 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 6.9183664, "process_in_blocks": "0", "process_kernel_time": 0.252014, "process_mem_max_rss": "225460", "process_out_blocks": "0", "process_user_time": 3.659243}
[0m09:02:58.409070 [debug] [MainThread]: Command `dbt run` succeeded at 09:02:58.408936 after 6.92 seconds
[0m09:02:58.410072 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0058c5d8d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0058c5fb50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f005c400b90>]}
[0m09:02:58.411296 [debug] [MainThread]: Flushing usage events
[0m09:02:59.905363 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m09:05:40.652242 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb0d047210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb0d09f310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb0d09f910>]}


============================== 09:05:40.655139 | 69f36ca5-b52f-4434-9df8-c01e6bfa18b1 ==============================
[0m09:05:40.655139 [info ] [MainThread]: Running with dbt=1.9.0
[0m09:05:40.657692 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt run', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m09:05:41.221983 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '69f36ca5-b52f-4434-9df8-c01e6bfa18b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feadf7d8090>]}
[0m09:05:41.272996 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '69f36ca5-b52f-4434-9df8-c01e6bfa18b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb0f2a18d0>]}
[0m09:05:41.274088 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m09:05:41.341978 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m09:05:41.506980 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m09:05:41.508246 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/staging/sources.yml
[0m09:05:41.843912 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.example
- models.dbt_project
[0m09:05:41.857778 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '69f36ca5-b52f-4434-9df8-c01e6bfa18b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feadf1e1210>]}
[0m09:05:41.924061 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m09:05:41.929959 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m09:05:41.945913 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '69f36ca5-b52f-4434-9df8-c01e6bfa18b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feadee1c650>]}
[0m09:05:41.947028 [info ] [MainThread]: Found 5 models, 8 sources, 488 macros
[0m09:05:41.948225 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '69f36ca5-b52f-4434-9df8-c01e6bfa18b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feadecb8d90>]}
[0m09:05:41.951359 [info ] [MainThread]: 
[0m09:05:41.952641 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m09:05:41.953677 [info ] [MainThread]: 
[0m09:05:41.954813 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m09:05:41.959141 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m09:05:41.959976 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:05:42.505924 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m09:05:42.508689 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m09:05:42.705898 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '69f36ca5-b52f-4434-9df8-c01e6bfa18b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feadee4bd50>]}
[0m09:05:42.707070 [debug] [MainThread]: Opening a new connection, currently in state init
[0m09:05:42.711777 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m09:05:42.712149 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m09:05:42.712530 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m09:05:42.712974 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m09:05:42.713593 [info ] [Thread-1 (]: 1 of 5 START sql incremental model rizky_dwh_hailing_source.dim_customer ....... [RUN]
[0m09:05:42.714723 [info ] [Thread-2 (]: 2 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [RUN]
[0m09:05:42.715762 [info ] [Thread-3 (]: 3 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [RUN]
[0m09:05:42.716752 [info ] [Thread-4 (]: 4 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [RUN]
[0m09:05:42.717724 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.dim_customer)
[0m09:05:42.718797 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_customer'
[0m09:05:42.719745 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m09:05:42.720696 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m09:05:42.721593 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m09:05:42.722431 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m09:05:42.723343 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m09:05:42.724209 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m09:05:42.733091 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m09:05:42.737167 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m09:05:42.742361 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m09:05:42.747988 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m09:05:42.757199 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m09:05:42.758157 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m09:05:42.759121 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m09:05:42.759747 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m09:05:42.808084 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m09:05:42.809762 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m09:05:42.812481 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m09:05:42.815776 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m09:05:43.112639 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m09:05:43.113519 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m09:05:43.115071 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m09:05:43.116180 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m09:05:43.122014 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m09:05:43.122620 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m09:05:43.125599 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`dim_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`production_hailing_staging_customer`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`dim_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m09:05:43.127344 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m09:05:43.421019 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:dc41b09a-2c91-4117-94e1-03dc32416fb4&page=queryresults
[0m09:05:43.421995 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:2ebf480d-6083-4b76-b06f-cc075be5146f&page=queryresults
[0m09:05:43.445782 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:f0f01d8c-25fa-49c7-abcb-197fde24211b&page=queryresults
[0m09:05:43.792253 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:2a8b8531-8b06-4a7c-90b5-eb8b68f29216&page=queryresults
[0m09:05:43.793595 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:2a8b8531-8b06-4a7c-90b5-eb8b68f29216&page=queryresults
[0m09:05:43.797989 [debug] [Thread-1 (]: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_facts was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m09:05:43.800027 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '69f36ca5-b52f-4434-9df8-c01e6bfa18b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feadc2c6610>]}
[0m09:05:43.800929 [error] [Thread-1 (]: 1 of 5 ERROR creating sql incremental model rizky_dwh_hailing_source.dim_customer  [[31mERROR[0m in 1.08s]
[0m09:05:43.802058 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m09:05:43.802775 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m09:05:43.803259 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.dim_customer' to be skipped because of status 'error'.  Reason: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_facts was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql.
[0m09:05:43.803975 [info ] [Thread-1 (]: 5 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [RUN]
[0m09:05:43.806136 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.hailing_project.dim_customer, now model.hailing_project.production_hailing_staging_vehicle)
[0m09:05:43.806851 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m09:05:43.811173 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m09:05:43.817349 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m09:05:43.821184 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m09:05:44.027398 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m09:05:44.035178 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m09:05:44.295538 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:1650f28a-0e0d-472d-9078-a9b6e4b6dc61&page=queryresults
[0m09:05:44.982314 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '69f36ca5-b52f-4434-9df8-c01e6bfa18b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feadc1a4910>]}
[0m09:05:44.984122 [info ] [Thread-4 (]: 4 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.26s]
[0m09:05:44.985539 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m09:05:45.233156 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '69f36ca5-b52f-4434-9df8-c01e6bfa18b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feac6ec44d0>]}
[0m09:05:45.235443 [info ] [Thread-3 (]: 3 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.51s]
[0m09:05:45.237945 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m09:05:45.255788 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '69f36ca5-b52f-4434-9df8-c01e6bfa18b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feadc2c0210>]}
[0m09:05:45.257290 [info ] [Thread-2 (]: 2 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.54s]
[0m09:05:45.258591 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m09:05:46.947955 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '69f36ca5-b52f-4434-9df8-c01e6bfa18b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feadc298f50>]}
[0m09:05:46.949453 [info ] [Thread-1 (]: 5 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 3.14s]
[0m09:05:46.950578 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m09:05:46.952496 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m09:05:46.955351 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:05:46.955931 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m09:05:46.956816 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m09:05:46.957511 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m09:05:46.958173 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m09:05:46.959013 [info ] [MainThread]: 
[0m09:05:46.959783 [info ] [MainThread]: Finished running 5 incremental models in 0 hours 0 minutes and 5.00 seconds (5.00s).
[0m09:05:46.961654 [debug] [MainThread]: Command end result
[0m09:05:46.996389 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m09:05:47.001341 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m09:05:47.010074 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m09:05:47.010829 [info ] [MainThread]: 
[0m09:05:47.012168 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m09:05:47.013214 [info ] [MainThread]: 
[0m09:05:47.014350 [error] [MainThread]:   Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_facts was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m09:05:47.015429 [info ] [MainThread]: 
[0m09:05:47.016467 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=0 TOTAL=5
[0m09:05:47.018282 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 6.4130325, "process_in_blocks": "0", "process_kernel_time": 0.23354, "process_mem_max_rss": "228600", "process_out_blocks": "0", "process_user_time": 3.564031}
[0m09:05:47.019699 [debug] [MainThread]: Command `dbt run` failed at 09:05:47.019516 after 6.41 seconds
[0m09:05:47.020730 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb0cec76d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb10995290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb10995390>]}
[0m09:05:47.021595 [debug] [MainThread]: Flushing usage events
[0m09:05:48.408742 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m10:47:05.225716 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3f28ee70d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3f293fc950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3f29cad5d0>]}


============================== 10:47:05.228612 | 70065145-3523-41bc-992e-7d6e2fb95346 ==============================
[0m10:47:05.228612 [info ] [MainThread]: Running with dbt=1.9.0
[0m10:47:05.230662 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt run --models dim_customer', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m10:47:05.808886 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '70065145-3523-41bc-992e-7d6e2fb95346', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3efb096f50>]}
[0m10:47:05.852676 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '70065145-3523-41bc-992e-7d6e2fb95346', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3efb152550>]}
[0m10:47:05.854086 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m10:47:05.916922 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m10:47:06.076192 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m10:47:06.077099 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/facts/dim_customer.sql
[0m10:47:06.328828 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project
- models.dbt_project.example
[0m10:47:06.341285 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '70065145-3523-41bc-992e-7d6e2fb95346', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3efb10ae90>]}
[0m10:47:06.413539 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m10:47:06.418740 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m10:47:06.434100 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '70065145-3523-41bc-992e-7d6e2fb95346', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3efb0b46d0>]}
[0m10:47:06.435339 [info ] [MainThread]: Found 5 models, 8 sources, 488 macros
[0m10:47:06.436370 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '70065145-3523-41bc-992e-7d6e2fb95346', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3efb08f350>]}
[0m10:47:06.438724 [info ] [MainThread]: 
[0m10:47:06.439927 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m10:47:06.441276 [info ] [MainThread]: 
[0m10:47:06.442827 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m10:47:06.444437 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m10:47:06.445411 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:47:17.822829 [debug] [ThreadPool]: BigQuery adapter: Unhandled error while running:
list dataset
[0m10:47:17.823799 [debug] [ThreadPool]: BigQuery adapter: HTTPSConnectionPool(host='oauth2.googleapis.com', port=443): Max retries exceeded with url: /token (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f3efac27490>: Failed to establish a new connection: [Errno 101] Network is unreachable'))
[0m10:47:17.825410 [debug] [MainThread]: Opening a new connection, currently in state init
[0m10:47:17.829274 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:47:17.830451 [debug] [MainThread]: Connection 'list_purwadika' was properly closed.
[0m10:47:17.831838 [info ] [MainThread]: 
[0m10:47:17.832922 [info ] [MainThread]: Finished running  in 0 hours 0 minutes and 11.39 seconds (11.39s).
[0m10:47:17.834442 [error] [MainThread]: Encountered an error:
Runtime Error
  HTTPSConnectionPool(host='oauth2.googleapis.com', port=443): Max retries exceeded with url: /token (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f3efac27490>: Failed to establish a new connection: [Errno 101] Network is unreachable'))
[0m10:47:17.836759 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 12.658774, "process_in_blocks": "0", "process_kernel_time": 0.222013, "process_mem_max_rss": "214436", "process_out_blocks": "0", "process_user_time": 3.037542}
[0m10:47:17.838187 [debug] [MainThread]: Command `dbt run` failed at 10:47:17.837949 after 12.66 seconds
[0m10:47:17.839805 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3f28f676d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3f28f67550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3efac01090>]}
[0m10:47:17.840947 [debug] [MainThread]: Flushing usage events
[0m10:47:19.128927 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m10:47:29.890639 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f010b0d8d50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f010b0db390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f010b0d9e50>]}


============================== 10:47:29.893103 | aed52596-fa5c-42f7-9590-4cbae6145803 ==============================
[0m10:47:29.893103 [info ] [MainThread]: Running with dbt=1.9.0
[0m10:47:29.894280 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt run', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m10:47:30.446491 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'aed52596-fa5c-42f7-9590-4cbae6145803', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f00dd2a1150>]}
[0m10:47:30.492198 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'aed52596-fa5c-42f7-9590-4cbae6145803', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f010d3657d0>]}
[0m10:47:30.493549 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m10:47:30.565273 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m10:47:30.718687 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m10:47:30.719554 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m10:47:30.724595 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.example
- models.dbt_project
[0m10:47:30.749674 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'aed52596-fa5c-42f7-9590-4cbae6145803', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f00dd336150>]}
[0m10:47:30.865414 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m10:47:30.873196 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m10:47:30.890421 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'aed52596-fa5c-42f7-9590-4cbae6145803', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f00dd47add0>]}
[0m10:47:30.891309 [info ] [MainThread]: Found 5 models, 8 sources, 488 macros
[0m10:47:30.893053 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'aed52596-fa5c-42f7-9590-4cbae6145803', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f00dd470150>]}
[0m10:47:30.896264 [info ] [MainThread]: 
[0m10:47:30.897417 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m10:47:30.898724 [info ] [MainThread]: 
[0m10:47:30.900159 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m10:47:30.904676 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m10:47:30.905776 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m10:47:30.906319 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:47:30.907107 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:47:31.889457 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now create_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_facts)
[0m10:47:31.890522 [debug] [ThreadPool]: Creating schema "database: "purwadika"
schema: "rizky_dwh_hailing_source_rizky_dwh_hailing_facts"
"
[0m10:47:31.900627 [debug] [ThreadPool]: On create_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_facts: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "connection_name": "create_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_facts"} */
create schema if not exists `purwadika`.`rizky_dwh_hailing_source_rizky_dwh_hailing_facts`
  
[0m10:47:31.901549 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:47:32.742313 [debug] [ThreadPool]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:8f19e5ce-566a-4a7d-b456-cfa1f1e47693&page=queryresults
[0m10:47:33.686668 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_facts, now list_purwadika_rizky_dwh_hailing_source)
[0m10:47:33.687280 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_facts)
[0m10:47:33.687978 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:47:33.688826 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:47:34.341070 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'aed52596-fa5c-42f7-9590-4cbae6145803', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f010c8f6e90>]}
[0m10:47:34.342752 [debug] [MainThread]: Opening a new connection, currently in state init
[0m10:47:34.381884 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m10:47:34.382382 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m10:47:34.382793 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m10:47:34.383101 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m10:47:34.383898 [info ] [Thread-1 (]: 1 of 5 START sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_facts.dim_customer  [RUN]
[0m10:47:34.386038 [info ] [Thread-2 (]: 2 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [RUN]
[0m10:47:34.387942 [info ] [Thread-3 (]: 3 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [RUN]
[0m10:47:34.389955 [info ] [Thread-4 (]: 4 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [RUN]
[0m10:47:34.391547 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_facts, now model.hailing_project.dim_customer)
[0m10:47:34.392633 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.production_hailing_staging_customer)
[0m10:47:34.393747 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m10:47:34.395249 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m10:47:34.396334 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m10:47:34.397367 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m10:47:34.398488 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m10:47:34.399620 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m10:47:34.413776 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m10:47:34.419657 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m10:47:34.423768 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m10:47:34.428177 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m10:47:34.434463 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m10:47:34.435678 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m10:47:34.436226 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m10:47:34.447262 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m10:47:34.487731 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m10:47:34.489182 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m10:47:34.513163 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m10:47:34.515725 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m10:47:34.567791 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source_rizky_dwh_hailing_facts`.`dim_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`production_hailing_staging_customer`
)

SELECT *
FROM source

    );
  
[0m10:47:34.592349 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m10:47:34.875333 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m10:47:34.876068 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m10:47:34.877706 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m10:47:34.883807 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m10:47:34.884528 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m10:47:34.886993 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m10:47:35.172063 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:13e00322-d17c-4cbe-b915-cdd8192c84c0&page=queryresults
[0m10:47:35.178874 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:11c1d713-f50b-42d6-b111-2ff54ccb4fbb&page=queryresults
[0m10:47:35.277297 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:5a647779-f690-45dc-a73b-bc1b9fada9a4&page=queryresults
[0m10:47:35.530748 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:4c8fb234-d042-4ba4-a29f-6efbe0a2a0fe&page=queryresults
[0m10:47:35.531684 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:4c8fb234-d042-4ba4-a29f-6efbe0a2a0fe&page=queryresults
[0m10:47:35.536624 [debug] [Thread-1 (]: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_facts was not found in location US
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m10:47:35.538460 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'aed52596-fa5c-42f7-9590-4cbae6145803', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f00dc2c1350>]}
[0m10:47:35.539431 [error] [Thread-1 (]: 1 of 5 ERROR creating sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_facts.dim_customer  [[31mERROR[0m in 1.15s]
[0m10:47:35.540637 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m10:47:35.541617 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m10:47:35.542159 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.dim_customer' to be skipped because of status 'error'.  Reason: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_facts was not found in location US
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql.
[0m10:47:35.543001 [info ] [Thread-1 (]: 5 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [RUN]
[0m10:47:35.545726 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.hailing_project.dim_customer, now model.hailing_project.production_hailing_staging_vehicle)
[0m10:47:35.546761 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m10:47:35.552090 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m10:47:35.558583 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m10:47:35.564042 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m10:47:35.829480 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m10:47:35.835495 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m10:47:36.117440 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:d05ca8ae-accb-459a-94c2-588490c5f08b&page=queryresults
[0m10:47:36.856692 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'aed52596-fa5c-42f7-9590-4cbae6145803', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f00dd07cf10>]}
[0m10:47:36.858301 [info ] [Thread-3 (]: 3 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.46s]
[0m10:47:36.859676 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m10:47:37.043756 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'aed52596-fa5c-42f7-9590-4cbae6145803', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f00dc38f510>]}
[0m10:47:37.045100 [info ] [Thread-2 (]: 2 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.65s]
[0m10:47:37.046657 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m10:47:37.059635 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'aed52596-fa5c-42f7-9590-4cbae6145803', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f00dc417bd0>]}
[0m10:47:37.060893 [info ] [Thread-4 (]: 4 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.66s]
[0m10:47:37.062248 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m10:47:37.944995 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'aed52596-fa5c-42f7-9590-4cbae6145803', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f00dc31cf10>]}
[0m10:47:37.946232 [info ] [Thread-1 (]: 5 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.40s]
[0m10:47:37.947712 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m10:47:37.950505 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m10:47:37.954244 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:47:37.955193 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m10:47:37.956014 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m10:47:37.956828 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m10:47:37.957779 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m10:47:37.958864 [info ] [MainThread]: 
[0m10:47:37.959765 [info ] [MainThread]: Finished running 5 incremental models in 0 hours 0 minutes and 7.06 seconds (7.06s).
[0m10:47:37.961967 [debug] [MainThread]: Command end result
[0m10:47:37.998440 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m10:47:38.003288 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m10:47:38.010868 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m10:47:38.011659 [info ] [MainThread]: 
[0m10:47:38.012678 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m10:47:38.013896 [info ] [MainThread]: 
[0m10:47:38.014928 [error] [MainThread]:   Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_facts was not found in location US
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m10:47:38.016006 [info ] [MainThread]: 
[0m10:47:38.017065 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=0 TOTAL=5
[0m10:47:38.018943 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 8.172857, "process_in_blocks": "0", "process_kernel_time": 0.264918, "process_mem_max_rss": "222012", "process_out_blocks": "0", "process_user_time": 3.505078}
[0m10:47:38.019974 [debug] [MainThread]: Command `dbt run` failed at 10:47:38.019806 after 8.17 seconds
[0m10:47:38.021093 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f010ea59290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f010ea59250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f010ea58950>]}
[0m10:47:38.022004 [debug] [MainThread]: Flushing usage events
[0m10:47:39.351814 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m10:52:38.348914 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8b682575d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8b682ab2d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8b682571d0>]}


============================== 10:52:38.351342 | 17fc23dc-a634-49a0-8b4c-e41baa1e2b8a ==============================
[0m10:52:38.351342 [info ] [MainThread]: Running with dbt=1.9.0
[0m10:52:38.352826 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt clean', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m10:52:38.432436 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '17fc23dc-a634-49a0-8b4c-e41baa1e2b8a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8b6815fc90>]}
[0m10:52:38.503026 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.2023951, "process_in_blocks": "0", "process_kernel_time": 0.112961, "process_mem_max_rss": "89976", "process_out_blocks": "0", "process_user_time": 0.90369}
[0m10:52:38.504197 [debug] [MainThread]: Command `dbt clean` succeeded at 10:52:38.504075 after 0.20 seconds
[0m10:52:38.505002 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8b6ba74b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8b6bbd1210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8b6bbd1150>]}
[0m10:52:38.505804 [debug] [MainThread]: Flushing usage events
[0m10:52:42.509533 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m10:52:43.744737 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f565c806c50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f565cbda1d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f565c84efd0>]}


============================== 10:52:43.748318 | 1c121a38-fa0e-401a-bf84-3f9485a1f1ce ==============================
[0m10:52:43.748318 [info ] [MainThread]: Running with dbt=1.9.0
[0m10:52:43.749671 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'invocation_command': 'dbt deps', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m10:52:43.851136 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1c121a38-fa0e-401a-bf84-3f9485a1f1ce', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f565c6f9510>]}
[0m10:52:43.864771 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m10:52:43.867773 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m10:52:43.869966 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.18397304, "process_in_blocks": "0", "process_kernel_time": 0.111166, "process_mem_max_rss": "90236", "process_out_blocks": "0", "process_user_time": 1.081347}
[0m10:52:43.871359 [debug] [MainThread]: Command `dbt deps` succeeded at 10:52:43.871158 after 0.19 seconds
[0m10:52:43.872336 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f565c67d450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f565c67f850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f565c74aa10>]}
[0m10:52:43.873362 [debug] [MainThread]: Flushing usage events
[0m10:52:47.878066 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m10:53:07.696733 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d955cabd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d96414610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d9561b410>]}


============================== 10:53:07.699204 | 47bb5eb9-06b2-4690-b05d-35c68e8e2196 ==============================
[0m10:53:07.699204 [info ] [MainThread]: Running with dbt=1.9.0
[0m10:53:07.702056 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt run', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m10:53:08.253466 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '47bb5eb9-06b2-4690-b05d-35c68e8e2196', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d677635d0>]}
[0m10:53:08.299888 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '47bb5eb9-06b2-4690-b05d-35c68e8e2196', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d9784ced0>]}
[0m10:53:08.301660 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m10:53:08.370858 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m10:53:08.372926 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m10:53:08.374931 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '47bb5eb9-06b2-4690-b05d-35c68e8e2196', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d67e93b50>]}
[0m10:53:09.371956 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project
- models.dbt_project.example
[0m10:53:09.383773 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '47bb5eb9-06b2-4690-b05d-35c68e8e2196', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d673785d0>]}
[0m10:53:09.450207 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m10:53:09.456044 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m10:53:09.471319 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '47bb5eb9-06b2-4690-b05d-35c68e8e2196', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d6711ebd0>]}
[0m10:53:09.472528 [info ] [MainThread]: Found 5 models, 8 sources, 488 macros
[0m10:53:09.473825 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '47bb5eb9-06b2-4690-b05d-35c68e8e2196', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d672ecd90>]}
[0m10:53:09.476804 [info ] [MainThread]: 
[0m10:53:09.477944 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m10:53:09.478929 [info ] [MainThread]: 
[0m10:53:09.480210 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m10:53:09.485253 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m10:53:09.485904 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m10:53:09.486780 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:53:09.487601 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:53:10.386444 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now create_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_facts)
[0m10:53:10.387554 [debug] [ThreadPool]: Creating schema "database: "purwadika"
schema: "rizky_dwh_hailing_source_rizky_dwh_hailing_facts"
"
[0m10:53:10.396096 [debug] [ThreadPool]: On create_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_facts: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "connection_name": "create_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_facts"} */
create schema if not exists `purwadika`.`rizky_dwh_hailing_source_rizky_dwh_hailing_facts`
  
[0m10:53:10.397067 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:53:11.471603 [debug] [ThreadPool]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:55bcf902-10df-41de-8cc7-ca93e88efd24&page=queryresults
[0m10:53:12.348471 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_facts, now list_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_facts)
[0m10:53:12.349105 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m10:53:12.350164 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:53:12.351336 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:53:12.931753 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '47bb5eb9-06b2-4690-b05d-35c68e8e2196', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d67301b10>]}
[0m10:53:12.932660 [debug] [MainThread]: Opening a new connection, currently in state init
[0m10:53:12.938348 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m10:53:12.938922 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m10:53:12.939270 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m10:53:12.939618 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m10:53:12.940152 [info ] [Thread-1 (]: 1 of 5 START sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_facts.dim_customer  [RUN]
[0m10:53:12.941465 [info ] [Thread-2 (]: 2 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [RUN]
[0m10:53:12.942901 [info ] [Thread-3 (]: 3 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [RUN]
[0m10:53:12.944061 [info ] [Thread-4 (]: 4 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [RUN]
[0m10:53:12.945068 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_facts, now model.hailing_project.dim_customer)
[0m10:53:12.945836 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.production_hailing_staging_customer)
[0m10:53:12.946885 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m10:53:12.948200 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m10:53:12.949027 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m10:53:12.949889 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m10:53:12.950723 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m10:53:12.951532 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m10:53:12.959698 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m10:53:12.965147 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m10:53:12.970622 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m10:53:12.976305 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m10:53:12.989110 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m10:53:12.990432 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m10:53:13.017386 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m10:53:13.028498 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m10:53:13.046872 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m10:53:13.057133 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m10:53:13.064165 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m10:53:13.067779 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m10:53:13.147882 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source_rizky_dwh_hailing_facts`.`dim_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`production_hailing_staging_customer`
)

SELECT *
FROM source

    );
  
[0m10:53:13.148872 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m10:53:13.365141 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m10:53:13.366434 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m10:53:13.367792 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m10:53:13.373978 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m10:53:13.376038 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m10:53:13.379635 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m10:53:13.418202 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:ce26da19-9c35-42c5-8056-6834abd4339a&page=queryresults
[0m10:53:13.419318 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:ce26da19-9c35-42c5-8056-6834abd4339a&page=queryresults
[0m10:53:13.424529 [debug] [Thread-1 (]: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_facts was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m10:53:13.426879 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '47bb5eb9-06b2-4690-b05d-35c68e8e2196', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d65eb5590>]}
[0m10:53:13.428449 [error] [Thread-1 (]: 1 of 5 ERROR creating sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_facts.dim_customer  [[31mERROR[0m in 0.48s]
[0m10:53:13.429664 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m10:53:13.430940 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m10:53:13.431452 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.dim_customer' to be skipped because of status 'error'.  Reason: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_facts was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql.
[0m10:53:13.432424 [info ] [Thread-1 (]: 5 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [RUN]
[0m10:53:13.435175 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.hailing_project.dim_customer, now model.hailing_project.production_hailing_staging_vehicle)
[0m10:53:13.436277 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m10:53:13.441153 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m10:53:13.447412 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m10:53:13.452686 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m10:53:13.601966 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:ecabaf8b-6d28-4398-b1b4-2b39571d7780&page=queryresults
[0m10:53:13.663075 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:528b00ba-53cb-426f-9c07-6cbd1426c40f&page=queryresults
[0m10:53:13.686981 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m10:53:13.693072 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m10:53:13.698507 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:edc7d4ea-af0c-450d-8f04-313b9cf6e6bb&page=queryresults
[0m10:53:13.922791 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:a49f2bc7-c3a9-4cb0-abd9-20081e720dd5&page=queryresults
[0m10:53:15.169462 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '47bb5eb9-06b2-4690-b05d-35c68e8e2196', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d65dfa290>]}
[0m10:53:15.171789 [info ] [Thread-3 (]: 3 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.22s]
[0m10:53:15.174204 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m10:53:15.258051 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '47bb5eb9-06b2-4690-b05d-35c68e8e2196', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d65da0950>]}
[0m10:53:15.259586 [info ] [Thread-2 (]: 2 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.31s]
[0m10:53:15.261503 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m10:53:15.403681 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '47bb5eb9-06b2-4690-b05d-35c68e8e2196', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d65d1d790>]}
[0m10:53:15.404760 [info ] [Thread-4 (]: 4 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.46s]
[0m10:53:15.406012 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m10:53:15.477536 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '47bb5eb9-06b2-4690-b05d-35c68e8e2196', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d64431c90>]}
[0m10:53:15.479227 [info ] [Thread-1 (]: 5 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.04s]
[0m10:53:15.481202 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m10:53:15.484080 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m10:53:15.487689 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:53:15.488387 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m10:53:15.489117 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m10:53:15.490038 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m10:53:15.490682 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m10:53:15.491520 [info ] [MainThread]: 
[0m10:53:15.492565 [info ] [MainThread]: Finished running 5 incremental models in 0 hours 0 minutes and 6.01 seconds (6.01s).
[0m10:53:15.494432 [debug] [MainThread]: Command end result
[0m10:53:15.529215 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m10:53:15.533998 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m10:53:15.541987 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m10:53:15.542915 [info ] [MainThread]: 
[0m10:53:15.544038 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m10:53:15.545046 [info ] [MainThread]: 
[0m10:53:15.546174 [error] [MainThread]:   Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_facts was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m10:53:15.547147 [info ] [MainThread]: 
[0m10:53:15.548413 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=0 TOTAL=5
[0m10:53:15.549979 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 7.898837, "process_in_blocks": "0", "process_kernel_time": 0.119124, "process_mem_max_rss": "228720", "process_out_blocks": "0", "process_user_time": 4.308323}
[0m10:53:15.551121 [debug] [MainThread]: Command `dbt run` failed at 10:53:15.551007 after 7.90 seconds
[0m10:53:15.552392 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d98f49350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d98f490d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d98f49210>]}
[0m10:53:15.553604 [debug] [MainThread]: Flushing usage events
[0m10:53:16.835917 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m10:56:36.132311 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff6a1f3fb50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff6a1f3ff10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff6a1ef6610>]}


============================== 10:56:36.135252 | 343c2afa-6065-4787-854b-1d60fb94f933 ==============================
[0m10:56:36.135252 [info ] [MainThread]: Running with dbt=1.9.0
[0m10:56:36.136883 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt clean', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m10:56:36.225961 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '343c2afa-6065-4787-854b-1d60fb94f933', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff6a1dc2bd0>]}
[0m10:56:36.292894 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.22640637, "process_in_blocks": "0", "process_kernel_time": 0.060813, "process_mem_max_rss": "90112", "process_out_blocks": "0", "process_user_time": 1.094648}
[0m10:56:36.294064 [debug] [MainThread]: Command `dbt clean` succeeded at 10:56:36.293919 after 0.23 seconds
[0m10:56:36.294837 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff6a1f3f410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff6a1f3ff10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff6a574cb90>]}
[0m10:56:36.295788 [debug] [MainThread]: Flushing usage events
[0m10:56:37.666836 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m10:56:39.006991 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8e3dd66a10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8e3e15e110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8e3ddb32d0>]}


============================== 10:56:39.010429 | 815e6183-476d-460e-8e95-5e318e25ca22 ==============================
[0m10:56:39.010429 [info ] [MainThread]: Running with dbt=1.9.0
[0m10:56:39.012443 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt deps', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m10:56:39.099022 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '815e6183-476d-460e-8e95-5e318e25ca22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8e3dbe3390>]}
[0m10:56:39.110292 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m10:56:39.113055 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m10:56:39.114874 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.16012742, "process_in_blocks": "0", "process_kernel_time": 0.121413, "process_mem_max_rss": "90280", "process_out_blocks": "0", "process_user_time": 1.092723}
[0m10:56:39.116214 [debug] [MainThread]: Command `dbt deps` succeeded at 10:56:39.116067 after 0.16 seconds
[0m10:56:39.117329 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8e3dd65e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8e41530b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8e416b5250>]}
[0m10:56:39.118296 [debug] [MainThread]: Flushing usage events
[0m10:56:40.153294 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:02:00.047549 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f880ee036d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f880f1aa110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f880edb1e50>]}


============================== 11:02:00.050164 | e8a77b28-d12e-46be-b714-e83cca3e5af3 ==============================
[0m11:02:00.050164 [info ] [MainThread]: Running with dbt=1.9.0
[0m11:02:00.051707 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt run', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m11:02:00.650740 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e8a77b28-d12e-46be-b714-e83cca3e5af3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87e4f5f290>]}
[0m11:02:00.699282 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e8a77b28-d12e-46be-b714-e83cca3e5af3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8811009ed0>]}
[0m11:02:00.700711 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m11:02:00.771486 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m11:02:00.774396 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m11:02:00.775527 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'e8a77b28-d12e-46be-b714-e83cca3e5af3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87e521ab10>]}
[0m11:02:01.812567 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_project.staging
[0m11:02:01.823962 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e8a77b28-d12e-46be-b714-e83cca3e5af3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87e4c4e050>]}
[0m11:02:01.894366 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m11:02:01.901120 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m11:02:01.917186 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e8a77b28-d12e-46be-b714-e83cca3e5af3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87e49aa790>]}
[0m11:02:01.918126 [info ] [MainThread]: Found 5 models, 8 sources, 488 macros
[0m11:02:01.919315 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e8a77b28-d12e-46be-b714-e83cca3e5af3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87e4fd8550>]}
[0m11:02:01.922066 [info ] [MainThread]: 
[0m11:02:01.923180 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m11:02:01.924383 [info ] [MainThread]: 
[0m11:02:01.925751 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m11:02:01.931864 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m11:02:01.933483 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m11:02:01.934266 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:02:01.935251 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:02:17.970612 [debug] [ThreadPool]: BigQuery adapter: Unhandled error while running:
list dataset
[0m11:02:17.971668 [debug] [ThreadPool]: BigQuery adapter: HTTPSConnectionPool(host='oauth2.googleapis.com', port=443): Max retries exceeded with url: /token (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f87e4a12510>: Failed to establish a new connection: [Errno 101] Network is unreachable'))
[0m11:02:17.994033 [debug] [ThreadPool]: BigQuery adapter: Unhandled error while running:
list dataset
[0m11:02:17.995312 [debug] [ThreadPool]: BigQuery adapter: HTTPSConnectionPool(host='oauth2.googleapis.com', port=443): Max retries exceeded with url: /token (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f87e4a12d10>: Failed to establish a new connection: [Errno 101] Network is unreachable'))
[0m11:02:17.996782 [debug] [MainThread]: Opening a new connection, currently in state init
[0m11:02:17.999626 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:02:18.000517 [debug] [MainThread]: Connection 'list_purwadika' was properly closed.
[0m11:02:18.001860 [debug] [MainThread]: Connection 'list_purwadika' was properly closed.
[0m11:02:18.002718 [info ] [MainThread]: 
[0m11:02:18.004022 [info ] [MainThread]: Finished running  in 0 hours 0 minutes and 16.08 seconds (16.08s).
[0m11:02:18.005311 [error] [MainThread]: Encountered an error:
Runtime Error
  HTTPSConnectionPool(host='oauth2.googleapis.com', port=443): Max retries exceeded with url: /token (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f87e4a12510>: Failed to establish a new connection: [Errno 101] Network is unreachable'))
[0m11:02:18.006975 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 18.019152, "process_in_blocks": "0", "process_kernel_time": 0.139877, "process_mem_max_rss": "218452", "process_out_blocks": "0", "process_user_time": 3.826657}
[0m11:02:18.008146 [debug] [MainThread]: Command `dbt run` failed at 11:02:18.008016 after 18.02 seconds
[0m11:02:18.009454 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f880ec33a50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f880ec31750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87e4b4ae50>]}
[0m11:02:18.010433 [debug] [MainThread]: Flushing usage events
[0m11:02:22.012970 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:05:22.851114 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb5f293450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb5f292f50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb5f292610>]}


============================== 11:05:22.853931 | 61ffee6b-2d10-4073-8f6b-890c3396aa61 ==============================
[0m11:05:22.853931 [info ] [MainThread]: Running with dbt=1.9.0
[0m11:05:22.855687 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt debug', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m11:05:22.864717 [info ] [MainThread]: dbt version: 1.9.0
[0m11:05:22.865689 [info ] [MainThread]: python version: 3.11.2
[0m11:05:22.867034 [info ] [MainThread]: python path: /usr/local/bin/python
[0m11:05:22.868130 [info ] [MainThread]: os info: Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.31
[0m11:05:23.438647 [info ] [MainThread]: Using profiles dir at /usr/app/dbt_project
[0m11:05:23.439783 [info ] [MainThread]: Using profiles.yml file at /usr/app/dbt_project/profiles.yml
[0m11:05:23.440969 [info ] [MainThread]: Using dbt_project.yml file at /usr/app/dbt_project/dbt_project.yml
[0m11:05:23.442227 [info ] [MainThread]: adapter type: bigquery
[0m11:05:23.443197 [info ] [MainThread]: adapter version: 1.9.0
[0m11:05:23.529769 [info ] [MainThread]: Configuration:
[0m11:05:23.530977 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m11:05:23.532248 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m11:05:23.533740 [info ] [MainThread]: Required dependencies:
[0m11:05:23.534889 [debug] [MainThread]: Executing "git --help"
[0m11:05:23.556307 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m11:05:23.557605 [debug] [MainThread]: STDERR: "b''"
[0m11:05:23.558535 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m11:05:23.559501 [info ] [MainThread]: Connection:
[0m11:05:23.560601 [info ] [MainThread]:   method: service-account
[0m11:05:23.561561 [info ] [MainThread]:   database: purwadika
[0m11:05:23.562445 [info ] [MainThread]:   execution_project: purwadika
[0m11:05:23.563618 [info ] [MainThread]:   schema: rizky_dwh_hailing_source
[0m11:05:23.564728 [info ] [MainThread]:   location: None
[0m11:05:23.565897 [info ] [MainThread]:   priority: None
[0m11:05:23.567202 [info ] [MainThread]:   maximum_bytes_billed: None
[0m11:05:23.568244 [info ] [MainThread]:   impersonate_service_account: None
[0m11:05:23.569213 [info ] [MainThread]:   job_retry_deadline_seconds: None
[0m11:05:23.570893 [info ] [MainThread]:   job_retries: 1
[0m11:05:23.572461 [info ] [MainThread]:   job_creation_timeout_seconds: None
[0m11:05:23.573736 [info ] [MainThread]:   job_execution_timeout_seconds: None
[0m11:05:23.574676 [info ] [MainThread]:   timeout_seconds: None
[0m11:05:23.575692 [info ] [MainThread]:   client_id: None
[0m11:05:23.576686 [info ] [MainThread]:   token_uri: None
[0m11:05:23.578282 [info ] [MainThread]:   dataproc_region: None
[0m11:05:23.579453 [info ] [MainThread]:   dataproc_cluster_name: None
[0m11:05:23.580522 [info ] [MainThread]:   gcs_bucket: None
[0m11:05:23.581577 [info ] [MainThread]:   dataproc_batch: None
[0m11:05:23.582855 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m11:05:23.640826 [debug] [MainThread]: Acquiring new bigquery connection 'debug'
[0m11:05:23.641831 [debug] [MainThread]: On debug: select 1 as id
[0m11:05:23.642730 [debug] [MainThread]: Opening a new connection, currently in state init
[0m11:05:24.460305 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:f0762509-4051-45ae-997f-9681928cc276&page=queryresults
[0m11:05:25.208408 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m11:05:25.209796 [info ] [MainThread]: [32mAll checks passed![0m
[0m11:05:25.211732 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": true, "command_wall_clock_time": 2.416877, "process_in_blocks": "0", "process_kernel_time": 0.178668, "process_mem_max_rss": "211840", "process_out_blocks": "0", "process_user_time": 2.799132}
[0m11:05:25.213225 [debug] [MainThread]: Command `dbt debug` succeeded at 11:05:25.213029 after 2.42 seconds
[0m11:05:25.214754 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m11:05:25.215781 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb5f2df010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb5f2df8d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb31503210>]}
[0m11:05:25.216958 [debug] [MainThread]: Flushing usage events
[0m11:05:30.425424 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:05:34.071442 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff6033d2f50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff6037ca110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff6033d2c50>]}


============================== 11:05:34.074281 | 46d3eba4-928d-4033-bfca-d452898145e4 ==============================
[0m11:05:34.074281 [info ] [MainThread]: Running with dbt=1.9.0
[0m11:05:34.075384 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m11:05:34.676214 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '46d3eba4-928d-4033-bfca-d452898145e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff5d555b350>]}
[0m11:05:34.743263 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '46d3eba4-928d-4033-bfca-d452898145e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff60562d6d0>]}
[0m11:05:34.744618 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m11:05:34.816693 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m11:05:34.892881 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m11:05:34.894050 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '46d3eba4-928d-4033-bfca-d452898145e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff603aba910>]}
[0m11:05:35.918442 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.example
- models.dbt_project
[0m11:05:35.931881 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '46d3eba4-928d-4033-bfca-d452898145e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff5d52f23d0>]}
[0m11:05:36.006038 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m11:05:36.012005 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m11:05:36.028391 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '46d3eba4-928d-4033-bfca-d452898145e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff5d4f836d0>]}
[0m11:05:36.029438 [info ] [MainThread]: Found 5 models, 8 sources, 488 macros
[0m11:05:36.030755 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '46d3eba4-928d-4033-bfca-d452898145e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff5d51e6810>]}
[0m11:05:36.033749 [info ] [MainThread]: 
[0m11:05:36.034940 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m11:05:36.036305 [info ] [MainThread]: 
[0m11:05:36.037869 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m11:05:36.043288 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m11:05:36.044276 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m11:05:36.045081 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:05:36.046060 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:05:37.411332 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now create_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_facts)
[0m11:05:37.412513 [debug] [ThreadPool]: Creating schema "database: "purwadika"
schema: "rizky_dwh_hailing_source_rizky_dwh_hailing_facts"
"
[0m11:05:37.420573 [debug] [ThreadPool]: On create_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_facts: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "connection_name": "create_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_facts"} */
create schema if not exists `purwadika`.`rizky_dwh_hailing_source_rizky_dwh_hailing_facts`
  
[0m11:05:37.421400 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:05:38.452477 [debug] [ThreadPool]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:b6be366f-1712-44de-82f8-3906d6bac1b2&page=queryresults
[0m11:05:39.638740 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_facts, now list_purwadika_rizky_dwh_hailing_source)
[0m11:05:39.639487 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_facts)
[0m11:05:39.640697 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:05:39.641995 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:05:40.287210 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '46d3eba4-928d-4033-bfca-d452898145e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff5d4f47990>]}
[0m11:05:40.288748 [debug] [MainThread]: Opening a new connection, currently in state init
[0m11:05:40.296401 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m11:05:40.297374 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m11:05:40.298037 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m11:05:40.298772 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m11:05:40.299870 [info ] [Thread-1 (]: 1 of 5 START sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_facts.dim_customer  [RUN]
[0m11:05:40.301772 [info ] [Thread-2 (]: 2 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [RUN]
[0m11:05:40.303407 [info ] [Thread-3 (]: 3 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [RUN]
[0m11:05:40.304989 [info ] [Thread-4 (]: 4 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [RUN]
[0m11:05:40.306409 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.dim_customer)
[0m11:05:40.307702 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_facts, now model.hailing_project.production_hailing_staging_customer)
[0m11:05:40.309240 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m11:05:40.310422 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m11:05:40.311479 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m11:05:40.312500 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m11:05:40.313399 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m11:05:40.314189 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m11:05:40.324907 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m11:05:40.331556 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m11:05:40.336841 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m11:05:40.341997 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m11:05:40.359449 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m11:05:40.360666 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m11:05:40.366628 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m11:05:40.377925 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m11:05:40.440805 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m11:05:40.447373 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m11:05:40.467845 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m11:05:40.475621 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m11:05:40.578089 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source_rizky_dwh_hailing_facts`.`dim_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`production_hailing_staging_customer`
)

SELECT *
FROM source

    );
  
[0m11:05:40.579760 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:05:40.832321 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m11:05:40.842349 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m11:05:40.861408 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m11:05:40.862738 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m11:05:40.868415 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m11:05:40.870179 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m11:05:40.962738 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:ca333fcf-3ee4-425c-aed5-397d6732d428&page=queryresults
[0m11:05:40.963808 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:ca333fcf-3ee4-425c-aed5-397d6732d428&page=queryresults
[0m11:05:40.969089 [debug] [Thread-1 (]: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_facts was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m11:05:40.971603 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '46d3eba4-928d-4033-bfca-d452898145e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff5d420c790>]}
[0m11:05:40.973065 [error] [Thread-1 (]: 1 of 5 ERROR creating sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_facts.dim_customer  [[31mERROR[0m in 0.66s]
[0m11:05:40.975576 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m11:05:40.976946 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m11:05:40.977592 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.dim_customer' to be skipped because of status 'error'.  Reason: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_facts was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql.
[0m11:05:40.978523 [info ] [Thread-1 (]: 5 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [RUN]
[0m11:05:40.981744 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.hailing_project.dim_customer, now model.hailing_project.production_hailing_staging_vehicle)
[0m11:05:40.983278 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m11:05:40.990984 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m11:05:40.997556 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m11:05:41.001914 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:05:41.218352 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:1132dcd3-cfdc-492b-ab44-c76d4f13ac12&page=queryresults
[0m11:05:41.222373 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:7622e553-68e2-4e93-88c4-c0e70b4ed595&page=queryresults
[0m11:05:41.235992 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:1de0a322-c038-4cd8-868b-8a98b0cc6910&page=queryresults
[0m11:05:41.639530 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m11:05:41.646522 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m11:05:41.899625 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:d27816b5-e3b2-46fc-b5d0-a87a08a8e27a&page=queryresults
[0m11:05:43.074203 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '46d3eba4-928d-4033-bfca-d452898145e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff5d43d1310>]}
[0m11:05:43.075642 [info ] [Thread-3 (]: 3 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.77s]
[0m11:05:43.077283 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m11:05:43.129154 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '46d3eba4-928d-4033-bfca-d452898145e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff5d43fe010>]}
[0m11:05:43.130337 [info ] [Thread-2 (]: 2 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.82s]
[0m11:05:43.131493 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m11:05:43.369516 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '46d3eba4-928d-4033-bfca-d452898145e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff5d4f66150>]}
[0m11:05:43.370763 [info ] [Thread-4 (]: 4 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 3.06s]
[0m11:05:43.372060 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m11:05:43.511571 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '46d3eba4-928d-4033-bfca-d452898145e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff5d44f24d0>]}
[0m11:05:43.512972 [info ] [Thread-1 (]: 5 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.53s]
[0m11:05:43.514422 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m11:05:43.517059 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m11:05:43.519992 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:05:43.520852 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m11:05:43.521697 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m11:05:43.522483 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m11:05:43.523261 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m11:05:43.524372 [info ] [MainThread]: 
[0m11:05:43.525306 [info ] [MainThread]: Finished running 5 incremental models in 0 hours 0 minutes and 7.49 seconds (7.49s).
[0m11:05:43.527931 [debug] [MainThread]: Command end result
[0m11:05:43.564131 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m11:05:43.568963 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m11:05:43.577240 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m11:05:43.578018 [info ] [MainThread]: 
[0m11:05:43.579374 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m11:05:43.580443 [info ] [MainThread]: 
[0m11:05:43.581544 [error] [MainThread]:   Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_facts was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m11:05:43.582646 [info ] [MainThread]: 
[0m11:05:43.583973 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=0 TOTAL=5
[0m11:05:43.586203 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 9.566539, "process_in_blocks": "0", "process_kernel_time": 0.296034, "process_mem_max_rss": "227232", "process_out_blocks": "0", "process_user_time": 4.489856}
[0m11:05:43.587638 [debug] [MainThread]: Command `dbt run` failed at 11:05:43.587446 after 9.57 seconds
[0m11:05:43.588695 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff60342e810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff60342c410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff606d21250>]}
[0m11:05:43.589646 [debug] [MainThread]: Flushing usage events
[0m11:05:44.881480 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:11:20.164168 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f39d29f7b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f39d29f7f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f39d29ae610>]}


============================== 11:11:20.166778 | 352c0ca1-4001-4c01-8397-e327d13dd56a ==============================
[0m11:11:20.166778 [info ] [MainThread]: Running with dbt=1.9.0
[0m11:11:20.168006 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt clean', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m11:11:20.256342 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '352c0ca1-4001-4c01-8397-e327d13dd56a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f39d28a86d0>]}
[0m11:11:20.323215 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.21705097, "process_in_blocks": "0", "process_kernel_time": 0.108743, "process_mem_max_rss": "90040", "process_out_blocks": "0", "process_user_time": 1.038006}
[0m11:11:20.324693 [debug] [MainThread]: Command `dbt clean` succeeded at 11:11:20.324463 after 0.22 seconds
[0m11:11:20.325986 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f39d6204b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f39d6361210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f39d6361150>]}
[0m11:11:20.327026 [debug] [MainThread]: Flushing usage events
[0m11:11:21.868659 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:11:23.209801 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd045262450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd045778990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd0452b3b50>]}


============================== 11:11:23.212936 | 64c026e8-c291-4d03-8efd-bec7f523fa8d ==============================
[0m11:11:23.212936 [info ] [MainThread]: Running with dbt=1.9.0
[0m11:11:23.214231 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'invocation_command': 'dbt deps', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m11:11:23.309690 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '64c026e8-c291-4d03-8efd-bec7f523fa8d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd0452610d0>]}
[0m11:11:23.322896 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m11:11:23.325257 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m11:11:23.327692 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.18529142, "process_in_blocks": "0", "process_kernel_time": 0.110625, "process_mem_max_rss": "90144", "process_out_blocks": "0", "process_user_time": 1.1666}
[0m11:11:23.329095 [debug] [MainThread]: Command `dbt deps` succeeded at 11:11:23.328846 after 0.19 seconds
[0m11:11:23.330160 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd045296650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd0452ee310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd048ab8b90>]}
[0m11:11:23.331476 [debug] [MainThread]: Flushing usage events
[0m11:11:24.397499 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:11:42.220268 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5be3aff210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5be5ca7650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5be3b57810>]}


============================== 11:11:42.222861 | 951a46fd-64bb-4334-b063-fdffaa2d940c ==============================
[0m11:11:42.222861 [info ] [MainThread]: Running with dbt=1.9.0
[0m11:11:42.224076 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt run', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m11:11:42.788686 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '951a46fd-64bb-4334-b063-fdffaa2d940c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5bb5f83510>]}
[0m11:11:42.840116 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '951a46fd-64bb-4334-b063-fdffaa2d940c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5bb5d66550>]}
[0m11:11:42.841411 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m11:11:42.908166 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m11:11:42.911147 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m11:11:42.912494 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '951a46fd-64bb-4334-b063-fdffaa2d940c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5bb6ed3e90>]}
[0m11:11:43.903632 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.staging
- models.dbt_project.facts
[0m11:11:43.915702 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '951a46fd-64bb-4334-b063-fdffaa2d940c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5bb58d9b50>]}
[0m11:11:43.987068 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m11:11:43.991622 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m11:11:44.006116 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '951a46fd-64bb-4334-b063-fdffaa2d940c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5bb56fafd0>]}
[0m11:11:44.007283 [info ] [MainThread]: Found 5 models, 8 sources, 488 macros
[0m11:11:44.008917 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '951a46fd-64bb-4334-b063-fdffaa2d940c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5bb59b1f50>]}
[0m11:11:44.011723 [info ] [MainThread]: 
[0m11:11:44.012827 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m11:11:44.013752 [info ] [MainThread]: 
[0m11:11:44.015404 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m11:11:44.020107 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m11:11:44.020755 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m11:11:44.021466 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:11:44.022580 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:11:45.077803 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m11:11:45.078467 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_facts)
[0m11:11:45.079375 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:11:45.080256 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:11:45.606745 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '951a46fd-64bb-4334-b063-fdffaa2d940c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5bb5e7fe10>]}
[0m11:11:45.607694 [debug] [MainThread]: Opening a new connection, currently in state init
[0m11:11:45.612544 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m11:11:45.613015 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m11:11:45.613496 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m11:11:45.613902 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m11:11:45.614544 [info ] [Thread-1 (]: 1 of 5 START sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_facts.dim_customer  [RUN]
[0m11:11:45.616005 [info ] [Thread-2 (]: 2 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [RUN]
[0m11:11:45.617378 [info ] [Thread-3 (]: 3 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [RUN]
[0m11:11:45.618688 [info ] [Thread-4 (]: 4 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [RUN]
[0m11:11:45.620434 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_facts, now model.hailing_project.dim_customer)
[0m11:11:45.621737 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.production_hailing_staging_customer)
[0m11:11:45.623315 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m11:11:45.624563 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m11:11:45.625680 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m11:11:45.626993 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m11:11:45.628245 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m11:11:45.629529 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m11:11:45.637783 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m11:11:45.643857 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m11:11:45.648064 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m11:11:45.652542 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m11:11:45.665391 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m11:11:45.665934 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m11:11:45.672126 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m11:11:45.709201 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m11:11:45.726323 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m11:11:45.729442 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m11:11:45.741602 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m11:11:45.746049 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m11:11:45.833003 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source_rizky_dwh_hailing_facts`.`dim_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`production_hailing_staging_customer`
)

SELECT *
FROM source

    );
  
[0m11:11:45.834212 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:11:46.036427 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m11:11:46.037638 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m11:11:46.042761 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m11:11:46.046576 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m11:11:46.059044 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m11:11:46.065029 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m11:11:46.126871 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:6b5c24cd-c51b-4d72-b832-035d9b243967&page=queryresults
[0m11:11:46.127883 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:6b5c24cd-c51b-4d72-b832-035d9b243967&page=queryresults
[0m11:11:46.132732 [debug] [Thread-1 (]: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_facts was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m11:11:46.134563 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '951a46fd-64bb-4334-b063-fdffaa2d940c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5bb45ff490>]}
[0m11:11:46.135995 [error] [Thread-1 (]: 1 of 5 ERROR creating sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_facts.dim_customer  [[31mERROR[0m in 0.51s]
[0m11:11:46.137393 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m11:11:46.138452 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m11:11:46.138968 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.dim_customer' to be skipped because of status 'error'.  Reason: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_facts was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql.
[0m11:11:46.139848 [info ] [Thread-1 (]: 5 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [RUN]
[0m11:11:46.142630 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.hailing_project.dim_customer, now model.hailing_project.production_hailing_staging_vehicle)
[0m11:11:46.143737 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m11:11:46.149646 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m11:11:46.156025 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m11:11:46.159630 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:11:46.332943 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:b96bca9f-1657-4cf3-a094-831b10087ded&page=queryresults
[0m11:11:46.336542 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:35953e6c-bc42-4ddd-b24d-18f83626225b&page=queryresults
[0m11:11:46.377864 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:dfd5267b-1445-4f2b-848e-1bc7b4effcb3&page=queryresults
[0m11:11:46.401031 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m11:11:46.408214 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m11:11:46.729761 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:d1b452ab-4521-43c1-9361-c7ea548ab8ed&page=queryresults
[0m11:11:48.233971 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '951a46fd-64bb-4334-b063-fdffaa2d940c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5bb44f92d0>]}
[0m11:11:48.234544 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '951a46fd-64bb-4334-b063-fdffaa2d940c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5bb44f8b50>]}
[0m11:11:48.237558 [info ] [Thread-4 (]: 4 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.61s]
[0m11:11:48.239409 [info ] [Thread-2 (]: 2 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.61s]
[0m11:11:48.240963 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m11:11:48.242361 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m11:11:48.279723 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '951a46fd-64bb-4334-b063-fdffaa2d940c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5bb58f72d0>]}
[0m11:11:48.281245 [info ] [Thread-3 (]: 3 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.66s]
[0m11:11:48.282955 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m11:11:48.296531 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '951a46fd-64bb-4334-b063-fdffaa2d940c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5bb46120d0>]}
[0m11:11:48.297992 [info ] [Thread-1 (]: 5 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.15s]
[0m11:11:48.299640 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m11:11:48.302491 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m11:11:48.305778 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:11:48.306497 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m11:11:48.307274 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m11:11:48.308344 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m11:11:48.309371 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m11:11:48.310188 [info ] [MainThread]: 
[0m11:11:48.311066 [info ] [MainThread]: Finished running 5 incremental models in 0 hours 0 minutes and 4.29 seconds (4.29s).
[0m11:11:48.313469 [debug] [MainThread]: Command end result
[0m11:11:48.348560 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m11:11:48.353288 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m11:11:48.362728 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m11:11:48.363757 [info ] [MainThread]: 
[0m11:11:48.364988 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m11:11:48.366078 [info ] [MainThread]: 
[0m11:11:48.367355 [error] [MainThread]:   Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_facts was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m11:11:48.368556 [info ] [MainThread]: 
[0m11:11:48.369628 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=0 TOTAL=5
[0m11:11:48.371639 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 6.1992674, "process_in_blocks": "0", "process_kernel_time": 0.298109, "process_mem_max_rss": "227780", "process_out_blocks": "0", "process_user_time": 4.204377}
[0m11:11:48.372981 [debug] [MainThread]: Command `dbt run` failed at 11:11:48.372826 after 6.20 seconds
[0m11:11:48.374238 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5be3b324d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5be3efa550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5be3b47810>]}
[0m11:11:48.375474 [debug] [MainThread]: Flushing usage events
[0m11:11:49.706061 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:12:25.320633 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1f98aafd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1f98aadd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1f98ab150>]}


============================== 11:12:25.323756 | 2b240de7-a472-4645-b8df-4bdf24c599ea ==============================
[0m11:12:25.323756 [info ] [MainThread]: Running with dbt=1.9.0
[0m11:12:25.325092 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt run', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m11:12:25.887941 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '2b240de7-a472-4645-b8df-4bdf24c599ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1d0be1b10>]}
[0m11:12:25.938949 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '2b240de7-a472-4645-b8df-4bdf24c599ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1fbaf9ed0>]}
[0m11:12:25.940241 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m11:12:26.007729 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m11:12:26.175082 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m11:12:26.176573 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/facts/dim_customer.sql
[0m11:12:26.436688 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.staging
- models.dbt_project.facts
[0m11:12:26.451352 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2b240de7-a472-4645-b8df-4bdf24c599ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1cbba5810>]}
[0m11:12:26.525465 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m11:12:26.531183 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m11:12:26.545458 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2b240de7-a472-4645-b8df-4bdf24c599ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1cb6a19d0>]}
[0m11:12:26.546755 [info ] [MainThread]: Found 5 models, 8 sources, 488 macros
[0m11:12:26.548077 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2b240de7-a472-4645-b8df-4bdf24c599ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1cb822890>]}
[0m11:12:26.550811 [info ] [MainThread]: 
[0m11:12:26.551901 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m11:12:26.553091 [info ] [MainThread]: 
[0m11:12:26.554544 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m11:12:26.559116 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m11:12:26.560109 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:12:34.211726 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m11:12:34.212503 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:12:34.470207 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2b240de7-a472-4645-b8df-4bdf24c599ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1fa66f250>]}
[0m11:12:34.471056 [debug] [MainThread]: Opening a new connection, currently in state init
[0m11:12:34.475300 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m11:12:34.475679 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m11:12:34.475995 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m11:12:34.476297 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m11:12:34.476975 [info ] [Thread-1 (]: 1 of 5 START sql incremental model rizky_dwh_hailing_source.dim_customer ....... [RUN]
[0m11:12:34.477920 [info ] [Thread-2 (]: 2 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [RUN]
[0m11:12:34.478937 [info ] [Thread-3 (]: 3 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [RUN]
[0m11:12:34.479946 [info ] [Thread-4 (]: 4 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [RUN]
[0m11:12:34.480911 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.dim_customer)
[0m11:12:34.481748 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_customer'
[0m11:12:34.482741 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m11:12:34.484178 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m11:12:34.485349 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m11:12:34.486270 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m11:12:34.487022 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m11:12:34.487777 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m11:12:34.495748 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m11:12:34.501918 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m11:12:34.506390 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m11:12:34.510269 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m11:12:34.515758 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m11:12:34.516234 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m11:12:34.516760 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m11:12:34.522763 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m11:12:34.565873 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m11:12:34.573741 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m11:12:34.592254 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m11:12:34.596978 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m11:12:34.670137 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`dim_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`production_hailing_staging_customer`
)

SELECT *
FROM source

    );
  
[0m11:12:34.671361 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:12:34.984724 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m11:12:34.985119 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m11:12:34.986380 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m11:12:34.992659 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m11:12:34.993482 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m11:12:34.995019 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m11:12:35.051475 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:58485596-4c07-4919-aba5-39d3708490dd&page=queryresults
[0m11:12:35.052612 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:58485596-4c07-4919-aba5-39d3708490dd&page=queryresults
[0m11:12:35.057574 [debug] [Thread-1 (]: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Table purwadika:rizky_dwh_hailing_facts.production_hailing_staging_customer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m11:12:35.059448 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2b240de7-a472-4645-b8df-4bdf24c599ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1c83cd1d0>]}
[0m11:12:35.060747 [error] [Thread-1 (]: 1 of 5 ERROR creating sql incremental model rizky_dwh_hailing_source.dim_customer  [[31mERROR[0m in 0.58s]
[0m11:12:35.062111 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m11:12:35.063052 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m11:12:35.063739 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.dim_customer' to be skipped because of status 'error'.  Reason: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Table purwadika:rizky_dwh_hailing_facts.production_hailing_staging_customer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql.
[0m11:12:35.064818 [info ] [Thread-1 (]: 5 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [RUN]
[0m11:12:35.067871 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.hailing_project.dim_customer, now model.hailing_project.production_hailing_staging_vehicle)
[0m11:12:35.069988 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m11:12:35.074579 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m11:12:35.080069 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m11:12:35.083419 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:12:35.244916 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:b662c5d1-b248-487d-a215-5163d58cad88&page=queryresults
[0m11:12:35.342687 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m11:12:35.352437 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m11:12:35.355985 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:344f6acf-49ac-4c9d-a26e-faecba5d993b&page=queryresults
[0m11:12:35.387883 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:f22020a1-4bf8-4992-9c40-613b8b4400d3&page=queryresults
[0m11:12:35.629978 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:66395169-37e2-4ed0-bea4-b525be61dcec&page=queryresults
[0m11:12:36.815843 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2b240de7-a472-4645-b8df-4bdf24c599ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1cb5a6650>]}
[0m11:12:36.817069 [info ] [Thread-4 (]: 4 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.33s]
[0m11:12:36.818448 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m11:12:36.933345 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2b240de7-a472-4645-b8df-4bdf24c599ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1cb5f5590>]}
[0m11:12:36.939146 [info ] [Thread-3 (]: 3 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.45s]
[0m11:12:36.941234 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m11:12:37.223626 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2b240de7-a472-4645-b8df-4bdf24c599ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1c841a410>]}
[0m11:12:37.225240 [info ] [Thread-2 (]: 2 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.74s]
[0m11:12:37.226891 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m11:12:37.458452 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2b240de7-a472-4645-b8df-4bdf24c599ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1c848a750>]}
[0m11:12:37.459453 [info ] [Thread-1 (]: 5 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.39s]
[0m11:12:37.460734 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m11:12:37.463097 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m11:12:37.466102 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:12:37.466934 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m11:12:37.467664 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m11:12:37.468464 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m11:12:37.469206 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m11:12:37.470360 [info ] [MainThread]: 
[0m11:12:37.471412 [info ] [MainThread]: Finished running 5 incremental models in 0 hours 0 minutes and 10.92 seconds (10.92s).
[0m11:12:37.473852 [debug] [MainThread]: Command end result
[0m11:12:37.512961 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m11:12:37.520492 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m11:12:37.529380 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m11:12:37.530390 [info ] [MainThread]: 
[0m11:12:37.531448 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m11:12:37.532708 [info ] [MainThread]: 
[0m11:12:37.534027 [error] [MainThread]:   Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Table purwadika:rizky_dwh_hailing_facts.production_hailing_staging_customer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m11:12:37.535102 [info ] [MainThread]: 
[0m11:12:37.536267 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=0 TOTAL=5
[0m11:12:37.538520 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 12.267568, "process_in_blocks": "0", "process_kernel_time": 0.23348, "process_mem_max_rss": "227292", "process_out_blocks": "0", "process_user_time": 3.583422}
[0m11:12:37.540330 [debug] [MainThread]: Command `dbt run` failed at 11:12:37.540085 after 12.27 seconds
[0m11:12:37.541902 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1f9725510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1f97275d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1fd1f55d0>]}
[0m11:12:37.543415 [debug] [MainThread]: Flushing usage events
[0m11:12:39.269721 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:20:27.443642 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8a5d5eb90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8a6159e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8a5d5e910>]}


============================== 11:20:27.446031 | 9b67a5a3-0d8d-411c-a510-77a5b190e2f0 ==============================
[0m11:20:27.446031 [info ] [MainThread]: Running with dbt=1.9.0
[0m11:20:27.447464 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt clean', 'send_anonymous_usage_stats': 'True'}
[0m11:20:27.525330 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '9b67a5a3-0d8d-411c-a510-77a5b190e2f0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8a5db3f90>]}
[0m11:20:27.584287 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.18763956, "process_in_blocks": "0", "process_kernel_time": 0.078613, "process_mem_max_rss": "90040", "process_out_blocks": "0", "process_user_time": 0.943366}
[0m11:20:27.585554 [debug] [MainThread]: Command `dbt clean` succeeded at 11:20:27.585450 after 0.19 seconds
[0m11:20:27.586382 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8a615a810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8a5e6db50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8a9590c10>]}
[0m11:20:27.587250 [debug] [MainThread]: Flushing usage events
[0m11:20:28.646025 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:20:29.854527 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2cc06bef50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2cc0a6a110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2cc066b210>]}


============================== 11:20:29.857240 | e90511b4-1b19-43da-92b3-ff1550aa43eb ==============================
[0m11:20:29.857240 [info ] [MainThread]: Running with dbt=1.9.0
[0m11:20:29.858571 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt deps', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m11:20:29.953347 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e90511b4-1b19-43da-92b3-ff1550aa43eb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2cc06bfb50>]}
[0m11:20:29.965825 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m11:20:29.968839 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m11:20:29.971013 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.1771441, "process_in_blocks": "0", "process_kernel_time": 0.079526, "process_mem_max_rss": "90148", "process_out_blocks": "0", "process_user_time": 1.063671}
[0m11:20:29.972289 [debug] [MainThread]: Command `dbt deps` succeeded at 11:20:29.972107 after 0.18 seconds
[0m11:20:29.973136 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2cc3e64b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2cc059ae10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2cc0a6a190>]}
[0m11:20:29.974071 [debug] [MainThread]: Flushing usage events
[0m11:20:31.219106 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:20:33.980730 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f923d229dd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f923d622110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f923d621e90>]}


============================== 11:20:33.983266 | a771e0bb-ed61-46fe-a139-720c065cd1f3 ==============================
[0m11:20:33.983266 [info ] [MainThread]: Running with dbt=1.9.0
[0m11:20:33.984569 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m11:20:34.566815 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a771e0bb-ed61-46fe-a139-720c065cd1f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f920f37e1d0>]}
[0m11:20:34.614149 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a771e0bb-ed61-46fe-a139-720c065cd1f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f923f47e3d0>]}
[0m11:20:34.615591 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m11:20:34.685479 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m11:20:34.687614 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m11:20:34.688615 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'a771e0bb-ed61-46fe-a139-720c065cd1f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f923d08fa90>]}
[0m11:20:35.729350 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.facts
- models.dbt_project.staging
[0m11:20:35.740322 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a771e0bb-ed61-46fe-a139-720c065cd1f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f920f077d90>]}
[0m11:20:35.817748 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m11:20:35.824563 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m11:20:35.841278 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a771e0bb-ed61-46fe-a139-720c065cd1f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f920ee024d0>]}
[0m11:20:35.842419 [info ] [MainThread]: Found 5 models, 8 sources, 488 macros
[0m11:20:35.843517 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a771e0bb-ed61-46fe-a139-720c065cd1f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f920eff4fd0>]}
[0m11:20:35.846663 [info ] [MainThread]: 
[0m11:20:35.848101 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m11:20:35.849379 [info ] [MainThread]: 
[0m11:20:35.851115 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m11:20:35.858595 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m11:20:35.860301 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:20:36.453988 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m11:20:36.455136 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:20:36.695701 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a771e0bb-ed61-46fe-a139-720c065cd1f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f920f3c9690>]}
[0m11:20:36.696687 [debug] [MainThread]: Opening a new connection, currently in state init
[0m11:20:36.702114 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m11:20:36.702501 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m11:20:36.702804 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m11:20:36.703113 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m11:20:36.703845 [info ] [Thread-1 (]: 1 of 5 START sql incremental model rizky_dwh_hailing_source.dim_customer ....... [RUN]
[0m11:20:36.705257 [info ] [Thread-2 (]: 2 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [RUN]
[0m11:20:36.707224 [info ] [Thread-3 (]: 3 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [RUN]
[0m11:20:36.708730 [info ] [Thread-4 (]: 4 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [RUN]
[0m11:20:36.709954 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.dim_customer)
[0m11:20:36.711035 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_customer'
[0m11:20:36.712250 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m11:20:36.713205 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m11:20:36.714081 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m11:20:36.714867 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m11:20:36.715727 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m11:20:36.716642 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m11:20:36.725944 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m11:20:36.730154 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m11:20:36.734238 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m11:20:36.738111 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m11:20:36.747403 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m11:20:36.756381 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m11:20:36.779545 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m11:20:36.779929 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m11:20:36.851541 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m11:20:36.852982 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m11:20:36.855206 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m11:20:36.858156 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m11:20:36.872845 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    );
  
[0m11:20:36.874934 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`dim_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
)

SELECT *
FROM source

    );
  
[0m11:20:36.875476 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m11:20:36.875985 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    );
  
[0m11:20:36.876852 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:20:36.877592 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    );
  
[0m11:20:36.880134 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m11:20:36.904900 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m11:20:37.369839 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:e6b52e01-2696-4ea6-9523-64de850e7ad8&page=queryresults
[0m11:20:37.388237 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:e6382486-ba08-46f2-8335-6610e6beb10c&page=queryresults
[0m11:20:37.421711 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:b1777447-7bfc-4032-b9f5-ff862fe1a271&page=queryresults
[0m11:20:38.064083 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:00e7b0ef-594b-4484-b356-33d133c24926&page=queryresults
[0m11:20:38.065191 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:00e7b0ef-594b-4484-b356-33d133c24926&page=queryresults
[0m11:20:38.070635 [debug] [Thread-1 (]: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m11:20:38.072445 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a771e0bb-ed61-46fe-a139-720c065cd1f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f920c4c5f90>]}
[0m11:20:38.073881 [error] [Thread-1 (]: 1 of 5 ERROR creating sql incremental model rizky_dwh_hailing_source.dim_customer  [[31mERROR[0m in 1.36s]
[0m11:20:38.075365 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m11:20:38.076586 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m11:20:38.077162 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.dim_customer' to be skipped because of status 'error'.  Reason: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql.
[0m11:20:38.078203 [info ] [Thread-1 (]: 5 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [RUN]
[0m11:20:38.081383 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.hailing_project.dim_customer, now model.hailing_project.production_hailing_staging_vehicle)
[0m11:20:38.082594 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m11:20:38.087693 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m11:20:38.093370 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m11:20:38.098268 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m11:20:38.104465 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    );
  
[0m11:20:38.105649 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:20:38.503930 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:9fc61d43-09a8-4f16-bd7c-04550e44920f&page=queryresults
[0m11:20:39.102115 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a771e0bb-ed61-46fe-a139-720c065cd1f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f920c3f5450>]}
[0m11:20:39.104756 [info ] [Thread-3 (]: 3 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [[32mCREATE TABLE (85.0 rows, 5.8 KiB processed)[0m in 2.39s]
[0m11:20:39.106413 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m11:20:39.340020 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a771e0bb-ed61-46fe-a139-720c065cd1f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f920c4d9a90>]}
[0m11:20:39.341390 [info ] [Thread-4 (]: 4 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [[32mCREATE TABLE (85.0 rows, 7.6 KiB processed)[0m in 2.63s]
[0m11:20:39.342718 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m11:20:39.360347 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a771e0bb-ed61-46fe-a139-720c065cd1f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f920efcb2d0>]}
[0m11:20:39.361927 [info ] [Thread-2 (]: 2 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [[32mCREATE TABLE (85.0 rows, 5.8 KiB processed)[0m in 2.65s]
[0m11:20:39.363386 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m11:20:40.189894 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a771e0bb-ed61-46fe-a139-720c065cd1f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f920f0cc890>]}
[0m11:20:40.192303 [info ] [Thread-1 (]: 5 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [[32mCREATE TABLE (85.0 rows, 4.7 KiB processed)[0m in 2.11s]
[0m11:20:40.194044 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m11:20:40.196901 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m11:20:40.199773 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:20:40.200525 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m11:20:40.201387 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m11:20:40.202206 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m11:20:40.202856 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m11:20:40.203644 [info ] [MainThread]: 
[0m11:20:40.204832 [info ] [MainThread]: Finished running 5 incremental models in 0 hours 0 minutes and 4.35 seconds (4.35s).
[0m11:20:40.207210 [debug] [MainThread]: Command end result
[0m11:20:40.238458 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m11:20:40.242663 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m11:20:40.251589 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m11:20:40.252487 [info ] [MainThread]: 
[0m11:20:40.253674 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m11:20:40.254787 [info ] [MainThread]: 
[0m11:20:40.255908 [error] [MainThread]:   Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m11:20:40.256898 [info ] [MainThread]: 
[0m11:20:40.257988 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=0 TOTAL=5
[0m11:20:40.259969 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 6.3339143, "process_in_blocks": "0", "process_kernel_time": 0.209476, "process_mem_max_rss": "227272", "process_out_blocks": "0", "process_user_time": 4.279306}
[0m11:20:40.261109 [debug] [MainThread]: Command `dbt run` failed at 11:20:40.260953 after 6.34 seconds
[0m11:20:40.262139 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f923d08f8d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f923d22acd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9240b79110>]}
[0m11:20:40.263170 [debug] [MainThread]: Flushing usage events
[0m11:20:41.820755 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:29:56.540319 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d487ea450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d487e9d50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d487ea610>]}


============================== 11:29:56.544016 | ed49ee63-15dd-48a1-bb5d-7672ccf4d5e5 ==============================
[0m11:29:56.544016 [info ] [MainThread]: Running with dbt=1.9.0
[0m11:29:56.545489 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt run', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m11:29:57.121455 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ed49ee63-15dd-48a1-bb5d-7672ccf4d5e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d1ac66c90>]}
[0m11:29:57.165259 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ed49ee63-15dd-48a1-bb5d-7672ccf4d5e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d4aa98750>]}
[0m11:29:57.166671 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m11:29:57.240947 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m11:29:57.313350 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m11:29:57.314733 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'ed49ee63-15dd-48a1-bb5d-7672ccf4d5e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d48ee2910>]}
[0m11:29:58.342206 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.staging
- models.dbt_project.facts
[0m11:29:58.355375 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ed49ee63-15dd-48a1-bb5d-7672ccf4d5e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d1a60e890>]}
[0m11:29:58.440070 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m11:29:58.447031 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m11:29:58.468438 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ed49ee63-15dd-48a1-bb5d-7672ccf4d5e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d1a3dbf10>]}
[0m11:29:58.469825 [info ] [MainThread]: Found 5 models, 8 sources, 488 macros
[0m11:29:58.471833 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ed49ee63-15dd-48a1-bb5d-7672ccf4d5e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d1a622d10>]}
[0m11:29:58.475310 [info ] [MainThread]: 
[0m11:29:58.476828 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m11:29:58.478305 [info ] [MainThread]: 
[0m11:29:58.480066 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m11:29:58.486059 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m11:29:58.487598 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:29:59.680488 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m11:29:59.681527 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:29:59.923577 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ed49ee63-15dd-48a1-bb5d-7672ccf4d5e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d487ff210>]}
[0m11:29:59.924538 [debug] [MainThread]: Opening a new connection, currently in state init
[0m11:29:59.929705 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m11:29:59.930226 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m11:29:59.930836 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m11:29:59.931245 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m11:29:59.931817 [info ] [Thread-1 (]: 1 of 5 START sql incremental model rizky_dwh_hailing_source.dim_customer ....... [RUN]
[0m11:29:59.933046 [info ] [Thread-2 (]: 2 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [RUN]
[0m11:29:59.934316 [info ] [Thread-3 (]: 3 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [RUN]
[0m11:29:59.935803 [info ] [Thread-4 (]: 4 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [RUN]
[0m11:29:59.937120 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.dim_customer)
[0m11:29:59.938440 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_customer'
[0m11:29:59.939512 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m11:29:59.940606 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m11:29:59.941484 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m11:29:59.942579 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m11:29:59.943365 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m11:29:59.944245 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m11:29:59.952524 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m11:29:59.958464 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m11:29:59.962952 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m11:29:59.968267 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m11:29:59.974277 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m11:29:59.975295 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m11:29:59.981335 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m11:29:59.991581 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m11:30:00.021812 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m11:30:00.043121 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m11:30:00.053845 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m11:30:00.057226 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m11:30:00.131298 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`dim_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
)

SELECT *
FROM source

    );
  
[0m11:30:00.133422 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:30:00.332358 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m11:30:00.334040 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m11:30:00.338121 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m11:30:00.340543 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m11:30:00.360936 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m11:30:00.365280 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m11:30:00.647026 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:d86aa73d-a630-4d34-9f1a-49826350d02e&page=queryresults
[0m11:30:00.649911 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:2f2fb1a3-ddeb-4695-8d7e-a6ed791adeea&page=queryresults
[0m11:30:00.663450 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:f6c1b27a-599d-49a8-a140-409e60da88a8&page=queryresults
[0m11:30:00.986754 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:1467d589-0f46-4073-8c82-286e9a012290&page=queryresults
[0m11:30:00.988629 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:1467d589-0f46-4073-8c82-286e9a012290&page=queryresults
[0m11:30:00.994584 [debug] [Thread-1 (]: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m11:30:00.997004 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ed49ee63-15dd-48a1-bb5d-7672ccf4d5e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d1a86d790>]}
[0m11:30:00.998075 [error] [Thread-1 (]: 1 of 5 ERROR creating sql incremental model rizky_dwh_hailing_source.dim_customer  [[31mERROR[0m in 1.06s]
[0m11:30:00.999252 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m11:30:01.000417 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m11:30:01.000933 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.dim_customer' to be skipped because of status 'error'.  Reason: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql.
[0m11:30:01.002284 [info ] [Thread-1 (]: 5 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [RUN]
[0m11:30:01.005060 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.hailing_project.dim_customer, now model.hailing_project.production_hailing_staging_vehicle)
[0m11:30:01.006277 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m11:30:01.011150 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m11:30:01.018174 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m11:30:01.021974 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:30:01.257937 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m11:30:01.267681 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m11:30:01.538987 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:2f58b09c-7625-4f60-929b-7ad2f4b9bc2d&page=queryresults
[0m11:30:02.244034 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ed49ee63-15dd-48a1-bb5d-7672ccf4d5e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d1a85c8d0>]}
[0m11:30:02.244911 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ed49ee63-15dd-48a1-bb5d-7672ccf4d5e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d1a3c0a50>]}
[0m11:30:02.246158 [info ] [Thread-2 (]: 2 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.31s]
[0m11:30:02.247660 [info ] [Thread-3 (]: 3 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.31s]
[0m11:30:02.249052 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m11:30:02.250160 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m11:30:02.524172 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ed49ee63-15dd-48a1-bb5d-7672ccf4d5e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d1a439790>]}
[0m11:30:02.525662 [info ] [Thread-4 (]: 4 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.58s]
[0m11:30:02.527230 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m11:30:03.094638 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ed49ee63-15dd-48a1-bb5d-7672ccf4d5e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d18280c50>]}
[0m11:30:03.096520 [info ] [Thread-1 (]: 5 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.09s]
[0m11:30:03.098403 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m11:30:03.101199 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m11:30:03.104463 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:30:03.105364 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m11:30:03.106211 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m11:30:03.106894 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m11:30:03.108831 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m11:30:03.110057 [info ] [MainThread]: 
[0m11:30:03.111554 [info ] [MainThread]: Finished running 5 incremental models in 0 hours 0 minutes and 4.63 seconds (4.63s).
[0m11:30:03.113928 [debug] [MainThread]: Command end result
[0m11:30:03.147483 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m11:30:03.151863 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m11:30:03.160322 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m11:30:03.161196 [info ] [MainThread]: 
[0m11:30:03.162282 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m11:30:03.163459 [info ] [MainThread]: 
[0m11:30:03.164644 [error] [MainThread]:   Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m11:30:03.166103 [info ] [MainThread]: 
[0m11:30:03.167099 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=0 TOTAL=5
[0m11:30:03.169012 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 6.6820965, "process_in_blocks": "0", "process_kernel_time": 0.219308, "process_mem_max_rss": "226096", "process_out_blocks": "0", "process_user_time": 4.256585}
[0m11:30:03.170354 [debug] [MainThread]: Command `dbt run` failed at 11:30:03.170209 after 6.68 seconds
[0m11:30:03.171440 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d48847cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d4c19d190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d4c19d210>]}
[0m11:30:03.172615 [debug] [MainThread]: Flushing usage events
[0m11:30:04.723165 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:31:16.787903 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5708f0e110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5708fc8490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5708b136d0>]}


============================== 11:31:16.790503 | febe273f-97c8-4d1e-a3c5-1b5309a8ad37 ==============================
[0m11:31:16.790503 [info ] [MainThread]: Running with dbt=1.9.0
[0m11:31:16.791783 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt clean', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m11:31:16.872313 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'febe273f-97c8-4d1e-a3c5-1b5309a8ad37', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5708a53350>]}
[0m11:31:16.943002 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.20395628, "process_in_blocks": "0", "process_kernel_time": 0.100567, "process_mem_max_rss": "90060", "process_out_blocks": "0", "process_user_time": 1.00567}
[0m11:31:16.944342 [debug] [MainThread]: Command `dbt clean` succeeded at 11:31:16.944168 after 0.21 seconds
[0m11:31:16.945223 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5708b674d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5708b67610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f570c308c10>]}
[0m11:31:16.946003 [debug] [MainThread]: Flushing usage events
[0m11:31:18.444590 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:31:19.597744 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb3dfb3e450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb3dfb3ee10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb3dfb3e610>]}


============================== 11:31:19.600594 | 1e4a9a36-06ea-4465-9085-f4fc67040004 ==============================
[0m11:31:19.600594 [info ] [MainThread]: Running with dbt=1.9.0
[0m11:31:19.602123 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt deps', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m11:31:19.693590 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1e4a9a36-06ea-4465-9085-f4fc67040004', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb3dfbc5a50>]}
[0m11:31:19.702885 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m11:31:19.705661 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m11:31:19.707187 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.1626803, "process_in_blocks": "0", "process_kernel_time": 0.1001, "process_mem_max_rss": "90184", "process_out_blocks": "0", "process_user_time": 1.001008}
[0m11:31:19.708434 [debug] [MainThread]: Command `dbt deps` succeeded at 11:31:19.708296 after 0.16 seconds
[0m11:31:19.709318 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb3dfb909d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb3dfa6cf50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb3dfbc6e50>]}
[0m11:31:19.710130 [debug] [MainThread]: Flushing usage events
[0m11:31:20.735242 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:31:23.537188 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc76d03edd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc76d08f610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc76d523890>]}


============================== 11:31:23.540272 | 73b3fc82-725f-477e-919d-9ee5848fe7da ==============================
[0m11:31:23.540272 [info ] [MainThread]: Running with dbt=1.9.0
[0m11:31:23.541492 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt run', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m11:31:24.129548 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '73b3fc82-725f-477e-919d-9ee5848fe7da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc73f1d0a50>]}
[0m11:31:24.175174 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '73b3fc82-725f-477e-919d-9ee5848fe7da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc76f2b63d0>]}
[0m11:31:24.176515 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m11:31:24.254757 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m11:31:24.258020 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m11:31:24.259904 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '73b3fc82-725f-477e-919d-9ee5848fe7da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc73f946a90>]}
[0m11:31:25.274792 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.facts
- models.dbt_project.staging
[0m11:31:25.287905 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '73b3fc82-725f-477e-919d-9ee5848fe7da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc73ee82050>]}
[0m11:31:25.360629 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m11:31:25.366480 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m11:31:25.383246 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '73b3fc82-725f-477e-919d-9ee5848fe7da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc73ec31590>]}
[0m11:31:25.384365 [info ] [MainThread]: Found 5 models, 8 sources, 488 macros
[0m11:31:25.385720 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '73b3fc82-725f-477e-919d-9ee5848fe7da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc73ee13150>]}
[0m11:31:25.388441 [info ] [MainThread]: 
[0m11:31:25.389516 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m11:31:25.390843 [info ] [MainThread]: 
[0m11:31:25.392273 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m11:31:25.397443 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m11:31:25.398444 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:31:25.953231 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m11:31:25.954095 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:31:26.191683 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '73b3fc82-725f-477e-919d-9ee5848fe7da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc73ee2dd10>]}
[0m11:31:26.192718 [debug] [MainThread]: Opening a new connection, currently in state init
[0m11:31:26.198018 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m11:31:26.198456 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m11:31:26.198856 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m11:31:26.199185 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m11:31:26.199944 [info ] [Thread-1 (]: 1 of 5 START sql incremental model rizky_dwh_hailing_source.dim_customer ....... [RUN]
[0m11:31:26.201527 [info ] [Thread-2 (]: 2 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [RUN]
[0m11:31:26.202695 [info ] [Thread-3 (]: 3 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [RUN]
[0m11:31:26.203808 [info ] [Thread-4 (]: 4 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [RUN]
[0m11:31:26.204911 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.dim_customer)
[0m11:31:26.206116 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_customer'
[0m11:31:26.207273 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m11:31:26.208412 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m11:31:26.209404 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m11:31:26.210246 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m11:31:26.211117 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m11:31:26.211959 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m11:31:26.221437 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m11:31:26.227588 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m11:31:26.231827 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m11:31:26.236500 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m11:31:26.250849 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m11:31:26.251438 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m11:31:26.263176 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m11:31:26.263537 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m11:31:26.300317 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m11:31:26.308005 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m11:31:26.330526 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m11:31:26.333010 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m11:31:26.421902 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`dim_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
)

SELECT *
FROM source

    );
  
[0m11:31:26.422856 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:31:26.648026 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m11:31:26.650380 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m11:31:26.651645 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m11:31:26.661727 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m11:31:26.664696 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m11:31:26.667607 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m11:31:26.953683 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:e627a688-b717-4be2-921a-c1d386c5f7a7&page=queryresults
[0m11:31:26.964758 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:626ad3a7-5ec2-4afb-8657-1e44348cc223&page=queryresults
[0m11:31:27.131845 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:0c64b30a-05d3-4f76-812e-2f8ecb112c93&page=queryresults
[0m11:31:27.132814 [error] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:0c64b30a-05d3-4f76-812e-2f8ecb112c93&page=queryresults
[0m11:31:27.137643 [debug] [Thread-2 (]: Database Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_customer.sql
[0m11:31:27.139426 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '73b3fc82-725f-477e-919d-9ee5848fe7da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc73c29f650>]}
[0m11:31:27.140429 [error] [Thread-2 (]: 2 of 5 ERROR creating sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [[31mERROR[0m in 0.93s]
[0m11:31:27.141491 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m11:31:27.142368 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m11:31:27.142826 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.production_hailing_staging_customer' to be skipped because of status 'error'.  Reason: Database Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_customer.sql.
[0m11:31:27.143649 [info ] [Thread-2 (]: 5 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [RUN]
[0m11:31:27.145609 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_customer, now model.hailing_project.production_hailing_staging_vehicle)
[0m11:31:27.146613 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m11:31:27.151116 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m11:31:27.157023 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m11:31:27.160343 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m11:31:27.392380 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m11:31:27.397854 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m11:31:27.533938 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:b7a29872-a4b8-4bda-a7a9-c9488af202d0&page=queryresults
[0m11:31:27.535141 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:b7a29872-a4b8-4bda-a7a9-c9488af202d0&page=queryresults
[0m11:31:27.539058 [debug] [Thread-1 (]: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m11:31:27.540285 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '73b3fc82-725f-477e-919d-9ee5848fe7da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc73ef25490>]}
[0m11:31:27.541427 [error] [Thread-1 (]: 1 of 5 ERROR creating sql incremental model rizky_dwh_hailing_source.dim_customer  [[31mERROR[0m in 1.34s]
[0m11:31:27.542617 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m11:31:27.543817 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.dim_customer' to be skipped because of status 'error'.  Reason: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql.
[0m11:31:27.708547 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:f6b2c0b6-363b-4479-86eb-a02749b1cef5&page=queryresults
[0m11:31:28.567941 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '73b3fc82-725f-477e-919d-9ee5848fe7da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc726fb0f50>]}
[0m11:31:28.568638 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '73b3fc82-725f-477e-919d-9ee5848fe7da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc73c21c650>]}
[0m11:31:28.569909 [info ] [Thread-4 (]: 4 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.36s]
[0m11:31:28.571811 [info ] [Thread-3 (]: 3 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.36s]
[0m11:31:28.572861 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m11:31:28.574116 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m11:31:29.254945 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '73b3fc82-725f-477e-919d-9ee5848fe7da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc73c211bd0>]}
[0m11:31:29.256190 [info ] [Thread-2 (]: 5 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.11s]
[0m11:31:29.257463 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m11:31:29.259692 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m11:31:29.262780 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:31:29.263611 [debug] [MainThread]: Connection 'model.hailing_project.dim_customer' was properly closed.
[0m11:31:29.264414 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m11:31:29.265257 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m11:31:29.266061 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m11:31:29.267086 [info ] [MainThread]: 
[0m11:31:29.268095 [info ] [MainThread]: Finished running 5 incremental models in 0 hours 0 minutes and 3.87 seconds (3.87s).
[0m11:31:29.270300 [debug] [MainThread]: Command end result
[0m11:31:29.306391 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m11:31:29.310744 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m11:31:29.318935 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m11:31:29.319616 [info ] [MainThread]: 
[0m11:31:29.320607 [info ] [MainThread]: [31mCompleted with 2 errors, 0 partial successes, and 0 warnings:[0m
[0m11:31:29.321777 [info ] [MainThread]: 
[0m11:31:29.322694 [error] [MainThread]:   Database Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_customer.sql
[0m11:31:29.323548 [info ] [MainThread]: 
[0m11:31:29.324854 [error] [MainThread]:   Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m11:31:29.325662 [info ] [MainThread]: 
[0m11:31:29.326777 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=2 SKIP=0 TOTAL=5
[0m11:31:29.328661 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 5.852827, "process_in_blocks": "0", "process_kernel_time": 0.211902, "process_mem_max_rss": "230036", "process_out_blocks": "0", "process_user_time": 4.227959}
[0m11:31:29.329755 [debug] [MainThread]: Command `dbt run` failed at 11:31:29.329625 after 5.85 seconds
[0m11:31:29.330616 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc76d0bbad0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc76d0bb790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc76d0bbf10>]}
[0m11:31:29.331708 [debug] [MainThread]: Flushing usage events
[0m11:31:30.889761 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:32:28.758726 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0f53e83e10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0f53edbf10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0f53edb7d0>]}


============================== 11:32:28.761494 | d0b34ed4-d42a-48ef-a4ca-757c75494cba ==============================
[0m11:32:28.761494 [info ] [MainThread]: Running with dbt=1.9.0
[0m11:32:28.763028 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt run', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m11:32:29.350576 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd0b34ed4-d42a-48ef-a4ca-757c75494cba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0f26056990>]}
[0m11:32:29.402656 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd0b34ed4-d42a-48ef-a4ca-757c75494cba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0f560f9e10>]}
[0m11:32:29.403761 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m11:32:29.467202 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m11:32:29.615293 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m11:32:29.616167 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/staging/production_hailing_staging_customer.sql
[0m11:32:29.862117 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.facts
- models.dbt_project.staging
[0m11:32:29.874187 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd0b34ed4-d42a-48ef-a4ca-757c75494cba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0f25cbf250>]}
[0m11:32:29.946424 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m11:32:29.952012 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m11:32:29.966328 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd0b34ed4-d42a-48ef-a4ca-757c75494cba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0f25b97510>]}
[0m11:32:29.967645 [info ] [MainThread]: Found 5 models, 8 sources, 488 macros
[0m11:32:29.969098 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd0b34ed4-d42a-48ef-a4ca-757c75494cba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0f25caf590>]}
[0m11:32:29.972076 [info ] [MainThread]: 
[0m11:32:29.973231 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m11:32:29.974416 [info ] [MainThread]: 
[0m11:32:29.975815 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m11:32:29.980270 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m11:32:29.981222 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:32:30.873793 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m11:32:30.874816 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:32:31.101657 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd0b34ed4-d42a-48ef-a4ca-757c75494cba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0f25e6b3d0>]}
[0m11:32:31.102801 [debug] [MainThread]: Opening a new connection, currently in state init
[0m11:32:31.108242 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m11:32:31.108711 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m11:32:31.109201 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m11:32:31.109542 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m11:32:31.110126 [info ] [Thread-1 (]: 1 of 5 START sql incremental model rizky_dwh_hailing_source.dim_customer ....... [RUN]
[0m11:32:31.111513 [info ] [Thread-2 (]: 2 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [RUN]
[0m11:32:31.112736 [info ] [Thread-3 (]: 3 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [RUN]
[0m11:32:31.114865 [info ] [Thread-4 (]: 4 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [RUN]
[0m11:32:31.116877 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.dim_customer)
[0m11:32:31.118347 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_customer'
[0m11:32:31.119413 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m11:32:31.121163 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m11:32:31.122299 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m11:32:31.123237 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m11:32:31.124011 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m11:32:31.125347 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m11:32:31.134551 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m11:32:31.140042 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m11:32:31.145315 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m11:32:31.149604 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m11:32:31.154068 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m11:32:31.155135 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m11:32:31.161077 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m11:32:31.161446 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m11:32:31.199080 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m11:32:31.199558 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m11:32:31.223711 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m11:32:31.231045 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m11:32:31.314574 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`dim_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
)

SELECT *
FROM source

    );
  
[0m11:32:31.315558 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:32:31.530156 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m11:32:31.532487 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m11:32:31.534156 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m11:32:31.539096 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m11:32:31.540457 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m11:32:31.542348 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m11:32:31.799093 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:812b7ba0-7fe3-4f01-9131-e8a5e39837dd&page=queryresults
[0m11:32:31.809849 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:4db3d389-ceb3-4800-a15f-05cb5ade3d14&page=queryresults
[0m11:32:31.921972 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:2fc360aa-15ad-48a2-85bc-2445f6641954&page=queryresults
[0m11:32:32.368277 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:5ba88e81-5ff8-4b0f-8969-7402cf217734&page=queryresults
[0m11:32:32.372431 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:5ba88e81-5ff8-4b0f-8969-7402cf217734&page=queryresults
[0m11:32:32.380728 [debug] [Thread-1 (]: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m11:32:32.382760 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd0b34ed4-d42a-48ef-a4ca-757c75494cba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0f2423f150>]}
[0m11:32:32.384072 [error] [Thread-1 (]: 1 of 5 ERROR creating sql incremental model rizky_dwh_hailing_source.dim_customer  [[31mERROR[0m in 1.27s]
[0m11:32:32.385546 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m11:32:32.386873 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m11:32:32.387401 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.dim_customer' to be skipped because of status 'error'.  Reason: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql.
[0m11:32:32.388192 [info ] [Thread-1 (]: 5 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [RUN]
[0m11:32:32.390369 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.hailing_project.dim_customer, now model.hailing_project.production_hailing_staging_vehicle)
[0m11:32:32.391516 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m11:32:32.396610 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m11:32:32.403395 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m11:32:32.407603 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:32:32.672519 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m11:32:32.680353 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m11:32:32.933038 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:03c381a0-3fc2-4abb-bbaf-c9ed0e0c4a46&page=queryresults
[0m11:32:33.365948 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd0b34ed4-d42a-48ef-a4ca-757c75494cba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0f25bcf210>]}
[0m11:32:33.369038 [info ] [Thread-4 (]: 4 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.24s]
[0m11:32:33.370529 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m11:32:33.685075 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd0b34ed4-d42a-48ef-a4ca-757c75494cba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0f2422bc50>]}
[0m11:32:33.686697 [info ] [Thread-2 (]: 2 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.57s]
[0m11:32:33.688850 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m11:32:33.742697 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd0b34ed4-d42a-48ef-a4ca-757c75494cba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0f241d53d0>]}
[0m11:32:33.746797 [info ] [Thread-3 (]: 3 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.62s]
[0m11:32:33.749397 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m11:32:34.762458 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd0b34ed4-d42a-48ef-a4ca-757c75494cba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0f241fbcd0>]}
[0m11:32:34.763796 [info ] [Thread-1 (]: 5 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.37s]
[0m11:32:34.765047 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m11:32:34.767131 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m11:32:34.770250 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:32:34.770955 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m11:32:34.771590 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m11:32:34.772307 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m11:32:34.772946 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m11:32:34.774337 [info ] [MainThread]: 
[0m11:32:34.775570 [info ] [MainThread]: Finished running 5 incremental models in 0 hours 0 minutes and 4.80 seconds (4.80s).
[0m11:32:34.777497 [debug] [MainThread]: Command end result
[0m11:32:34.811082 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m11:32:34.815173 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m11:32:34.823165 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m11:32:34.824056 [info ] [MainThread]: 
[0m11:32:34.825051 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m11:32:34.826157 [info ] [MainThread]: 
[0m11:32:34.827215 [error] [MainThread]:   Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m11:32:34.828033 [info ] [MainThread]: 
[0m11:32:34.829288 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=0 TOTAL=5
[0m11:32:34.831162 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 6.1225686, "process_in_blocks": "0", "process_kernel_time": 0.285821, "process_mem_max_rss": "226000", "process_out_blocks": "0", "process_user_time": 3.511524}
[0m11:32:34.832401 [debug] [MainThread]: Command `dbt run` failed at 11:32:34.832272 after 6.12 seconds
[0m11:32:34.833284 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0f53edb7d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0f5427e210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0f560e9190>]}
[0m11:32:34.834042 [debug] [MainThread]: Flushing usage events
[0m11:32:38.837431 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:33:17.063249 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87bfc9f150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87c0987990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87bfc9eb50>]}


============================== 11:33:17.066039 | 10575560-8b1f-4499-9aec-bb1a9e4d8e1c ==============================
[0m11:33:17.066039 [info ] [MainThread]: Running with dbt=1.9.0
[0m11:33:17.067494 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m11:33:17.722606 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '10575560-8b1f-4499-9aec-bb1a9e4d8e1c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8791fb5d90>]}
[0m11:33:17.775893 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '10575560-8b1f-4499-9aec-bb1a9e4d8e1c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87c1f2a3d0>]}
[0m11:33:17.777070 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m11:33:17.865471 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m11:33:17.946309 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m11:33:17.947560 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '10575560-8b1f-4499-9aec-bb1a9e4d8e1c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87c0aa43d0>]}
[0m11:33:19.042025 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.facts
- models.dbt_project.staging
[0m11:33:19.056027 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '10575560-8b1f-4499-9aec-bb1a9e4d8e1c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8791d09510>]}
[0m11:33:19.133452 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m11:33:19.139021 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m11:33:19.153720 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '10575560-8b1f-4499-9aec-bb1a9e4d8e1c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f879187c210>]}
[0m11:33:19.154698 [info ] [MainThread]: Found 5 models, 8 sources, 488 macros
[0m11:33:19.158501 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '10575560-8b1f-4499-9aec-bb1a9e4d8e1c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8791aac990>]}
[0m11:33:19.161634 [info ] [MainThread]: 
[0m11:33:19.162818 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m11:33:19.164082 [info ] [MainThread]: 
[0m11:33:19.165427 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m11:33:19.170550 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m11:33:19.171478 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:33:20.213818 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m11:33:20.214859 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:33:20.471933 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '10575560-8b1f-4499-9aec-bb1a9e4d8e1c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8791b72690>]}
[0m11:33:20.472967 [debug] [MainThread]: Opening a new connection, currently in state init
[0m11:33:20.478036 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m11:33:20.478402 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m11:33:20.478782 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m11:33:20.479072 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m11:33:20.479575 [info ] [Thread-1 (]: 1 of 5 START sql incremental model rizky_dwh_hailing_source.dim_customer ....... [RUN]
[0m11:33:20.480825 [info ] [Thread-2 (]: 2 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [RUN]
[0m11:33:20.482278 [info ] [Thread-3 (]: 3 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [RUN]
[0m11:33:20.483390 [info ] [Thread-4 (]: 4 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [RUN]
[0m11:33:20.484538 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.dim_customer)
[0m11:33:20.485603 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_customer'
[0m11:33:20.486577 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m11:33:20.487584 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m11:33:20.488621 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m11:33:20.489506 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m11:33:20.490298 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m11:33:20.491311 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m11:33:20.499441 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m11:33:20.506367 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m11:33:20.511362 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m11:33:20.516952 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m11:33:20.523007 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m11:33:20.523646 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m11:33:20.524098 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m11:33:20.529979 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m11:33:20.570112 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m11:33:20.579419 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m11:33:20.605013 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m11:33:20.605248 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m11:33:20.680230 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`dim_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
)

SELECT *
FROM source

    );
  
[0m11:33:20.681345 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:33:20.919728 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m11:33:20.921154 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m11:33:20.923024 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m11:33:20.928663 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m11:33:20.929348 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m11:33:20.933097 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m11:33:21.204316 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:f19c1f4e-abe1-4a59-aa7a-49c90325e418&page=queryresults
[0m11:33:21.208815 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:a2e4a738-9fb5-4e70-8ab4-660b9511f8f4&page=queryresults
[0m11:33:21.209455 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:54bc30b8-c0e4-4c55-9b62-076cc18ddd51&page=queryresults
[0m11:33:21.455132 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:a8804f99-cdf1-4573-bfa3-3d7e985a1fcc&page=queryresults
[0m11:33:21.456440 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:a8804f99-cdf1-4573-bfa3-3d7e985a1fcc&page=queryresults
[0m11:33:21.461028 [debug] [Thread-1 (]: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m11:33:21.463527 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '10575560-8b1f-4499-9aec-bb1a9e4d8e1c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8781f1c290>]}
[0m11:33:21.464948 [error] [Thread-1 (]: 1 of 5 ERROR creating sql incremental model rizky_dwh_hailing_source.dim_customer  [[31mERROR[0m in 0.98s]
[0m11:33:21.466103 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m11:33:21.467203 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m11:33:21.467813 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.dim_customer' to be skipped because of status 'error'.  Reason: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql.
[0m11:33:21.468764 [info ] [Thread-1 (]: 5 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [RUN]
[0m11:33:21.471720 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.hailing_project.dim_customer, now model.hailing_project.production_hailing_staging_vehicle)
[0m11:33:21.472880 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m11:33:21.477840 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m11:33:21.485397 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m11:33:21.489400 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:33:21.742332 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m11:33:21.750118 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m11:33:22.001026 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:086fd329-0363-4989-b014-c834262650d3&page=queryresults
[0m11:33:22.762427 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '10575560-8b1f-4499-9aec-bb1a9e4d8e1c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8781e5ce10>]}
[0m11:33:22.763846 [info ] [Thread-4 (]: 4 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.27s]
[0m11:33:22.765328 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m11:33:23.005717 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '10575560-8b1f-4499-9aec-bb1a9e4d8e1c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8781f35f50>]}
[0m11:33:23.007378 [info ] [Thread-3 (]: 3 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.52s]
[0m11:33:23.008674 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m11:33:23.018617 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '10575560-8b1f-4499-9aec-bb1a9e4d8e1c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f879192fc90>]}
[0m11:33:23.019901 [info ] [Thread-2 (]: 2 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.53s]
[0m11:33:23.021728 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m11:33:23.521383 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '10575560-8b1f-4499-9aec-bb1a9e4d8e1c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8791af0a10>]}
[0m11:33:23.522532 [info ] [Thread-1 (]: 5 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.05s]
[0m11:33:23.523719 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m11:33:23.525823 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m11:33:23.528833 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:33:23.529574 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m11:33:23.530432 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m11:33:23.531397 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m11:33:23.532075 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m11:33:23.532881 [info ] [MainThread]: 
[0m11:33:23.534070 [info ] [MainThread]: Finished running 5 incremental models in 0 hours 0 minutes and 4.37 seconds (4.37s).
[0m11:33:23.535951 [debug] [MainThread]: Command end result
[0m11:33:23.570109 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m11:33:23.574183 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m11:33:23.581754 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m11:33:23.582822 [info ] [MainThread]: 
[0m11:33:23.584013 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m11:33:23.585231 [info ] [MainThread]: 
[0m11:33:23.586496 [error] [MainThread]:   Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m11:33:23.587460 [info ] [MainThread]: 
[0m11:33:23.588465 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=0 TOTAL=5
[0m11:33:23.590500 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 6.589186, "process_in_blocks": "0", "process_kernel_time": 0.188083, "process_mem_max_rss": "230292", "process_out_blocks": "0", "process_user_time": 4.484314}
[0m11:33:23.592600 [debug] [MainThread]: Command `dbt run` failed at 11:33:23.592435 after 6.59 seconds
[0m11:33:23.593608 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87bfcd1250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87c3791850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87bfcefd50>]}
[0m11:33:23.594555 [debug] [MainThread]: Flushing usage events
[0m11:33:24.907413 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:01:23.041808 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f183c2caf90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f183c2cb110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f183c2cb1d0>]}


============================== 12:01:23.044429 | 2ba89753-9768-4f8a-b7f2-6b094f0fe7b7 ==============================
[0m12:01:23.044429 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:01:23.047094 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt run', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m12:01:23.680012 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '2ba89753-9768-4f8a-b7f2-6b094f0fe7b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f180f61add0>]}
[0m12:01:23.733319 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '2ba89753-9768-4f8a-b7f2-6b094f0fe7b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f183e544b90>]}
[0m12:01:23.734714 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m12:01:23.806481 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m12:01:23.877494 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m12:01:23.879576 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '2ba89753-9768-4f8a-b7f2-6b094f0fe7b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f180e4b61d0>]}
[0m12:01:25.118524 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.facts
- models.dbt_project.staging
[0m12:01:25.132728 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2ba89753-9768-4f8a-b7f2-6b094f0fe7b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f180e108ad0>]}
[0m12:01:25.217637 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m12:01:25.225075 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m12:01:25.245321 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2ba89753-9768-4f8a-b7f2-6b094f0fe7b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f180de88150>]}
[0m12:01:25.246613 [info ] [MainThread]: Found 5 models, 8 sources, 488 macros
[0m12:01:25.248027 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2ba89753-9768-4f8a-b7f2-6b094f0fe7b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f180dea6e10>]}
[0m12:01:25.250992 [info ] [MainThread]: 
[0m12:01:25.252512 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m12:01:25.253530 [info ] [MainThread]: 
[0m12:01:25.255032 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m12:01:25.260178 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m12:01:25.261626 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:01:25.900015 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m12:01:25.903003 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:01:26.170599 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2ba89753-9768-4f8a-b7f2-6b094f0fe7b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f180e59eb50>]}
[0m12:01:26.172041 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:01:26.178845 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m12:01:26.179249 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m12:01:26.179681 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m12:01:26.180075 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m12:01:26.180842 [info ] [Thread-1 (]: 1 of 5 START sql incremental model rizky_dwh_hailing_source.dim_customer ....... [RUN]
[0m12:01:26.182127 [info ] [Thread-2 (]: 2 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [RUN]
[0m12:01:26.183529 [info ] [Thread-3 (]: 3 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [RUN]
[0m12:01:26.184622 [info ] [Thread-4 (]: 4 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [RUN]
[0m12:01:26.186030 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.dim_customer)
[0m12:01:26.187461 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_customer'
[0m12:01:26.188740 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m12:01:26.189763 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m12:01:26.190717 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m12:01:26.191588 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m12:01:26.192329 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m12:01:26.193016 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m12:01:26.200604 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m12:01:26.206393 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m12:01:26.210531 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m12:01:26.215356 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m12:01:26.222096 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m12:01:26.223400 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m12:01:26.229143 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m12:01:26.239452 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m12:01:26.282538 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m12:01:26.292039 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m12:01:26.311097 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m12:01:26.314172 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m12:01:26.367791 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`dim_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
)

SELECT *
FROM source

    );
  
[0m12:01:26.393723 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:01:26.636590 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m12:01:26.645750 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m12:01:26.647494 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m12:01:26.654944 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m12:01:26.667413 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m12:01:26.675209 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m12:01:27.003611 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:fd0297e6-69fc-4cae-b438-e94d1a05b14b&page=queryresults
[0m12:01:27.201704 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:79769e63-e351-4cae-994b-7c78c08b6e0e&page=queryresults
[0m12:01:27.218517 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:162be8a4-aaf8-4df4-9526-5d502be3b88c&page=queryresults
[0m12:01:27.310780 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:db1111d1-93e1-44e8-b511-5a1989193ce3&page=queryresults
[0m12:01:27.311802 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:db1111d1-93e1-44e8-b511-5a1989193ce3&page=queryresults
[0m12:01:27.316815 [debug] [Thread-1 (]: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m12:01:27.319057 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2ba89753-9768-4f8a-b7f2-6b094f0fe7b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f180e08a610>]}
[0m12:01:27.320309 [error] [Thread-1 (]: 1 of 5 ERROR creating sql incremental model rizky_dwh_hailing_source.dim_customer  [[31mERROR[0m in 1.13s]
[0m12:01:27.321488 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m12:01:27.322630 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m12:01:27.323145 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.dim_customer' to be skipped because of status 'error'.  Reason: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql.
[0m12:01:27.324294 [info ] [Thread-1 (]: 5 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [RUN]
[0m12:01:27.326713 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.hailing_project.dim_customer, now model.hailing_project.production_hailing_staging_vehicle)
[0m12:01:27.327614 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m12:01:27.333135 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m12:01:27.344289 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m12:01:27.348855 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:01:27.615966 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m12:01:27.622104 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m12:01:27.919878 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:ee21e364-b539-45b7-b799-5c4d9e7d44e3&page=queryresults
[0m12:01:28.917833 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2ba89753-9768-4f8a-b7f2-6b094f0fe7b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f180e0bccd0>]}
[0m12:01:28.919708 [info ] [Thread-3 (]: 3 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.73s]
[0m12:01:28.921311 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m12:01:29.114175 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2ba89753-9768-4f8a-b7f2-6b094f0fe7b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f180de82750>]}
[0m12:01:29.115991 [info ] [Thread-4 (]: 4 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.92s]
[0m12:01:29.119290 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m12:01:29.119987 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2ba89753-9768-4f8a-b7f2-6b094f0fe7b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f180de88d10>]}
[0m12:01:29.121583 [info ] [Thread-2 (]: 2 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.93s]
[0m12:01:29.122565 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m12:01:29.532469 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2ba89753-9768-4f8a-b7f2-6b094f0fe7b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f180c56a390>]}
[0m12:01:29.533427 [info ] [Thread-1 (]: 5 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.21s]
[0m12:01:29.534626 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m12:01:29.536609 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m12:01:29.539546 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:01:29.540232 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m12:01:29.540783 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m12:01:29.541380 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m12:01:29.542334 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m12:01:29.543443 [info ] [MainThread]: 
[0m12:01:29.544933 [info ] [MainThread]: Finished running 5 incremental models in 0 hours 0 minutes and 4.29 seconds (4.29s).
[0m12:01:29.547106 [debug] [MainThread]: Command end result
[0m12:01:29.581528 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m12:01:29.585508 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m12:01:29.593859 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m12:01:29.594594 [info ] [MainThread]: 
[0m12:01:29.595587 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m12:01:29.596569 [info ] [MainThread]: 
[0m12:01:29.597515 [error] [MainThread]:   Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m12:01:29.598491 [info ] [MainThread]: 
[0m12:01:29.599484 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=0 TOTAL=5
[0m12:01:29.601208 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 6.6118755, "process_in_blocks": "0", "process_kernel_time": 0.223851, "process_mem_max_rss": "226992", "process_out_blocks": "0", "process_user_time": 4.466847}
[0m12:01:29.602333 [debug] [MainThread]: Command `dbt run` failed at 12:01:29.602155 after 6.61 seconds
[0m12:01:29.603455 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f183c6c6710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f183c31b610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f183fc44a50>]}
[0m12:01:29.605309 [debug] [MainThread]: Flushing usage events
[0m12:01:31.039522 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:05:38.304484 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb0da673810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb0dab4b990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb0da6735d0>]}


============================== 12:05:38.307713 | f9c893d6-2bde-4050-a55e-1e02c4b8110f ==============================
[0m12:05:38.307713 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:05:38.309552 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m12:05:38.892751 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f9c893d6-2bde-4050-a55e-1e02c4b8110f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb0b088b690>]}
[0m12:05:38.938640 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f9c893d6-2bde-4050-a55e-1e02c4b8110f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb0dc8cdf10>]}
[0m12:05:38.940110 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m12:05:39.013672 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m12:05:39.168197 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m12:05:39.169719 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/staging/production_hailing_staging_customer.sql
[0m12:05:39.374120 [error] [MainThread]: Encountered an error:
Compilation Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  invalid syntax for function call expression
    line 2
      config(
[0m12:05:39.376534 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.1221713, "process_in_blocks": "0", "process_kernel_time": 0.229939, "process_mem_max_rss": "214568", "process_out_blocks": "0", "process_user_time": 2.869246}
[0m12:05:39.377851 [debug] [MainThread]: Command `dbt run` failed at 12:05:39.377708 after 1.12 seconds
[0m12:05:39.378768 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb0da4d1710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb0da4d0690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb0b0840190>]}
[0m12:05:39.379824 [debug] [MainThread]: Flushing usage events
[0m12:05:40.687083 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:06:54.076428 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3fc3de3150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3fc3de2f90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3fc3de2890>]}


============================== 12:06:54.078947 | a3ead25e-b070-4466-9b8a-0b6f3629b4eb ==============================
[0m12:06:54.078947 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:06:54.081273 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt clean', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m12:06:54.168819 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a3ead25e-b070-4466-9b8a-0b6f3629b4eb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3fc41da3d0>]}
[0m12:06:54.229774 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.1988981, "process_in_blocks": "0", "process_kernel_time": 0.097518, "process_mem_max_rss": "90112", "process_out_blocks": "0", "process_user_time": 0.955679}
[0m12:06:54.230916 [debug] [MainThread]: Command `dbt clean` succeeded at 12:06:54.230744 after 0.20 seconds
[0m12:06:54.231757 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3fc3d1bf50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3fc3e15c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3fc75d4c10>]}
[0m12:06:54.232854 [debug] [MainThread]: Flushing usage events
[0m12:06:55.275371 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:06:56.473248 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f121fc6b090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f121fcaf490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f121fc6ae10>]}


============================== 12:06:56.476038 | 355a9074-6bed-498a-bab7-e6e35b153367 ==============================
[0m12:06:56.476038 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:06:56.477140 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt deps', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m12:06:56.564639 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '355a9074-6bed-498a-bab7-e6e35b153367', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f121fafd090>]}
[0m12:06:56.575520 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m12:06:56.578000 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m12:06:56.579474 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.16740432, "process_in_blocks": "0", "process_kernel_time": 0.100529, "process_mem_max_rss": "90192", "process_out_blocks": "0", "process_user_time": 1.025405}
[0m12:06:56.580816 [debug] [MainThread]: Command `dbt deps` succeeded at 12:06:56.580648 after 0.17 seconds
[0m12:06:56.581819 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f121fc9ce50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f121fc6b010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1223434b90>]}
[0m12:06:56.582708 [debug] [MainThread]: Flushing usage events
[0m12:06:57.645667 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:07:00.830664 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f83737ff210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8373cdf790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8373cdf6d0>]}


============================== 12:07:00.833489 | be01370c-820b-4130-93b4-4aa76e8fbb28 ==============================
[0m12:07:00.833489 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:07:00.834617 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt run', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m12:07:01.418288 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'be01370c-820b-4130-93b4-4aa76e8fbb28', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f83459a6e10>]}
[0m12:07:01.470950 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'be01370c-820b-4130-93b4-4aa76e8fbb28', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8375a51ed0>]}
[0m12:07:01.472459 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m12:07:01.558442 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m12:07:01.561315 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m12:07:01.562420 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'be01370c-820b-4130-93b4-4aa76e8fbb28', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8346fe6ed0>]}
[0m12:07:02.471392 [error] [MainThread]: Encountered an error:
Compilation Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  invalid syntax for function call expression
    line 2
      config(
[0m12:07:02.472929 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.6912909, "process_in_blocks": "0", "process_kernel_time": 0.180507, "process_mem_max_rss": "212280", "process_out_blocks": "0", "process_user_time": 3.610142}
[0m12:07:02.474009 [debug] [MainThread]: Command `dbt run` failed at 12:07:02.473886 after 1.69 seconds
[0m12:07:02.474781 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8373663450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8373663910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8345f49410>]}
[0m12:07:02.475586 [debug] [MainThread]: Flushing usage events
[0m12:07:03.520886 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:08:18.671457 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f56e8d36a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f56e8d36890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f56e8d368d0>]}


============================== 12:08:18.674089 | 3ce10335-4778-4cac-9a10-29aae94e2109 ==============================
[0m12:08:18.674089 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:08:18.675315 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'version_check': 'True', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt clean', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m12:08:18.761271 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '3ce10335-4778-4cac-9a10-29aae94e2109', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f56e8c73510>]}
[0m12:08:18.789072 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.1728333, "process_in_blocks": "0", "process_kernel_time": 0.08973, "process_mem_max_rss": "90128", "process_out_blocks": "0", "process_user_time": 1.016945}
[0m12:08:18.790539 [debug] [MainThread]: Command `dbt clean` succeeded at 12:08:18.790425 after 0.17 seconds
[0m12:08:18.791706 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f56e8d69290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f56e8d69b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f56ec685110>]}
[0m12:08:18.793608 [debug] [MainThread]: Flushing usage events
[0m12:08:20.093374 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:08:21.263507 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ef476f050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ef47c2fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ef4b6a0d0>]}


============================== 12:08:21.266440 | d910b610-cd9a-4cdc-8642-8e8bab061d93 ==============================
[0m12:08:21.266440 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:08:21.267776 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt deps', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m12:08:21.355016 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd910b610-cd9a-4cdc-8642-8e8bab061d93', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ef466c350>]}
[0m12:08:21.366077 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m12:08:21.368873 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m12:08:21.370410 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.16112548, "process_in_blocks": "0", "process_kernel_time": 0.050841, "process_mem_max_rss": "90184", "process_out_blocks": "0", "process_user_time": 1.057495}
[0m12:08:21.371464 [debug] [MainThread]: Command `dbt deps` succeeded at 12:08:21.371321 after 0.16 seconds
[0m12:08:21.372222 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ef47c3110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ef471b550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ef7fc8b90>]}
[0m12:08:21.373043 [debug] [MainThread]: Flushing usage events
[0m12:08:22.411523 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:08:26.840281 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f08ba1e2090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f08ba2377d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f08ba237550>]}


============================== 12:08:26.842899 | ca4c587d-64de-4d11-9d71-104282f79f41 ==============================
[0m12:08:26.842899 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:08:26.844168 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt run', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m12:08:27.440523 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ca4c587d-64de-4d11-9d71-104282f79f41', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f089058b4d0>]}
[0m12:08:27.489054 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ca4c587d-64de-4d11-9d71-104282f79f41', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f08bc492310>]}
[0m12:08:27.490483 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m12:08:27.566023 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m12:08:27.568812 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m12:08:27.569792 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'ca4c587d-64de-4d11-9d71-104282f79f41', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f08ba239c90>]}
[0m12:08:28.466267 [error] [MainThread]: Encountered an error:
Compilation Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  invalid syntax for function call expression
    line 2
      config(
[0m12:08:28.468284 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.6833, "process_in_blocks": "0", "process_kernel_time": 0.178624, "process_mem_max_rss": "212036", "process_out_blocks": "0", "process_user_time": 3.572497}
[0m12:08:28.470348 [debug] [MainThread]: Command `dbt run` failed at 12:08:28.470195 after 1.69 seconds
[0m12:08:28.471674 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f08ba23b7d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0890253a50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f08ba23b9d0>]}
[0m12:08:28.472719 [debug] [MainThread]: Flushing usage events
[0m12:08:29.525590 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:10:05.913438 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd3b92bec90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd3b9307590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd3b979f750>]}


============================== 12:10:05.916133 | 68d81414-eb80-436b-8f13-72f9f9356c39 ==============================
[0m12:10:05.916133 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:10:05.920392 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt run', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m12:10:06.493126 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '68d81414-eb80-436b-8f13-72f9f9356c39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd38b5430d0>]}
[0m12:10:06.543156 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '68d81414-eb80-436b-8f13-72f9f9356c39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd3bb51a1d0>]}
[0m12:10:06.545057 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m12:10:06.611318 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m12:10:06.613544 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m12:10:06.614389 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '68d81414-eb80-436b-8f13-72f9f9356c39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd38b268c90>]}
[0m12:10:07.615662 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.facts
- models.dbt_project.staging
[0m12:10:07.627172 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '68d81414-eb80-436b-8f13-72f9f9356c39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd38b177f90>]}
[0m12:10:07.696145 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m12:10:07.701545 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m12:10:07.716025 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '68d81414-eb80-436b-8f13-72f9f9356c39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd38aec4d10>]}
[0m12:10:07.717143 [info ] [MainThread]: Found 5 models, 8 sources, 488 macros
[0m12:10:07.718269 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '68d81414-eb80-436b-8f13-72f9f9356c39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd38aee3710>]}
[0m12:10:07.720782 [info ] [MainThread]: 
[0m12:10:07.722121 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m12:10:07.723205 [info ] [MainThread]: 
[0m12:10:07.724862 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m12:10:07.731481 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m12:10:07.732627 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:10:08.346235 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m12:10:08.347658 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:10:08.610951 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '68d81414-eb80-436b-8f13-72f9f9356c39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd38b0ba0d0>]}
[0m12:10:08.612421 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:10:08.619143 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m12:10:08.619599 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m12:10:08.620004 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m12:10:08.620504 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m12:10:08.621248 [info ] [Thread-1 (]: 1 of 5 START sql incremental model rizky_dwh_hailing_source.dim_customer ....... [RUN]
[0m12:10:08.622600 [info ] [Thread-2 (]: 2 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [RUN]
[0m12:10:08.624011 [info ] [Thread-3 (]: 3 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [RUN]
[0m12:10:08.625412 [info ] [Thread-4 (]: 4 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [RUN]
[0m12:10:08.626773 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.dim_customer)
[0m12:10:08.627862 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_customer'
[0m12:10:08.628841 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m12:10:08.629920 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m12:10:08.630809 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m12:10:08.631794 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m12:10:08.632768 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m12:10:08.633627 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m12:10:08.642909 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m12:10:08.650212 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m12:10:08.654891 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m12:10:08.659401 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m12:10:08.673388 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m12:10:08.673943 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m12:10:08.685425 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m12:10:08.714156 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m12:10:08.717154 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m12:10:08.736582 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m12:10:08.748058 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m12:10:08.751051 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m12:10:08.836389 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`dim_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
)

SELECT *
FROM source

    );
  
[0m12:10:08.837254 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:10:09.051461 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m12:10:09.052854 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m12:10:09.058874 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m12:10:09.061367 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m12:10:09.077703 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m12:10:09.082892 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m12:10:09.440854 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:a77580ae-74d7-4082-945e-1557dcd44eb3&page=queryresults
[0m12:10:09.444775 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:5de3a9cf-f8f8-4fd6-927c-73b22a522df2&page=queryresults
[0m12:10:09.445230 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:f11cbfee-0399-46d4-91a6-108a550c3f25&page=queryresults
[0m12:10:09.660010 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:f6e52364-52f9-4897-a96e-199f121bf859&page=queryresults
[0m12:10:09.661133 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:f6e52364-52f9-4897-a96e-199f121bf859&page=queryresults
[0m12:10:09.665395 [debug] [Thread-1 (]: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m12:10:09.667377 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '68d81414-eb80-436b-8f13-72f9f9356c39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd3885b8350>]}
[0m12:10:09.668387 [error] [Thread-1 (]: 1 of 5 ERROR creating sql incremental model rizky_dwh_hailing_source.dim_customer  [[31mERROR[0m in 1.04s]
[0m12:10:09.670203 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m12:10:09.671349 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m12:10:09.671869 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.dim_customer' to be skipped because of status 'error'.  Reason: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql.
[0m12:10:09.672662 [info ] [Thread-1 (]: 5 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [RUN]
[0m12:10:09.675555 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.hailing_project.dim_customer, now model.hailing_project.production_hailing_staging_vehicle)
[0m12:10:09.676387 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m12:10:09.681006 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m12:10:09.686430 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m12:10:09.690206 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:10:09.951947 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m12:10:09.959043 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m12:10:10.237203 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:86441706-7148-489f-9571-02540b89f3e9&page=queryresults
[0m12:10:11.054244 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '68d81414-eb80-436b-8f13-72f9f9356c39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd3882d1110>]}
[0m12:10:11.055069 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '68d81414-eb80-436b-8f13-72f9f9356c39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd38b05e790>]}
[0m12:10:11.056035 [info ] [Thread-2 (]: 2 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.43s]
[0m12:10:11.057364 [info ] [Thread-4 (]: 4 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.43s]
[0m12:10:11.058794 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m12:10:11.059985 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m12:10:11.074131 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '68d81414-eb80-436b-8f13-72f9f9356c39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd388517dd0>]}
[0m12:10:11.075411 [info ] [Thread-3 (]: 3 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.45s]
[0m12:10:11.076808 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m12:10:12.113754 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '68d81414-eb80-436b-8f13-72f9f9356c39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd388499850>]}
[0m12:10:12.115368 [info ] [Thread-1 (]: 5 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.44s]
[0m12:10:12.116850 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m12:10:12.120018 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m12:10:12.123544 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:10:12.124481 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m12:10:12.125629 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m12:10:12.126520 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m12:10:12.127419 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m12:10:12.128389 [info ] [MainThread]: 
[0m12:10:12.129362 [info ] [MainThread]: Finished running 5 incremental models in 0 hours 0 minutes and 4.40 seconds (4.40s).
[0m12:10:12.131340 [debug] [MainThread]: Command end result
[0m12:10:12.173739 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m12:10:12.178852 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m12:10:12.188667 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m12:10:12.189541 [info ] [MainThread]: 
[0m12:10:12.190646 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m12:10:12.191954 [info ] [MainThread]: 
[0m12:10:12.193119 [error] [MainThread]:   Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m12:10:12.194426 [info ] [MainThread]: 
[0m12:10:12.195568 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=0 TOTAL=5
[0m12:10:12.197869 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 6.334941, "process_in_blocks": "0", "process_kernel_time": 0.357176, "process_mem_max_rss": "227504", "process_out_blocks": "0", "process_user_time": 4.010581}
[0m12:10:12.199660 [debug] [MainThread]: Command `dbt run` failed at 12:10:12.199414 after 6.34 seconds
[0m12:10:12.200837 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd3b99a1f50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd3bcc0d610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd3bcc0c910>]}
[0m12:10:12.202260 [debug] [MainThread]: Flushing usage events
[0m12:10:13.536417 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:11:35.168713 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb4887bb50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb48c70190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb488cfb50>]}


============================== 12:11:35.171253 | 47c6053b-faf4-41c5-a733-a1dd39b8a577 ==============================
[0m12:11:35.171253 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:11:35.176483 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'invocation_command': 'dbt clean', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m12:11:35.256286 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '47c6053b-faf4-41c5-a733-a1dd39b8a577', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb488d2210>]}
[0m12:11:35.314893 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.19363533, "process_in_blocks": "0", "process_kernel_time": 0.08905, "process_mem_max_rss": "90032", "process_out_blocks": "0", "process_user_time": 0.959763}
[0m12:11:35.315982 [debug] [MainThread]: Command `dbt clean` succeeded at 12:11:35.315862 after 0.19 seconds
[0m12:11:35.316715 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb48c72950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb48766950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb4c044c10>]}
[0m12:11:35.317586 [debug] [MainThread]: Flushing usage events
[0m12:11:36.402937 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:11:37.603564 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f25dc71b090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f25dcbd0490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f25dc71bdd0>]}


============================== 12:11:37.606573 | 684b4dc2-2ab3-424a-8bde-28c45ccc22ee ==============================
[0m12:11:37.606573 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:11:37.608495 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt deps', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m12:11:37.691974 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '684b4dc2-2ab3-424a-8bde-28c45ccc22ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f25dc65ae10>]}
[0m12:11:37.702257 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m12:11:37.704740 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m12:11:37.706480 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.15209816, "process_in_blocks": "0", "process_kernel_time": 0.111289, "process_mem_max_rss": "90192", "process_out_blocks": "0", "process_user_time": 0.991485}
[0m12:11:37.707620 [debug] [MainThread]: Command `dbt deps` succeeded at 12:11:37.707487 after 0.15 seconds
[0m12:11:37.708400 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f25dc76edd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f25dff10c90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f25dcb163d0>]}
[0m12:11:37.709156 [debug] [MainThread]: Flushing usage events
[0m12:11:38.942306 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:11:41.650625 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fed506d7310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fed513b7990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fed506d6fd0>]}


============================== 12:11:41.653819 | 073d100a-dfe2-4ee1-9503-299194de87b3 ==============================
[0m12:11:41.653819 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:11:41.655146 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'invocation_command': 'dbt run', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m12:11:42.258854 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '073d100a-dfe2-4ee1-9503-299194de87b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fed228a73d0>]}
[0m12:11:42.309621 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '073d100a-dfe2-4ee1-9503-299194de87b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fed52930bd0>]}
[0m12:11:42.310934 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m12:11:42.381136 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m12:11:42.385700 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m12:11:42.386707 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '073d100a-dfe2-4ee1-9503-299194de87b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fed50bb7790>]}
[0m12:11:43.508970 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.staging
- models.dbt_project.facts
[0m12:11:43.519654 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '073d100a-dfe2-4ee1-9503-299194de87b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fed22609690>]}
[0m12:11:43.598261 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m12:11:43.605464 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m12:11:43.621321 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '073d100a-dfe2-4ee1-9503-299194de87b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fed222da6d0>]}
[0m12:11:43.622368 [info ] [MainThread]: Found 5 models, 8 sources, 488 macros
[0m12:11:43.623326 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '073d100a-dfe2-4ee1-9503-299194de87b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fed222fe110>]}
[0m12:11:43.626204 [info ] [MainThread]: 
[0m12:11:43.627503 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m12:11:43.628455 [info ] [MainThread]: 
[0m12:11:43.629659 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m12:11:43.633839 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m12:11:43.635054 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:11:44.154201 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m12:11:44.155576 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:11:44.401719 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '073d100a-dfe2-4ee1-9503-299194de87b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fed22512cd0>]}
[0m12:11:44.402882 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:11:44.410050 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m12:11:44.410402 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m12:11:44.410831 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m12:11:44.411275 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m12:11:44.411854 [info ] [Thread-1 (]: 1 of 5 START sql incremental model rizky_dwh_hailing_source.dim_customer ....... [RUN]
[0m12:11:44.413065 [info ] [Thread-2 (]: 2 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [RUN]
[0m12:11:44.414307 [info ] [Thread-3 (]: 3 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [RUN]
[0m12:11:44.415469 [info ] [Thread-4 (]: 4 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [RUN]
[0m12:11:44.416435 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.dim_customer)
[0m12:11:44.417560 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_customer'
[0m12:11:44.418619 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m12:11:44.419483 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m12:11:44.420249 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m12:11:44.421223 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m12:11:44.422172 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m12:11:44.423786 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m12:11:44.432352 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m12:11:44.438179 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m12:11:44.442372 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m12:11:44.446291 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m12:11:44.458565 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m12:11:44.459090 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m12:11:44.465786 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m12:11:44.475922 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m12:11:44.519929 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m12:11:44.532109 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m12:11:44.541641 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m12:11:44.545307 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m12:11:44.628486 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`dim_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
)

SELECT *
FROM source

    );
  
[0m12:11:44.629488 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:11:44.848938 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m12:11:44.850431 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m12:11:44.851554 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m12:11:44.862853 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m12:11:44.865903 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m12:11:44.869830 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m12:11:45.016089 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:53a73ffb-79b6-48c9-8489-6a88a8382c0e&page=queryresults
[0m12:11:45.102723 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:197f5a52-0a08-4a33-8bb6-39402abe47cd&page=queryresults
[0m12:11:45.108728 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:313f6ff8-f2da-45f7-a325-eb66ba5c750c&page=queryresults
[0m12:11:45.123873 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:7d479716-f885-4c5f-952d-34846b43049f&page=queryresults
[0m12:11:46.672117 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '073d100a-dfe2-4ee1-9503-299194de87b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fed201d7550>]}
[0m12:11:46.672494 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '073d100a-dfe2-4ee1-9503-299194de87b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fed2232c9d0>]}
[0m12:11:46.673577 [info ] [Thread-2 (]: 2 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.25s]
[0m12:11:46.675150 [info ] [Thread-3 (]: 3 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.25s]
[0m12:11:46.676771 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m12:11:46.677936 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m12:11:46.678940 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m12:11:46.681084 [info ] [Thread-2 (]: 5 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [RUN]
[0m12:11:46.682336 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_customer, now model.hailing_project.production_hailing_staging_vehicle)
[0m12:11:46.683373 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m12:11:46.688350 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m12:11:46.693224 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '073d100a-dfe2-4ee1-9503-299194de87b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fed2017a0d0>]}
[0m12:11:46.695192 [info ] [Thread-4 (]: 4 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.27s]
[0m12:11:46.696817 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m12:11:46.700049 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m12:11:46.705266 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m12:11:46.897861 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '073d100a-dfe2-4ee1-9503-299194de87b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fed222af610>]}
[0m12:11:46.899345 [info ] [Thread-1 (]: 1 of 5 OK created sql incremental model rizky_dwh_hailing_source.dim_customer .. [[32mCREATE TABLE (85.0 rows, 5.7 KiB processed)[0m in 2.48s]
[0m12:11:46.900838 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m12:11:46.941289 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m12:11:46.948468 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m12:11:47.298041 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:6c829dee-2bf7-409f-aa18-1248149b1271&page=queryresults
[0m12:11:48.873005 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '073d100a-dfe2-4ee1-9503-299194de87b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fed124749d0>]}
[0m12:11:48.874508 [info ] [Thread-2 (]: 5 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.19s]
[0m12:11:48.875890 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m12:11:48.878734 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m12:11:48.882337 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:11:48.883237 [debug] [MainThread]: Connection 'model.hailing_project.dim_customer' was properly closed.
[0m12:11:48.884050 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m12:11:48.884835 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m12:11:48.885837 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m12:11:48.886720 [info ] [MainThread]: 
[0m12:11:48.887577 [info ] [MainThread]: Finished running 5 incremental models in 0 hours 0 minutes and 5.26 seconds (5.26s).
[0m12:11:48.889466 [debug] [MainThread]: Command end result
[0m12:11:48.926176 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m12:11:48.930205 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m12:11:48.938203 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m12:11:48.938973 [info ] [MainThread]: 
[0m12:11:48.940020 [info ] [MainThread]: [32mCompleted successfully[0m
[0m12:11:48.941212 [info ] [MainThread]: 
[0m12:11:48.942310 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
[0m12:11:48.943887 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 7.3556, "process_in_blocks": "0", "process_kernel_time": 0.329294, "process_mem_max_rss": "229256", "process_out_blocks": "0", "process_user_time": 4.270848}
[0m12:11:48.945162 [debug] [MainThread]: Command `dbt run` succeeded at 12:11:48.945016 after 7.36 seconds
[0m12:11:48.946035 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fed50ace090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fed53ea0b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fed54024910>]}
[0m12:11:48.946878 [debug] [MainThread]: Flushing usage events
[0m12:11:50.262714 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:14:19.473043 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffbf6c32bd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffbf6c87d10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffbf6c30950>]}


============================== 12:14:19.475646 | 9bc05b03-72be-4f12-bad1-482f86995b7b ==============================
[0m12:14:19.475646 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:14:19.478172 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt clean', 'send_anonymous_usage_stats': 'True'}
[0m12:14:19.565999 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '9bc05b03-72be-4f12-bad1-482f86995b7b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffbf6ac0c90>]}
[0m12:14:19.625509 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.20065594, "process_in_blocks": "0", "process_kernel_time": 0.0879, "process_mem_max_rss": "90048", "process_out_blocks": "0", "process_user_time": 0.947373}
[0m12:14:19.626680 [debug] [MainThread]: Command `dbt clean` succeeded at 12:14:19.626575 after 0.20 seconds
[0m12:14:19.627353 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffbf6c8db90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffbf6c8c950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffbfa428c90>]}
[0m12:14:19.628047 [debug] [MainThread]: Flushing usage events
[0m12:14:20.943576 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:14:22.121699 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa303976990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa303e57790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa303976890>]}


============================== 12:14:22.124290 | d9546f3a-3557-4e9d-a57c-42d8ecafd4cb ==============================
[0m12:14:22.124290 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:14:22.125415 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt deps', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m12:14:22.211035 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd9546f3a-3557-4e9d-a57c-42d8ecafd4cb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa304667290>]}
[0m12:14:22.221264 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m12:14:22.223764 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m12:14:22.226094 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.15758468, "process_in_blocks": "0", "process_kernel_time": 0.079564, "process_mem_max_rss": "90244", "process_out_blocks": "0", "process_user_time": 1.024392}
[0m12:14:22.227380 [debug] [MainThread]: Command `dbt deps` succeeded at 12:14:22.227240 after 0.16 seconds
[0m12:14:22.228215 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa3039cf150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa3072c5110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa3072c5390>]}
[0m12:14:22.229115 [debug] [MainThread]: Flushing usage events
[0m12:14:23.276970 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:14:26.250444 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2541131dd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f254161b790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2541132fd0>]}


============================== 12:14:26.253042 | 04c831b9-45ce-431c-b173-055c55d37ab0 ==============================
[0m12:14:26.253042 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:14:26.254557 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m12:14:26.839004 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '04c831b9-45ce-431c-b173-055c55d37ab0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2513557590>]}
[0m12:14:26.888323 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '04c831b9-45ce-431c-b173-055c55d37ab0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f25433b9f50>]}
[0m12:14:26.890098 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m12:14:26.956775 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m12:14:26.958759 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m12:14:26.959673 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '04c831b9-45ce-431c-b173-055c55d37ab0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f25132986d0>]}
[0m12:14:28.038029 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.staging
- models.dbt_project.facts
[0m12:14:28.049247 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '04c831b9-45ce-431c-b173-055c55d37ab0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2512fa3c50>]}
[0m12:14:28.122172 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m12:14:28.129770 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m12:14:28.144730 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '04c831b9-45ce-431c-b173-055c55d37ab0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2512cd9550>]}
[0m12:14:28.145949 [info ] [MainThread]: Found 5 models, 8 sources, 488 macros
[0m12:14:28.147221 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '04c831b9-45ce-431c-b173-055c55d37ab0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2512d9ab10>]}
[0m12:14:28.150270 [info ] [MainThread]: 
[0m12:14:28.151515 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m12:14:28.152554 [info ] [MainThread]: 
[0m12:14:28.154108 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m12:14:28.159369 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m12:14:28.160494 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:14:28.634639 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m12:14:28.642530 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:14:28.866016 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '04c831b9-45ce-431c-b173-055c55d37ab0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2512d99c90>]}
[0m12:14:28.867438 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:14:28.873152 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m12:14:28.873632 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m12:14:28.873976 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m12:14:28.874345 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m12:14:28.875011 [info ] [Thread-1 (]: 1 of 5 START sql incremental model rizky_dwh_hailing_source.dim_customer ....... [RUN]
[0m12:14:28.876268 [info ] [Thread-2 (]: 2 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [RUN]
[0m12:14:28.877460 [info ] [Thread-3 (]: 3 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [RUN]
[0m12:14:28.878555 [info ] [Thread-4 (]: 4 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [RUN]
[0m12:14:28.879884 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.dim_customer)
[0m12:14:28.881012 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_customer'
[0m12:14:28.882001 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m12:14:28.882858 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m12:14:28.883917 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m12:14:28.884945 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m12:14:28.885731 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m12:14:28.886833 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m12:14:28.897534 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m12:14:28.901822 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m12:14:28.906517 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m12:14:28.912908 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m12:14:28.928453 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m12:14:28.929203 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m12:14:28.951625 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m12:14:28.957849 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m12:14:28.978371 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:14:28.979788 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m12:14:28.983259 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m12:14:28.987543 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m12:14:29.283489 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m12:14:29.285377 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m12:14:29.286867 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m12:14:29.288281 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m12:14:29.305352 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m12:14:29.307366 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m12:14:29.308202 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m12:14:29.308895 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`dim_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`dim_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m12:14:29.572549 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:bf07f2b2-99ea-4d53-89cd-6901a3997f16&page=queryresults
[0m12:14:29.575205 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:513296c1-c5c5-46cf-812d-6bc9c80f7d67&page=queryresults
[0m12:14:29.575962 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:83d3ae75-aa55-4a3c-a3ed-eec7fe88ccae&page=queryresults
[0m12:14:29.587219 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:31dd3710-8939-4d31-925f-55686ab54e26&page=queryresults
[0m12:14:31.092116 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '04c831b9-45ce-431c-b173-055c55d37ab0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f251037f690>]}
[0m12:14:31.092999 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '04c831b9-45ce-431c-b173-055c55d37ab0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2510388990>]}
[0m12:14:31.093884 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '04c831b9-45ce-431c-b173-055c55d37ab0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2512e89350>]}
[0m12:14:31.096518 [info ] [Thread-4 (]: 4 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.20s]
[0m12:14:31.098289 [info ] [Thread-2 (]: 2 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.21s]
[0m12:14:31.100123 [info ] [Thread-1 (]: 1 of 5 OK created sql incremental model rizky_dwh_hailing_source.dim_customer .. [[32mMERGE (0.0 rows, 11.3 KiB processed)[0m in 2.21s]
[0m12:14:31.101913 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m12:14:31.103510 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m12:14:31.105221 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m12:14:31.106477 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m12:14:31.109959 [info ] [Thread-4 (]: 5 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [RUN]
[0m12:14:31.111271 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_ride, now model.hailing_project.production_hailing_staging_vehicle)
[0m12:14:31.112564 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m12:14:31.117440 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m12:14:31.123234 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m12:14:31.127103 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:14:31.158249 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '04c831b9-45ce-431c-b173-055c55d37ab0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f251038b550>]}
[0m12:14:31.159826 [info ] [Thread-3 (]: 3 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.28s]
[0m12:14:31.161157 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m12:14:31.331237 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m12:14:31.339277 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m12:14:31.588307 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:ca60e0b1-0e1d-4b54-b1d4-1d7d56ea477c&page=queryresults
[0m12:14:33.191816 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '04c831b9-45ce-431c-b173-055c55d37ab0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2512d4e390>]}
[0m12:14:33.193413 [info ] [Thread-4 (]: 5 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.08s]
[0m12:14:33.195094 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m12:14:33.197792 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m12:14:33.201545 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:14:33.202508 [debug] [MainThread]: Connection 'model.hailing_project.dim_customer' was properly closed.
[0m12:14:33.203175 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m12:14:33.203946 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m12:14:33.204876 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m12:14:33.205791 [info ] [MainThread]: 
[0m12:14:33.206684 [info ] [MainThread]: Finished running 5 incremental models in 0 hours 0 minutes and 5.05 seconds (5.05s).
[0m12:14:33.208978 [debug] [MainThread]: Command end result
[0m12:14:33.247311 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m12:14:33.252699 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m12:14:33.263204 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m12:14:33.264377 [info ] [MainThread]: 
[0m12:14:33.265811 [info ] [MainThread]: [32mCompleted successfully[0m
[0m12:14:33.267101 [info ] [MainThread]: 
[0m12:14:33.268162 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
[0m12:14:33.269810 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 7.077331, "process_in_blocks": "0", "process_kernel_time": 0.182434, "process_mem_max_rss": "227056", "process_out_blocks": "0", "process_user_time": 4.317616}
[0m12:14:33.270949 [debug] [MainThread]: Command `dbt run` succeeded at 12:14:33.270824 after 7.08 seconds
[0m12:14:33.271860 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f254181df50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2544ab1110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2544ab0910>]}
[0m12:14:33.272989 [debug] [MainThread]: Flushing usage events
[0m12:14:34.815361 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:22:28.535967 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffb7597ffd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffb75d26410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffb7592b710>]}


============================== 12:22:28.538465 | 00707613-d893-44b3-8421-9ece7ed0ae42 ==============================
[0m12:22:28.538465 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:22:28.540221 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt clean', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m12:22:28.623364 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '00707613-d893-44b3-8421-9ece7ed0ae42', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffb75ddc550>]}
[0m12:22:28.687460 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.20204052, "process_in_blocks": "0", "process_kernel_time": 0.079582, "process_mem_max_rss": "90048", "process_out_blocks": "0", "process_user_time": 0.97489}
[0m12:22:28.688389 [debug] [MainThread]: Command `dbt clean` succeeded at 12:22:28.688259 after 0.20 seconds
[0m12:22:28.689175 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffb75d268d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffb75d264d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffb75817d10>]}
[0m12:22:28.689874 [debug] [MainThread]: Flushing usage events
[0m12:22:30.188452 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:22:31.357624 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fae2bffb150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fae2c3f2110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fae2c4ac290>]}


============================== 12:22:31.360329 | 4e26e73a-e023-46db-864a-94a0378ce498 ==============================
[0m12:22:31.360329 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:22:31.361514 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt deps', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m12:22:31.448064 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '4e26e73a-e023-46db-864a-94a0378ce498', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fae2c055350>]}
[0m12:22:31.461030 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m12:22:31.463759 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m12:22:31.465446 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.16211414, "process_in_blocks": "0", "process_kernel_time": 0.079951, "process_mem_max_rss": "90168", "process_out_blocks": "0", "process_user_time": 1.039364}
[0m12:22:31.466440 [debug] [MainThread]: Command `dbt deps` succeeded at 12:22:31.466299 after 0.16 seconds
[0m12:22:31.467225 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fae2c4ac350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fae2c3f2110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fae2f7c4b90>]}
[0m12:22:31.468047 [debug] [MainThread]: Flushing usage events
[0m12:22:32.711996 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:22:37.279476 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f20e1133090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f20e152a110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f20e1183690>]}


============================== 12:22:37.282021 | e8e934d5-ebb0-4544-b08e-ea96d9089c6e ==============================
[0m12:22:37.282021 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:22:37.285912 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m12:22:37.925687 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e8e934d5-ebb0-4544-b08e-ea96d9089c6e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f20b32b3b90>]}
[0m12:22:37.974327 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e8e934d5-ebb0-4544-b08e-ea96d9089c6e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f20e338ddd0>]}
[0m12:22:37.975900 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m12:22:38.048025 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m12:22:38.051182 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m12:22:38.052136 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'e8e934d5-ebb0-4544-b08e-ea96d9089c6e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f20b3a051d0>]}
[0m12:22:38.912227 [error] [MainThread]: Encountered an error:
Compilation Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  invalid syntax for function call expression
    line 1
      {{ config(
[0m12:22:38.913720 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.6879505, "process_in_blocks": "0", "process_kernel_time": 0.2304, "process_mem_max_rss": "211984", "process_out_blocks": "0", "process_user_time": 3.49608}
[0m12:22:38.914912 [debug] [MainThread]: Command `dbt run` failed at 12:22:38.914760 after 1.69 seconds
[0m12:22:38.916136 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f20e116a2d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f20e4a81290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f20b385d410>]}
[0m12:22:38.917693 [debug] [MainThread]: Flushing usage events
[0m12:22:40.225349 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:24:50.347572 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6b64a02b10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6b64a02a10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6b64a01e90>]}


============================== 12:24:50.351031 | 5e7a04af-ab2c-429a-b9a2-5fd6defde211 ==============================
[0m12:24:50.351031 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:24:50.353079 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt debug', 'send_anonymous_usage_stats': 'True'}
[0m12:24:50.361777 [info ] [MainThread]: dbt version: 1.9.0
[0m12:24:50.363262 [info ] [MainThread]: python version: 3.11.2
[0m12:24:50.364666 [info ] [MainThread]: python path: /usr/local/bin/python
[0m12:24:50.366517 [info ] [MainThread]: os info: Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.31
[0m12:24:50.907611 [info ] [MainThread]: Using profiles dir at /usr/app/dbt_project
[0m12:24:50.908813 [info ] [MainThread]: Using profiles.yml file at /usr/app/dbt_project/profiles.yml
[0m12:24:50.909750 [info ] [MainThread]: Using dbt_project.yml file at /usr/app/dbt_project/dbt_project.yml
[0m12:24:50.990226 [info ] [MainThread]: Configuration:
[0m12:24:50.991664 [info ] [MainThread]:   profiles.yml file [[31mERROR invalid[0m]
[0m12:24:50.992923 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m12:24:50.993884 [info ] [MainThread]: Required dependencies:
[0m12:24:50.994803 [debug] [MainThread]: Executing "git --help"
[0m12:24:50.998514 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m12:24:50.999350 [debug] [MainThread]: STDERR: "b''"
[0m12:24:51.000211 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m12:24:51.001056 [info ] [MainThread]: Connection test skipped since no profile was found
[0m12:24:51.002568 [info ] [MainThread]: [31m1 check failed:[0m
[0m12:24:51.003524 [info ] [MainThread]: Profile loading failed for the following reason:
Runtime Error
  Credentials in profile "hailing_project", target "dev" invalid: Runtime Error
    Must specify schema


[0m12:24:51.005126 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": false, "command_wall_clock_time": 0.70546657, "process_in_blocks": "0", "process_kernel_time": 0.192204, "process_mem_max_rss": "206772", "process_out_blocks": "0", "process_user_time": 2.569475}
[0m12:24:51.006267 [debug] [MainThread]: Command `dbt debug` failed at 12:24:51.006128 after 0.71 seconds
[0m12:24:51.007996 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6b64a57310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6b36c36a10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6b3736b150>]}
[0m12:24:51.009173 [debug] [MainThread]: Flushing usage events
[0m12:24:52.114373 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:25:02.227394 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff0caea7290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff0cb38b7d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff0cb38b6d0>]}


============================== 12:25:02.230811 | 42bce0e9-25c5-4560-a6d4-37ab17094f2a ==============================
[0m12:25:02.230811 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:25:02.232172 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'invocation_command': 'dbt debug', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m12:25:02.239302 [info ] [MainThread]: dbt version: 1.9.0
[0m12:25:02.240291 [info ] [MainThread]: python version: 3.11.2
[0m12:25:02.241268 [info ] [MainThread]: python path: /usr/local/bin/python
[0m12:25:02.242526 [info ] [MainThread]: os info: Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.31
[0m12:25:02.773632 [info ] [MainThread]: Using profiles dir at /usr/app/dbt_project
[0m12:25:02.774683 [info ] [MainThread]: Using profiles.yml file at /usr/app/dbt_project/profiles.yml
[0m12:25:02.775972 [info ] [MainThread]: Using dbt_project.yml file at /usr/app/dbt_project/dbt_project.yml
[0m12:25:02.777199 [info ] [MainThread]: adapter type: bigquery
[0m12:25:02.778140 [info ] [MainThread]: adapter version: 1.9.0
[0m12:25:02.859356 [info ] [MainThread]: Configuration:
[0m12:25:02.860768 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m12:25:02.861994 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m12:25:02.863064 [info ] [MainThread]: Required dependencies:
[0m12:25:02.863977 [debug] [MainThread]: Executing "git --help"
[0m12:25:02.866047 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m12:25:02.866783 [debug] [MainThread]: STDERR: "b''"
[0m12:25:02.867742 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m12:25:02.868702 [info ] [MainThread]: Connection:
[0m12:25:02.870019 [info ] [MainThread]:   method: service-account
[0m12:25:02.871601 [info ] [MainThread]:   database: purwadika
[0m12:25:02.872664 [info ] [MainThread]:   execution_project: purwadika
[0m12:25:02.873606 [info ] [MainThread]:   schema: rizky_dwh_hailing_source
[0m12:25:02.874874 [info ] [MainThread]:   location: None
[0m12:25:02.876224 [info ] [MainThread]:   priority: None
[0m12:25:02.877343 [info ] [MainThread]:   maximum_bytes_billed: None
[0m12:25:02.878250 [info ] [MainThread]:   impersonate_service_account: None
[0m12:25:02.879179 [info ] [MainThread]:   job_retry_deadline_seconds: None
[0m12:25:02.880040 [info ] [MainThread]:   job_retries: 1
[0m12:25:02.881541 [info ] [MainThread]:   job_creation_timeout_seconds: None
[0m12:25:02.882636 [info ] [MainThread]:   job_execution_timeout_seconds: None
[0m12:25:02.883719 [info ] [MainThread]:   timeout_seconds: None
[0m12:25:02.884683 [info ] [MainThread]:   client_id: None
[0m12:25:02.885697 [info ] [MainThread]:   token_uri: None
[0m12:25:02.887209 [info ] [MainThread]:   dataproc_region: None
[0m12:25:02.888398 [info ] [MainThread]:   dataproc_cluster_name: None
[0m12:25:02.889561 [info ] [MainThread]:   gcs_bucket: None
[0m12:25:02.890798 [info ] [MainThread]:   dataproc_batch: None
[0m12:25:02.892004 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m12:25:02.945830 [debug] [MainThread]: Acquiring new bigquery connection 'debug'
[0m12:25:02.946883 [debug] [MainThread]: On debug: select 1 as id
[0m12:25:02.947681 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:25:03.617215 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:fc931634-228d-4b58-82f4-4600c2cb892c&page=queryresults
[0m12:25:04.366891 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m12:25:04.368622 [info ] [MainThread]: [32mAll checks passed![0m
[0m12:25:04.370913 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": true, "command_wall_clock_time": 2.1982403, "process_in_blocks": "0", "process_kernel_time": 0.190733, "process_mem_max_rss": "212356", "process_out_blocks": "0", "process_user_time": 2.680304}
[0m12:25:04.371960 [debug] [MainThread]: Command `dbt debug` succeeded at 12:25:04.371855 after 2.20 seconds
[0m12:25:04.372729 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m12:25:04.373547 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff0caf1f310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff0caf1f290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff0ce69cc10>]}
[0m12:25:04.374454 [debug] [MainThread]: Flushing usage events
[0m12:25:05.434130 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:27:08.731101 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0cd7b76ed0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0cd7b76b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0cd7b76bd0>]}


============================== 12:27:08.735636 | 2d6f5382-0d24-42c2-a797-dd2a7bdc0c10 ==============================
[0m12:27:08.735636 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:27:08.738532 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'version_check': 'True', 'warn_error': 'None', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt debug', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m12:27:08.747167 [info ] [MainThread]: dbt version: 1.9.0
[0m12:27:08.749696 [info ] [MainThread]: python version: 3.11.2
[0m12:27:08.751053 [info ] [MainThread]: python path: /usr/local/bin/python
[0m12:27:08.752173 [info ] [MainThread]: os info: Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.31
[0m12:27:09.244898 [info ] [MainThread]: Using profiles dir at /usr/app/dbt_project
[0m12:27:09.248064 [info ] [MainThread]: Using profiles.yml file at /usr/app/dbt_project/profiles.yml
[0m12:27:09.249293 [info ] [MainThread]: Using dbt_project.yml file at /usr/app/dbt_project/dbt_project.yml
[0m12:27:09.250749 [info ] [MainThread]: adapter type: bigquery
[0m12:27:09.253528 [info ] [MainThread]: adapter version: 1.9.0
[0m12:27:09.335546 [info ] [MainThread]: Configuration:
[0m12:27:09.336904 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m12:27:09.338304 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m12:27:09.339333 [info ] [MainThread]: Required dependencies:
[0m12:27:09.340379 [debug] [MainThread]: Executing "git --help"
[0m12:27:09.342518 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m12:27:09.343447 [debug] [MainThread]: STDERR: "b''"
[0m12:27:09.344307 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m12:27:09.345287 [info ] [MainThread]: Connection:
[0m12:27:09.346476 [info ] [MainThread]:   method: service-account
[0m12:27:09.347409 [info ] [MainThread]:   database: purwadika
[0m12:27:09.348385 [info ] [MainThread]:   execution_project: purwadika
[0m12:27:09.349459 [info ] [MainThread]:   schema: rizky_dwh_hailing_staging
[0m12:27:09.350324 [info ] [MainThread]:   location: None
[0m12:27:09.351261 [info ] [MainThread]:   priority: None
[0m12:27:09.352361 [info ] [MainThread]:   maximum_bytes_billed: None
[0m12:27:09.353185 [info ] [MainThread]:   impersonate_service_account: None
[0m12:27:09.354030 [info ] [MainThread]:   job_retry_deadline_seconds: None
[0m12:27:09.354903 [info ] [MainThread]:   job_retries: 1
[0m12:27:09.355721 [info ] [MainThread]:   job_creation_timeout_seconds: None
[0m12:27:09.356701 [info ] [MainThread]:   job_execution_timeout_seconds: None
[0m12:27:09.357587 [info ] [MainThread]:   timeout_seconds: None
[0m12:27:09.358371 [info ] [MainThread]:   client_id: None
[0m12:27:09.359542 [info ] [MainThread]:   token_uri: None
[0m12:27:09.360405 [info ] [MainThread]:   dataproc_region: None
[0m12:27:09.361317 [info ] [MainThread]:   dataproc_cluster_name: None
[0m12:27:09.362109 [info ] [MainThread]:   gcs_bucket: None
[0m12:27:09.362929 [info ] [MainThread]:   dataproc_batch: None
[0m12:27:09.363861 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m12:27:09.419090 [debug] [MainThread]: Acquiring new bigquery connection 'debug'
[0m12:27:09.420242 [debug] [MainThread]: On debug: select 1 as id
[0m12:27:09.421033 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:27:10.103520 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:d560c700-4198-4148-a916-ecc982868603&page=queryresults
[0m12:27:10.827252 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m12:27:10.829173 [info ] [MainThread]: [32mAll checks passed![0m
[0m12:27:10.831613 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": true, "command_wall_clock_time": 2.150948, "process_in_blocks": "0", "process_kernel_time": 0.142167, "process_mem_max_rss": "214748", "process_out_blocks": "0", "process_user_time": 2.741803}
[0m12:27:10.832989 [debug] [MainThread]: Command `dbt debug` succeeded at 12:27:10.832802 after 2.15 seconds
[0m12:27:10.834598 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m12:27:10.836028 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0cdb661850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ca9cc64d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0cd7f72310>]}
[0m12:27:10.837288 [debug] [MainThread]: Flushing usage events
[0m12:27:11.950725 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:35:04.068492 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f19879f6f50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1987f10c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f19879f6e90>]}


============================== 12:35:04.071731 | f84d009d-3405-42d6-90ea-73e2a8b99d79 ==============================
[0m12:35:04.071731 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:35:04.074743 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt run', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m12:35:04.675180 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f84d009d-3405-42d6-90ea-73e2a8b99d79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1987a3e3d0>]}
[0m12:35:04.728646 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f84d009d-3405-42d6-90ea-73e2a8b99d79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1989ca9fd0>]}
[0m12:35:04.729926 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m12:35:04.797959 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m12:35:04.799988 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m12:35:04.801138 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'f84d009d-3405-42d6-90ea-73e2a8b99d79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1959cdef10>]}
[0m12:35:05.827022 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.facts
- models.dbt_project.staging
[0m12:35:05.837875 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f84d009d-3405-42d6-90ea-73e2a8b99d79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1959d61750>]}
[0m12:35:05.907689 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m12:35:05.913855 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m12:35:05.932847 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f84d009d-3405-42d6-90ea-73e2a8b99d79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f19595ef490>]}
[0m12:35:05.933946 [info ] [MainThread]: Found 5 models, 8 sources, 488 macros
[0m12:35:05.935229 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f84d009d-3405-42d6-90ea-73e2a8b99d79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1959615d10>]}
[0m12:35:05.937988 [info ] [MainThread]: 
[0m12:35:05.939417 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m12:35:05.940607 [info ] [MainThread]: 
[0m12:35:05.942773 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m12:35:05.947710 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m12:35:05.948888 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:35:06.619118 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now create_purwadika_rizky_dwh_hailing_staging)
[0m12:35:06.621289 [debug] [ThreadPool]: Creating schema "database: "purwadika"
schema: "rizky_dwh_hailing_staging"
"
[0m12:35:06.629410 [debug] [ThreadPool]: On create_purwadika_rizky_dwh_hailing_staging: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "connection_name": "create_purwadika_rizky_dwh_hailing_staging"} */
create schema if not exists `purwadika`.`rizky_dwh_hailing_staging`
  
[0m12:35:06.630746 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:35:07.669352 [debug] [ThreadPool]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:f94c82ed-3ee3-4d95-a86f-b35b0b08b108&page=queryresults
[0m12:35:08.621745 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_purwadika_rizky_dwh_hailing_staging, now list_purwadika_rizky_dwh_hailing_staging)
[0m12:35:08.622808 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:35:09.185113 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f84d009d-3405-42d6-90ea-73e2a8b99d79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1959be1750>]}
[0m12:35:09.186288 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:35:09.191852 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m12:35:09.192202 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m12:35:09.192633 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m12:35:09.193007 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m12:35:09.193538 [info ] [Thread-1 (]: 1 of 5 START sql incremental model rizky_dwh_hailing_staging.dim_customer ...... [RUN]
[0m12:35:09.194694 [info ] [Thread-2 (]: 2 of 5 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [RUN]
[0m12:35:09.195909 [info ] [Thread-3 (]: 3 of 5 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [RUN]
[0m12:35:09.196976 [info ] [Thread-4 (]: 4 of 5 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [RUN]
[0m12:35:09.198094 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_staging, now model.hailing_project.dim_customer)
[0m12:35:09.199187 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_customer'
[0m12:35:09.200130 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m12:35:09.201399 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m12:35:09.202741 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m12:35:09.204027 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m12:35:09.205064 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m12:35:09.206099 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m12:35:09.215127 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m12:35:09.219018 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m12:35:09.223146 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m12:35:09.227159 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m12:35:09.244137 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m12:35:09.244637 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m12:35:09.250834 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m12:35:09.277877 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m12:35:09.326644 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m12:35:09.329615 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m12:35:09.324564 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m12:35:09.333413 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m12:35:09.348764 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    );
  
[0m12:35:09.349395 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_staging`.`dim_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
)

SELECT *
FROM source

    );
  
[0m12:35:09.350516 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m12:35:09.351654 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    );
  
[0m12:35:09.352217 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:35:09.353753 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    );
  
[0m12:35:09.354796 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m12:35:09.381099 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m12:35:09.713385 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:352fa713-7282-4532-91ac-48e7d7c9fd3c&page=queryresults
[0m12:35:09.714761 [error] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:352fa713-7282-4532-91ac-48e7d7c9fd3c&page=queryresults
[0m12:35:09.719095 [debug] [Thread-3 (]: Database Error in model production_hailing_staging_driver (models/staging/production_hailing_staging_driver.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_driver.sql
[0m12:35:09.721633 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f84d009d-3405-42d6-90ea-73e2a8b99d79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1958b826d0>]}
[0m12:35:09.723173 [error] [Thread-3 (]: 3 of 5 ERROR creating sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [[31mERROR[0m in 0.52s]
[0m12:35:09.725411 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m12:35:09.726776 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m12:35:09.728961 [info ] [Thread-3 (]: 5 of 5 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [RUN]
[0m12:35:09.727795 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.production_hailing_staging_driver' to be skipped because of status 'error'.  Reason: Database Error in model production_hailing_staging_driver (models/staging/production_hailing_staging_driver.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_driver.sql.
[0m12:35:09.730813 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_driver, now model.hailing_project.production_hailing_staging_vehicle)
[0m12:35:09.733449 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m12:35:09.738642 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m12:35:09.740316 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:34e3ada8-b940-4fd9-9dd7-85c5c8805f47&page=queryresults
[0m12:35:09.741838 [error] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:34e3ada8-b940-4fd9-9dd7-85c5c8805f47&page=queryresults
[0m12:35:09.746416 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:33b2d751-c286-44fd-aac9-bb75cae310bb&page=queryresults
[0m12:35:09.747878 [debug] [Thread-2 (]: Database Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_customer.sql
[0m12:35:09.748603 [error] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:33b2d751-c286-44fd-aac9-bb75cae310bb&page=queryresults
[0m12:35:09.749252 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m12:35:09.750339 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f84d009d-3405-42d6-90ea-73e2a8b99d79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1958b5eb90>]}
[0m12:35:09.754365 [debug] [Thread-4 (]: Database Error in model production_hailing_staging_ride (models/staging/production_hailing_staging_ride.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_ride.sql
[0m12:35:09.758314 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m12:35:09.759958 [error] [Thread-2 (]: 2 of 5 ERROR creating sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [[31mERROR[0m in 0.55s]
[0m12:35:09.761183 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f84d009d-3405-42d6-90ea-73e2a8b99d79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f195962d7d0>]}
[0m12:35:09.763429 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m12:35:09.764696 [error] [Thread-4 (]: 4 of 5 ERROR creating sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [[31mERROR[0m in 0.56s]
[0m12:35:09.766007 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.production_hailing_staging_customer' to be skipped because of status 'error'.  Reason: Database Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_customer.sql.
[0m12:35:09.767545 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m12:35:09.769903 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    );
  
[0m12:35:09.770828 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.production_hailing_staging_ride' to be skipped because of status 'error'.  Reason: Database Error in model production_hailing_staging_ride (models/staging/production_hailing_staging_ride.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_ride.sql.
[0m12:35:09.771806 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m12:35:10.055438 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:71d0a539-5076-4f7a-9818-e399bd338ee0&page=queryresults
[0m12:35:10.056663 [error] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:71d0a539-5076-4f7a-9818-e399bd338ee0&page=queryresults
[0m12:35:10.060669 [debug] [Thread-3 (]: Database Error in model production_hailing_staging_vehicle (models/staging/production_hailing_staging_vehicle.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_vehicle.sql
[0m12:35:10.061991 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f84d009d-3405-42d6-90ea-73e2a8b99d79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1958b63890>]}
[0m12:35:10.063334 [error] [Thread-3 (]: 5 of 5 ERROR creating sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [[31mERROR[0m in 0.33s]
[0m12:35:10.064640 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m12:35:10.065856 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.production_hailing_staging_vehicle' to be skipped because of status 'error'.  Reason: Database Error in model production_hailing_staging_vehicle (models/staging/production_hailing_staging_vehicle.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_vehicle.sql.
[0m12:35:10.122443 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:e357a4e2-0d1c-4229-94b7-3606ac8b9cfb&page=queryresults
[0m12:35:10.123704 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:e357a4e2-0d1c-4229-94b7-3606ac8b9cfb&page=queryresults
[0m12:35:10.127682 [debug] [Thread-1 (]: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Table purwadika:rizky_dwh_hailing_staging.production_hailing_staging_customer was not found in location US
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m12:35:10.129198 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f84d009d-3405-42d6-90ea-73e2a8b99d79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1958a0edd0>]}
[0m12:35:10.131220 [error] [Thread-1 (]: 1 of 5 ERROR creating sql incremental model rizky_dwh_hailing_staging.dim_customer  [[31mERROR[0m in 0.93s]
[0m12:35:10.132622 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m12:35:10.134163 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.dim_customer' to be skipped because of status 'error'.  Reason: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Table purwadika:rizky_dwh_hailing_staging.production_hailing_staging_customer was not found in location US
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql.
[0m12:35:10.136862 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m12:35:10.141750 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:35:10.142881 [debug] [MainThread]: Connection 'model.hailing_project.dim_customer' was properly closed.
[0m12:35:10.143817 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m12:35:10.144725 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m12:35:10.145687 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m12:35:10.146686 [info ] [MainThread]: 
[0m12:35:10.147711 [info ] [MainThread]: Finished running 5 incremental models in 0 hours 0 minutes and 4.20 seconds (4.20s).
[0m12:35:10.150147 [debug] [MainThread]: Command end result
[0m12:35:10.184708 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m12:35:10.189132 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m12:35:10.196887 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m12:35:10.197597 [info ] [MainThread]: 
[0m12:35:10.198781 [info ] [MainThread]: [31mCompleted with 5 errors, 0 partial successes, and 0 warnings:[0m
[0m12:35:10.199910 [info ] [MainThread]: 
[0m12:35:10.201024 [error] [MainThread]:   Database Error in model production_hailing_staging_driver (models/staging/production_hailing_staging_driver.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_driver.sql
[0m12:35:10.202095 [info ] [MainThread]: 
[0m12:35:10.203354 [error] [MainThread]:   Database Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_customer.sql
[0m12:35:10.204557 [info ] [MainThread]: 
[0m12:35:10.205835 [error] [MainThread]:   Database Error in model production_hailing_staging_ride (models/staging/production_hailing_staging_ride.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_ride.sql
[0m12:35:10.207134 [info ] [MainThread]: 
[0m12:35:10.208569 [error] [MainThread]:   Database Error in model production_hailing_staging_vehicle (models/staging/production_hailing_staging_vehicle.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_vehicle.sql
[0m12:35:10.209700 [info ] [MainThread]: 
[0m12:35:10.210951 [error] [MainThread]:   Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Table purwadika:rizky_dwh_hailing_staging.production_hailing_staging_customer was not found in location US
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m12:35:10.212219 [info ] [MainThread]: 
[0m12:35:10.213799 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=5 SKIP=0 TOTAL=5
[0m12:35:10.216211 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 6.1943884, "process_in_blocks": "0", "process_kernel_time": 0.218868, "process_mem_max_rss": "229740", "process_out_blocks": "0", "process_user_time": 4.188339}
[0m12:35:10.217388 [debug] [MainThread]: Command `dbt run` failed at 12:35:10.217250 after 6.20 seconds
[0m12:35:10.218490 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1987a779d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f198b3ad190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f195999aa10>]}
[0m12:35:10.219479 [debug] [MainThread]: Flushing usage events
[0m12:35:11.899031 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:35:24.781940 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7944bd7190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7944c2b1d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7944bd6cd0>]}


============================== 12:35:24.784962 | a7cf52e0-3a42-472a-a444-5c0691b23049 ==============================
[0m12:35:24.784962 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:35:24.786074 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt debug', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m12:35:24.793244 [info ] [MainThread]: dbt version: 1.9.0
[0m12:35:24.794469 [info ] [MainThread]: python version: 3.11.2
[0m12:35:24.795776 [info ] [MainThread]: python path: /usr/local/bin/python
[0m12:35:24.797085 [info ] [MainThread]: os info: Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.31
[0m12:35:25.342777 [info ] [MainThread]: Using profiles dir at /usr/app/dbt_project
[0m12:35:25.343847 [info ] [MainThread]: Using profiles.yml file at /usr/app/dbt_project/profiles.yml
[0m12:35:25.344761 [info ] [MainThread]: Using dbt_project.yml file at /usr/app/dbt_project/dbt_project.yml
[0m12:35:25.345889 [info ] [MainThread]: adapter type: bigquery
[0m12:35:25.346786 [info ] [MainThread]: adapter version: 1.9.0
[0m12:35:25.425664 [info ] [MainThread]: Configuration:
[0m12:35:25.427205 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m12:35:25.428354 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m12:35:25.429525 [info ] [MainThread]: Required dependencies:
[0m12:35:25.430730 [debug] [MainThread]: Executing "git --help"
[0m12:35:25.432704 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m12:35:25.433991 [debug] [MainThread]: STDERR: "b''"
[0m12:35:25.434875 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m12:35:25.436078 [info ] [MainThread]: Connection:
[0m12:35:25.437308 [info ] [MainThread]:   method: service-account
[0m12:35:25.438423 [info ] [MainThread]:   database: purwadika
[0m12:35:25.439661 [info ] [MainThread]:   execution_project: purwadika
[0m12:35:25.440629 [info ] [MainThread]:   schema: rizky_dwh_hailing_source
[0m12:35:25.441662 [info ] [MainThread]:   location: None
[0m12:35:25.443336 [info ] [MainThread]:   priority: None
[0m12:35:25.444898 [info ] [MainThread]:   maximum_bytes_billed: None
[0m12:35:25.445953 [info ] [MainThread]:   impersonate_service_account: None
[0m12:35:25.446972 [info ] [MainThread]:   job_retry_deadline_seconds: None
[0m12:35:25.447964 [info ] [MainThread]:   job_retries: 1
[0m12:35:25.448949 [info ] [MainThread]:   job_creation_timeout_seconds: None
[0m12:35:25.450109 [info ] [MainThread]:   job_execution_timeout_seconds: None
[0m12:35:25.451116 [info ] [MainThread]:   timeout_seconds: None
[0m12:35:25.452085 [info ] [MainThread]:   client_id: None
[0m12:35:25.452895 [info ] [MainThread]:   token_uri: None
[0m12:35:25.453846 [info ] [MainThread]:   dataproc_region: None
[0m12:35:25.455107 [info ] [MainThread]:   dataproc_cluster_name: None
[0m12:35:25.456096 [info ] [MainThread]:   gcs_bucket: None
[0m12:35:25.457028 [info ] [MainThread]:   dataproc_batch: None
[0m12:35:25.458245 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m12:35:25.515866 [debug] [MainThread]: Acquiring new bigquery connection 'debug'
[0m12:35:25.516671 [debug] [MainThread]: On debug: select 1 as id
[0m12:35:25.517560 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:35:26.182606 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:5dd687be-1a3a-43e9-b75f-24f363e7c354&page=queryresults
[0m12:35:26.906317 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m12:35:26.910046 [info ] [MainThread]: [32mAll checks passed![0m
[0m12:35:26.914259 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": true, "command_wall_clock_time": 2.1825113, "process_in_blocks": "0", "process_kernel_time": 0.216603, "process_mem_max_rss": "212388", "process_out_blocks": "0", "process_user_time": 2.737082}
[0m12:35:26.918161 [debug] [MainThread]: Command `dbt debug` succeeded at 12:35:26.917918 after 2.19 seconds
[0m12:35:26.919472 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m12:35:26.921367 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7916e47790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7948408c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7916d47110>]}
[0m12:35:26.922968 [debug] [MainThread]: Flushing usage events
[0m12:35:27.954886 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:35:35.128813 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa1a8427390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa1a8472a50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa1a8472b90>]}


============================== 12:35:35.132311 | e44f0043-5b68-49aa-aa98-d702a4eff2e0 ==============================
[0m12:35:35.132311 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:35:35.133532 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt clean', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m12:35:35.226883 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e44f0043-5b68-49aa-aa98-d702a4eff2e0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa1a847d890>]}
[0m12:35:35.291775 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.21464151, "process_in_blocks": "0", "process_kernel_time": 0.08995, "process_mem_max_rss": "90152", "process_out_blocks": "0", "process_user_time": 1.029437}
[0m12:35:35.292995 [debug] [MainThread]: Command `dbt clean` succeeded at 12:35:35.292876 after 0.22 seconds
[0m12:35:35.293816 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa1a8427010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa1abbf0b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa1a9107310>]}
[0m12:35:35.294743 [debug] [MainThread]: Flushing usage events
[0m12:35:36.338119 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:35:37.536545 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efd18b8ee50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efd18bdff10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efd18b8ec10>]}


============================== 12:35:37.540987 | deaf3887-16cb-4d4f-b5f1-26be96e016fb ==============================
[0m12:35:37.540987 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:35:37.542517 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'version_check': 'True', 'warn_error': 'None', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'invocation_command': 'dbt deps', 'send_anonymous_usage_stats': 'True'}
[0m12:35:37.673678 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'deaf3887-16cb-4d4f-b5f1-26be96e016fb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efd18bdfd90>]}
[0m12:35:37.692677 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m12:35:37.696532 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m12:35:37.698928 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.24335356, "process_in_blocks": "0", "process_kernel_time": 0.160146, "process_mem_max_rss": "90096", "process_out_blocks": "0", "process_user_time": 1.030945}
[0m12:35:37.700486 [debug] [MainThread]: Command `dbt deps` succeeded at 12:35:37.700283 after 0.25 seconds
[0m12:35:37.701784 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efd18be1850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efd18be31d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efd1c3bcc10>]}
[0m12:35:37.702952 [debug] [MainThread]: Flushing usage events
[0m12:35:38.771242 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:35:42.196966 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b4c203190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b4c5fa2d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b4c5f9f10>]}


============================== 12:35:42.200034 | 03123977-0378-4c9c-a69f-0bf3ad79167a ==============================
[0m12:35:42.200034 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:35:42.201396 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt run', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m12:35:42.829783 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '03123977-0378-4c9c-a69f-0bf3ad79167a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b1e3c47d0>]}
[0m12:35:42.876135 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '03123977-0378-4c9c-a69f-0bf3ad79167a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b1e504f10>]}
[0m12:35:42.877503 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m12:35:42.950039 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m12:35:42.952711 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m12:35:42.953606 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '03123977-0378-4c9c-a69f-0bf3ad79167a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b1e983b50>]}
[0m12:35:44.040659 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.facts
- models.dbt_project.staging
[0m12:35:44.054036 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '03123977-0378-4c9c-a69f-0bf3ad79167a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b1e387410>]}
[0m12:35:44.130108 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m12:35:44.135162 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m12:35:44.150344 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '03123977-0378-4c9c-a69f-0bf3ad79167a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b1ddf2510>]}
[0m12:35:44.151657 [info ] [MainThread]: Found 5 models, 8 sources, 488 macros
[0m12:35:44.153365 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '03123977-0378-4c9c-a69f-0bf3ad79167a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b1e256490>]}
[0m12:35:44.157258 [info ] [MainThread]: 
[0m12:35:44.158604 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m12:35:44.159848 [info ] [MainThread]: 
[0m12:35:44.161462 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m12:35:44.167067 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m12:35:44.168288 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:35:44.953393 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m12:35:44.955842 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:35:45.228815 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '03123977-0378-4c9c-a69f-0bf3ad79167a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b1df8d310>]}
[0m12:35:45.230372 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:35:45.237270 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m12:35:45.237620 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m12:35:45.238032 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m12:35:45.238414 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m12:35:45.239222 [info ] [Thread-1 (]: 1 of 5 START sql incremental model rizky_dwh_hailing_source.dim_customer ....... [RUN]
[0m12:35:45.240468 [info ] [Thread-2 (]: 2 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [RUN]
[0m12:35:45.242137 [info ] [Thread-3 (]: 3 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [RUN]
[0m12:35:45.243358 [info ] [Thread-4 (]: 4 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [RUN]
[0m12:35:45.244818 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.dim_customer)
[0m12:35:45.246008 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_customer'
[0m12:35:45.247466 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m12:35:45.248547 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m12:35:45.249537 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m12:35:45.250610 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m12:35:45.251461 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m12:35:45.252484 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m12:35:45.263383 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m12:35:45.268115 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m12:35:45.273416 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m12:35:45.277587 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m12:35:45.290847 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m12:35:45.291334 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m12:35:45.303153 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m12:35:45.330171 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m12:35:45.330556 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m12:35:45.334013 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:35:45.337165 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m12:35:45.340848 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m12:35:45.672109 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m12:35:45.675954 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m12:35:45.679573 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m12:35:45.681724 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m12:35:45.689368 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m12:35:45.689959 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`dim_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`dim_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m12:35:45.692577 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m12:35:45.694630 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m12:35:45.924486 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:6f216068-b27c-4e17-b374-12982d4a3c97&page=queryresults
[0m12:35:45.925606 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:6f216068-b27c-4e17-b374-12982d4a3c97&page=queryresults
[0m12:35:45.931143 [debug] [Thread-1 (]: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m12:35:45.933100 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '03123977-0378-4c9c-a69f-0bf3ad79167a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b1c43f2d0>]}
[0m12:35:45.934971 [error] [Thread-1 (]: 1 of 5 ERROR creating sql incremental model rizky_dwh_hailing_source.dim_customer  [[31mERROR[0m in 0.69s]
[0m12:35:45.936375 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m12:35:45.937684 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m12:35:45.938230 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.dim_customer' to be skipped because of status 'error'.  Reason: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql.
[0m12:35:45.939219 [info ] [Thread-1 (]: 5 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [RUN]
[0m12:35:45.941332 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.hailing_project.dim_customer, now model.hailing_project.production_hailing_staging_vehicle)
[0m12:35:45.942200 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m12:35:45.946801 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m12:35:45.953178 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m12:35:45.957034 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:35:46.035462 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:6be76204-0106-45db-8e0b-351a846328bd&page=queryresults
[0m12:35:46.048460 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:0fe0823f-427e-4ddd-8dfb-5ceb41d603c3&page=queryresults
[0m12:35:46.096361 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:697a74cf-f6ef-4511-9189-64f1aad1ac9d&page=queryresults
[0m12:35:46.306248 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m12:35:46.313577 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m12:35:46.603670 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:cd5bcbee-bd2d-416b-b912-17de78c692ba&page=queryresults
[0m12:35:47.750441 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '03123977-0378-4c9c-a69f-0bf3ad79167a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b1c3ada50>]}
[0m12:35:47.751006 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '03123977-0378-4c9c-a69f-0bf3ad79167a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b1c3b1710>]}
[0m12:35:47.752082 [info ] [Thread-2 (]: 2 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.50s]
[0m12:35:47.753540 [info ] [Thread-3 (]: 3 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.50s]
[0m12:35:47.754817 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m12:35:47.756088 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m12:35:47.760978 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '03123977-0378-4c9c-a69f-0bf3ad79167a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b1c481d50>]}
[0m12:35:47.762665 [info ] [Thread-4 (]: 4 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.51s]
[0m12:35:47.764203 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m12:35:48.204856 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '03123977-0378-4c9c-a69f-0bf3ad79167a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b1c481690>]}
[0m12:35:48.205864 [info ] [Thread-1 (]: 5 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.26s]
[0m12:35:48.207254 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m12:35:48.209746 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m12:35:48.213135 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:35:48.214094 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m12:35:48.215136 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m12:35:48.216503 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m12:35:48.217501 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m12:35:48.218750 [info ] [MainThread]: 
[0m12:35:48.219867 [info ] [MainThread]: Finished running 5 incremental models in 0 hours 0 minutes and 4.06 seconds (4.06s).
[0m12:35:48.222086 [debug] [MainThread]: Command end result
[0m12:35:48.258089 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m12:35:48.262037 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m12:35:48.271323 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m12:35:48.272381 [info ] [MainThread]: 
[0m12:35:48.273544 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m12:35:48.274744 [info ] [MainThread]: 
[0m12:35:48.275702 [error] [MainThread]:   Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m12:35:48.276591 [info ] [MainThread]: 
[0m12:35:48.277614 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=0 TOTAL=5
[0m12:35:48.279407 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 6.1315765, "process_in_blocks": "0", "process_kernel_time": 0.241492, "process_mem_max_rss": "227800", "process_out_blocks": "0", "process_user_time": 4.296552}
[0m12:35:48.280698 [debug] [MainThread]: Command `dbt run` failed at 12:35:48.280532 after 6.13 seconds
[0m12:35:48.281712 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b4c081290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b4c083690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b4fb515d0>]}
[0m12:35:48.282635 [debug] [MainThread]: Flushing usage events
[0m12:35:49.612867 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:38:00.616728 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47fbe1b790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47fcc21790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47fbe1b5d0>]}


============================== 12:38:00.620358 | 67a234b6-9058-4d4c-a33a-a03b021aace6 ==============================
[0m12:38:00.620358 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:38:00.622428 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'profiles_dir': '/usr/app/dbt_project', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m12:38:01.222524 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '67a234b6-9058-4d4c-a33a-a03b021aace6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47ce777fd0>]}
[0m12:38:01.272648 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '67a234b6-9058-4d4c-a33a-a03b021aace6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47fe0a5d90>]}
[0m12:38:01.273822 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m12:38:01.340824 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m12:38:01.407525 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m12:38:01.410508 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '67a234b6-9058-4d4c-a33a-a03b021aace6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47fcc20410>]}
[0m12:38:02.421856 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.facts
- models.dbt_project.staging
[0m12:38:02.432965 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '67a234b6-9058-4d4c-a33a-a03b021aace6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47cdbcda10>]}
[0m12:38:02.506942 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m12:38:02.512595 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m12:38:02.527154 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '67a234b6-9058-4d4c-a33a-a03b021aace6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47cd9e1510>]}
[0m12:38:02.528071 [info ] [MainThread]: Found 5 models, 8 sources, 488 macros
[0m12:38:02.529448 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '67a234b6-9058-4d4c-a33a-a03b021aace6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47cdc12250>]}
[0m12:38:02.532344 [info ] [MainThread]: 
[0m12:38:02.533594 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m12:38:02.534886 [info ] [MainThread]: 
[0m12:38:02.536327 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m12:38:02.541633 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m12:38:02.542823 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:38:03.132534 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m12:38:03.133388 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:38:03.395520 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '67a234b6-9058-4d4c-a33a-a03b021aace6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47cdbceb50>]}
[0m12:38:03.396511 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:38:03.401000 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m12:38:03.401334 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m12:38:03.401644 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m12:38:03.401965 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m12:38:03.402623 [info ] [Thread-1 (]: 1 of 5 START sql incremental model rizky_dwh_hailing_source.dim_customer ....... [RUN]
[0m12:38:03.403748 [info ] [Thread-2 (]: 2 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [RUN]
[0m12:38:03.405269 [info ] [Thread-3 (]: 3 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [RUN]
[0m12:38:03.406422 [info ] [Thread-4 (]: 4 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [RUN]
[0m12:38:03.407508 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.dim_customer)
[0m12:38:03.408504 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_customer'
[0m12:38:03.409548 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m12:38:03.410879 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m12:38:03.412195 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m12:38:03.413284 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m12:38:03.414371 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m12:38:03.415550 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m12:38:03.424881 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m12:38:03.428970 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m12:38:03.433974 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m12:38:03.439798 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m12:38:03.446476 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m12:38:03.446995 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m12:38:03.447392 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m12:38:03.447732 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m12:38:03.496875 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m12:38:03.498401 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m12:38:03.501996 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:38:03.505118 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m12:38:03.832636 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m12:38:03.833467 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m12:38:03.835501 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m12:38:03.836763 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m12:38:03.842273 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m12:38:03.842808 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`dim_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`dim_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m12:38:03.843320 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m12:38:03.845430 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m12:38:04.060908 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:7672eb36-f05c-4022-a962-14265aff265c&page=queryresults
[0m12:38:04.062019 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:7672eb36-f05c-4022-a962-14265aff265c&page=queryresults
[0m12:38:04.066939 [debug] [Thread-1 (]: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m12:38:04.068696 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '67a234b6-9058-4d4c-a33a-a03b021aace6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47cdc27f90>]}
[0m12:38:04.070294 [error] [Thread-1 (]: 1 of 5 ERROR creating sql incremental model rizky_dwh_hailing_source.dim_customer  [[31mERROR[0m in 0.66s]
[0m12:38:04.072564 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m12:38:04.074814 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m12:38:04.075599 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.dim_customer' to be skipped because of status 'error'.  Reason: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql.
[0m12:38:04.076716 [info ] [Thread-1 (]: 5 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [RUN]
[0m12:38:04.079499 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.hailing_project.dim_customer, now model.hailing_project.production_hailing_staging_vehicle)
[0m12:38:04.081543 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m12:38:04.086519 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m12:38:04.089455 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:adfbbf34-4e18-442f-86f7-bb1b7d267442&page=queryresults
[0m12:38:04.095950 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m12:38:04.099569 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:38:04.126292 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:61f6272e-dcc3-46d5-b629-ba526e2feb0a&page=queryresults
[0m12:38:04.126836 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:9f8a9487-0cd8-41c1-a734-e205ae14d043&page=queryresults
[0m12:38:04.369037 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m12:38:04.378019 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m12:38:04.638641 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:1a38cf87-7f2a-442c-b83f-e02fcbdb63de&page=queryresults
[0m12:38:05.667709 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '67a234b6-9058-4d4c-a33a-a03b021aace6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47bdf58790>]}
[0m12:38:05.669970 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '67a234b6-9058-4d4c-a33a-a03b021aace6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47bdcc7c90>]}
[0m12:38:05.670698 [info ] [Thread-4 (]: 4 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.26s]
[0m12:38:05.671922 [info ] [Thread-3 (]: 3 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.26s]
[0m12:38:05.672969 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m12:38:05.674037 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m12:38:05.835757 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '67a234b6-9058-4d4c-a33a-a03b021aace6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47cda35850>]}
[0m12:38:05.837024 [info ] [Thread-2 (]: 2 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.43s]
[0m12:38:05.838897 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m12:38:06.164209 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '67a234b6-9058-4d4c-a33a-a03b021aace6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47cc0e2610>]}
[0m12:38:06.165612 [info ] [Thread-1 (]: 5 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.08s]
[0m12:38:06.166981 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m12:38:06.169280 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m12:38:06.172684 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:38:06.173700 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m12:38:06.174716 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m12:38:06.175989 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m12:38:06.177080 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m12:38:06.179000 [info ] [MainThread]: 
[0m12:38:06.180564 [info ] [MainThread]: Finished running 5 incremental models in 0 hours 0 minutes and 3.64 seconds (3.64s).
[0m12:38:06.183075 [debug] [MainThread]: Command end result
[0m12:38:06.223587 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m12:38:06.230096 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m12:38:06.239402 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m12:38:06.240794 [info ] [MainThread]: 
[0m12:38:06.241981 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m12:38:06.243320 [info ] [MainThread]: 
[0m12:38:06.244643 [error] [MainThread]:   Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m12:38:06.245911 [info ] [MainThread]: 
[0m12:38:06.247227 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=0 TOTAL=5
[0m12:38:06.249252 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 5.686209, "process_in_blocks": "0", "process_kernel_time": 0.241691, "process_mem_max_rss": "228712", "process_out_blocks": "0", "process_user_time": 4.179252}
[0m12:38:06.250777 [debug] [MainThread]: Command `dbt run` failed at 12:38:06.250652 after 5.69 seconds
[0m12:38:06.251855 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47fbe74090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47fbe75c90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47ff799250>]}
[0m12:38:06.252941 [debug] [MainThread]: Flushing usage events
[0m12:38:07.684839 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:40:22.716955 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f06afffed50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f06b04e7690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f06b004bfd0>]}


============================== 12:40:22.719605 | e8364ab3-67c4-429a-99b4-7126fb79e266 ==============================
[0m12:40:22.719605 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:40:22.721157 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'version_check': 'True', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt clean', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m12:40:22.804962 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e8364ab3-67c4-429a-99b4-7126fb79e266', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f06b0059d10>]}
[0m12:40:22.869526 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.20637281, "process_in_blocks": "0", "process_kernel_time": 0.122746, "process_mem_max_rss": "89996", "process_out_blocks": "0", "process_user_time": 0.971743}
[0m12:40:22.870857 [debug] [MainThread]: Command `dbt clean` succeeded at 12:40:22.870556 after 0.21 seconds
[0m12:40:22.871698 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f06b0058ad0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f06b00319d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f06b3924b10>]}
[0m12:40:22.872543 [debug] [MainThread]: Flushing usage events
[0m12:40:26.876124 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:40:27.998908 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f938e13ff10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f938e623690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f938e13e9d0>]}


============================== 12:40:28.001850 | 62e82b7e-ff14-41b3-9a12-987090e68aba ==============================
[0m12:40:28.001850 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:40:28.003047 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'warn_error': 'None', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt deps', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m12:40:28.087268 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '62e82b7e-ff14-41b3-9a12-987090e68aba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f938e192f10>]}
[0m12:40:28.096846 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m12:40:28.099842 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m12:40:28.101655 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.15786701, "process_in_blocks": "0", "process_kernel_time": 0.081048, "process_mem_max_rss": "90252", "process_out_blocks": "0", "process_user_time": 0.982718}
[0m12:40:28.102856 [debug] [MainThread]: Command `dbt deps` succeeded at 12:40:28.102729 after 0.16 seconds
[0m12:40:28.103739 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f938e53a710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f938e1b5010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f938e02bd10>]}
[0m12:40:28.104642 [debug] [MainThread]: Flushing usage events
[0m12:40:31.985681 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:40:34.752626 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f18bab2af90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f18baf264d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f18bab2ac90>]}


============================== 12:40:34.755367 | 5b93f61f-8719-40db-b2f0-a7334df7040a ==============================
[0m12:40:34.755367 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:40:34.756644 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m12:40:35.371648 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5b93f61f-8719-40db-b2f0-a7334df7040a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f189370b6d0>]}
[0m12:40:35.421232 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '5b93f61f-8719-40db-b2f0-a7334df7040a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f18bcddc8d0>]}
[0m12:40:35.422389 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m12:40:35.495821 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m12:40:35.499338 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m12:40:35.500407 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '5b93f61f-8719-40db-b2f0-a7334df7040a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f189370aad0>]}
[0m12:40:36.540615 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.facts
- models.dbt_project.staging
[0m12:40:36.553984 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5b93f61f-8719-40db-b2f0-a7334df7040a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1890a9b5d0>]}
[0m12:40:36.640200 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m12:40:36.647392 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m12:40:36.665754 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5b93f61f-8719-40db-b2f0-a7334df7040a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1890717790>]}
[0m12:40:36.666806 [info ] [MainThread]: Found 4 models, 8 sources, 488 macros
[0m12:40:36.668410 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5b93f61f-8719-40db-b2f0-a7334df7040a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1890ad8950>]}
[0m12:40:36.671304 [info ] [MainThread]: 
[0m12:40:36.672464 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m12:40:36.673590 [info ] [MainThread]: 
[0m12:40:36.675612 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m12:40:36.681736 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m12:40:36.682846 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:40:37.251390 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m12:40:37.252299 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:40:37.501569 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5b93f61f-8719-40db-b2f0-a7334df7040a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f18bba63f90>]}
[0m12:40:37.502605 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:40:37.508984 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m12:40:37.509420 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m12:40:37.509861 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m12:40:37.510338 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m12:40:37.511102 [info ] [Thread-1 (]: 1 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [RUN]
[0m12:40:37.512541 [info ] [Thread-2 (]: 2 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [RUN]
[0m12:40:37.514017 [info ] [Thread-3 (]: 3 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [RUN]
[0m12:40:37.515758 [info ] [Thread-4 (]: 4 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [RUN]
[0m12:40:37.517247 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.production_hailing_staging_customer)
[0m12:40:37.518580 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m12:40:37.519897 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m12:40:37.521430 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_vehicle'
[0m12:40:37.522988 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m12:40:37.524365 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m12:40:37.525887 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m12:40:37.527215 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m12:40:37.538773 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m12:40:37.543207 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m12:40:37.548034 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m12:40:37.553786 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m12:40:37.569493 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m12:40:37.571031 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m12:40:37.603358 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m12:40:37.614444 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m12:40:37.624815 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m12:40:37.625394 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m12:40:37.628085 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:40:37.631753 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m12:40:37.951004 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m12:40:37.953262 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m12:40:37.954853 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m12:40:37.956501 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m12:40:37.971504 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m12:40:37.972425 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m12:40:37.976284 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m12:40:37.978296 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m12:40:38.217058 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:04fa07f2-9e8a-447c-bac9-6f52330976fb&page=queryresults
[0m12:40:38.255553 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:8ecf0cfd-a580-48fa-b11e-40eb2ab7387b&page=queryresults
[0m12:40:38.261291 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:3faf8c96-e29d-4593-a958-af0802db3e5b&page=queryresults
[0m12:40:38.344578 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:285274e9-d77a-4f26-8962-b07558cd260e&page=queryresults
[0m12:40:39.811462 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5b93f61f-8719-40db-b2f0-a7334df7040a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1890628410>]}
[0m12:40:39.812599 [info ] [Thread-3 (]: 3 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.29s]
[0m12:40:39.813860 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m12:40:39.867814 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5b93f61f-8719-40db-b2f0-a7334df7040a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f18907f7510>]}
[0m12:40:39.869189 [info ] [Thread-4 (]: 4 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.35s]
[0m12:40:39.870696 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m12:40:39.972164 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5b93f61f-8719-40db-b2f0-a7334df7040a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f18907a7650>]}
[0m12:40:39.973479 [info ] [Thread-1 (]: 1 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.46s]
[0m12:40:39.974926 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m12:40:40.011624 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5b93f61f-8719-40db-b2f0-a7334df7040a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1890614810>]}
[0m12:40:40.013345 [info ] [Thread-2 (]: 2 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.49s]
[0m12:40:40.014678 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m12:40:40.017324 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m12:40:40.020334 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:40:40.021199 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m12:40:40.021992 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m12:40:40.023670 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m12:40:40.024822 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m12:40:40.026228 [info ] [MainThread]: 
[0m12:40:40.027341 [info ] [MainThread]: Finished running 4 incremental models in 0 hours 0 minutes and 3.35 seconds (3.35s).
[0m12:40:40.029574 [debug] [MainThread]: Command end result
[0m12:40:40.064933 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m12:40:40.069320 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m12:40:40.079259 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m12:40:40.080168 [info ] [MainThread]: 
[0m12:40:40.081253 [info ] [MainThread]: [32mCompleted successfully[0m
[0m12:40:40.082343 [info ] [MainThread]: 
[0m12:40:40.083555 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m12:40:40.085552 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 5.3841953, "process_in_blocks": "0", "process_kernel_time": 0.231955, "process_mem_max_rss": "226544", "process_out_blocks": "0", "process_user_time": 4.265955}
[0m12:40:40.086775 [debug] [MainThread]: Command `dbt run` succeeded at 12:40:40.086611 after 5.39 seconds
[0m12:40:40.087869 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f18be384b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1890233690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f18baf26910>]}
[0m12:40:40.089226 [debug] [MainThread]: Flushing usage events
[0m12:40:41.151013 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:41:03.946633 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7954fa74d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f79553a6110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7954fa7110>]}


============================== 12:41:03.949221 | 95b15488-65bc-469d-83e6-67fee15d43e9 ==============================
[0m12:41:03.949221 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:41:03.950262 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt run', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m12:41:04.522735 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '95b15488-65bc-469d-83e6-67fee15d43e9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f792715a390>]}
[0m12:41:04.567364 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '95b15488-65bc-469d-83e6-67fee15d43e9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f792729ff10>]}
[0m12:41:04.568557 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m12:41:04.638132 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m12:41:04.771246 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m12:41:04.772161 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/staging/production_hailing_staging_customer.sql
[0m12:41:05.019694 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.facts
- models.dbt_project.staging
[0m12:41:05.035177 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '95b15488-65bc-469d-83e6-67fee15d43e9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7926db5c50>]}
[0m12:41:05.106925 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m12:41:05.112412 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m12:41:05.127712 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '95b15488-65bc-469d-83e6-67fee15d43e9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7926c65c50>]}
[0m12:41:05.129069 [info ] [MainThread]: Found 4 models, 8 sources, 488 macros
[0m12:41:05.130229 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '95b15488-65bc-469d-83e6-67fee15d43e9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7926e27f10>]}
[0m12:41:05.132924 [info ] [MainThread]: 
[0m12:41:05.134239 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m12:41:05.135447 [info ] [MainThread]: 
[0m12:41:05.136881 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m12:41:05.142071 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m12:41:05.143035 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:41:05.675811 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m12:41:05.677302 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:41:05.889896 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '95b15488-65bc-469d-83e6-67fee15d43e9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f79554fcc50>]}
[0m12:41:05.891701 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:41:05.897709 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m12:41:05.898084 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m12:41:05.898405 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m12:41:05.898735 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m12:41:05.899419 [info ] [Thread-1 (]: 1 of 4 START sql view model rizky_dwh_hailing_source.production_hailing_staging_customer  [RUN]
[0m12:41:05.900791 [info ] [Thread-2 (]: 2 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [RUN]
[0m12:41:05.902280 [info ] [Thread-3 (]: 3 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [RUN]
[0m12:41:05.903657 [info ] [Thread-4 (]: 4 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [RUN]
[0m12:41:05.905067 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.production_hailing_staging_customer)
[0m12:41:05.906173 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m12:41:05.907271 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m12:41:05.908564 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_vehicle'
[0m12:41:05.909571 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m12:41:05.910417 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m12:41:05.911391 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m12:41:05.916546 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m12:41:05.928405 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m12:41:05.935301 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m12:41:05.941944 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m12:41:05.946522 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m12:41:05.957399 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m12:41:05.958167 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m12:41:05.958737 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m12:41:05.975675 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m12:41:05.975385 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:41:06.008982 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m12:41:06.011314 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m12:41:06.013878 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m12:41:06.069309 [debug] [Thread-1 (]: Compilation Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  Trying to create view `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`, but it currently exists as a table. Either drop `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` manually, or run dbt with `--full-refresh` and dbt will drop it for you.
  
  > in macro bigquery__handle_existing_table (macros/materializations/view.sql)
  > called by macro handle_existing_table (macros/relations/view/replace.sql)
  > called by macro bigquery__create_or_replace_view (macros/relations/view/replace.sql)
  > called by macro materialization_view_bigquery (macros/materializations/view.sql)
  > called by model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
[0m12:41:06.095417 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '95b15488-65bc-469d-83e6-67fee15d43e9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f792437f510>]}
[0m12:41:06.096711 [error] [Thread-1 (]: 1 of 4 ERROR creating sql view model rizky_dwh_hailing_source.production_hailing_staging_customer  [[31mERROR[0m in 0.19s]
[0m12:41:06.097896 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m12:41:06.099096 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.production_hailing_staging_customer' to be skipped because of status 'error'.  Reason: Compilation Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  Trying to create view `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`, but it currently exists as a table. Either drop `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` manually, or run dbt with `--full-refresh` and dbt will drop it for you.
  
  > in macro bigquery__handle_existing_table (macros/materializations/view.sql)
  > called by macro handle_existing_table (macros/relations/view/replace.sql)
  > called by macro bigquery__create_or_replace_view (macros/relations/view/replace.sql)
  > called by macro materialization_view_bigquery (macros/materializations/view.sql)
  > called by model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql).
[0m12:41:06.318785 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m12:41:06.319505 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m12:41:06.324337 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m12:41:06.326238 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m12:41:06.592375 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m12:41:06.603481 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m12:41:06.626595 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:fb186b7a-c146-4103-99fd-a540f000dc68&page=queryresults
[0m12:41:06.730600 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:5c854dc4-e8f0-4b69-acd4-105569b8e022&page=queryresults
[0m12:41:06.857379 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:a169fed4-a8bc-4c83-b82a-94ff1a63fd8f&page=queryresults
[0m12:41:08.161064 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '95b15488-65bc-469d-83e6-67fee15d43e9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7926d19650>]}
[0m12:41:08.162903 [info ] [Thread-4 (]: 4 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.25s]
[0m12:41:08.164836 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m12:41:08.243634 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '95b15488-65bc-469d-83e6-67fee15d43e9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7926cf3b50>]}
[0m12:41:08.245632 [info ] [Thread-2 (]: 2 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.34s]
[0m12:41:08.247603 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m12:41:08.368400 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '95b15488-65bc-469d-83e6-67fee15d43e9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f79243c5f90>]}
[0m12:41:08.369534 [info ] [Thread-3 (]: 3 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.46s]
[0m12:41:08.371239 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m12:41:08.374407 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m12:41:08.378606 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:41:08.379402 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m12:41:08.380190 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m12:41:08.380806 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m12:41:08.381481 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m12:41:08.382217 [info ] [MainThread]: 
[0m12:41:08.383081 [info ] [MainThread]: Finished running 3 incremental models, 1 view model in 0 hours 0 minutes and 3.25 seconds (3.25s).
[0m12:41:08.385579 [debug] [MainThread]: Command end result
[0m12:41:08.420532 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m12:41:08.425800 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m12:41:08.435161 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m12:41:08.436026 [info ] [MainThread]: 
[0m12:41:08.437231 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m12:41:08.438397 [info ] [MainThread]: 
[0m12:41:08.439610 [error] [MainThread]:   Compilation Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  Trying to create view `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`, but it currently exists as a table. Either drop `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` manually, or run dbt with `--full-refresh` and dbt will drop it for you.
  
  > in macro bigquery__handle_existing_table (macros/materializations/view.sql)
  > called by macro handle_existing_table (macros/relations/view/replace.sql)
  > called by macro bigquery__create_or_replace_view (macros/relations/view/replace.sql)
  > called by macro materialization_view_bigquery (macros/materializations/view.sql)
  > called by model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
[0m12:41:08.440711 [info ] [MainThread]: 
[0m12:41:08.441861 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=1 SKIP=0 TOTAL=4
[0m12:41:08.443647 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 4.549744, "process_in_blocks": "16", "process_kernel_time": 0.243292, "process_mem_max_rss": "225336", "process_out_blocks": "0", "process_user_time": 3.466916}
[0m12:41:08.444751 [debug] [MainThread]: Command `dbt run` failed at 12:41:08.444567 after 4.55 seconds
[0m12:41:08.445886 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7927158910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f790efb3450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f795721d710>]}
[0m12:41:08.446672 [debug] [MainThread]: Flushing usage events
[0m12:41:09.512271 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:41:26.454650 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4ac4eeafd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4ac4eeae50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4ac4f435d0>]}


============================== 12:41:26.457455 | 819d282b-95c4-42a4-8aa3-4f78cafa4317 ==============================
[0m12:41:26.457455 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:41:26.458586 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'log_format': 'default', 'invocation_command': 'dbt run', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m12:41:27.014207 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '819d282b-95c4-42a4-8aa3-4f78cafa4317', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4a977e3a90>]}
[0m12:41:27.062840 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '819d282b-95c4-42a4-8aa3-4f78cafa4317', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4ac7164b10>]}
[0m12:41:27.064062 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m12:41:27.135174 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m12:41:27.278006 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m12:41:27.279276 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/staging/production_hailing_staging_customer.sql
[0m12:41:27.537153 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.staging
- models.dbt_project.facts
[0m12:41:27.550252 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '819d282b-95c4-42a4-8aa3-4f78cafa4317', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4ac5cb0610>]}
[0m12:41:27.630504 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m12:41:27.636094 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m12:41:27.649680 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '819d282b-95c4-42a4-8aa3-4f78cafa4317', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4a96d02150>]}
[0m12:41:27.650781 [info ] [MainThread]: Found 4 models, 8 sources, 488 macros
[0m12:41:27.651861 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '819d282b-95c4-42a4-8aa3-4f78cafa4317', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4a96b9c0d0>]}
[0m12:41:27.654530 [info ] [MainThread]: 
[0m12:41:27.655814 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m12:41:27.656833 [info ] [MainThread]: 
[0m12:41:27.658356 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m12:41:27.662693 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m12:41:27.663928 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:41:28.169416 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m12:41:28.170332 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:41:28.385373 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '819d282b-95c4-42a4-8aa3-4f78cafa4317', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4a971da490>]}
[0m12:41:28.386506 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:41:28.391210 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m12:41:28.391536 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m12:41:28.391981 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m12:41:28.392418 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m12:41:28.393016 [info ] [Thread-1 (]: 1 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [RUN]
[0m12:41:28.394269 [info ] [Thread-2 (]: 2 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [RUN]
[0m12:41:28.395312 [info ] [Thread-3 (]: 3 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [RUN]
[0m12:41:28.396500 [info ] [Thread-4 (]: 4 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [RUN]
[0m12:41:28.397615 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.production_hailing_staging_customer)
[0m12:41:28.398738 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m12:41:28.399736 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m12:41:28.400864 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_vehicle'
[0m12:41:28.401741 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m12:41:28.402883 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m12:41:28.403713 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m12:41:28.404556 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m12:41:28.413910 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m12:41:28.418039 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m12:41:28.423070 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m12:41:28.427072 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m12:41:28.434206 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m12:41:28.434823 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m12:41:28.441705 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m12:41:28.442216 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m12:41:28.476357 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m12:41:28.476759 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m12:41:28.480058 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:41:28.482888 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m12:41:28.778709 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m12:41:28.781342 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m12:41:28.783555 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m12:41:28.784828 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m12:41:28.793103 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m12:41:28.793837 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m12:41:28.795181 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m12:41:28.798734 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m12:41:29.025528 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:9acce181-9288-4590-b114-ae1db5f62339&page=queryresults
[0m12:41:29.029475 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:de479302-a0a6-482b-8751-94e0aee19e75&page=queryresults
[0m12:41:29.073980 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:d1cd8456-6637-4927-9730-ce0ea608069c&page=queryresults
[0m12:41:29.110758 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:76ae07ed-c020-4db6-a99d-47fc7d78a5a8&page=queryresults
[0m12:41:30.595164 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '819d282b-95c4-42a4-8aa3-4f78cafa4317', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4a96e912d0>]}
[0m12:41:30.596844 [info ] [Thread-4 (]: 4 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.19s]
[0m12:41:30.599156 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m12:41:30.890796 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '819d282b-95c4-42a4-8aa3-4f78cafa4317', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4a7ee39290>]}
[0m12:41:30.895371 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '819d282b-95c4-42a4-8aa3-4f78cafa4317', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4a96c3f050>]}
[0m12:41:30.896135 [info ] [Thread-3 (]: 3 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.49s]
[0m12:41:30.898220 [info ] [Thread-1 (]: 1 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.50s]
[0m12:41:30.900702 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m12:41:30.906534 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '819d282b-95c4-42a4-8aa3-4f78cafa4317', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4a942524d0>]}
[0m12:41:30.907710 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m12:41:30.910096 [info ] [Thread-2 (]: 2 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.51s]
[0m12:41:30.912362 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m12:41:30.914979 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m12:41:30.918982 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:41:30.920023 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m12:41:30.922273 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m12:41:30.923799 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m12:41:30.925339 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m12:41:30.926698 [info ] [MainThread]: 
[0m12:41:30.927822 [info ] [MainThread]: Finished running 4 incremental models in 0 hours 0 minutes and 3.27 seconds (3.27s).
[0m12:41:30.930023 [debug] [MainThread]: Command end result
[0m12:41:30.966979 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m12:41:30.971968 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m12:41:30.980023 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m12:41:30.980776 [info ] [MainThread]: 
[0m12:41:30.981881 [info ] [MainThread]: [32mCompleted successfully[0m
[0m12:41:30.983115 [info ] [MainThread]: 
[0m12:41:30.984479 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m12:41:30.986027 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 4.583139, "process_in_blocks": "0", "process_kernel_time": 0.172975, "process_mem_max_rss": "224628", "process_out_blocks": "0", "process_user_time": 3.571426}
[0m12:41:30.986960 [debug] [MainThread]: Command `dbt run` succeeded at 12:41:30.986851 after 4.58 seconds
[0m12:41:30.987839 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4ac4f67c50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4ac4f67910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4ac8708b90>]}
[0m12:41:30.988843 [debug] [MainThread]: Flushing usage events
[0m12:41:32.116889 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:04:30.215006 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd90578750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd905cfd10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd90a90a50>]}


============================== 13:04:30.217578 | aa6da955-2f8a-48a3-918e-e20a8e100b45 ==============================
[0m13:04:30.217578 [info ] [MainThread]: Running with dbt=1.9.0
[0m13:04:30.218910 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt clean', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m13:04:30.299867 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'aa6da955-2f8a-48a3-918e-e20a8e100b45', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd905d0050>]}
[0m13:04:30.362748 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.19812414, "process_in_blocks": "0", "process_kernel_time": 0.098588, "process_mem_max_rss": "90064", "process_out_blocks": "0", "process_user_time": 0.946453}
[0m13:04:30.363980 [debug] [MainThread]: Command `dbt clean` succeeded at 13:04:30.363867 after 0.20 seconds
[0m13:04:30.364971 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd905cf050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd90976710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd93e64b10>]}
[0m13:04:30.365897 [debug] [MainThread]: Flushing usage events
[0m13:04:31.533743 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:04:32.727574 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb3dd37f490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb3dd3d3d10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb3dd3d3b10>]}


============================== 13:04:32.730744 | 8be0ee3e-ff6a-4c75-bf6b-a942a96b7829 ==============================
[0m13:04:32.730744 [info ] [MainThread]: Running with dbt=1.9.0
[0m13:04:32.731849 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'version_check': 'True', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt deps', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m13:04:32.820152 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '8be0ee3e-ff6a-4c75-bf6b-a942a96b7829', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb3dd3d3210>]}
[0m13:04:32.830306 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m13:04:32.833007 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m13:04:32.834931 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.15978639, "process_in_blocks": "0", "process_kernel_time": 0.070179, "process_mem_max_rss": "90252", "process_out_blocks": "0", "process_user_time": 1.042672}
[0m13:04:32.836058 [debug] [MainThread]: Command `dbt deps` succeeded at 13:04:32.835939 after 0.16 seconds
[0m13:04:32.836886 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb3dd894b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb3dd77a8d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb3e0c68b10>]}
[0m13:04:32.837818 [debug] [MainThread]: Flushing usage events
[0m13:04:33.899913 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:04:37.238260 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe6247ff050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe62490db90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe6247fed90>]}


============================== 13:04:37.240947 | 57bb519e-32be-47f6-8474-1a6959e2f6dd ==============================
[0m13:04:37.240947 [info ] [MainThread]: Running with dbt=1.9.0
[0m13:04:37.242157 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt run', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m13:04:37.847743 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '57bb519e-32be-47f6-8474-1a6959e2f6dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe62487bdd0>]}
[0m13:04:37.895403 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '57bb519e-32be-47f6-8474-1a6959e2f6dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe626a76150>]}
[0m13:04:37.897073 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m13:04:37.971236 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m13:04:37.973711 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m13:04:37.974758 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '57bb519e-32be-47f6-8474-1a6959e2f6dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe5f713ea90>]}
[0m13:04:39.001832 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.facts
- models.dbt_project.staging
[0m13:04:39.014727 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '57bb519e-32be-47f6-8474-1a6959e2f6dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe5f65beed0>]}
[0m13:04:39.086344 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m13:04:39.090968 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m13:04:39.105433 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '57bb519e-32be-47f6-8474-1a6959e2f6dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe5f63d4250>]}
[0m13:04:39.106284 [info ] [MainThread]: Found 4 models, 8 sources, 488 macros
[0m13:04:39.107262 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '57bb519e-32be-47f6-8474-1a6959e2f6dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe5f65c3310>]}
[0m13:04:39.110229 [info ] [MainThread]: 
[0m13:04:39.111425 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m13:04:39.112411 [info ] [MainThread]: 
[0m13:04:39.114564 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m13:04:39.119013 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m13:04:39.119804 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:04:39.721601 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m13:04:39.722370 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:04:39.969512 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '57bb519e-32be-47f6-8474-1a6959e2f6dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe5f6863110>]}
[0m13:04:39.970598 [debug] [MainThread]: Opening a new connection, currently in state init
[0m13:04:39.975512 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m13:04:39.975881 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m13:04:39.976276 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m13:04:39.976730 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m13:04:39.977455 [info ] [Thread-1 (]: 1 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [RUN]
[0m13:04:39.978680 [info ] [Thread-2 (]: 2 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [RUN]
[0m13:04:39.979799 [info ] [Thread-3 (]: 3 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [RUN]
[0m13:04:39.981148 [info ] [Thread-4 (]: 4 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [RUN]
[0m13:04:39.982493 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.production_hailing_staging_customer)
[0m13:04:39.983596 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m13:04:39.984837 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m13:04:39.985908 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_vehicle'
[0m13:04:39.986924 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m13:04:39.987816 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m13:04:39.988709 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m13:04:39.989590 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m13:04:40.001208 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m13:04:40.005148 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m13:04:40.010924 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m13:04:40.015304 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m13:04:40.026408 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m13:04:40.032887 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m13:04:40.061284 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m13:04:40.064559 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m13:04:40.067313 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m13:04:40.067679 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m13:04:40.070353 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:04:40.097056 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m13:04:40.407452 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m13:04:40.406883 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m13:04:40.408814 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m13:04:40.409995 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m13:04:40.422678 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m13:04:40.425588 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m13:04:40.428801 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m13:04:40.431344 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m13:04:40.776294 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:5f42f04e-80f8-4c1b-b3ee-5b3d73f3ee0c&page=queryresults
[0m13:04:40.779280 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:ecaf25ce-6b16-4d3d-9d31-6a2f03a2e657&page=queryresults
[0m13:04:40.781904 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:f9766849-24a6-4566-b815-627a8d889cae&page=queryresults
[0m13:04:40.804274 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:934d088e-b302-46ae-882d-5ace413cc7df&page=queryresults
[0m13:04:42.427825 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '57bb519e-32be-47f6-8474-1a6959e2f6dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe5f42c02d0>]}
[0m13:04:42.429256 [info ] [Thread-4 (]: 4 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.44s]
[0m13:04:42.430621 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m13:04:42.625174 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '57bb519e-32be-47f6-8474-1a6959e2f6dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe5e6644590>]}
[0m13:04:42.626305 [info ] [Thread-1 (]: 1 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.64s]
[0m13:04:42.627335 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m13:04:42.645697 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '57bb519e-32be-47f6-8474-1a6959e2f6dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe5f42e0310>]}
[0m13:04:42.649622 [info ] [Thread-3 (]: 3 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.66s]
[0m13:04:42.651444 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m13:04:43.221335 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '57bb519e-32be-47f6-8474-1a6959e2f6dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe5f42d5dd0>]}
[0m13:04:43.222646 [info ] [Thread-2 (]: 2 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 3.24s]
[0m13:04:43.223943 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m13:04:43.226654 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m13:04:43.229553 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:04:43.230486 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m13:04:43.231279 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m13:04:43.232318 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m13:04:43.233312 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m13:04:43.234466 [info ] [MainThread]: 
[0m13:04:43.236076 [info ] [MainThread]: Finished running 4 incremental models in 0 hours 0 minutes and 4.12 seconds (4.12s).
[0m13:04:43.238329 [debug] [MainThread]: Command end result
[0m13:04:43.280106 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m13:04:43.285816 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m13:04:43.295542 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m13:04:43.296686 [info ] [MainThread]: 
[0m13:04:43.297828 [info ] [MainThread]: [32mCompleted successfully[0m
[0m13:04:43.299244 [info ] [MainThread]: 
[0m13:04:43.300338 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m13:04:43.302167 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 6.118044, "process_in_blocks": "0", "process_kernel_time": 0.279574, "process_mem_max_rss": "226860", "process_out_blocks": "0", "process_user_time": 4.143692}
[0m13:04:43.303254 [debug] [MainThread]: Command `dbt run` succeeded at 13:04:43.303128 after 6.12 seconds
[0m13:04:43.304636 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe62487b950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe6254e3410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe627ff4c10>]}
[0m13:04:43.306021 [debug] [MainThread]: Flushing usage events
[0m13:04:44.332051 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:04:59.894249 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9697016c50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96974fb7d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96974fb6d0>]}


============================== 13:04:59.897387 | df1191e8-082e-415c-a1b1-1d6436904ad5 ==============================
[0m13:04:59.897387 [info ] [MainThread]: Running with dbt=1.9.0
[0m13:04:59.898512 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m13:05:00.494732 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'df1191e8-082e-415c-a1b1-1d6436904ad5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f966d31f510>]}
[0m13:05:00.539864 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'df1191e8-082e-415c-a1b1-1d6436904ad5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96992c61d0>]}
[0m13:05:00.541071 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m13:05:00.614183 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m13:05:00.698105 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m13:05:00.699261 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'df1191e8-082e-415c-a1b1-1d6436904ad5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f969770e9d0>]}
[0m13:05:01.738866 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.facts
- models.dbt_project.staging
[0m13:05:01.752419 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'df1191e8-082e-415c-a1b1-1d6436904ad5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f966d040750>]}
[0m13:05:01.826316 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m13:05:01.831651 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m13:05:01.846511 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'df1191e8-082e-415c-a1b1-1d6436904ad5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f966cc03ad0>]}
[0m13:05:01.847735 [info ] [MainThread]: Found 4 models, 8 sources, 488 macros
[0m13:05:01.848913 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'df1191e8-082e-415c-a1b1-1d6436904ad5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f966ced55d0>]}
[0m13:05:01.851629 [info ] [MainThread]: 
[0m13:05:01.852850 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m13:05:01.853808 [info ] [MainThread]: 
[0m13:05:01.855147 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m13:05:01.860370 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m13:05:01.861398 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:05:02.362027 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m13:05:02.363021 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:05:02.596490 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'df1191e8-082e-415c-a1b1-1d6436904ad5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9698204590>]}
[0m13:05:02.597756 [debug] [MainThread]: Opening a new connection, currently in state init
[0m13:05:02.603834 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m13:05:02.604187 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m13:05:02.604612 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m13:05:02.605022 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m13:05:02.605549 [info ] [Thread-1 (]: 1 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [RUN]
[0m13:05:02.606661 [info ] [Thread-2 (]: 2 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [RUN]
[0m13:05:02.607741 [info ] [Thread-3 (]: 3 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [RUN]
[0m13:05:02.609115 [info ] [Thread-4 (]: 4 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [RUN]
[0m13:05:02.610453 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.production_hailing_staging_customer)
[0m13:05:02.611505 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m13:05:02.612838 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m13:05:02.613924 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_vehicle'
[0m13:05:02.615208 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m13:05:02.616333 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m13:05:02.617440 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m13:05:02.618372 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m13:05:02.628897 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m13:05:02.633021 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m13:05:02.638292 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m13:05:02.642896 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m13:05:02.648808 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m13:05:02.649307 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m13:05:02.650103 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m13:05:02.678445 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m13:05:02.694909 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m13:05:02.695266 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m13:05:02.698260 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:05:02.702739 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m13:05:03.020345 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m13:05:03.023164 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m13:05:03.024401 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m13:05:03.027278 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m13:05:03.032974 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m13:05:03.033803 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m13:05:03.034346 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m13:05:03.037070 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m13:05:03.294893 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:44931d65-5ad1-455c-a4e0-1ecec25dcb8f&page=queryresults
[0m13:05:03.310916 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:9250afe5-4c20-4546-af43-045413354c82&page=queryresults
[0m13:05:03.343923 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:3b29a5f9-b7a0-477e-87c6-cd3cda73b8e8&page=queryresults
[0m13:05:03.396303 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:74deef52-0b46-4e23-a205-c85ebbd1e329&page=queryresults
[0m13:05:04.870040 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'df1191e8-082e-415c-a1b1-1d6436904ad5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f966c2aaf90>]}
[0m13:05:04.871594 [info ] [Thread-1 (]: 1 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.26s]
[0m13:05:04.873007 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m13:05:05.129408 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'df1191e8-082e-415c-a1b1-1d6436904ad5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f966ccb4450>]}
[0m13:05:05.131010 [info ] [Thread-4 (]: 4 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.52s]
[0m13:05:05.132426 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m13:05:05.193083 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'df1191e8-082e-415c-a1b1-1d6436904ad5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f966cd42250>]}
[0m13:05:05.194580 [info ] [Thread-2 (]: 2 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.58s]
[0m13:05:05.195996 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m13:05:05.230248 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'df1191e8-082e-415c-a1b1-1d6436904ad5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f966ccb5f10>]}
[0m13:05:05.232258 [info ] [Thread-3 (]: 3 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.62s]
[0m13:05:05.234525 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m13:05:05.237889 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m13:05:05.242282 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:05:05.243733 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m13:05:05.244724 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m13:05:05.245697 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m13:05:05.246670 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m13:05:05.248299 [info ] [MainThread]: 
[0m13:05:05.249576 [info ] [MainThread]: Finished running 4 incremental models in 0 hours 0 minutes and 3.39 seconds (3.39s).
[0m13:05:05.251631 [debug] [MainThread]: Command end result
[0m13:05:05.293374 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m13:05:05.298518 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m13:05:05.307696 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m13:05:05.308545 [info ] [MainThread]: 
[0m13:05:05.309795 [info ] [MainThread]: [32mCompleted successfully[0m
[0m13:05:05.311029 [info ] [MainThread]: 
[0m13:05:05.312173 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m13:05:05.314372 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 5.480524, "process_in_blocks": "0", "process_kernel_time": 0.232791, "process_mem_max_rss": "229904", "process_out_blocks": "0", "process_user_time": 4.271217}
[0m13:05:05.315613 [debug] [MainThread]: Command `dbt run` succeeded at 13:05:05.315456 after 5.48 seconds
[0m13:05:05.316564 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9697091310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96974fb7d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f969a92be10>]}
[0m13:05:05.317526 [debug] [MainThread]: Flushing usage events
[0m13:05:06.349827 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:07:59.053840 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f56c6eeaf90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f56c6eeac50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f56c6eeaf50>]}


============================== 13:07:59.056481 | a6bb6628-fde7-4881-a1a4-e4119e95a538 ==============================
[0m13:07:59.056481 [info ] [MainThread]: Running with dbt=1.9.0
[0m13:07:59.057724 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m13:07:59.662090 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a6bb6628-fde7-4881-a1a4-e4119e95a538', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f56c6eedf90>]}
[0m13:07:59.707876 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a6bb6628-fde7-4881-a1a4-e4119e95a538', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f56c915c790>]}
[0m13:07:59.709599 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m13:07:59.775706 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m13:07:59.846358 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m13:07:59.847741 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'a6bb6628-fde7-4881-a1a4-e4119e95a538', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f56c75d69d0>]}
[0m13:08:00.887434 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.staging
- models.dbt_project.facts
[0m13:08:00.899538 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a6bb6628-fde7-4881-a1a4-e4119e95a538', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f569f477d10>]}
[0m13:08:00.978183 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m13:08:00.985351 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m13:08:01.003787 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a6bb6628-fde7-4881-a1a4-e4119e95a538', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f569caf3d90>]}
[0m13:08:01.005332 [info ] [MainThread]: Found 4 models, 8 sources, 488 macros
[0m13:08:01.006653 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a6bb6628-fde7-4881-a1a4-e4119e95a538', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f569ced3510>]}
[0m13:08:01.010142 [info ] [MainThread]: 
[0m13:08:01.011601 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m13:08:01.012837 [info ] [MainThread]: 
[0m13:08:01.014242 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m13:08:01.019706 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m13:08:01.020659 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:08:01.583141 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m13:08:01.584093 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:08:01.862589 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a6bb6628-fde7-4881-a1a4-e4119e95a538', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f56c9011f90>]}
[0m13:08:01.863838 [debug] [MainThread]: Opening a new connection, currently in state init
[0m13:08:01.869286 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m13:08:01.869655 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m13:08:01.870024 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m13:08:01.870367 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m13:08:01.871091 [info ] [Thread-1 (]: 1 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [RUN]
[0m13:08:01.872168 [info ] [Thread-2 (]: 2 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [RUN]
[0m13:08:01.873359 [info ] [Thread-3 (]: 3 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [RUN]
[0m13:08:01.874548 [info ] [Thread-4 (]: 4 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [RUN]
[0m13:08:01.876041 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.production_hailing_staging_customer)
[0m13:08:01.877495 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m13:08:01.879093 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m13:08:01.880479 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_vehicle'
[0m13:08:01.881487 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m13:08:01.882801 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m13:08:01.883818 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m13:08:01.884823 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m13:08:01.895753 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m13:08:01.900230 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m13:08:01.905087 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m13:08:01.910425 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m13:08:01.915782 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m13:08:01.916723 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m13:08:01.922616 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m13:08:01.935532 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m13:08:01.967987 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:08:01.968460 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m13:08:01.971402 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m13:08:01.975677 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m13:08:02.313802 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m13:08:02.314877 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m13:08:02.316303 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m13:08:02.317721 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m13:08:02.323491 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m13:08:02.324241 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m13:08:02.327012 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m13:08:02.328715 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m13:08:02.572851 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:8d29f365-e9c5-4ff0-b47f-69fe7f095339&page=queryresults
[0m13:08:02.603562 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:78ed6424-d9d1-440e-8db9-4e5a0311335d&page=queryresults
[0m13:08:02.609181 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:5f47deb5-a31d-491f-8381-fbbe6608b888&page=queryresults
[0m13:08:02.672347 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:55ada9be-9e72-4779-b980-94410cfa83b9&page=queryresults
[0m13:08:04.263629 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a6bb6628-fde7-4881-a1a4-e4119e95a538', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f569c167a50>]}
[0m13:08:04.265050 [info ] [Thread-3 (]: 3 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.38s]
[0m13:08:04.266601 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m13:08:04.390753 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a6bb6628-fde7-4881-a1a4-e4119e95a538', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f569c14e190>]}
[0m13:08:04.392072 [info ] [Thread-2 (]: 2 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.51s]
[0m13:08:04.393526 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m13:08:04.399426 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a6bb6628-fde7-4881-a1a4-e4119e95a538', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f569cb77850>]}
[0m13:08:04.400685 [info ] [Thread-1 (]: 1 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.52s]
[0m13:08:04.402032 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m13:08:04.431138 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a6bb6628-fde7-4881-a1a4-e4119e95a538', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f569c1f3710>]}
[0m13:08:04.432821 [info ] [Thread-4 (]: 4 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.55s]
[0m13:08:04.434791 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m13:08:04.437055 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m13:08:04.439585 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:08:04.440345 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m13:08:04.441189 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m13:08:04.441913 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m13:08:04.442575 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m13:08:04.443360 [info ] [MainThread]: 
[0m13:08:04.444348 [info ] [MainThread]: Finished running 4 incremental models in 0 hours 0 minutes and 3.43 seconds (3.43s).
[0m13:08:04.446096 [debug] [MainThread]: Command end result
[0m13:08:04.480727 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m13:08:04.485320 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m13:08:04.493109 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m13:08:04.494210 [info ] [MainThread]: 
[0m13:08:04.495661 [info ] [MainThread]: [32mCompleted successfully[0m
[0m13:08:04.496924 [info ] [MainThread]: 
[0m13:08:04.498314 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m13:08:04.500114 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 5.502689, "process_in_blocks": "0", "process_kernel_time": 0.243895, "process_mem_max_rss": "227840", "process_out_blocks": "0", "process_user_time": 4.23768}
[0m13:08:04.501419 [debug] [MainThread]: Command `dbt run` succeeded at 13:08:04.501265 after 5.50 seconds
[0m13:08:04.502663 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f56c6f2af50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f56c6f29410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f56ca704b90>]}
[0m13:08:04.503900 [debug] [MainThread]: Flushing usage events
[0m13:08:05.622675 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:15:09.496157 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fed474e6d10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fed478de110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fed474e69d0>]}


============================== 13:15:09.499642 | 5df33357-857e-4641-bfd0-be65f9d9be07 ==============================
[0m13:15:09.499642 [info ] [MainThread]: Running with dbt=1.9.0
[0m13:15:09.502193 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt debug', 'send_anonymous_usage_stats': 'True'}
[0m13:15:09.511900 [info ] [MainThread]: dbt version: 1.9.0
[0m13:15:09.513016 [info ] [MainThread]: python version: 3.11.2
[0m13:15:09.514060 [info ] [MainThread]: python path: /usr/local/bin/python
[0m13:15:09.516140 [info ] [MainThread]: os info: Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.31
[0m13:15:10.021621 [info ] [MainThread]: Using profiles dir at /usr/app/dbt_project
[0m13:15:10.022995 [info ] [MainThread]: Using profiles.yml file at /usr/app/dbt_project/profiles.yml
[0m13:15:10.024367 [info ] [MainThread]: Using dbt_project.yml file at /usr/app/dbt_project/dbt_project.yml
[0m13:15:10.025953 [info ] [MainThread]: adapter type: bigquery
[0m13:15:10.027026 [info ] [MainThread]: adapter version: 1.9.0
[0m13:15:10.102573 [info ] [MainThread]: Configuration:
[0m13:15:10.104006 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m13:15:10.105584 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m13:15:10.106948 [info ] [MainThread]: Required dependencies:
[0m13:15:10.108149 [debug] [MainThread]: Executing "git --help"
[0m13:15:10.112662 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m13:15:10.113782 [debug] [MainThread]: STDERR: "b''"
[0m13:15:10.114725 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m13:15:10.116260 [info ] [MainThread]: Connection:
[0m13:15:10.117483 [info ] [MainThread]:   method: service-account
[0m13:15:10.118576 [info ] [MainThread]:   database: purwadika
[0m13:15:10.119814 [info ] [MainThread]:   execution_project: purwadika
[0m13:15:10.120805 [info ] [MainThread]:   schema: rizky_dwh_hailing_source
[0m13:15:10.121726 [info ] [MainThread]:   location: None
[0m13:15:10.122595 [info ] [MainThread]:   priority: None
[0m13:15:10.123468 [info ] [MainThread]:   maximum_bytes_billed: None
[0m13:15:10.124538 [info ] [MainThread]:   impersonate_service_account: None
[0m13:15:10.125550 [info ] [MainThread]:   job_retry_deadline_seconds: None
[0m13:15:10.126605 [info ] [MainThread]:   job_retries: 1
[0m13:15:10.127539 [info ] [MainThread]:   job_creation_timeout_seconds: None
[0m13:15:10.128511 [info ] [MainThread]:   job_execution_timeout_seconds: None
[0m13:15:10.129337 [info ] [MainThread]:   timeout_seconds: None
[0m13:15:10.130437 [info ] [MainThread]:   client_id: None
[0m13:15:10.131816 [info ] [MainThread]:   token_uri: None
[0m13:15:10.133473 [info ] [MainThread]:   dataproc_region: None
[0m13:15:10.134729 [info ] [MainThread]:   dataproc_cluster_name: None
[0m13:15:10.135837 [info ] [MainThread]:   gcs_bucket: None
[0m13:15:10.136687 [info ] [MainThread]:   dataproc_batch: None
[0m13:15:10.137942 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m13:15:10.192550 [debug] [MainThread]: Acquiring new bigquery connection 'debug'
[0m13:15:10.193555 [debug] [MainThread]: On debug: select 1 as id
[0m13:15:10.194505 [debug] [MainThread]: Opening a new connection, currently in state init
[0m13:15:10.944013 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:35e2048f-d81b-41f3-9268-46082b060f01&page=queryresults
[0m13:15:11.676046 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m13:15:11.677687 [info ] [MainThread]: [32mAll checks passed![0m
[0m13:15:11.680547 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": true, "command_wall_clock_time": 2.2425096, "process_in_blocks": "0", "process_kernel_time": 0.181806, "process_mem_max_rss": "211980", "process_out_blocks": "0", "process_user_time": 2.716993}
[0m13:15:11.681957 [debug] [MainThread]: Command `dbt debug` succeeded at 13:15:11.681840 after 2.24 seconds
[0m13:15:11.683081 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m13:15:11.685136 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fed475432d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fed47543210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fed478ddfd0>]}
[0m13:15:11.686212 [debug] [MainThread]: Flushing usage events
[0m13:15:12.988319 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:15:15.944842 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0370cb2e10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0370dbdc90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0370cb2dd0>]}


============================== 13:15:15.947648 | 8923e300-2883-4069-84a0-c7d9da18900e ==============================
[0m13:15:15.947648 [info ] [MainThread]: Running with dbt=1.9.0
[0m13:15:15.950000 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m13:15:16.555650 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '8923e300-2883-4069-84a0-c7d9da18900e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0343423f90>]}
[0m13:15:16.611401 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '8923e300-2883-4069-84a0-c7d9da18900e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0372f0d990>]}
[0m13:15:16.612637 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m13:15:16.682719 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m13:15:16.822717 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m13:15:16.824089 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/staging/production_hailing_staging_customer.sql
[0m13:15:17.016867 [error] [MainThread]: Encountered an error:
Runtime Error
  Got duplicate keys: (dataset) all map to "schema"
[0m13:15:17.019515 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.1228918, "process_in_blocks": "0", "process_kernel_time": 0.212611, "process_mem_max_rss": "212360", "process_out_blocks": "0", "process_user_time": 2.966443}
[0m13:15:17.020983 [debug] [MainThread]: Command `dbt run` failed at 13:15:17.020790 after 1.12 seconds
[0m13:15:17.022436 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0370b13b10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0370b13a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0342aa8b90>]}
[0m13:15:17.023701 [debug] [MainThread]: Flushing usage events
[0m13:15:18.122710 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:16:34.406950 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdd63a53510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdd63e4e690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdd63a52e90>]}


============================== 13:16:34.409694 | f109e6c3-730b-4b0c-a1f2-158774552dbc ==============================
[0m13:16:34.409694 [info ] [MainThread]: Running with dbt=1.9.0
[0m13:16:34.411322 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'warn_error': 'None', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run --select production_hailing_staging_customers', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m13:16:34.981295 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f109e6c3-730b-4b0c-a1f2-158774552dbc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdd35d909d0>]}
[0m13:16:35.031014 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f109e6c3-730b-4b0c-a1f2-158774552dbc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdd65cd4a90>]}
[0m13:16:35.032246 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m13:16:35.103208 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m13:16:35.233286 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m13:16:35.234391 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/staging/production_hailing_staging_customer.sql
[0m13:16:35.441728 [error] [MainThread]: Encountered an error:
Runtime Error
  Got duplicate keys: (dataset) all map to "schema"
[0m13:16:35.443818 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.0867047, "process_in_blocks": "0", "process_kernel_time": 0.168808, "process_mem_max_rss": "213880", "process_out_blocks": "0", "process_user_time": 2.949179}
[0m13:16:35.445055 [debug] [MainThread]: Command `dbt run` failed at 13:16:35.444914 after 1.09 seconds
[0m13:16:35.446039 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdd63aab850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdd63aabb50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdd35ddb550>]}
[0m13:16:35.446854 [debug] [MainThread]: Flushing usage events
[0m13:16:36.631813 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:17:12.051500 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f01b24fb890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f01b254b390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f01b28f1f50>]}


============================== 13:17:12.054295 | c664f7b9-f272-4053-b7c7-a46fd89fe508 ==============================
[0m13:17:12.054295 [info ] [MainThread]: Running with dbt=1.9.0
[0m13:17:12.055633 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt run --select production_hailing_staging_customer', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m13:17:12.667561 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'c664f7b9-f272-4053-b7c7-a46fd89fe508', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f01886a2210>]}
[0m13:17:12.724263 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'c664f7b9-f272-4053-b7c7-a46fd89fe508', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f01b4756410>]}
[0m13:17:12.726088 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m13:17:12.797115 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m13:17:12.958292 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m13:17:12.959479 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/staging/production_hailing_staging_customer.sql
[0m13:17:13.227769 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.facts
- models.dbt_project.staging
[0m13:17:13.242489 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c664f7b9-f272-4053-b7c7-a46fd89fe508', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f01886d7850>]}
[0m13:17:13.318146 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m13:17:13.323368 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m13:17:13.339467 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c664f7b9-f272-4053-b7c7-a46fd89fe508', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f018832afd0>]}
[0m13:17:13.340778 [info ] [MainThread]: Found 4 models, 8 sources, 488 macros
[0m13:17:13.342040 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c664f7b9-f272-4053-b7c7-a46fd89fe508', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f01b3288290>]}
[0m13:17:13.344391 [info ] [MainThread]: 
[0m13:17:13.345598 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m13:17:13.346529 [info ] [MainThread]: 
[0m13:17:13.347708 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m13:17:13.350033 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m13:17:13.351079 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:17:13.967585 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now create_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_staging)
[0m13:17:13.969034 [debug] [ThreadPool]: Creating schema "database: "purwadika"
schema: "rizky_dwh_hailing_source_rizky_dwh_hailing_staging"
"
[0m13:17:13.977918 [debug] [ThreadPool]: On create_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_staging: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "connection_name": "create_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_staging"} */
create schema if not exists `purwadika`.`rizky_dwh_hailing_source_rizky_dwh_hailing_staging`
  
[0m13:17:13.978918 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:17:14.792965 [debug] [ThreadPool]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:843c2bd2-6b87-4bf9-822c-5d171463b07d&page=queryresults
[0m13:17:15.789447 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_staging, now list_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_staging)
[0m13:17:15.790205 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_source'
[0m13:17:15.791137 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:17:15.792049 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:17:16.555990 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c664f7b9-f272-4053-b7c7-a46fd89fe508', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0188495b10>]}
[0m13:17:16.557024 [debug] [MainThread]: Opening a new connection, currently in state init
[0m13:17:16.561923 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m13:17:16.563281 [info ] [Thread-1 (]: 1 of 1 START sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_staging.production_hailing_staging_customer  [RUN]
[0m13:17:16.565004 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_staging, now model.hailing_project.production_hailing_staging_customer)
[0m13:17:16.566082 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m13:17:16.574353 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m13:17:16.583028 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m13:17:16.649507 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m13:17:16.658202 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source_rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    );
  
[0m13:17:16.659518 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:17:16.989538 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:b513af43-7d0b-4501-b241-838bb223ce4e&page=queryresults
[0m13:17:16.990834 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:b513af43-7d0b-4501-b241-838bb223ce4e&page=queryresults
[0m13:17:16.996454 [debug] [Thread-1 (]: Database Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_customer.sql
[0m13:17:16.998680 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c664f7b9-f272-4053-b7c7-a46fd89fe508', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f01836a1d50>]}
[0m13:17:17.000033 [error] [Thread-1 (]: 1 of 1 ERROR creating sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_staging.production_hailing_staging_customer  [[31mERROR[0m in 0.43s]
[0m13:17:17.001561 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m13:17:17.002937 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.production_hailing_staging_customer' to be skipped because of status 'error'.  Reason: Database Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_customer.sql.
[0m13:17:17.005664 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m13:17:17.008553 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:17:17.009345 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m13:17:17.010169 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_source' was properly closed.
[0m13:17:17.011008 [info ] [MainThread]: 
[0m13:17:17.011831 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 3.66 seconds (3.66s).
[0m13:17:17.013447 [debug] [MainThread]: Command end result
[0m13:17:17.046926 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m13:17:17.050887 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m13:17:17.058718 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m13:17:17.059607 [info ] [MainThread]: 
[0m13:17:17.060690 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m13:17:17.061741 [info ] [MainThread]: 
[0m13:17:17.062804 [error] [MainThread]:   Database Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_customer.sql
[0m13:17:17.063806 [info ] [MainThread]: 
[0m13:17:17.064791 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m13:17:17.066496 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 5.069591, "process_in_blocks": "0", "process_kernel_time": 0.203535, "process_mem_max_rss": "222448", "process_out_blocks": "0", "process_user_time": 3.500809}
[0m13:17:17.067955 [debug] [MainThread]: Command `dbt run` failed at 13:17:17.067745 after 5.07 seconds
[0m13:17:17.069033 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f01b235ba10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f01b23580d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f01b35d19d0>]}
[0m13:17:17.070055 [debug] [MainThread]: Flushing usage events
[0m13:17:18.345895 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:18:09.299081 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1de4007c50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1de3373610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1de4007550>]}


============================== 13:18:09.301595 | ba3a0f5b-d76a-496c-8e26-8c32da4bb23d ==============================
[0m13:18:09.301595 [info ] [MainThread]: Running with dbt=1.9.0
[0m13:18:09.303019 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m13:18:09.885550 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ba3a0f5b-d76a-496c-8e26-8c32da4bb23d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1db953e690>]}
[0m13:18:09.931295 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ba3a0f5b-d76a-496c-8e26-8c32da4bb23d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1db9586550>]}
[0m13:18:09.932427 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m13:18:09.997513 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m13:18:10.061856 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m13:18:10.063055 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'ba3a0f5b-d76a-496c-8e26-8c32da4bb23d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1db9c3bb50>]}
[0m13:18:11.033328 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_project.staging
[0m13:18:11.045516 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ba3a0f5b-d76a-496c-8e26-8c32da4bb23d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1db954c2d0>]}
[0m13:18:11.119950 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m13:18:11.126930 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m13:18:11.142246 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ba3a0f5b-d76a-496c-8e26-8c32da4bb23d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1db8f1be90>]}
[0m13:18:11.143445 [info ] [MainThread]: Found 4 models, 8 sources, 488 macros
[0m13:18:11.144605 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ba3a0f5b-d76a-496c-8e26-8c32da4bb23d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1db90d6f90>]}
[0m13:18:11.147200 [info ] [MainThread]: 
[0m13:18:11.148498 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m13:18:11.149511 [info ] [MainThread]: 
[0m13:18:11.151083 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m13:18:11.155766 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m13:18:11.156717 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m13:18:11.157226 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:18:11.157957 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:18:12.138147 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_staging)
[0m13:18:12.138924 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m13:18:12.140093 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:18:12.141264 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:18:12.689001 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ba3a0f5b-d76a-496c-8e26-8c32da4bb23d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1de3329550>]}
[0m13:18:12.691589 [debug] [MainThread]: Opening a new connection, currently in state init
[0m13:18:12.696604 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m13:18:12.697010 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m13:18:12.697389 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m13:18:12.697951 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m13:18:12.698797 [info ] [Thread-1 (]: 1 of 4 START sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_staging.production_hailing_staging_customer  [RUN]
[0m13:18:12.699820 [info ] [Thread-2 (]: 2 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [RUN]
[0m13:18:12.701651 [info ] [Thread-3 (]: 3 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [RUN]
[0m13:18:12.702955 [info ] [Thread-4 (]: 4 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [RUN]
[0m13:18:12.704189 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_staging, now model.hailing_project.production_hailing_staging_customer)
[0m13:18:12.705383 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.production_hailing_staging_driver)
[0m13:18:12.706589 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m13:18:12.707597 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_vehicle'
[0m13:18:12.708724 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m13:18:12.709552 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m13:18:12.710669 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m13:18:12.711577 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m13:18:12.721508 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m13:18:12.727763 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m13:18:12.732179 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m13:18:12.737160 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m13:18:12.743382 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m13:18:12.743886 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m13:18:12.755096 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m13:18:12.765280 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m13:18:12.788921 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m13:18:12.808818 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m13:18:12.812110 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m13:18:12.815767 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m13:18:12.901126 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source_rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    );
  
[0m13:18:12.902419 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:18:13.131369 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m13:18:13.136914 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m13:18:13.150439 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m13:18:13.153696 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m13:18:13.157429 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m13:18:13.159342 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m13:18:13.219993 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:51f18cbc-3486-4311-b2a5-a5d7dc81fabc&page=queryresults
[0m13:18:13.221359 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:51f18cbc-3486-4311-b2a5-a5d7dc81fabc&page=queryresults
[0m13:18:13.226564 [debug] [Thread-1 (]: Database Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_customer.sql
[0m13:18:13.228474 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ba3a0f5b-d76a-496c-8e26-8c32da4bb23d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1db8592650>]}
[0m13:18:13.229791 [error] [Thread-1 (]: 1 of 4 ERROR creating sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_staging.production_hailing_staging_customer  [[31mERROR[0m in 0.52s]
[0m13:18:13.231108 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m13:18:13.232281 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.production_hailing_staging_customer' to be skipped because of status 'error'.  Reason: Database Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_customer.sql.
[0m13:18:13.430359 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:fd8fc93c-67d7-442e-9e0a-0ecbf5683778&page=queryresults
[0m13:18:13.441282 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:b3181c64-6878-4ad9-b23b-1a504d11e9be&page=queryresults
[0m13:18:13.446357 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:1d66b080-2788-437c-8d52-d7f9c5b1d049&page=queryresults
[0m13:18:15.437184 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ba3a0f5b-d76a-496c-8e26-8c32da4bb23d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1db84d1ed0>]}
[0m13:18:15.438466 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ba3a0f5b-d76a-496c-8e26-8c32da4bb23d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1db84d16d0>]}
[0m13:18:15.440846 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ba3a0f5b-d76a-496c-8e26-8c32da4bb23d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1db85be290>]}
[0m13:18:15.441582 [info ] [Thread-3 (]: 3 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.73s]
[0m13:18:15.443181 [info ] [Thread-2 (]: 2 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.73s]
[0m13:18:15.444498 [info ] [Thread-4 (]: 4 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.73s]
[0m13:18:15.445862 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m13:18:15.446972 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m13:18:15.447920 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m13:18:15.450690 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m13:18:15.453770 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:18:15.454818 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m13:18:15.455866 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m13:18:15.456877 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m13:18:15.458650 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m13:18:15.460110 [info ] [MainThread]: 
[0m13:18:15.461152 [info ] [MainThread]: Finished running 4 incremental models in 0 hours 0 minutes and 4.31 seconds (4.31s).
[0m13:18:15.463076 [debug] [MainThread]: Command end result
[0m13:18:15.500162 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m13:18:15.507358 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m13:18:15.520133 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m13:18:15.521370 [info ] [MainThread]: 
[0m13:18:15.522709 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m13:18:15.524071 [info ] [MainThread]: 
[0m13:18:15.525448 [error] [MainThread]:   Database Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_customer.sql
[0m13:18:15.526614 [info ] [MainThread]: 
[0m13:18:15.527610 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=1 SKIP=0 TOTAL=4
[0m13:18:15.529653 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 6.280024, "process_in_blocks": "0", "process_kernel_time": 0.301807, "process_mem_max_rss": "227316", "process_out_blocks": "0", "process_user_time": 4.174999}
[0m13:18:15.531042 [debug] [MainThread]: Command `dbt run` failed at 13:18:15.530833 after 6.28 seconds
[0m13:18:15.532274 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1de371e510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1de339ff10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1de339fa10>]}
[0m13:18:15.533322 [debug] [MainThread]: Flushing usage events
[0m13:18:16.702574 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:18:36.511580 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd203fb0d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd20447e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd203faf90>]}


============================== 13:18:36.514423 | 04ea4408-25db-4cb9-a242-d365727bf5aa ==============================
[0m13:18:36.514423 [info ] [MainThread]: Running with dbt=1.9.0
[0m13:18:36.515799 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --select production_hailing_staging_customer', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m13:18:37.118026 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '04ea4408-25db-4cb9-a242-d365727bf5aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fccf25a8950>]}
[0m13:18:37.164382 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '04ea4408-25db-4cb9-a242-d365727bf5aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd2264e250>]}
[0m13:18:37.165828 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m13:18:37.240461 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m13:18:37.380530 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m13:18:37.381529 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m13:18:37.386926 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_project.staging
[0m13:18:37.415041 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '04ea4408-25db-4cb9-a242-d365727bf5aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fccf89ab690>]}
[0m13:18:37.548577 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m13:18:37.555947 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m13:18:37.571105 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '04ea4408-25db-4cb9-a242-d365727bf5aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fccf25899d0>]}
[0m13:18:37.572117 [info ] [MainThread]: Found 4 models, 8 sources, 488 macros
[0m13:18:37.573558 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '04ea4408-25db-4cb9-a242-d365727bf5aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fccf2580550>]}
[0m13:18:37.576317 [info ] [MainThread]: 
[0m13:18:37.577850 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m13:18:37.579128 [info ] [MainThread]: 
[0m13:18:37.580805 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m13:18:37.582875 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m13:18:37.583787 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:18:38.125972 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_staging)
[0m13:18:38.126762 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_source'
[0m13:18:38.127699 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:18:38.128752 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:18:38.665419 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '04ea4408-25db-4cb9-a242-d365727bf5aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fccf2391cd0>]}
[0m13:18:38.666698 [debug] [MainThread]: Opening a new connection, currently in state init
[0m13:18:38.673847 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m13:18:38.675504 [info ] [Thread-1 (]: 1 of 1 START sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_staging.production_hailing_staging_customer  [RUN]
[0m13:18:38.677060 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_staging, now model.hailing_project.production_hailing_staging_customer)
[0m13:18:38.678037 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m13:18:38.694982 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m13:18:38.703412 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m13:18:38.775952 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m13:18:38.784893 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source_rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    );
  
[0m13:18:38.786446 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:18:39.079955 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:724037aa-9a76-4ed8-ba4f-31e596e19122&page=queryresults
[0m13:18:39.081025 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:724037aa-9a76-4ed8-ba4f-31e596e19122&page=queryresults
[0m13:18:39.086770 [debug] [Thread-1 (]: Database Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_customer.sql
[0m13:18:39.089138 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '04ea4408-25db-4cb9-a242-d365727bf5aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fccf25fe790>]}
[0m13:18:39.090601 [error] [Thread-1 (]: 1 of 1 ERROR creating sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_staging.production_hailing_staging_customer  [[31mERROR[0m in 0.41s]
[0m13:18:39.092584 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m13:18:39.094222 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.production_hailing_staging_customer' to be skipped because of status 'error'.  Reason: Database Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_customer.sql.
[0m13:18:39.097431 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m13:18:39.100862 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:18:39.101808 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m13:18:39.102657 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_source' was properly closed.
[0m13:18:39.103674 [info ] [MainThread]: 
[0m13:18:39.104668 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 1.52 seconds (1.52s).
[0m13:18:39.106533 [debug] [MainThread]: Command end result
[0m13:18:39.144478 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m13:18:39.149528 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m13:18:39.159515 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m13:18:39.160535 [info ] [MainThread]: 
[0m13:18:39.162043 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m13:18:39.163380 [info ] [MainThread]: 
[0m13:18:39.164766 [error] [MainThread]:   Database Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_customer.sql
[0m13:18:39.166014 [info ] [MainThread]: 
[0m13:18:39.167132 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m13:18:39.169299 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 2.7154295, "process_in_blocks": "0", "process_kernel_time": 0.18182, "process_mem_max_rss": "216208", "process_out_blocks": "0", "process_user_time": 3.292972}
[0m13:18:39.170757 [debug] [MainThread]: Command `dbt run` failed at 13:18:39.170536 after 2.72 seconds
[0m13:18:39.171960 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd204472d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd209a0610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd20505b50>]}
[0m13:18:39.173070 [debug] [MainThread]: Flushing usage events
[0m13:18:40.210200 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:20:03.106688 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f85a13da910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f85a13daf10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f85a17d2390>]}


============================== 13:20:03.109393 | 33ab6204-76d1-47e7-a2eb-015985276d0c ==============================
[0m13:20:03.109393 [info ] [MainThread]: Running with dbt=1.9.0
[0m13:20:03.110598 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt run --select production_hailing_staging_customer', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m13:20:03.667820 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '33ab6204-76d1-47e7-a2eb-015985276d0c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f85736b3210>]}
[0m13:20:03.715076 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '33ab6204-76d1-47e7-a2eb-015985276d0c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f85a3688850>]}
[0m13:20:03.716764 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m13:20:03.785839 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m13:20:03.852772 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m13:20:03.854079 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '33ab6204-76d1-47e7-a2eb-015985276d0c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f85a1ad2a50>]}
[0m13:20:04.815046 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_project.staging
[0m13:20:04.831872 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '33ab6204-76d1-47e7-a2eb-015985276d0c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f857312cbd0>]}
[0m13:20:04.921506 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m13:20:04.928300 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m13:20:04.944693 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '33ab6204-76d1-47e7-a2eb-015985276d0c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8572f191d0>]}
[0m13:20:04.946412 [info ] [MainThread]: Found 4 models, 8 sources, 488 macros
[0m13:20:04.947673 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '33ab6204-76d1-47e7-a2eb-015985276d0c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f85731b9cd0>]}
[0m13:20:04.950352 [info ] [MainThread]: 
[0m13:20:04.951606 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m13:20:04.952712 [info ] [MainThread]: 
[0m13:20:04.954105 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m13:20:04.956284 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m13:20:04.957730 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:20:05.552532 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_staging)
[0m13:20:05.553973 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_source'
[0m13:20:05.555650 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:20:05.557119 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:20:06.106065 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '33ab6204-76d1-47e7-a2eb-015985276d0c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8572f33190>]}
[0m13:20:06.107787 [debug] [MainThread]: Opening a new connection, currently in state init
[0m13:20:06.115685 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m13:20:06.116950 [info ] [Thread-1 (]: 1 of 1 START sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_staging.production_hailing_staging_customer  [RUN]
[0m13:20:06.118233 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_staging, now model.hailing_project.production_hailing_staging_customer)
[0m13:20:06.119399 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m13:20:06.131026 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m13:20:06.139524 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m13:20:06.212713 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m13:20:06.220020 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source_rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    );
  
[0m13:20:06.221467 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:20:06.516893 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:5e2c42fc-2497-411c-ba3e-590bd46d8218&page=queryresults
[0m13:20:06.517944 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:5e2c42fc-2497-411c-ba3e-590bd46d8218&page=queryresults
[0m13:20:06.523249 [debug] [Thread-1 (]: Database Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_customer.sql
[0m13:20:06.525146 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '33ab6204-76d1-47e7-a2eb-015985276d0c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f85730b60d0>]}
[0m13:20:06.526354 [error] [Thread-1 (]: 1 of 1 ERROR creating sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_staging.production_hailing_staging_customer  [[31mERROR[0m in 0.41s]
[0m13:20:06.527445 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m13:20:06.529005 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.production_hailing_staging_customer' to be skipped because of status 'error'.  Reason: Database Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_customer.sql.
[0m13:20:06.531885 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m13:20:06.534889 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:20:06.535983 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m13:20:06.536933 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_source' was properly closed.
[0m13:20:06.537971 [info ] [MainThread]: 
[0m13:20:06.539068 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 1.58 seconds (1.58s).
[0m13:20:06.540712 [debug] [MainThread]: Command end result
[0m13:20:06.580584 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m13:20:06.585040 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m13:20:06.594274 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m13:20:06.595192 [info ] [MainThread]: 
[0m13:20:06.596327 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m13:20:06.597514 [info ] [MainThread]: 
[0m13:20:06.598963 [error] [MainThread]:   Database Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_customer.sql
[0m13:20:06.599879 [info ] [MainThread]: 
[0m13:20:06.600976 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m13:20:06.603651 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 3.555093, "process_in_blocks": "0", "process_kernel_time": 0.23179, "process_mem_max_rss": "221320", "process_out_blocks": "0", "process_user_time": 3.990819}
[0m13:20:06.605493 [debug] [MainThread]: Command `dbt run` failed at 13:20:06.605312 after 3.56 seconds
[0m13:20:06.606651 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f85a4cfca50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f85a4d8d310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f85a4d8d090>]}
[0m13:20:06.607911 [debug] [MainThread]: Flushing usage events
[0m13:20:07.908198 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:21:52.375956 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f35ffc8fd50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f35ffc8f850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3600036110>]}


============================== 13:21:52.378542 | b0c1bdd6-e923-4ad0-96ca-7d3fbfb43e0d ==============================
[0m13:21:52.378542 [info ] [MainThread]: Running with dbt=1.9.0
[0m13:21:52.379874 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt run --select production_hailing_staging_customer', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m13:21:52.976826 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b0c1bdd6-e923-4ad0-96ca-7d3fbfb43e0d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f35d2d7a310>]}
[0m13:21:53.031705 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b0c1bdd6-e923-4ad0-96ca-7d3fbfb43e0d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3601e99750>]}
[0m13:21:53.034182 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m13:21:53.106189 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m13:21:53.261028 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m13:21:53.262256 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/staging/production_hailing_staging_customer.sql
[0m13:21:53.534698 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_project.staging
[0m13:21:53.546949 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b0c1bdd6-e923-4ad0-96ca-7d3fbfb43e0d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f35d1f8e850>]}
[0m13:21:53.620568 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m13:21:53.628256 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m13:21:53.645167 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b0c1bdd6-e923-4ad0-96ca-7d3fbfb43e0d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f35d1a86010>]}
[0m13:21:53.646471 [info ] [MainThread]: Found 4 models, 8 sources, 488 macros
[0m13:21:53.647821 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b0c1bdd6-e923-4ad0-96ca-7d3fbfb43e0d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f35d1bf9050>]}
[0m13:21:53.650558 [info ] [MainThread]: 
[0m13:21:53.651815 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m13:21:53.652923 [info ] [MainThread]: 
[0m13:21:53.654416 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m13:21:53.656713 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m13:21:53.657987 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:21:54.687003 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m13:21:54.687897 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:21:54.918316 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b0c1bdd6-e923-4ad0-96ca-7d3fbfb43e0d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f35d1e91dd0>]}
[0m13:21:54.920559 [debug] [MainThread]: Opening a new connection, currently in state init
[0m13:21:54.925700 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m13:21:54.926719 [info ] [Thread-1 (]: 1 of 1 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [RUN]
[0m13:21:54.927783 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.production_hailing_staging_customer)
[0m13:21:54.928736 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m13:21:54.936416 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m13:21:54.942225 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m13:21:55.007441 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m13:21:55.014768 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    );
  
[0m13:21:55.016096 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:21:55.471181 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:efa6d99e-c855-406f-9d57-28ac167cdfad&page=queryresults
[0m13:21:57.417096 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b0c1bdd6-e923-4ad0-96ca-7d3fbfb43e0d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f35d1a875d0>]}
[0m13:21:57.418800 [info ] [Thread-1 (]: 1 of 1 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [[32mCREATE TABLE (85.0 rows, 5.8 KiB processed)[0m in 2.49s]
[0m13:21:57.420128 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m13:21:57.421971 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m13:21:57.425615 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:21:57.426606 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m13:21:57.427716 [info ] [MainThread]: 
[0m13:21:57.428966 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 3.77 seconds (3.77s).
[0m13:21:57.430813 [debug] [MainThread]: Command end result
[0m13:21:57.465006 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m13:21:57.469273 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m13:21:57.477248 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m13:21:57.477938 [info ] [MainThread]: 
[0m13:21:57.478926 [info ] [MainThread]: [32mCompleted successfully[0m
[0m13:21:57.480020 [info ] [MainThread]: 
[0m13:21:57.481124 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m13:21:57.482885 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 5.162988, "process_in_blocks": "0", "process_kernel_time": 0.128869, "process_mem_max_rss": "223124", "process_out_blocks": "0", "process_user_time": 3.558785}
[0m13:21:57.483807 [debug] [MainThread]: Command `dbt run` succeeded at 13:21:57.483699 after 5.16 seconds
[0m13:21:57.484842 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3603408cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f35c1b22bd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f360358c9d0>]}
[0m13:21:57.485865 [debug] [MainThread]: Flushing usage events
[0m13:21:58.622811 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:24:58.619842 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbb99da2b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbb99ea9c90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbb99df3690>]}


============================== 13:24:58.622800 | 4388e728-0f0d-471d-9e5c-e9af4a810ed9 ==============================
[0m13:24:58.622800 [info ] [MainThread]: Running with dbt=1.9.0
[0m13:24:58.624149 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'warn_error': 'None', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt clean', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m13:24:58.707148 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '4388e728-0f0d-471d-9e5c-e9af4a810ed9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbb99df6090>]}
[0m13:24:58.762513 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.19943619, "process_in_blocks": "0", "process_kernel_time": 0.119847, "process_mem_max_rss": "90060", "process_out_blocks": "0", "process_user_time": 0.988741}
[0m13:24:58.763735 [debug] [MainThread]: Command `dbt clean` succeeded at 13:24:58.763573 after 0.20 seconds
[0m13:24:58.764676 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbb99dd5c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbb9d590c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbb9a196090>]}
[0m13:24:58.765891 [debug] [MainThread]: Flushing usage events
[0m13:25:00.044199 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:25:01.216045 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe9b962ad90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe9ba30ba50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe9b965f910>]}


============================== 13:25:01.219314 | f3c424e0-5af2-4aff-be03-0bbe4245d811 ==============================
[0m13:25:01.219314 [info ] [MainThread]: Running with dbt=1.9.0
[0m13:25:01.220900 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt deps', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m13:25:01.302345 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f3c424e0-5af2-4aff-be03-0bbe4245d811', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe9b952e510>]}
[0m13:25:01.315481 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m13:25:01.318906 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m13:25:01.320701 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.15545255, "process_in_blocks": "0", "process_kernel_time": 0.069638, "process_mem_max_rss": "90104", "process_out_blocks": "0", "process_user_time": 1.034623}
[0m13:25:01.322161 [debug] [MainThread]: Command `dbt deps` succeeded at 13:25:01.322016 after 0.16 seconds
[0m13:25:01.323102 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe9b96738d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe9b94ba310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe9bcfa1010>]}
[0m13:25:01.324039 [debug] [MainThread]: Flushing usage events
[0m13:25:02.569701 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:25:15.994659 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3dc69d2c90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3dc69d2b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3dc69d2e10>]}


============================== 13:25:15.997386 | ec9afc33-20f9-48e5-a74c-7c1bd377728b ==============================
[0m13:25:15.997386 [info ] [MainThread]: Running with dbt=1.9.0
[0m13:25:15.999537 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt run --select production_hailing_staging_customer', 'send_anonymous_usage_stats': 'True'}
[0m13:25:16.584538 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ec9afc33-20f9-48e5-a74c-7c1bd377728b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d9cb7ae90>]}
[0m13:25:16.629962 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ec9afc33-20f9-48e5-a74c-7c1bd377728b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d9ccdf550>]}
[0m13:25:16.631086 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m13:25:16.700095 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m13:25:16.702159 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m13:25:16.703229 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'ec9afc33-20f9-48e5-a74c-7c1bd377728b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d9d7f3150>]}
[0m13:25:17.745963 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_project.staging
[0m13:25:17.759955 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ec9afc33-20f9-48e5-a74c-7c1bd377728b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d9cb8b890>]}
[0m13:25:17.837093 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m13:25:17.843893 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m13:25:17.860759 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ec9afc33-20f9-48e5-a74c-7c1bd377728b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d9c5af350>]}
[0m13:25:17.862182 [info ] [MainThread]: Found 4 models, 8 sources, 488 macros
[0m13:25:17.863290 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ec9afc33-20f9-48e5-a74c-7c1bd377728b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d9c7c0d10>]}
[0m13:25:17.865834 [info ] [MainThread]: 
[0m13:25:17.867163 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m13:25:17.868273 [info ] [MainThread]: 
[0m13:25:17.870064 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m13:25:17.873291 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m13:25:17.874321 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:25:18.467030 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_staging)
[0m13:25:18.468004 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:25:18.957214 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ec9afc33-20f9-48e5-a74c-7c1bd377728b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d9c8a8410>]}
[0m13:25:18.958335 [debug] [MainThread]: Opening a new connection, currently in state init
[0m13:25:18.963463 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m13:25:18.964619 [info ] [Thread-1 (]: 1 of 1 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [RUN]
[0m13:25:18.966410 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_staging, now model.hailing_project.production_hailing_staging_customer)
[0m13:25:18.967393 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m13:25:18.976168 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m13:25:18.988797 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m13:25:19.054443 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m13:25:19.072342 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    );
  
[0m13:25:19.074293 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:25:19.440535 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:92b935d8-1a63-4911-ae53-31c4cfef5d6d&page=queryresults
[0m13:25:19.441925 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:92b935d8-1a63-4911-ae53-31c4cfef5d6d&page=queryresults
[0m13:25:19.447439 [debug] [Thread-1 (]: Database Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_customer.sql
[0m13:25:19.449621 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ec9afc33-20f9-48e5-a74c-7c1bd377728b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d9c623010>]}
[0m13:25:19.450932 [error] [Thread-1 (]: 1 of 1 ERROR creating sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [[31mERROR[0m in 0.48s]
[0m13:25:19.452766 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m13:25:19.454342 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.production_hailing_staging_customer' to be skipped because of status 'error'.  Reason: Database Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_customer.sql.
[0m13:25:19.457303 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m13:25:19.460621 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:25:19.461522 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m13:25:19.462900 [info ] [MainThread]: 
[0m13:25:19.464068 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 1.59 seconds (1.59s).
[0m13:25:19.465633 [debug] [MainThread]: Command end result
[0m13:25:19.499885 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m13:25:19.504194 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m13:25:19.513237 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m13:25:19.514020 [info ] [MainThread]: 
[0m13:25:19.515229 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m13:25:19.516671 [info ] [MainThread]: 
[0m13:25:19.517998 [error] [MainThread]:   Database Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_customer.sql
[0m13:25:19.519000 [info ] [MainThread]: 
[0m13:25:19.520219 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m13:25:19.522197 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 3.5749357, "process_in_blocks": "0", "process_kernel_time": 0.243853, "process_mem_max_rss": "219532", "process_out_blocks": "0", "process_user_time": 4.023579}
[0m13:25:19.523343 [debug] [MainThread]: Command `dbt run` failed at 13:25:19.523212 after 3.58 seconds
[0m13:25:19.524347 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3dc6a4ff50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3dc6a4fa50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3dca34d210>]}
[0m13:25:19.525814 [debug] [MainThread]: Flushing usage events
[0m13:25:20.606022 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:26:59.008725 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7b7572f150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7b7572ef50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7b7572f290>]}


============================== 13:26:59.011526 | 772cb824-f634-4804-8cca-be6ca583e19d ==============================
[0m13:26:59.011526 [info ] [MainThread]: Running with dbt=1.9.0
[0m13:26:59.013050 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'warn_error': 'None', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'invocation_command': 'dbt run --select production_hailing_staging_customer', 'send_anonymous_usage_stats': 'True'}
[0m13:26:59.566218 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '772cb824-f634-4804-8cca-be6ca583e19d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7b4781f590>]}
[0m13:26:59.617539 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '772cb824-f634-4804-8cca-be6ca583e19d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7b779a2010>]}
[0m13:26:59.618995 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m13:26:59.694603 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m13:26:59.824112 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m13:26:59.825152 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m13:26:59.830204 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_project.staging
[0m13:26:59.855725 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '772cb824-f634-4804-8cca-be6ca583e19d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7b4dcca990>]}
[0m13:26:59.972972 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m13:26:59.978550 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m13:26:59.992563 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '772cb824-f634-4804-8cca-be6ca583e19d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7b4d01d390>]}
[0m13:26:59.993565 [info ] [MainThread]: Found 4 models, 8 sources, 488 macros
[0m13:26:59.994562 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '772cb824-f634-4804-8cca-be6ca583e19d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7b479fc150>]}
[0m13:26:59.997066 [info ] [MainThread]: 
[0m13:26:59.998438 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m13:26:59.999649 [info ] [MainThread]: 
[0m13:27:00.001111 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m13:27:00.003961 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m13:27:00.005276 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:27:00.621443 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_staging)
[0m13:27:00.623102 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:27:00.905838 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '772cb824-f634-4804-8cca-be6ca583e19d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7b4752fc10>]}
[0m13:27:00.907199 [debug] [MainThread]: Opening a new connection, currently in state init
[0m13:27:00.911996 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m13:27:00.913149 [info ] [Thread-1 (]: 1 of 1 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [RUN]
[0m13:27:00.914728 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_staging, now model.hailing_project.production_hailing_staging_customer)
[0m13:27:00.915627 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m13:27:00.929121 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m13:27:00.938152 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m13:27:00.999666 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m13:27:01.005908 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    );
  
[0m13:27:01.007009 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:27:01.671168 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:ce5173bd-ad03-4cb0-ab94-6ea5d94af2ec&page=queryresults
[0m13:27:03.835109 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '772cb824-f634-4804-8cca-be6ca583e19d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7b476881d0>]}
[0m13:27:03.836333 [info ] [Thread-1 (]: 1 of 1 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [[32mCREATE TABLE (85.0 rows, 5.8 KiB processed)[0m in 2.92s]
[0m13:27:03.837934 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m13:27:03.840315 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m13:27:03.843017 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:27:03.843981 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m13:27:03.845151 [info ] [MainThread]: 
[0m13:27:03.846149 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 3.84 seconds (3.84s).
[0m13:27:03.847826 [debug] [MainThread]: Command end result
[0m13:27:03.887706 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m13:27:03.892416 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m13:27:03.901233 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m13:27:03.901978 [info ] [MainThread]: 
[0m13:27:03.903118 [info ] [MainThread]: [32mCompleted successfully[0m
[0m13:27:03.904143 [info ] [MainThread]: 
[0m13:27:03.905433 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m13:27:03.907830 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 4.9503984, "process_in_blocks": "0", "process_kernel_time": 0.212752, "process_mem_max_rss": "219764", "process_out_blocks": "0", "process_user_time": 3.089977}
[0m13:27:03.909026 [debug] [MainThread]: Command `dbt run` succeeded at 13:27:03.908895 after 4.95 seconds
[0m13:27:03.909815 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7b75b26710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7b79014a50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7b78f48bd0>]}
[0m13:27:03.910703 [debug] [MainThread]: Flushing usage events
[0m13:27:05.056599 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:54:50.255905 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb62f4dee10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb6301bf690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb62f8d6110>]}


============================== 13:54:50.258916 | dde81cc7-4e54-401d-8918-ba886b5d4763 ==============================
[0m13:54:50.258916 [info ] [MainThread]: Running with dbt=1.9.0
[0m13:54:50.260006 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m13:54:50.869604 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'dde81cc7-4e54-401d-8918-ba886b5d4763', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb601681790>]}
[0m13:54:50.918630 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'dde81cc7-4e54-401d-8918-ba886b5d4763', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb601832c50>]}
[0m13:54:50.920320 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m13:54:50.984634 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m13:54:51.163290 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m13:54:51.165614 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m13:54:51.170573 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_project.staging
[0m13:54:51.195285 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'dde81cc7-4e54-401d-8918-ba886b5d4763', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb601515310>]}
[0m13:54:51.313021 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m13:54:51.318427 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m13:54:51.335786 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'dde81cc7-4e54-401d-8918-ba886b5d4763', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb60168b5d0>]}
[0m13:54:51.336835 [info ] [MainThread]: Found 4 models, 8 sources, 488 macros
[0m13:54:51.338251 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'dde81cc7-4e54-401d-8918-ba886b5d4763', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb6014c1550>]}
[0m13:54:51.340893 [info ] [MainThread]: 
[0m13:54:51.342141 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m13:54:51.343216 [info ] [MainThread]: 
[0m13:54:51.344840 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m13:54:51.349561 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m13:54:51.350594 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:54:52.012706 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_staging)
[0m13:54:52.013786 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:54:52.243500 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'dde81cc7-4e54-401d-8918-ba886b5d4763', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb60e2cd310>]}
[0m13:54:52.246330 [debug] [MainThread]: Opening a new connection, currently in state init
[0m13:54:52.252221 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m13:54:52.252907 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m13:54:52.253394 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m13:54:52.253746 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m13:54:52.254676 [info ] [Thread-1 (]: 1 of 4 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [RUN]
[0m13:54:52.255835 [info ] [Thread-2 (]: 2 of 4 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [RUN]
[0m13:54:52.257159 [info ] [Thread-3 (]: 3 of 4 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [RUN]
[0m13:54:52.258514 [info ] [Thread-4 (]: 4 of 4 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [RUN]
[0m13:54:52.259959 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_staging, now model.hailing_project.production_hailing_staging_customer)
[0m13:54:52.261268 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m13:54:52.262295 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m13:54:52.263312 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_vehicle'
[0m13:54:52.264026 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m13:54:52.265263 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m13:54:52.266182 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m13:54:52.266923 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m13:54:52.282445 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m13:54:52.286935 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m13:54:52.291915 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m13:54:52.296615 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m13:54:52.302819 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m13:54:52.305112 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m13:54:52.312352 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m13:54:52.318400 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m13:54:52.382823 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:54:52.427351 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m13:54:52.425385 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m13:54:52.430405 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m13:54:52.458271 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    );
  
[0m13:54:52.459976 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m13:54:52.460427 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    );
  
[0m13:54:52.462458 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    );
  
[0m13:54:52.463081 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m13:54:52.465304 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m13:54:52.690311 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m13:54:52.696681 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m13:54:52.888587 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:0adc48c6-d4d2-46b7-b3f1-0e37fc1b1425&page=queryresults
[0m13:54:52.892619 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:d04fd668-dc05-4028-8fd5-f8b7bf1ec648&page=queryresults
[0m13:54:53.044576 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:33593c9a-be8a-4b37-ad73-4eacc0def65d&page=queryresults
[0m13:54:53.096117 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:505ce8f2-9600-4f47-855f-6a2f49504828&page=queryresults
[0m13:54:54.614677 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dde81cc7-4e54-401d-8918-ba886b5d4763', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb5f9500d50>]}
[0m13:54:54.615745 [info ] [Thread-1 (]: 1 of 4 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.35s]
[0m13:54:54.617416 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m13:54:54.689170 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dde81cc7-4e54-401d-8918-ba886b5d4763', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb601830d50>]}
[0m13:54:54.690463 [info ] [Thread-3 (]: 3 of 4 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [[32mCREATE TABLE (85.0 rows, 7.6 KiB processed)[0m in 2.43s]
[0m13:54:54.691678 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m13:54:54.915896 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dde81cc7-4e54-401d-8918-ba886b5d4763', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb60129d590>]}
[0m13:54:54.917199 [info ] [Thread-2 (]: 2 of 4 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [[32mCREATE TABLE (85.0 rows, 5.8 KiB processed)[0m in 2.65s]
[0m13:54:54.919051 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m13:54:55.109216 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dde81cc7-4e54-401d-8918-ba886b5d4763', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb601479a10>]}
[0m13:54:55.110821 [info ] [Thread-4 (]: 4 of 4 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [[32mCREATE TABLE (85.0 rows, 4.7 KiB processed)[0m in 2.85s]
[0m13:54:55.112372 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m13:54:55.115083 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m13:54:55.119577 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:54:55.120440 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m13:54:55.121098 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m13:54:55.121700 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m13:54:55.122515 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m13:54:55.123390 [info ] [MainThread]: 
[0m13:54:55.124445 [info ] [MainThread]: Finished running 4 incremental models in 0 hours 0 minutes and 3.78 seconds (3.78s).
[0m13:54:55.126731 [debug] [MainThread]: Command end result
[0m13:54:55.172366 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m13:54:55.177986 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m13:54:55.192154 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m13:54:55.192938 [info ] [MainThread]: 
[0m13:54:55.194050 [info ] [MainThread]: [32mCompleted successfully[0m
[0m13:54:55.195230 [info ] [MainThread]: 
[0m13:54:55.196174 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m13:54:55.197696 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 5.0081086, "process_in_blocks": "0", "process_kernel_time": 0.340253, "process_mem_max_rss": "223988", "process_out_blocks": "0", "process_user_time": 3.382524}
[0m13:54:55.198676 [debug] [MainThread]: Command `dbt run` succeeded at 13:54:55.198558 after 5.01 seconds
[0m13:54:55.199491 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb632e2d390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb632e2d110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb632e2d290>]}
[0m13:54:55.200227 [debug] [MainThread]: Flushing usage events
[0m13:54:56.653405 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:03:44.754148 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1f7712be90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1f774da110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1f770de210>]}


============================== 14:03:44.757626 | 998797d1-caa4-4baf-93ac-f135b54deab4 ==============================
[0m14:03:44.757626 [info ] [MainThread]: Running with dbt=1.9.0
[0m14:03:44.758680 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt debug', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m14:03:44.765801 [info ] [MainThread]: dbt version: 1.9.0
[0m14:03:44.766642 [info ] [MainThread]: python version: 3.11.2
[0m14:03:44.767844 [info ] [MainThread]: python path: /usr/local/bin/python
[0m14:03:44.769023 [info ] [MainThread]: os info: Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.31
[0m14:03:45.283825 [info ] [MainThread]: Using profiles dir at /usr/app/dbt_project
[0m14:03:45.285019 [info ] [MainThread]: Using profiles.yml file at /usr/app/dbt_project/profiles.yml
[0m14:03:45.286065 [info ] [MainThread]: Using dbt_project.yml file at /usr/app/dbt_project/dbt_project.yml
[0m14:03:45.287981 [error] [MainThread]: Encountered an error:
Internal Error
  Profile should not be None if loading profile completed
[0m14:03:45.290202 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": false, "command_wall_clock_time": 0.5915002, "process_in_blocks": "0", "process_kernel_time": 0.118833, "process_mem_max_rss": "204716", "process_out_blocks": "0", "process_user_time": 2.624243}
[0m14:03:45.291679 [debug] [MainThread]: Command `dbt debug` failed at 14:03:45.291528 after 0.59 seconds
[0m14:03:45.292976 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1f4988af10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1f4a48a3d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1f49a58f90>]}
[0m14:03:45.294072 [debug] [MainThread]: Flushing usage events
[0m14:03:46.416460 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:04:03.621246 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f79be5f2450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f79be5f3590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f79be5f2610>]}


============================== 14:04:03.624595 | 53330be2-2b71-4fd9-b3ab-1f57917e1cfc ==============================
[0m14:04:03.624595 [info ] [MainThread]: Running with dbt=1.9.0
[0m14:04:03.625925 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt clean', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m14:04:03.716898 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '53330be2-2b71-4fd9-b3ab-1f57917e1cfc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f79be5f0f50>]}
[0m14:04:03.770990 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.2020723, "process_in_blocks": "0", "process_kernel_time": 0.059387, "process_mem_max_rss": "90132", "process_out_blocks": "0", "process_user_time": 1.138268}
[0m14:04:03.772290 [debug] [MainThread]: Command `dbt clean` succeeded at 14:04:03.772092 after 0.20 seconds
[0m14:04:03.773259 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f79be646a50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f79be646350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f79c1e10b90>]}
[0m14:04:03.774280 [debug] [MainThread]: Flushing usage events
[0m14:04:04.833132 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:04:06.076006 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f081fb9ba50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f081ff9a110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f081fb9b550>]}


============================== 14:04:06.078941 | 09da480d-60cf-4123-ae30-f8b41c1c5d59 ==============================
[0m14:04:06.078941 [info ] [MainThread]: Running with dbt=1.9.0
[0m14:04:06.080228 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt deps', 'send_anonymous_usage_stats': 'True'}
[0m14:04:06.166402 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '09da480d-60cf-4123-ae30-f8b41c1c5d59', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f081fad6950>]}
[0m14:04:06.176491 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m14:04:06.179142 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m14:04:06.180934 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.15953642, "process_in_blocks": "0", "process_kernel_time": 0.050109, "process_mem_max_rss": "90248", "process_out_blocks": "0", "process_user_time": 1.102411}
[0m14:04:06.182052 [debug] [MainThread]: Command `dbt deps` succeeded at 14:04:06.181912 after 0.16 seconds
[0m14:04:06.182765 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0823394b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0823519290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0823519250>]}
[0m14:04:06.183548 [debug] [MainThread]: Flushing usage events
[0m14:04:07.211759 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:04:10.113722 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f183316e610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f18331bf610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f18331bffd0>]}


============================== 14:04:10.116618 | 31f492ea-3657-4f5c-9241-fba033c3866a ==============================
[0m14:04:10.116618 [info ] [MainThread]: Running with dbt=1.9.0
[0m14:04:10.118609 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'invocation_command': 'dbt debug', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m14:04:10.126108 [info ] [MainThread]: dbt version: 1.9.0
[0m14:04:10.127419 [info ] [MainThread]: python version: 3.11.2
[0m14:04:10.128733 [info ] [MainThread]: python path: /usr/local/bin/python
[0m14:04:10.129809 [info ] [MainThread]: os info: Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.31
[0m14:04:10.675577 [info ] [MainThread]: Using profiles dir at /usr/app/dbt_project
[0m14:04:10.676745 [info ] [MainThread]: Using profiles.yml file at /usr/app/dbt_project/profiles.yml
[0m14:04:10.677800 [info ] [MainThread]: Using dbt_project.yml file at /usr/app/dbt_project/dbt_project.yml
[0m14:04:10.678666 [info ] [MainThread]: adapter type: bigquery
[0m14:04:10.679527 [info ] [MainThread]: adapter version: 1.9.0
[0m14:04:10.761024 [info ] [MainThread]: Configuration:
[0m14:04:10.762134 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m14:04:10.763999 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m14:04:10.765107 [info ] [MainThread]: Required dependencies:
[0m14:04:10.766194 [debug] [MainThread]: Executing "git --help"
[0m14:04:10.768538 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m14:04:10.769452 [debug] [MainThread]: STDERR: "b''"
[0m14:04:10.770195 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m14:04:10.771104 [info ] [MainThread]: Connection:
[0m14:04:10.772367 [info ] [MainThread]:   method: service-account
[0m14:04:10.773469 [info ] [MainThread]:   database: purwadika
[0m14:04:10.774719 [info ] [MainThread]:   execution_project: purwadika
[0m14:04:10.776061 [info ] [MainThread]:   schema: rizky_dwh_hailing_staging
[0m14:04:10.777085 [info ] [MainThread]:   location: None
[0m14:04:10.778245 [info ] [MainThread]:   priority: None
[0m14:04:10.779420 [info ] [MainThread]:   maximum_bytes_billed: None
[0m14:04:10.780401 [info ] [MainThread]:   impersonate_service_account: None
[0m14:04:10.781574 [info ] [MainThread]:   job_retry_deadline_seconds: None
[0m14:04:10.782515 [info ] [MainThread]:   job_retries: 1
[0m14:04:10.783336 [info ] [MainThread]:   job_creation_timeout_seconds: None
[0m14:04:10.784190 [info ] [MainThread]:   job_execution_timeout_seconds: None
[0m14:04:10.785373 [info ] [MainThread]:   timeout_seconds: None
[0m14:04:10.786360 [info ] [MainThread]:   client_id: None
[0m14:04:10.787392 [info ] [MainThread]:   token_uri: None
[0m14:04:10.788398 [info ] [MainThread]:   dataproc_region: None
[0m14:04:10.789284 [info ] [MainThread]:   dataproc_cluster_name: None
[0m14:04:10.790191 [info ] [MainThread]:   gcs_bucket: None
[0m14:04:10.791078 [info ] [MainThread]:   dataproc_batch: None
[0m14:04:10.792286 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m14:04:10.853854 [debug] [MainThread]: Acquiring new bigquery connection 'debug'
[0m14:04:10.855028 [debug] [MainThread]: On debug: select 1 as id
[0m14:04:10.856016 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:04:11.555173 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:67a4a5cd-aad4-4aa3-94a9-193502ff120e&page=queryresults
[0m14:04:12.258679 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m14:04:12.260366 [info ] [MainThread]: [32mAll checks passed![0m
[0m14:04:12.262060 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": true, "command_wall_clock_time": 2.2002223, "process_in_blocks": "0", "process_kernel_time": 0.196612, "process_mem_max_rss": "214536", "process_out_blocks": "0", "process_user_time": 2.783617}
[0m14:04:12.263167 [debug] [MainThread]: Command `dbt debug` succeeded at 14:04:12.263051 after 2.20 seconds
[0m14:04:12.264296 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m14:04:12.265190 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f18331c5190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f18331c4510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1805360f90>]}
[0m14:04:12.266060 [debug] [MainThread]: Flushing usage events
[0m14:04:13.334154 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:06:10.430779 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4d1de3a10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4d1de7e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4d1de3810>]}


============================== 14:06:10.433530 | 990edc3b-c853-4c58-9e99-9d80e2109395 ==============================
[0m14:06:10.433530 [info ] [MainThread]: Running with dbt=1.9.0
[0m14:06:10.434951 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt run --select dim_customer', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m14:06:11.028688 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '990edc3b-c853-4c58-9e99-9d80e2109395', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4a9ac6390>]}
[0m14:06:11.076154 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '990edc3b-c853-4c58-9e99-9d80e2109395', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4d4030e10>]}
[0m14:06:11.077636 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m14:06:11.145870 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m14:06:11.148101 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m14:06:11.149073 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '990edc3b-c853-4c58-9e99-9d80e2109395', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4a8bfead0>]}
[0m14:06:12.241094 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.staging
- models.dbt_project.facts
[0m14:06:12.254288 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '990edc3b-c853-4c58-9e99-9d80e2109395', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4a3c436d0>]}
[0m14:06:12.334517 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m14:06:12.343611 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m14:06:12.363695 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '990edc3b-c853-4c58-9e99-9d80e2109395', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4a3955a10>]}
[0m14:06:12.365179 [info ] [MainThread]: Found 5 models, 8 sources, 488 macros
[0m14:06:12.366575 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '990edc3b-c853-4c58-9e99-9d80e2109395', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4a3a1c050>]}
[0m14:06:12.369732 [info ] [MainThread]: 
[0m14:06:12.371259 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m14:06:12.372508 [info ] [MainThread]: 
[0m14:06:12.374027 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m14:06:12.376163 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m14:06:12.377645 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:06:14.013618 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_staging)
[0m14:06:14.014536 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:06:14.304146 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '990edc3b-c853-4c58-9e99-9d80e2109395', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4a3a170d0>]}
[0m14:06:14.305200 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:06:14.310370 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m14:06:14.311589 [info ] [Thread-1 (]: 1 of 1 START sql incremental model rizky_dwh_hailing_staging.dim_customer ...... [RUN]
[0m14:06:14.313201 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_staging, now model.hailing_project.dim_customer)
[0m14:06:14.314169 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m14:06:14.322578 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m14:06:14.337217 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m14:06:14.396859 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m14:06:14.410379 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_staging`.`dim_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    );
  
[0m14:06:14.411659 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:06:14.890413 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:de0ef1e4-1b53-4b35-a70e-c9728a594e59&page=queryresults
[0m14:06:16.920227 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '990edc3b-c853-4c58-9e99-9d80e2109395', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4a39b2690>]}
[0m14:06:16.922020 [info ] [Thread-1 (]: 1 of 1 OK created sql incremental model rizky_dwh_hailing_staging.dim_customer . [[32mCREATE TABLE (85.0 rows, 5.7 KiB processed)[0m in 2.61s]
[0m14:06:16.923895 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m14:06:16.926664 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:06:16.929954 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:06:16.930864 [debug] [MainThread]: Connection 'model.hailing_project.dim_customer' was properly closed.
[0m14:06:16.931794 [info ] [MainThread]: 
[0m14:06:16.932884 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 4.56 seconds (4.56s).
[0m14:06:16.934825 [debug] [MainThread]: Command end result
[0m14:06:16.973219 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m14:06:16.977673 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m14:06:16.986841 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m14:06:16.987655 [info ] [MainThread]: 
[0m14:06:16.989328 [info ] [MainThread]: [32mCompleted successfully[0m
[0m14:06:16.990642 [info ] [MainThread]: 
[0m14:06:16.991902 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m14:06:16.993619 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 6.616357, "process_in_blocks": "0", "process_kernel_time": 0.230728, "process_mem_max_rss": "223072", "process_out_blocks": "0", "process_user_time": 4.012675}
[0m14:06:16.994731 [debug] [MainThread]: Command `dbt run` succeeded at 14:06:16.994602 after 6.62 seconds
[0m14:06:16.995963 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4d55d0e10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4d572d490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4d572d710>]}
[0m14:06:16.996866 [debug] [MainThread]: Flushing usage events
[0m14:06:18.905618 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:13:10.558763 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7ff5297910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7ff539dc90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7ff5296e50>]}


============================== 14:13:10.561754 | ab91b90e-be4d-4b1d-8048-2f4ea986bd24 ==============================
[0m14:13:10.561754 [info ] [MainThread]: Running with dbt=1.9.0
[0m14:13:10.562949 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt debug', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m14:13:10.585508 [info ] [MainThread]: dbt version: 1.9.0
[0m14:13:10.586438 [info ] [MainThread]: python version: 3.11.2
[0m14:13:10.587614 [info ] [MainThread]: python path: /usr/local/bin/python
[0m14:13:10.588936 [info ] [MainThread]: os info: Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.31
[0m14:13:11.115417 [info ] [MainThread]: Using profiles dir at /usr/app/dbt_project
[0m14:13:11.116920 [info ] [MainThread]: Using profiles.yml file at /usr/app/dbt_project/profiles.yml
[0m14:13:11.118209 [info ] [MainThread]: Using dbt_project.yml file at /usr/app/dbt_project/dbt_project.yml
[0m14:13:11.119774 [info ] [MainThread]: adapter type: bigquery
[0m14:13:11.121179 [info ] [MainThread]: adapter version: 1.9.0
[0m14:13:11.200435 [info ] [MainThread]: Configuration:
[0m14:13:11.201622 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m14:13:11.202815 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m14:13:11.204216 [info ] [MainThread]: Required dependencies:
[0m14:13:11.205637 [debug] [MainThread]: Executing "git --help"
[0m14:13:11.208228 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m14:13:11.209338 [debug] [MainThread]: STDERR: "b''"
[0m14:13:11.210191 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m14:13:11.211179 [info ] [MainThread]: Connection:
[0m14:13:11.212506 [info ] [MainThread]:   method: service-account
[0m14:13:11.213583 [info ] [MainThread]:   database: purwadika
[0m14:13:11.214643 [info ] [MainThread]:   execution_project: purwadika
[0m14:13:11.215725 [info ] [MainThread]:   schema: rizky_dwh_hailing_staging
[0m14:13:11.216762 [info ] [MainThread]:   location: None
[0m14:13:11.217903 [info ] [MainThread]:   priority: None
[0m14:13:11.218963 [info ] [MainThread]:   maximum_bytes_billed: None
[0m14:13:11.220594 [info ] [MainThread]:   impersonate_service_account: None
[0m14:13:11.222055 [info ] [MainThread]:   job_retry_deadline_seconds: None
[0m14:13:11.223425 [info ] [MainThread]:   job_retries: 1
[0m14:13:11.224673 [info ] [MainThread]:   job_creation_timeout_seconds: None
[0m14:13:11.225873 [info ] [MainThread]:   job_execution_timeout_seconds: None
[0m14:13:11.227110 [info ] [MainThread]:   timeout_seconds: None
[0m14:13:11.228412 [info ] [MainThread]:   client_id: None
[0m14:13:11.229999 [info ] [MainThread]:   token_uri: None
[0m14:13:11.231185 [info ] [MainThread]:   dataproc_region: None
[0m14:13:11.232362 [info ] [MainThread]:   dataproc_cluster_name: None
[0m14:13:11.233565 [info ] [MainThread]:   gcs_bucket: None
[0m14:13:11.235824 [info ] [MainThread]:   dataproc_batch: None
[0m14:13:11.237387 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m14:13:11.302183 [debug] [MainThread]: Acquiring new bigquery connection 'debug'
[0m14:13:11.303166 [debug] [MainThread]: On debug: select 1 as id
[0m14:13:11.303812 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:13:12.026184 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:71981590-2bbc-48cb-8f69-83307cdbc353&page=queryresults
[0m14:13:12.760155 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m14:13:12.762535 [info ] [MainThread]: [32mAll checks passed![0m
[0m14:13:12.765976 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": true, "command_wall_clock_time": 2.2612748, "process_in_blocks": "0", "process_kernel_time": 0.331915, "process_mem_max_rss": "213060", "process_out_blocks": "24", "process_user_time": 2.615088}
[0m14:13:12.767553 [debug] [MainThread]: Command `dbt debug` succeeded at 14:13:12.767406 after 2.26 seconds
[0m14:13:12.768641 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m14:13:12.769837 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7fc72bf590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7fc73efc50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7ff568a1d0>]}
[0m14:13:12.770892 [debug] [MainThread]: Flushing usage events
[0m14:13:14.103131 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:15:24.714527 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fef474e6450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fef474e4190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fef474e7410>]}


============================== 14:15:24.717663 | 89cf1819-3008-4c48-9e53-948c54b82096 ==============================
[0m14:15:24.717663 [info ] [MainThread]: Running with dbt=1.9.0
[0m14:15:24.719175 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt debug', 'send_anonymous_usage_stats': 'True'}
[0m14:15:24.726887 [info ] [MainThread]: dbt version: 1.9.0
[0m14:15:24.728129 [info ] [MainThread]: python version: 3.11.2
[0m14:15:24.729618 [info ] [MainThread]: python path: /usr/local/bin/python
[0m14:15:24.730910 [info ] [MainThread]: os info: Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.31
[0m14:15:24.742067 [info ] [MainThread]: target not specified in profile 'hailing_project', using 'default'
[0m14:15:24.743604 [info ] [MainThread]: Using profiles dir at /usr/app/dbt_project
[0m14:15:24.744792 [info ] [MainThread]: Using profiles.yml file at /usr/app/dbt_project/profiles.yml
[0m14:15:24.745895 [info ] [MainThread]: Using dbt_project.yml file at /usr/app/dbt_project/dbt_project.yml
[0m14:15:24.833783 [info ] [MainThread]: Configuration:
[0m14:15:24.834811 [info ] [MainThread]:   profiles.yml file [[31mERROR invalid[0m]
[0m14:15:24.835959 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m14:15:24.836918 [info ] [MainThread]: Required dependencies:
[0m14:15:24.838019 [debug] [MainThread]: Executing "git --help"
[0m14:15:24.840544 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m14:15:24.841567 [debug] [MainThread]: STDERR: "b''"
[0m14:15:24.842505 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m14:15:24.843463 [info ] [MainThread]: Connection test skipped since no profile was found
[0m14:15:24.845028 [info ] [MainThread]: [31m1 check failed:[0m
[0m14:15:24.846680 [info ] [MainThread]: Profile loading failed for the following reason:
Runtime Error
  The profile 'hailing_project' does not have a target named 'default'. The valid target names for this profile are:
   - source_data
   - staging_data


[0m14:15:24.849427 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": false, "command_wall_clock_time": 0.19467512, "process_in_blocks": "0", "process_kernel_time": 0.079991, "process_mem_max_rss": "90508", "process_out_blocks": "0", "process_user_time": 1.079891}
[0m14:15:24.850830 [debug] [MainThread]: Command `dbt debug` failed at 14:15:24.850672 after 0.20 seconds
[0m14:15:24.851953 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fef475121d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fef4ae99210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fef4ae99150>]}
[0m14:15:24.853103 [debug] [MainThread]: Flushing usage events
[0m14:15:26.208393 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:16:16.244148 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f34b8543b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f34b84f6d50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f34b84f6e50>]}


============================== 14:16:16.247476 | 5276e3cf-e951-4c37-a3fc-aa961ee047f9 ==============================
[0m14:16:16.247476 [info ] [MainThread]: Running with dbt=1.9.0
[0m14:16:16.248646 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt debug', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m14:16:16.257558 [info ] [MainThread]: dbt version: 1.9.0
[0m14:16:16.258682 [info ] [MainThread]: python version: 3.11.2
[0m14:16:16.260112 [info ] [MainThread]: python path: /usr/local/bin/python
[0m14:16:16.261656 [info ] [MainThread]: os info: Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.31
[0m14:16:16.272771 [info ] [MainThread]: target not specified in profile 'hailing_project', using 'default'
[0m14:16:16.273829 [info ] [MainThread]: Using profiles dir at /usr/app/dbt_project
[0m14:16:16.274880 [info ] [MainThread]: Using profiles.yml file at /usr/app/dbt_project/profiles.yml
[0m14:16:16.276120 [info ] [MainThread]: Using dbt_project.yml file at /usr/app/dbt_project/dbt_project.yml
[0m14:16:16.362925 [info ] [MainThread]: Configuration:
[0m14:16:16.364157 [info ] [MainThread]:   profiles.yml file [[31mERROR invalid[0m]
[0m14:16:16.365511 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m14:16:16.366673 [info ] [MainThread]: Required dependencies:
[0m14:16:16.367750 [debug] [MainThread]: Executing "git --help"
[0m14:16:16.369949 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m14:16:16.370778 [debug] [MainThread]: STDERR: "b''"
[0m14:16:16.371657 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m14:16:16.372805 [info ] [MainThread]: Connection test skipped since no profile was found
[0m14:16:16.373973 [info ] [MainThread]: [31m1 check failed:[0m
[0m14:16:16.375268 [info ] [MainThread]: Profile loading failed for the following reason:
Runtime Error
  The profile 'hailing_project' does not have a target named 'default'. The valid target names for this profile are:
   - source_data
   - staging_data


[0m14:16:16.377004 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": false, "command_wall_clock_time": 0.18434772, "process_in_blocks": "0", "process_kernel_time": 0.148561, "process_mem_max_rss": "90508", "process_out_blocks": "0", "process_user_time": 1.039932}
[0m14:16:16.378175 [debug] [MainThread]: Command `dbt debug` failed at 14:16:16.378053 after 0.19 seconds
[0m14:16:16.379188 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f34b849aa10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f34bbead210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f34bbead150>]}
[0m14:16:16.380649 [debug] [MainThread]: Flushing usage events
[0m14:16:17.868058 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:16:44.864849 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2e3e2d2850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2e3e2d3450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2e3e2d2d90>]}


============================== 14:16:44.867575 | 01289af6-0bdf-462b-85ab-5a7f5f93bb20 ==============================
[0m14:16:44.867575 [info ] [MainThread]: Running with dbt=1.9.0
[0m14:16:44.870114 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt debug', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m14:16:44.877834 [info ] [MainThread]: dbt version: 1.9.0
[0m14:16:44.879646 [info ] [MainThread]: python version: 3.11.2
[0m14:16:44.881091 [info ] [MainThread]: python path: /usr/local/bin/python
[0m14:16:44.882459 [info ] [MainThread]: os info: Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.31
[0m14:16:44.892050 [info ] [MainThread]: target not specified in profile 'hailing_project', using 'default'
[0m14:16:44.893325 [info ] [MainThread]: Using profiles dir at /usr/app/dbt_project
[0m14:16:44.894392 [info ] [MainThread]: Using profiles.yml file at /usr/app/dbt_project/profiles.yml
[0m14:16:44.895407 [info ] [MainThread]: Using dbt_project.yml file at /usr/app/dbt_project/dbt_project.yml
[0m14:16:44.976796 [info ] [MainThread]: Configuration:
[0m14:16:44.977929 [info ] [MainThread]:   profiles.yml file [[31mERROR invalid[0m]
[0m14:16:44.979281 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m14:16:44.980494 [info ] [MainThread]: Required dependencies:
[0m14:16:44.981551 [debug] [MainThread]: Executing "git --help"
[0m14:16:44.983637 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m14:16:44.984373 [debug] [MainThread]: STDERR: "b''"
[0m14:16:44.985237 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m14:16:44.986190 [info ] [MainThread]: Connection test skipped since no profile was found
[0m14:16:44.987793 [info ] [MainThread]: [31m1 check failed:[0m
[0m14:16:44.988865 [info ] [MainThread]: Profile loading failed for the following reason:
Runtime Error
  The profile 'hailing_project' does not have a target named 'default'. The valid target names for this profile are:
   - source_data
   - staging_data


[0m14:16:44.990661 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": false, "command_wall_clock_time": 0.17773876, "process_in_blocks": "0", "process_kernel_time": 0.069498, "process_mem_max_rss": "90576", "process_out_blocks": "0", "process_user_time": 0.982904}
[0m14:16:44.991916 [debug] [MainThread]: Command `dbt debug` failed at 14:16:44.991763 after 0.18 seconds
[0m14:16:44.993370 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2e41c21350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2e41c210d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2e3e14f0d0>]}
[0m14:16:44.994434 [debug] [MainThread]: Flushing usage events
[0m14:16:46.285431 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:17:38.677407 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4d00d13f50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4d00d12990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4d00d121d0>]}


============================== 14:17:38.680469 | 0cc35554-7fa5-4052-984f-b9671c1f93a0 ==============================
[0m14:17:38.680469 [info ] [MainThread]: Running with dbt=1.9.0
[0m14:17:38.681692 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'warn_error': 'None', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt debug', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m14:17:38.689453 [info ] [MainThread]: dbt version: 1.9.0
[0m14:17:38.690623 [info ] [MainThread]: python version: 3.11.2
[0m14:17:38.692007 [info ] [MainThread]: python path: /usr/local/bin/python
[0m14:17:38.693121 [info ] [MainThread]: os info: Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.31
[0m14:17:39.189776 [info ] [MainThread]: Using profiles dir at /usr/app/dbt_project
[0m14:17:39.191197 [info ] [MainThread]: Using profiles.yml file at /usr/app/dbt_project/profiles.yml
[0m14:17:39.192497 [info ] [MainThread]: Using dbt_project.yml file at /usr/app/dbt_project/dbt_project.yml
[0m14:17:39.193624 [info ] [MainThread]: adapter type: bigquery
[0m14:17:39.195135 [info ] [MainThread]: adapter version: 1.9.0
[0m14:17:39.279036 [info ] [MainThread]: Configuration:
[0m14:17:39.281161 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m14:17:39.282639 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m14:17:39.284006 [info ] [MainThread]: Required dependencies:
[0m14:17:39.285121 [debug] [MainThread]: Executing "git --help"
[0m14:17:39.287184 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m14:17:39.288275 [debug] [MainThread]: STDERR: "b''"
[0m14:17:39.289176 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m14:17:39.290007 [info ] [MainThread]: Connection:
[0m14:17:39.291262 [info ] [MainThread]:   method: service-account
[0m14:17:39.292264 [info ] [MainThread]:   database: purwadika
[0m14:17:39.293397 [info ] [MainThread]:   execution_project: purwadika
[0m14:17:39.294633 [info ] [MainThread]:   schema: rizky_dwh_hailing_staging
[0m14:17:39.295701 [info ] [MainThread]:   location: None
[0m14:17:39.297023 [info ] [MainThread]:   priority: None
[0m14:17:39.298391 [info ] [MainThread]:   maximum_bytes_billed: None
[0m14:17:39.299349 [info ] [MainThread]:   impersonate_service_account: None
[0m14:17:39.300248 [info ] [MainThread]:   job_retry_deadline_seconds: None
[0m14:17:39.301121 [info ] [MainThread]:   job_retries: 1
[0m14:17:39.302043 [info ] [MainThread]:   job_creation_timeout_seconds: None
[0m14:17:39.303801 [info ] [MainThread]:   job_execution_timeout_seconds: None
[0m14:17:39.305045 [info ] [MainThread]:   timeout_seconds: None
[0m14:17:39.305928 [info ] [MainThread]:   client_id: None
[0m14:17:39.306989 [info ] [MainThread]:   token_uri: None
[0m14:17:39.307880 [info ] [MainThread]:   dataproc_region: None
[0m14:17:39.309145 [info ] [MainThread]:   dataproc_cluster_name: None
[0m14:17:39.310492 [info ] [MainThread]:   gcs_bucket: None
[0m14:17:39.312097 [info ] [MainThread]:   dataproc_batch: None
[0m14:17:39.313269 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m14:17:39.368995 [debug] [MainThread]: Acquiring new bigquery connection 'debug'
[0m14:17:39.370189 [debug] [MainThread]: On debug: select 1 as id
[0m14:17:39.371563 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:17:40.039431 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:c58d470b-e5eb-4df8-abfc-43665ab7d00a&page=queryresults
[0m14:17:40.772093 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m14:17:40.773378 [info ] [MainThread]: [32mAll checks passed![0m
[0m14:17:40.775894 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": true, "command_wall_clock_time": 2.151395, "process_in_blocks": "0", "process_kernel_time": 0.111987, "process_mem_max_rss": "212340", "process_out_blocks": "0", "process_user_time": 2.789518}
[0m14:17:40.776971 [debug] [MainThread]: Command `dbt debug` succeeded at 14:17:40.776842 after 2.15 seconds
[0m14:17:40.777632 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m14:17:40.778427 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4d00d66f90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4d0110e810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4d04544c10>]}
[0m14:17:40.779267 [debug] [MainThread]: Flushing usage events
[0m14:17:41.815485 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:17:44.792228 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbd187270d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbd18726dd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbd18727150>]}


============================== 14:17:44.795022 | 82d178b7-1440-48e2-b384-f6ba05410009 ==============================
[0m14:17:44.795022 [info ] [MainThread]: Running with dbt=1.9.0
[0m14:17:44.796246 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt run', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m14:17:45.405307 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '82d178b7-1440-48e2-b384-f6ba05410009', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbceaa8e850>]}
[0m14:17:45.463871 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '82d178b7-1440-48e2-b384-f6ba05410009', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbd1a9988d0>]}
[0m14:17:45.465190 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m14:17:45.541786 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m14:17:45.715714 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m14:17:45.716663 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m14:17:45.721648 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.facts
- models.dbt_project.staging
[0m14:17:45.751584 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '82d178b7-1440-48e2-b384-f6ba05410009', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbcea9862d0>]}
[0m14:17:45.874217 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m14:17:45.879739 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m14:17:45.903700 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '82d178b7-1440-48e2-b384-f6ba05410009', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbcea8c8bd0>]}
[0m14:17:45.905204 [info ] [MainThread]: Found 5 models, 8 sources, 488 macros
[0m14:17:45.906911 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '82d178b7-1440-48e2-b384-f6ba05410009', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbcea8bda90>]}
[0m14:17:45.910075 [info ] [MainThread]: 
[0m14:17:45.911336 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m14:17:45.912237 [info ] [MainThread]: 
[0m14:17:45.913713 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m14:17:45.918689 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m14:17:45.919632 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:17:46.484667 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_staging)
[0m14:17:46.485507 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:17:46.748433 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '82d178b7-1440-48e2-b384-f6ba05410009', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbd1aabb690>]}
[0m14:17:46.749742 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:17:46.755543 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m14:17:46.756004 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m14:17:46.756476 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m14:17:46.756901 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m14:17:46.757658 [info ] [Thread-1 (]: 1 of 5 START sql incremental model rizky_dwh_hailing_staging.dim_customer ...... [RUN]
[0m14:17:46.759116 [info ] [Thread-2 (]: 2 of 5 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [RUN]
[0m14:17:46.760349 [info ] [Thread-3 (]: 3 of 5 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [RUN]
[0m14:17:46.761561 [info ] [Thread-4 (]: 4 of 5 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [RUN]
[0m14:17:46.762857 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_staging, now model.hailing_project.dim_customer)
[0m14:17:46.764178 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_customer'
[0m14:17:46.765409 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m14:17:46.766428 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m14:17:46.767543 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m14:17:46.768562 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m14:17:46.769639 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m14:17:46.770635 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m14:17:46.787047 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m14:17:46.792358 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m14:17:46.796628 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m14:17:46.800694 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m14:17:46.808964 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m14:17:46.809516 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m14:17:46.821300 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m14:17:46.834143 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m14:17:46.858466 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m14:17:46.876091 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m14:17:46.889372 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m14:17:46.891948 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m14:17:46.945228 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_staging`.`dim_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    );
  
[0m14:17:46.970946 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:17:47.249108 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m14:17:47.249913 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m14:17:47.251477 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m14:17:47.258394 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m14:17:47.260867 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m14:17:47.265164 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m14:17:47.514742 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:2471bffc-48ea-4371-8064-c336f467eb84&page=queryresults
[0m14:17:47.585751 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:40e7c351-484f-474d-9379-8bad3db7614c&page=queryresults
[0m14:17:47.604839 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:9fd93cf9-1b74-4744-8a33-011de5f884ef&page=queryresults
[0m14:17:47.658042 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:6b134efc-42cc-4278-a428-2323928894a3&page=queryresults
[0m14:17:49.032656 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '82d178b7-1440-48e2-b384-f6ba05410009', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbcea6c69d0>]}
[0m14:17:49.034035 [info ] [Thread-1 (]: 1 of 5 OK created sql incremental model rizky_dwh_hailing_staging.dim_customer . [[32mCREATE TABLE (85.0 rows, 5.7 KiB processed)[0m in 2.27s]
[0m14:17:49.035576 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m14:17:49.036681 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m14:17:49.037668 [info ] [Thread-1 (]: 5 of 5 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [RUN]
[0m14:17:49.039074 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.hailing_project.dim_customer, now model.hailing_project.production_hailing_staging_vehicle)
[0m14:17:49.040401 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m14:17:49.045211 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m14:17:49.052215 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m14:17:49.056935 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:17:49.201617 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '82d178b7-1440-48e2-b384-f6ba05410009', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbcea4f5910>]}
[0m14:17:49.203180 [info ] [Thread-4 (]: 4 of 5 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.44s]
[0m14:17:49.204573 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m14:17:49.245025 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '82d178b7-1440-48e2-b384-f6ba05410009', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbcea513e90>]}
[0m14:17:49.246292 [info ] [Thread-3 (]: 3 of 5 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.48s]
[0m14:17:49.247941 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m14:17:49.316128 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '82d178b7-1440-48e2-b384-f6ba05410009', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbce838fcd0>]}
[0m14:17:49.317468 [info ] [Thread-2 (]: 2 of 5 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.55s]
[0m14:17:49.318605 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m14:17:49.335929 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m14:17:49.342636 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m14:17:49.647967 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:775a5d31-b8ab-411d-94a7-d322e682123d&page=queryresults
[0m14:17:51.239621 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '82d178b7-1440-48e2-b384-f6ba05410009', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbce80e9a90>]}
[0m14:17:51.241622 [info ] [Thread-1 (]: 5 of 5 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.20s]
[0m14:17:51.243119 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m14:17:51.245655 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:17:51.248863 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:17:51.249682 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m14:17:51.250472 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m14:17:51.251161 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m14:17:51.251852 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m14:17:51.252669 [info ] [MainThread]: 
[0m14:17:51.253616 [info ] [MainThread]: Finished running 5 incremental models in 0 hours 0 minutes and 5.34 seconds (5.34s).
[0m14:17:51.256353 [debug] [MainThread]: Command end result
[0m14:17:51.291054 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m14:17:51.295554 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m14:17:51.303483 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m14:17:51.304408 [info ] [MainThread]: 
[0m14:17:51.305501 [info ] [MainThread]: [32mCompleted successfully[0m
[0m14:17:51.306856 [info ] [MainThread]: 
[0m14:17:51.307939 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
[0m14:17:51.309527 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 6.5712976, "process_in_blocks": "0", "process_kernel_time": 0.229025, "process_mem_max_rss": "223216", "process_out_blocks": "120", "process_user_time": 3.48517}
[0m14:17:51.310455 [debug] [MainThread]: Command `dbt run` succeeded at 14:17:51.310341 after 6.57 seconds
[0m14:17:51.311415 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbd1879fa10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbd1c211790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbd1bf40c10>]}
[0m14:17:51.312337 [debug] [MainThread]: Flushing usage events
[0m14:17:52.694159 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:19:18.008064 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91b1817410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91b186b950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91b3bac9d0>]}


============================== 14:19:18.010837 | 129bac6e-7cd5-423e-b3cc-f19a47468701 ==============================
[0m14:19:18.010837 [info ] [MainThread]: Running with dbt=1.9.0
[0m14:19:18.012247 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'version_check': 'True', 'warn_error': 'None', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'invocation_command': 'dbt debug', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m14:19:18.019972 [info ] [MainThread]: dbt version: 1.9.0
[0m14:19:18.021093 [info ] [MainThread]: python version: 3.11.2
[0m14:19:18.022484 [info ] [MainThread]: python path: /usr/local/bin/python
[0m14:19:18.023827 [info ] [MainThread]: os info: Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.31
[0m14:19:18.583568 [info ] [MainThread]: Using profiles dir at /usr/app/dbt_project
[0m14:19:18.584738 [info ] [MainThread]: Using profiles.yml file at /usr/app/dbt_project/profiles.yml
[0m14:19:18.586014 [info ] [MainThread]: Using dbt_project.yml file at /usr/app/dbt_project/dbt_project.yml
[0m14:19:18.587072 [info ] [MainThread]: adapter type: bigquery
[0m14:19:18.588382 [info ] [MainThread]: adapter version: 1.9.0
[0m14:19:18.675931 [info ] [MainThread]: Configuration:
[0m14:19:18.677037 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m14:19:18.678609 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m14:19:18.679585 [info ] [MainThread]: Required dependencies:
[0m14:19:18.680628 [debug] [MainThread]: Executing "git --help"
[0m14:19:18.682891 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m14:19:18.683649 [debug] [MainThread]: STDERR: "b''"
[0m14:19:18.684406 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m14:19:18.685562 [info ] [MainThread]: Connection:
[0m14:19:18.687254 [info ] [MainThread]:   method: service-account
[0m14:19:18.688712 [info ] [MainThread]:   database: purwadika
[0m14:19:18.690166 [info ] [MainThread]:   execution_project: purwadika
[0m14:19:18.691084 [info ] [MainThread]:   schema: rizky_dwh_hailing_staging
[0m14:19:18.692249 [info ] [MainThread]:   location: None
[0m14:19:18.694277 [info ] [MainThread]:   priority: None
[0m14:19:18.695748 [info ] [MainThread]:   maximum_bytes_billed: None
[0m14:19:18.696688 [info ] [MainThread]:   impersonate_service_account: None
[0m14:19:18.697642 [info ] [MainThread]:   job_retry_deadline_seconds: None
[0m14:19:18.698547 [info ] [MainThread]:   job_retries: 1
[0m14:19:18.699713 [info ] [MainThread]:   job_creation_timeout_seconds: None
[0m14:19:18.700916 [info ] [MainThread]:   job_execution_timeout_seconds: None
[0m14:19:18.701835 [info ] [MainThread]:   timeout_seconds: None
[0m14:19:18.702855 [info ] [MainThread]:   client_id: None
[0m14:19:18.703853 [info ] [MainThread]:   token_uri: None
[0m14:19:18.704854 [info ] [MainThread]:   dataproc_region: None
[0m14:19:18.706249 [info ] [MainThread]:   dataproc_cluster_name: None
[0m14:19:18.707705 [info ] [MainThread]:   gcs_bucket: None
[0m14:19:18.708841 [info ] [MainThread]:   dataproc_batch: None
[0m14:19:18.709950 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m14:19:18.777520 [debug] [MainThread]: Acquiring new bigquery connection 'debug'
[0m14:19:18.778647 [debug] [MainThread]: On debug: select 1 as id
[0m14:19:18.779551 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:19:19.465508 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:23be2415-d9c4-4976-a6b8-5a15ebb2c423&page=queryresults
[0m14:19:20.240156 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m14:19:20.242282 [info ] [MainThread]: [32mAll checks passed![0m
[0m14:19:20.244168 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": true, "command_wall_clock_time": 2.303079, "process_in_blocks": "0", "process_kernel_time": 0.210186, "process_mem_max_rss": "212480", "process_out_blocks": "0", "process_user_time": 2.812492}
[0m14:19:20.245270 [debug] [MainThread]: Command `dbt debug` succeeded at 14:19:20.245146 after 2.30 seconds
[0m14:19:20.246092 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m14:19:20.246821 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91b1c125d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91b184dc10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91b181c650>]}
[0m14:19:20.247832 [debug] [MainThread]: Flushing usage events
[0m14:19:21.871541 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:19:24.816482 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9de6aef250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9de6eee690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9de6aeed50>]}


============================== 14:19:24.820542 | 5d25e228-44bd-42f6-96b1-69d249746859 ==============================
[0m14:19:24.820542 [info ] [MainThread]: Running with dbt=1.9.0
[0m14:19:24.821736 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m14:19:25.460164 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5d25e228-44bd-42f6-96b1-69d249746859', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9de6b20d90>]}
[0m14:19:25.510372 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '5d25e228-44bd-42f6-96b1-69d249746859', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9de8d79850>]}
[0m14:19:25.512680 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m14:19:25.594217 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m14:19:25.768636 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m14:19:25.769460 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m14:19:25.774526 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.staging
- models.dbt_project.facts
[0m14:19:25.801373 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5d25e228-44bd-42f6-96b1-69d249746859', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9dc5601e50>]}
[0m14:19:25.927914 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m14:19:25.933552 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m14:19:25.951910 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5d25e228-44bd-42f6-96b1-69d249746859', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9dbce785d0>]}
[0m14:19:25.953283 [info ] [MainThread]: Found 5 models, 8 sources, 488 macros
[0m14:19:25.954483 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5d25e228-44bd-42f6-96b1-69d249746859', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9dbce6d0d0>]}
[0m14:19:25.957367 [info ] [MainThread]: 
[0m14:19:25.958432 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m14:19:25.959455 [info ] [MainThread]: 
[0m14:19:25.960639 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m14:19:25.965490 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m14:19:25.966500 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:19:26.457433 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_staging)
[0m14:19:26.459095 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:19:26.649652 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5d25e228-44bd-42f6-96b1-69d249746859', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9de7907690>]}
[0m14:19:26.651202 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:19:26.656542 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m14:19:26.657366 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m14:19:26.657865 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m14:19:26.658209 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m14:19:26.658904 [info ] [Thread-1 (]: 1 of 5 START sql incremental model rizky_dwh_hailing_staging.dim_customer ...... [RUN]
[0m14:19:26.659992 [info ] [Thread-2 (]: 2 of 5 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [RUN]
[0m14:19:26.660932 [info ] [Thread-3 (]: 3 of 5 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [RUN]
[0m14:19:26.661950 [info ] [Thread-4 (]: 4 of 5 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [RUN]
[0m14:19:26.663038 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_staging, now model.hailing_project.dim_customer)
[0m14:19:26.664044 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_customer'
[0m14:19:26.665804 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m14:19:26.667023 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m14:19:26.667970 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m14:19:26.668815 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m14:19:26.669500 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m14:19:26.670296 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m14:19:26.688634 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m14:19:26.692810 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m14:19:26.697443 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m14:19:26.701634 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m14:19:26.707886 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m14:19:26.708897 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m14:19:26.714676 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m14:19:26.724968 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m14:19:26.752786 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m14:19:26.753243 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:19:26.756172 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m14:19:26.760111 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m14:19:27.024028 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m14:19:27.028508 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m14:19:27.030497 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m14:19:27.032244 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m14:19:27.037890 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m14:19:27.038524 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m14:19:27.039458 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m14:19:27.040992 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`dim_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`dim_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m14:19:27.289968 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:850e034c-4be3-46a0-92f3-ebbe6bea7d85&page=queryresults
[0m14:19:27.297566 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:95afeeb9-7b7f-4504-b977-2aa619dceb68&page=queryresults
[0m14:19:27.361265 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:89c10ba0-07ee-48f8-9b53-82a1bfbf9f56&page=queryresults
[0m14:19:27.361799 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:d2bc393d-d245-4e90-b0d4-eef873e32206&page=queryresults
[0m14:19:28.900561 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5d25e228-44bd-42f6-96b1-69d249746859', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9dbc943ed0>]}
[0m14:19:28.902242 [info ] [Thread-4 (]: 4 of 5 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.23s]
[0m14:19:28.903737 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m14:19:28.904850 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m14:19:28.905907 [info ] [Thread-4 (]: 5 of 5 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [RUN]
[0m14:19:28.906969 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_ride, now model.hailing_project.production_hailing_staging_vehicle)
[0m14:19:28.908298 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m14:19:28.912771 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m14:19:28.920921 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m14:19:28.925203 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m14:19:29.048734 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5d25e228-44bd-42f6-96b1-69d249746859', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9db4c4b350>]}
[0m14:19:29.049979 [info ] [Thread-2 (]: 2 of 5 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.38s]
[0m14:19:29.051255 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m14:19:29.085448 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5d25e228-44bd-42f6-96b1-69d249746859', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9dbc94cb90>]}
[0m14:19:29.088522 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5d25e228-44bd-42f6-96b1-69d249746859', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9dbcb18ed0>]}
[0m14:19:29.089613 [info ] [Thread-3 (]: 3 of 5 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.42s]
[0m14:19:29.090996 [info ] [Thread-1 (]: 1 of 5 OK created sql incremental model rizky_dwh_hailing_staging.dim_customer . [[32mMERGE (0.0 rows, 11.3 KiB processed)[0m in 2.43s]
[0m14:19:29.092236 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m14:19:29.093350 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m14:19:29.170558 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m14:19:29.177394 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m14:19:29.473608 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:b5dd4f33-c2dd-42ff-a4bf-1b674aaf4b86&page=queryresults
[0m14:19:31.006223 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5d25e228-44bd-42f6-96b1-69d249746859', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9de6af5d10>]}
[0m14:19:31.008099 [info ] [Thread-4 (]: 5 of 5 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.10s]
[0m14:19:31.009900 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m14:19:31.012994 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:19:31.016513 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:19:31.017366 [debug] [MainThread]: Connection 'model.hailing_project.dim_customer' was properly closed.
[0m14:19:31.018304 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m14:19:31.019493 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m14:19:31.020686 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m14:19:31.021733 [info ] [MainThread]: 
[0m14:19:31.022930 [info ] [MainThread]: Finished running 5 incremental models in 0 hours 0 minutes and 5.06 seconds (5.06s).
[0m14:19:31.025113 [debug] [MainThread]: Command end result
[0m14:19:31.066445 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m14:19:31.072630 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m14:19:31.084429 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m14:19:31.085428 [info ] [MainThread]: 
[0m14:19:31.086699 [info ] [MainThread]: [32mCompleted successfully[0m
[0m14:19:31.088260 [info ] [MainThread]: 
[0m14:19:31.089604 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
[0m14:19:31.092007 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 6.337032, "process_in_blocks": "0", "process_kernel_time": 0.168976, "process_mem_max_rss": "222724", "process_out_blocks": "0", "process_user_time": 3.508751}
[0m14:19:31.094173 [debug] [MainThread]: Command `dbt run` succeeded at 14:19:31.093962 after 6.34 seconds
[0m14:19:31.095978 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9de6b4c4d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9de6b4c2d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9dea310c90>]}
[0m14:19:31.097932 [debug] [MainThread]: Flushing usage events
[0m14:19:32.645756 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:21:02.265651 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9a1c15b9d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9a1c1a3c90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9a1c15b5d0>]}


============================== 14:21:02.269413 | 2f93d259-b38e-4a47-bf46-437955dd32a5 ==============================
[0m14:21:02.269413 [info ] [MainThread]: Running with dbt=1.9.0
[0m14:21:02.272203 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt debug', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m14:21:02.279962 [info ] [MainThread]: dbt version: 1.9.0
[0m14:21:02.281231 [info ] [MainThread]: python version: 3.11.2
[0m14:21:02.283212 [info ] [MainThread]: python path: /usr/local/bin/python
[0m14:21:02.285136 [info ] [MainThread]: os info: Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.31
[0m14:21:02.295612 [info ] [MainThread]: Using profiles dir at /usr/app/dbt_project
[0m14:21:02.297274 [info ] [MainThread]: Using profiles.yml file at /usr/app/dbt_project/profiles.yml
[0m14:21:02.298986 [info ] [MainThread]: Using dbt_project.yml file at /usr/app/dbt_project/dbt_project.yml
[0m14:21:02.380606 [info ] [MainThread]: Configuration:
[0m14:21:02.382231 [info ] [MainThread]:   profiles.yml file [[31mERROR invalid[0m]
[0m14:21:02.383387 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m14:21:02.384499 [info ] [MainThread]: Required dependencies:
[0m14:21:02.385768 [debug] [MainThread]: Executing "git --help"
[0m14:21:02.388639 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m14:21:02.389678 [debug] [MainThread]: STDERR: "b''"
[0m14:21:02.390457 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m14:21:02.391460 [info ] [MainThread]: Connection test skipped since no profile was found
[0m14:21:02.392813 [info ] [MainThread]: [31m1 check failed:[0m
[0m14:21:02.394112 [info ] [MainThread]: Profile loading failed for the following reason:
Runtime Error
  The profile 'hailing_project' does not have a target named 'dev'. The valid target names for this profile are:
   - staging
   - facts


[0m14:21:02.396026 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": false, "command_wall_clock_time": 0.18709344, "process_in_blocks": "0", "process_kernel_time": 0.03997, "process_mem_max_rss": "90368", "process_out_blocks": "0", "process_user_time": 1.109182}
[0m14:21:02.397032 [debug] [MainThread]: Command `dbt debug` failed at 14:21:02.396925 after 0.19 seconds
[0m14:21:02.398223 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9a1c1861d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9a1fad1210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9a1fad1150>]}
[0m14:21:02.399065 [debug] [MainThread]: Flushing usage events
[0m14:21:03.540504 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:21:29.440030 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f00fa2740d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f00fb061550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f00fa2befd0>]}


============================== 14:21:29.442554 | 280159b5-8ac2-4177-ad64-ce9951fcdf36 ==============================
[0m14:21:29.442554 [info ] [MainThread]: Running with dbt=1.9.0
[0m14:21:29.444701 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'invocation_command': 'dbt debug', 'send_anonymous_usage_stats': 'True'}
[0m14:21:29.451847 [info ] [MainThread]: dbt version: 1.9.0
[0m14:21:29.452786 [info ] [MainThread]: python version: 3.11.2
[0m14:21:29.453739 [info ] [MainThread]: python path: /usr/local/bin/python
[0m14:21:29.454884 [info ] [MainThread]: os info: Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.31
[0m14:21:29.997814 [info ] [MainThread]: Using profiles dir at /usr/app/dbt_project
[0m14:21:29.998891 [info ] [MainThread]: Using profiles.yml file at /usr/app/dbt_project/profiles.yml
[0m14:21:30.000373 [info ] [MainThread]: Using dbt_project.yml file at /usr/app/dbt_project/dbt_project.yml
[0m14:21:30.001717 [info ] [MainThread]: adapter type: bigquery
[0m14:21:30.002845 [info ] [MainThread]: adapter version: 1.9.0
[0m14:21:30.085528 [info ] [MainThread]: Configuration:
[0m14:21:30.086697 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m14:21:30.088051 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m14:21:30.090598 [info ] [MainThread]: Required dependencies:
[0m14:21:30.092013 [debug] [MainThread]: Executing "git --help"
[0m14:21:30.094328 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m14:21:30.095457 [debug] [MainThread]: STDERR: "b''"
[0m14:21:30.096501 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m14:21:30.097893 [info ] [MainThread]: Connection:
[0m14:21:30.099658 [info ] [MainThread]:   method: service-account
[0m14:21:30.101071 [info ] [MainThread]:   database: purwadika
[0m14:21:30.101917 [info ] [MainThread]:   execution_project: purwadika
[0m14:21:30.102739 [info ] [MainThread]:   schema: rizky_dwh_hailing_staging
[0m14:21:30.104332 [info ] [MainThread]:   location: None
[0m14:21:30.105939 [info ] [MainThread]:   priority: None
[0m14:21:30.107807 [info ] [MainThread]:   maximum_bytes_billed: None
[0m14:21:30.110995 [info ] [MainThread]:   impersonate_service_account: None
[0m14:21:30.112422 [info ] [MainThread]:   job_retry_deadline_seconds: None
[0m14:21:30.113680 [info ] [MainThread]:   job_retries: 1
[0m14:21:30.115099 [info ] [MainThread]:   job_creation_timeout_seconds: None
[0m14:21:30.116008 [info ] [MainThread]:   job_execution_timeout_seconds: None
[0m14:21:30.116885 [info ] [MainThread]:   timeout_seconds: None
[0m14:21:30.117962 [info ] [MainThread]:   client_id: None
[0m14:21:30.119003 [info ] [MainThread]:   token_uri: None
[0m14:21:30.120003 [info ] [MainThread]:   dataproc_region: None
[0m14:21:30.120979 [info ] [MainThread]:   dataproc_cluster_name: None
[0m14:21:30.121844 [info ] [MainThread]:   gcs_bucket: None
[0m14:21:30.122662 [info ] [MainThread]:   dataproc_batch: None
[0m14:21:30.123656 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m14:21:30.181321 [debug] [MainThread]: Acquiring new bigquery connection 'debug'
[0m14:21:30.182275 [debug] [MainThread]: On debug: select 1 as id
[0m14:21:30.183076 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:21:30.876971 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:f99d9e6c-98a9-44dc-9ff6-b8f3a04e353e&page=queryresults
[0m14:21:31.580049 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m14:21:31.581064 [info ] [MainThread]: [32mAll checks passed![0m
[0m14:21:31.582724 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": true, "command_wall_clock_time": 2.1959321, "process_in_blocks": "0", "process_kernel_time": 0.180092, "process_mem_max_rss": "211908", "process_out_blocks": "0", "process_user_time": 2.801439}
[0m14:21:31.584265 [debug] [MainThread]: Command `dbt debug` succeeded at 14:21:31.584051 after 2.20 seconds
[0m14:21:31.585467 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m14:21:31.586430 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f00fa72c310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f00fa2c9210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f00fa278710>]}
[0m14:21:31.587394 [debug] [MainThread]: Flushing usage events
[0m14:21:32.838069 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:22:00.572477 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6485c26f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6486907450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6485c26510>]}


============================== 14:22:00.575573 | 0add5a11-981a-4f48-877c-b7811cf2739b ==============================
[0m14:22:00.575573 [info ] [MainThread]: Running with dbt=1.9.0
[0m14:22:00.576865 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt debug', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m14:22:00.584214 [info ] [MainThread]: dbt version: 1.9.0
[0m14:22:00.585635 [info ] [MainThread]: python version: 3.11.2
[0m14:22:00.586911 [info ] [MainThread]: python path: /usr/local/bin/python
[0m14:22:00.588182 [info ] [MainThread]: os info: Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.31
[0m14:22:01.151103 [info ] [MainThread]: Using profiles dir at /usr/app/dbt_project
[0m14:22:01.152530 [info ] [MainThread]: Using profiles.yml file at /usr/app/dbt_project/profiles.yml
[0m14:22:01.154102 [info ] [MainThread]: Using dbt_project.yml file at /usr/app/dbt_project/dbt_project.yml
[0m14:22:01.156065 [info ] [MainThread]: adapter type: bigquery
[0m14:22:01.157551 [info ] [MainThread]: adapter version: 1.9.0
[0m14:22:01.239754 [info ] [MainThread]: Configuration:
[0m14:22:01.241109 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m14:22:01.242192 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m14:22:01.243253 [info ] [MainThread]: Required dependencies:
[0m14:22:01.244304 [debug] [MainThread]: Executing "git --help"
[0m14:22:01.246608 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m14:22:01.247407 [debug] [MainThread]: STDERR: "b''"
[0m14:22:01.248128 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m14:22:01.249507 [info ] [MainThread]: Connection:
[0m14:22:01.250615 [info ] [MainThread]:   method: service-account
[0m14:22:01.251755 [info ] [MainThread]:   database: purwadika
[0m14:22:01.253550 [info ] [MainThread]:   execution_project: purwadika
[0m14:22:01.254847 [info ] [MainThread]:   schema: rizky_dwh_hailing_staging
[0m14:22:01.255892 [info ] [MainThread]:   location: None
[0m14:22:01.256938 [info ] [MainThread]:   priority: None
[0m14:22:01.257825 [info ] [MainThread]:   maximum_bytes_billed: None
[0m14:22:01.259247 [info ] [MainThread]:   impersonate_service_account: None
[0m14:22:01.260766 [info ] [MainThread]:   job_retry_deadline_seconds: None
[0m14:22:01.261943 [info ] [MainThread]:   job_retries: 1
[0m14:22:01.262996 [info ] [MainThread]:   job_creation_timeout_seconds: None
[0m14:22:01.263887 [info ] [MainThread]:   job_execution_timeout_seconds: None
[0m14:22:01.265003 [info ] [MainThread]:   timeout_seconds: None
[0m14:22:01.266388 [info ] [MainThread]:   client_id: None
[0m14:22:01.267585 [info ] [MainThread]:   token_uri: None
[0m14:22:01.268716 [info ] [MainThread]:   dataproc_region: None
[0m14:22:01.269960 [info ] [MainThread]:   dataproc_cluster_name: None
[0m14:22:01.270993 [info ] [MainThread]:   gcs_bucket: None
[0m14:22:01.271925 [info ] [MainThread]:   dataproc_batch: None
[0m14:22:01.273474 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m14:22:01.331644 [debug] [MainThread]: Acquiring new bigquery connection 'debug'
[0m14:22:01.332644 [debug] [MainThread]: On debug: select 1 as id
[0m14:22:01.333585 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:22:01.991757 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:c4f31956-dde8-44eb-a9fd-e101c16b7b98&page=queryresults
[0m14:22:02.706573 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m14:22:02.707952 [info ] [MainThread]: [32mAll checks passed![0m
[0m14:22:02.710007 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": true, "command_wall_clock_time": 2.191244, "process_in_blocks": "0", "process_kernel_time": 0.168452, "process_mem_max_rss": "212356", "process_out_blocks": "0", "process_user_time": 2.814151}
[0m14:22:02.711404 [debug] [MainThread]: Command `dbt debug` succeeded at 14:22:02.711224 after 2.19 seconds
[0m14:22:02.712539 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m14:22:02.713429 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6457cc2390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6457d78f90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6485c28710>]}
[0m14:22:02.714452 [debug] [MainThread]: Flushing usage events
[0m14:22:04.266274 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:22:43.228833 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2f1a5eebd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2f1a9e6690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2f1a6431d0>]}


============================== 14:22:43.231718 | 75cbbe04-b220-4aaa-a9c5-bb49bfb3808d ==============================
[0m14:22:43.231718 [info ] [MainThread]: Running with dbt=1.9.0
[0m14:22:43.232839 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt debug', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m14:22:43.241543 [info ] [MainThread]: dbt version: 1.9.0
[0m14:22:43.242963 [info ] [MainThread]: python version: 3.11.2
[0m14:22:43.244729 [info ] [MainThread]: python path: /usr/local/bin/python
[0m14:22:43.246019 [info ] [MainThread]: os info: Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.31
[0m14:22:43.780920 [info ] [MainThread]: Using profiles dir at /usr/app/dbt_project
[0m14:22:43.782032 [info ] [MainThread]: Using profiles.yml file at /usr/app/dbt_project/profiles.yml
[0m14:22:43.783622 [info ] [MainThread]: Using dbt_project.yml file at /usr/app/dbt_project/dbt_project.yml
[0m14:22:43.785641 [info ] [MainThread]: adapter type: bigquery
[0m14:22:43.786857 [info ] [MainThread]: adapter version: 1.9.0
[0m14:22:43.869235 [info ] [MainThread]: Configuration:
[0m14:22:43.870428 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m14:22:43.871524 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m14:22:43.872780 [info ] [MainThread]: Required dependencies:
[0m14:22:43.874138 [debug] [MainThread]: Executing "git --help"
[0m14:22:43.876528 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m14:22:43.877289 [debug] [MainThread]: STDERR: "b''"
[0m14:22:43.878102 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m14:22:43.878969 [info ] [MainThread]: Connection:
[0m14:22:43.880195 [info ] [MainThread]:   method: service-account
[0m14:22:43.881549 [info ] [MainThread]:   database: purwadika
[0m14:22:43.883084 [info ] [MainThread]:   execution_project: purwadika
[0m14:22:43.884092 [info ] [MainThread]:   schema: rizky_dwh_hailing_facts
[0m14:22:43.885125 [info ] [MainThread]:   location: None
[0m14:22:43.886190 [info ] [MainThread]:   priority: None
[0m14:22:43.887447 [info ] [MainThread]:   maximum_bytes_billed: None
[0m14:22:43.888770 [info ] [MainThread]:   impersonate_service_account: None
[0m14:22:43.890047 [info ] [MainThread]:   job_retry_deadline_seconds: None
[0m14:22:43.891065 [info ] [MainThread]:   job_retries: 1
[0m14:22:43.892026 [info ] [MainThread]:   job_creation_timeout_seconds: None
[0m14:22:43.892956 [info ] [MainThread]:   job_execution_timeout_seconds: None
[0m14:22:43.893875 [info ] [MainThread]:   timeout_seconds: None
[0m14:22:43.895245 [info ] [MainThread]:   client_id: None
[0m14:22:43.896924 [info ] [MainThread]:   token_uri: None
[0m14:22:43.898205 [info ] [MainThread]:   dataproc_region: None
[0m14:22:43.899205 [info ] [MainThread]:   dataproc_cluster_name: None
[0m14:22:43.900213 [info ] [MainThread]:   gcs_bucket: None
[0m14:22:43.901183 [info ] [MainThread]:   dataproc_batch: None
[0m14:22:43.902662 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m14:22:43.961700 [debug] [MainThread]: Acquiring new bigquery connection 'debug'
[0m14:22:43.962680 [debug] [MainThread]: On debug: select 1 as id
[0m14:22:43.963618 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:22:44.569898 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:133408e0-1e67-484c-be0c-245451e7d5bb&page=queryresults
[0m14:22:45.378632 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m14:22:45.379884 [info ] [MainThread]: [32mAll checks passed![0m
[0m14:22:45.382698 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": true, "command_wall_clock_time": 2.2135456, "process_in_blocks": "0", "process_kernel_time": 0.110118, "process_mem_max_rss": "212264", "process_out_blocks": "0", "process_user_time": 2.873085}
[0m14:22:45.384382 [debug] [MainThread]: Command `dbt debug` succeeded at 14:22:45.384243 after 2.22 seconds
[0m14:22:45.385233 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m14:22:45.386243 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ef0783690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2f1a9e6310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2f1deaca90>]}
[0m14:22:45.387300 [debug] [MainThread]: Flushing usage events
[0m14:22:46.422689 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:22:55.316100 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f46ec677490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f46eca75ed0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f46eca75fd0>]}


============================== 14:22:55.319192 | cd2da8bb-217b-4e71-b4dc-8daf99e2d7de ==============================
[0m14:22:55.319192 [info ] [MainThread]: Running with dbt=1.9.0
[0m14:22:55.320411 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'warn_error': 'None', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt debug', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m14:22:55.327546 [info ] [MainThread]: dbt version: 1.9.0
[0m14:22:55.328464 [info ] [MainThread]: python version: 3.11.2
[0m14:22:55.329698 [info ] [MainThread]: python path: /usr/local/bin/python
[0m14:22:55.330998 [info ] [MainThread]: os info: Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.31
[0m14:22:55.345372 [info ] [MainThread]: Using profiles dir at /usr/app/dbt_project
[0m14:22:55.346475 [info ] [MainThread]: Using profiles.yml file at /usr/app/dbt_project/profiles.yml
[0m14:22:55.347408 [info ] [MainThread]: Using dbt_project.yml file at /usr/app/dbt_project/dbt_project.yml
[0m14:22:55.423513 [info ] [MainThread]: Configuration:
[0m14:22:55.424676 [info ] [MainThread]:   profiles.yml file [[31mERROR invalid[0m]
[0m14:22:55.426167 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m14:22:55.427293 [info ] [MainThread]: Required dependencies:
[0m14:22:55.428282 [debug] [MainThread]: Executing "git --help"
[0m14:22:55.430808 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m14:22:55.431664 [debug] [MainThread]: STDERR: "b''"
[0m14:22:55.432489 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m14:22:55.433254 [info ] [MainThread]: Connection test skipped since no profile was found
[0m14:22:55.434556 [info ] [MainThread]: [31m1 check failed:[0m
[0m14:22:55.435557 [info ] [MainThread]: Profile loading failed for the following reason:
Runtime Error
  The profile 'hailing_project' does not have a target named 'dev, facts'. The valid target names for this profile are:
   - dev
   - facts


[0m14:22:55.438009 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": false, "command_wall_clock_time": 0.17276138, "process_in_blocks": "0", "process_kernel_time": 0.089727, "process_mem_max_rss": "90612", "process_out_blocks": "0", "process_user_time": 1.116606}
[0m14:22:55.439276 [debug] [MainThread]: Command `dbt debug` failed at 14:22:55.439153 after 0.17 seconds
[0m14:22:55.440062 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f46efff5290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f46efff4910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f46efff5250>]}
[0m14:22:55.440816 [debug] [MainThread]: Flushing usage events
[0m14:22:56.495375 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:23:15.429839 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe81882ef50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe81882f0d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe81882e990>]}


============================== 14:23:15.433061 | 73f5604a-2c09-42fb-81ff-cb1ba5c513e1 ==============================
[0m14:23:15.433061 [info ] [MainThread]: Running with dbt=1.9.0
[0m14:23:15.434278 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'invocation_command': 'dbt debug', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m14:23:15.442041 [info ] [MainThread]: dbt version: 1.9.0
[0m14:23:15.443220 [info ] [MainThread]: python version: 3.11.2
[0m14:23:15.444323 [info ] [MainThread]: python path: /usr/local/bin/python
[0m14:23:15.446229 [info ] [MainThread]: os info: Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.31
[0m14:23:15.459847 [info ] [MainThread]: target not specified in profile 'hailing_project', using 'default'
[0m14:23:15.461064 [info ] [MainThread]: Using profiles dir at /usr/app/dbt_project
[0m14:23:15.462518 [info ] [MainThread]: Using profiles.yml file at /usr/app/dbt_project/profiles.yml
[0m14:23:15.463509 [info ] [MainThread]: Using dbt_project.yml file at /usr/app/dbt_project/dbt_project.yml
[0m14:23:15.556615 [info ] [MainThread]: Configuration:
[0m14:23:15.557968 [info ] [MainThread]:   profiles.yml file [[31mERROR invalid[0m]
[0m14:23:15.559307 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m14:23:15.560377 [info ] [MainThread]: Required dependencies:
[0m14:23:15.561365 [debug] [MainThread]: Executing "git --help"
[0m14:23:15.563418 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m14:23:15.564409 [debug] [MainThread]: STDERR: "b''"
[0m14:23:15.565541 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m14:23:15.566663 [info ] [MainThread]: Connection test skipped since no profile was found
[0m14:23:15.567557 [info ] [MainThread]: [31m1 check failed:[0m
[0m14:23:15.568674 [info ] [MainThread]: Profile loading failed for the following reason:
Runtime Error
  The profile 'hailing_project' does not have a target named 'default'. The valid target names for this profile are:
   - dev
   - facts


[0m14:23:15.570464 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": false, "command_wall_clock_time": 0.19949, "process_in_blocks": "0", "process_kernel_time": 0.020305, "process_mem_max_rss": "90468", "process_out_blocks": "0", "process_user_time": 1.137084}
[0m14:23:15.572414 [debug] [MainThread]: Command `dbt debug` failed at 14:23:15.572225 after 0.20 seconds
[0m14:23:15.573366 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe81887ee10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe818792a10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe81c1a4850>]}
[0m14:23:15.574386 [debug] [MainThread]: Flushing usage events
[0m14:23:16.899149 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:26:14.906284 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f75c915a450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f75c9269c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f75c915a610>]}


============================== 14:26:14.909494 | 55db6db5-2d0e-4f14-85f2-8e1792aa8e42 ==============================
[0m14:26:14.909494 [info ] [MainThread]: Running with dbt=1.9.0
[0m14:26:14.910755 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt debug', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m14:26:14.917704 [info ] [MainThread]: dbt version: 1.9.0
[0m14:26:14.918672 [info ] [MainThread]: python version: 3.11.2
[0m14:26:14.920090 [info ] [MainThread]: python path: /usr/local/bin/python
[0m14:26:14.921617 [info ] [MainThread]: os info: Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.31
[0m14:26:15.458033 [info ] [MainThread]: Using profiles dir at /usr/app/dbt_project
[0m14:26:15.459293 [info ] [MainThread]: Using profiles.yml file at /usr/app/dbt_project/profiles.yml
[0m14:26:15.460331 [info ] [MainThread]: Using dbt_project.yml file at /usr/app/dbt_project/dbt_project.yml
[0m14:26:15.537946 [info ] [MainThread]: Configuration:
[0m14:26:15.539033 [info ] [MainThread]:   profiles.yml file [[31mERROR invalid[0m]
[0m14:26:15.539974 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m14:26:15.540952 [info ] [MainThread]: Required dependencies:
[0m14:26:15.542278 [debug] [MainThread]: Executing "git --help"
[0m14:26:15.544330 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m14:26:15.545166 [debug] [MainThread]: STDERR: "b''"
[0m14:26:15.545893 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m14:26:15.546821 [info ] [MainThread]: Connection test skipped since no profile was found
[0m14:26:15.548105 [info ] [MainThread]: [31m1 check failed:[0m
[0m14:26:15.549313 [info ] [MainThread]: Profile loading failed for the following reason:
Runtime Error
  Credentials in profile "hailing_project", target "dev" invalid: Runtime Error
    Must specify schema


[0m14:26:15.551287 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": false, "command_wall_clock_time": 0.69950664, "process_in_blocks": "0", "process_kernel_time": 0.151951, "process_mem_max_rss": "208568", "process_out_blocks": "0", "process_user_time": 2.633829}
[0m14:26:15.552334 [debug] [MainThread]: Command `dbt debug` failed at 14:26:15.552206 after 0.70 seconds
[0m14:26:15.553247 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f75c91ab110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f759b318050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f75c91d3650>]}
[0m14:26:15.554444 [debug] [MainThread]: Flushing usage events
[0m14:26:16.946074 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:29:29.422640 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5faa21f250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5faa649f50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5faa707710>]}


============================== 14:29:29.425374 | 2f11b091-eb6a-4b46-800a-11581e404d15 ==============================
[0m14:29:29.425374 [info ] [MainThread]: Running with dbt=1.9.0
[0m14:29:29.426471 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt debug', 'send_anonymous_usage_stats': 'True'}
[0m14:29:29.433368 [info ] [MainThread]: dbt version: 1.9.0
[0m14:29:29.434726 [info ] [MainThread]: python version: 3.11.2
[0m14:29:29.435933 [info ] [MainThread]: python path: /usr/local/bin/python
[0m14:29:29.437197 [info ] [MainThread]: os info: Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.31
[0m14:29:29.939045 [info ] [MainThread]: Using profiles dir at /usr/app/dbt_project
[0m14:29:29.940896 [info ] [MainThread]: Using profiles.yml file at /usr/app/dbt_project/profiles.yml
[0m14:29:29.942342 [info ] [MainThread]: Using dbt_project.yml file at /usr/app/dbt_project/dbt_project.yml
[0m14:29:29.944452 [info ] [MainThread]: adapter type: bigquery
[0m14:29:29.945675 [info ] [MainThread]: adapter version: 1.9.0
[0m14:29:30.022359 [info ] [MainThread]: Configuration:
[0m14:29:30.023588 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m14:29:30.024689 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m14:29:30.025983 [info ] [MainThread]: Required dependencies:
[0m14:29:30.027086 [debug] [MainThread]: Executing "git --help"
[0m14:29:30.029304 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m14:29:30.030025 [debug] [MainThread]: STDERR: "b''"
[0m14:29:30.030805 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m14:29:30.031710 [info ] [MainThread]: Connection:
[0m14:29:30.032809 [info ] [MainThread]:   method: service-account
[0m14:29:30.033942 [info ] [MainThread]:   database: purwadika
[0m14:29:30.035173 [info ] [MainThread]:   execution_project: purwadika
[0m14:29:30.036796 [info ] [MainThread]:   schema: rizky_dwh_hailing_staging
[0m14:29:30.038447 [info ] [MainThread]:   location: None
[0m14:29:30.039418 [info ] [MainThread]:   priority: None
[0m14:29:30.040473 [info ] [MainThread]:   maximum_bytes_billed: None
[0m14:29:30.041599 [info ] [MainThread]:   impersonate_service_account: None
[0m14:29:30.042605 [info ] [MainThread]:   job_retry_deadline_seconds: None
[0m14:29:30.043723 [info ] [MainThread]:   job_retries: 1
[0m14:29:30.045105 [info ] [MainThread]:   job_creation_timeout_seconds: None
[0m14:29:30.045954 [info ] [MainThread]:   job_execution_timeout_seconds: None
[0m14:29:30.046837 [info ] [MainThread]:   timeout_seconds: None
[0m14:29:30.047686 [info ] [MainThread]:   client_id: None
[0m14:29:30.048515 [info ] [MainThread]:   token_uri: None
[0m14:29:30.049817 [info ] [MainThread]:   dataproc_region: None
[0m14:29:30.051788 [info ] [MainThread]:   dataproc_cluster_name: None
[0m14:29:30.053108 [info ] [MainThread]:   gcs_bucket: None
[0m14:29:30.054074 [info ] [MainThread]:   dataproc_batch: None
[0m14:29:30.055292 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m14:29:30.115934 [debug] [MainThread]: Acquiring new bigquery connection 'debug'
[0m14:29:30.117019 [debug] [MainThread]: On debug: select 1 as id
[0m14:29:30.117964 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:29:30.810283 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:290e0302-7e1b-41fc-aee3-93f2d8975e93&page=queryresults
[0m14:29:31.531832 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m14:29:31.533154 [info ] [MainThread]: [32mAll checks passed![0m
[0m14:29:31.535029 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": true, "command_wall_clock_time": 2.1681876, "process_in_blocks": "0", "process_kernel_time": 0.21207, "process_mem_max_rss": "212280", "process_out_blocks": "0", "process_user_time": 2.706418}
[0m14:29:31.536240 [debug] [MainThread]: Command `dbt debug` succeeded at 14:29:31.536126 after 2.17 seconds
[0m14:29:31.537071 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m14:29:31.537834 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5faa2544d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5faa255590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5faa2248d0>]}
[0m14:29:31.538695 [debug] [MainThread]: Flushing usage events
[0m14:29:32.857047 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:29:36.352344 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb82587690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb82587310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb82586b50>]}


============================== 14:29:36.355536 | a46a4e95-cffb-45a2-9134-694d682cd294 ==============================
[0m14:29:36.355536 [info ] [MainThread]: Running with dbt=1.9.0
[0m14:29:36.356958 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'profiles_dir': '/usr/app/dbt_project', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m14:29:36.908677 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a46a4e95-cffb-45a2-9134-694d682cd294', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb58893dd0>]}
[0m14:29:36.955733 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a46a4e95-cffb-45a2-9134-694d682cd294', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb8480cdd0>]}
[0m14:29:36.957047 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m14:29:37.029382 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m14:29:37.180391 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m14:29:37.181135 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m14:29:37.188016 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.staging
- models.dbt_project.facts
[0m14:29:37.213849 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a46a4e95-cffb-45a2-9134-694d682cd294', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb59392a10>]}
[0m14:29:37.338333 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m14:29:37.343971 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m14:29:37.359163 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a46a4e95-cffb-45a2-9134-694d682cd294', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb58734a50>]}
[0m14:29:37.360429 [info ] [MainThread]: Found 5 models, 8 sources, 488 macros
[0m14:29:37.361749 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a46a4e95-cffb-45a2-9134-694d682cd294', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb5872b490>]}
[0m14:29:37.364928 [info ] [MainThread]: 
[0m14:29:37.366141 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m14:29:37.367409 [info ] [MainThread]: 
[0m14:29:37.368866 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m14:29:37.374653 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m14:29:37.375651 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:29:37.923106 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_staging)
[0m14:29:37.923943 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:29:38.204848 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a46a4e95-cffb-45a2-9134-694d682cd294', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb588339d0>]}
[0m14:29:38.205961 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:29:38.210939 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m14:29:38.211285 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m14:29:38.211609 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m14:29:38.211903 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m14:29:38.212425 [info ] [Thread-1 (]: 1 of 5 START sql incremental model rizky_dwh_hailing_staging.dim_customer ...... [RUN]
[0m14:29:38.213460 [info ] [Thread-2 (]: 2 of 5 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [RUN]
[0m14:29:38.214848 [info ] [Thread-3 (]: 3 of 5 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [RUN]
[0m14:29:38.215999 [info ] [Thread-4 (]: 4 of 5 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [RUN]
[0m14:29:38.217217 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_staging, now model.hailing_project.dim_customer)
[0m14:29:38.218193 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_customer'
[0m14:29:38.219055 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m14:29:38.219969 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m14:29:38.220918 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m14:29:38.221795 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m14:29:38.222640 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m14:29:38.223813 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m14:29:38.240471 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m14:29:38.244350 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m14:29:38.249144 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m14:29:38.252879 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m14:29:38.258222 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m14:29:38.259098 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m14:29:38.269961 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m14:29:38.295762 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m14:29:38.297909 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m14:29:38.300609 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:29:38.304126 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m14:29:38.307214 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m14:29:38.676607 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m14:29:38.680532 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m14:29:38.683295 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m14:29:38.685143 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m14:29:38.690340 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m14:29:38.693590 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m14:29:38.694271 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`dim_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`dim_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m14:29:38.695048 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m14:29:38.993599 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:e6191c3a-35f4-4ce6-a19f-a36e0fb2c684&page=queryresults
[0m14:29:38.994294 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:b622a155-ab62-4920-a7b4-5f9ed5034a89&page=queryresults
[0m14:29:38.995622 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:53a26851-6978-4058-9d0c-4adc760db68b&page=queryresults
[0m14:29:38.999240 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:46cc4866-f465-4d5b-ab90-28bae0e46c2c&page=queryresults
[0m14:29:40.556360 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a46a4e95-cffb-45a2-9134-694d682cd294', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb584925d0>]}
[0m14:29:40.557915 [info ] [Thread-4 (]: 4 of 5 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.34s]
[0m14:29:40.559831 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m14:29:40.560968 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m14:29:40.563019 [info ] [Thread-4 (]: 5 of 5 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [RUN]
[0m14:29:40.567306 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_ride, now model.hailing_project.production_hailing_staging_vehicle)
[0m14:29:40.568298 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a46a4e95-cffb-45a2-9134-694d682cd294', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb58606190>]}
[0m14:29:40.571823 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a46a4e95-cffb-45a2-9134-694d682cd294', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb833a6690>]}
[0m14:29:40.572531 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m14:29:40.575519 [info ] [Thread-1 (]: 1 of 5 OK created sql incremental model rizky_dwh_hailing_staging.dim_customer . [[32mMERGE (0.0 rows, 11.3 KiB processed)[0m in 2.35s]
[0m14:29:40.576902 [info ] [Thread-3 (]: 3 of 5 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.35s]
[0m14:29:40.581446 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m14:29:40.582659 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m14:29:40.583840 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m14:29:40.591236 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m14:29:40.594715 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m14:29:40.623376 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a46a4e95-cffb-45a2-9134-694d682cd294', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb585d3610>]}
[0m14:29:40.624546 [info ] [Thread-2 (]: 2 of 5 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.41s]
[0m14:29:40.625683 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m14:29:40.878575 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m14:29:40.884018 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m14:29:41.154707 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:ee3527dd-f162-4e8f-84b3-42fc4cf0432d&page=queryresults
[0m14:29:43.356731 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a46a4e95-cffb-45a2-9134-694d682cd294', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb590d4690>]}
[0m14:29:43.358353 [info ] [Thread-4 (]: 5 of 5 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.79s]
[0m14:29:43.359975 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m14:29:43.362132 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:29:43.364771 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:29:43.365542 [debug] [MainThread]: Connection 'model.hailing_project.dim_customer' was properly closed.
[0m14:29:43.366289 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m14:29:43.367351 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m14:29:43.368064 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m14:29:43.368876 [info ] [MainThread]: 
[0m14:29:43.369782 [info ] [MainThread]: Finished running 5 incremental models in 0 hours 0 minutes and 6.00 seconds (6.00s).
[0m14:29:43.372010 [debug] [MainThread]: Command end result
[0m14:29:43.410015 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m14:29:43.414323 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m14:29:43.422110 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m14:29:43.422841 [info ] [MainThread]: 
[0m14:29:43.423932 [info ] [MainThread]: [32mCompleted successfully[0m
[0m14:29:43.425125 [info ] [MainThread]: 
[0m14:29:43.426472 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
[0m14:29:43.428128 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 7.1249037, "process_in_blocks": "0", "process_kernel_time": 0.178991, "process_mem_max_rss": "221544", "process_out_blocks": "0", "process_user_time": 3.420732}
[0m14:29:43.429231 [debug] [MainThread]: Command `dbt run` succeeded at 14:29:43.429120 after 7.13 seconds
[0m14:29:43.430044 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb823ffbd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb823ffa50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb85da4c10>]}
[0m14:29:43.430951 [debug] [MainThread]: Flushing usage events
[0m14:29:44.732955 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:39:24.287117 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f64057f6f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f64057f6e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f64057f60d0>]}


============================== 14:39:24.289637 | 4d1bde08-f870-458f-bee7-60fdb81249dd ==============================
[0m14:39:24.289637 [info ] [MainThread]: Running with dbt=1.9.0
[0m14:39:24.291595 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt debug', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m14:39:24.298682 [info ] [MainThread]: dbt version: 1.9.0
[0m14:39:24.299908 [info ] [MainThread]: python version: 3.11.2
[0m14:39:24.301161 [info ] [MainThread]: python path: /usr/local/bin/python
[0m14:39:24.302206 [info ] [MainThread]: os info: Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.31
[0m14:39:24.858791 [info ] [MainThread]: Using profiles dir at /usr/app/dbt_project
[0m14:39:24.860248 [info ] [MainThread]: Using profiles.yml file at /usr/app/dbt_project/profiles.yml
[0m14:39:24.861535 [info ] [MainThread]: Using dbt_project.yml file at /usr/app/dbt_project/dbt_project.yml
[0m14:39:24.955245 [info ] [MainThread]: Configuration:
[0m14:39:24.956657 [info ] [MainThread]:   profiles.yml file [[31mERROR invalid[0m]
[0m14:39:24.958037 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m14:39:24.959209 [info ] [MainThread]: Required dependencies:
[0m14:39:24.960688 [debug] [MainThread]: Executing "git --help"
[0m14:39:24.963036 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m14:39:24.964514 [debug] [MainThread]: STDERR: "b''"
[0m14:39:24.965512 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m14:39:24.967090 [info ] [MainThread]: Connection test skipped since no profile was found
[0m14:39:24.969078 [info ] [MainThread]: [31m1 check failed:[0m
[0m14:39:24.970019 [info ] [MainThread]: Profile loading failed for the following reason:
Runtime Error
  Credentials in profile "hailing_project", target "dev" invalid: Runtime Error
    Must specify schema


[0m14:39:24.972285 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": false, "command_wall_clock_time": 0.7399506, "process_in_blocks": "0", "process_kernel_time": 0.191108, "process_mem_max_rss": "207272", "process_out_blocks": "0", "process_user_time": 2.625221}
[0m14:39:24.973905 [debug] [MainThread]: Command `dbt debug` failed at 14:39:24.973779 after 0.74 seconds
[0m14:39:24.975120 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6405835890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f64058471d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f63d7fe3f90>]}
[0m14:39:24.976261 [debug] [MainThread]: Flushing usage events
[0m14:39:26.925810 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:41:27.514733 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e4e92ba10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e4e928090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e4e92a850>]}


============================== 14:41:27.517375 | 1ab5ab76-602f-490b-9ba4-e7e7c6234b57 ==============================
[0m14:41:27.517375 [info ] [MainThread]: Running with dbt=1.9.0
[0m14:41:27.518559 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'version_check': 'True', 'warn_error': 'None', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m14:41:28.078596 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1ab5ab76-602f-490b-9ba4-e7e7c6234b57', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e24d97090>]}
[0m14:41:28.123474 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '1ab5ab76-602f-490b-9ba4-e7e7c6234b57', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e50bda110>]}
[0m14:41:28.124648 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m14:41:28.191751 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m14:41:28.256099 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m14:41:28.258144 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '1ab5ab76-602f-490b-9ba4-e7e7c6234b57', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e4f7502d0>]}
[0m14:41:29.243278 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.facts
- models.dbt_project.staging
[0m14:41:29.255434 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1ab5ab76-602f-490b-9ba4-e7e7c6234b57', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e24750a90>]}
[0m14:41:29.328444 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m14:41:29.336339 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m14:41:29.351793 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1ab5ab76-602f-490b-9ba4-e7e7c6234b57', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e246b8090>]}
[0m14:41:29.352794 [info ] [MainThread]: Found 5 models, 8 sources, 488 macros
[0m14:41:29.353986 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1ab5ab76-602f-490b-9ba4-e7e7c6234b57', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e2472fb10>]}
[0m14:41:29.356948 [info ] [MainThread]: 
[0m14:41:29.358117 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m14:41:29.359076 [info ] [MainThread]: 
[0m14:41:29.360125 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m14:41:29.365878 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m14:41:29.366894 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:41:30.015104 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m14:41:30.016380 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:41:30.268856 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1ab5ab76-602f-490b-9ba4-e7e7c6234b57', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e249e6610>]}
[0m14:41:30.269858 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:41:30.275109 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m14:41:30.275422 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m14:41:30.275792 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m14:41:30.276271 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m14:41:30.276782 [info ] [Thread-1 (]: 1 of 5 START sql incremental model rizky_dwh_hailing_source.dim_customer ....... [RUN]
[0m14:41:30.277887 [info ] [Thread-2 (]: 2 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [RUN]
[0m14:41:30.278934 [info ] [Thread-3 (]: 3 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [RUN]
[0m14:41:30.280098 [info ] [Thread-4 (]: 4 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [RUN]
[0m14:41:30.281426 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.dim_customer)
[0m14:41:30.282658 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_customer'
[0m14:41:30.283971 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m14:41:30.285122 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m14:41:30.286003 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m14:41:30.286904 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m14:41:30.287837 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m14:41:30.288746 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m14:41:30.300030 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m14:41:30.305399 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m14:41:30.311335 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m14:41:30.315946 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m14:41:30.322564 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m14:41:30.323895 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m14:41:30.324433 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m14:41:30.330632 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m14:41:30.384503 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:41:30.421102 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m14:41:30.422008 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m14:41:30.425105 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m14:41:30.458543 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    );
  
[0m14:41:30.459342 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    );
  
[0m14:41:30.460409 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m14:41:30.460890 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    );
  
[0m14:41:30.461908 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m14:41:30.464129 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m14:41:30.752045 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m14:41:30.760246 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`dim_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`dim_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m14:41:30.956362 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:2a1108c4-c46e-426c-918f-7f1e3964bb25&page=queryresults
[0m14:41:30.958830 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:6dbabaf5-565c-4c1b-a081-2064147f9eca&page=queryresults
[0m14:41:31.050193 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:e9b02dc5-d17e-4d21-b593-08dca78f7781&page=queryresults
[0m14:41:31.070649 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:a006c98f-8ea2-478f-9fba-2ab67e7843ff&page=queryresults
[0m14:41:32.974304 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1ab5ab76-602f-490b-9ba4-e7e7c6234b57', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e245a2610>]}
[0m14:41:32.977012 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1ab5ab76-602f-490b-9ba4-e7e7c6234b57', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e243d97d0>]}
[0m14:41:32.979339 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1ab5ab76-602f-490b-9ba4-e7e7c6234b57', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e245684d0>]}
[0m14:41:32.979865 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1ab5ab76-602f-490b-9ba4-e7e7c6234b57', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e243f8990>]}
[0m14:41:32.980551 [info ] [Thread-3 (]: 3 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [[32mCREATE TABLE (85.0 rows, 5.8 KiB processed)[0m in 2.69s]
[0m14:41:32.982156 [info ] [Thread-4 (]: 4 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [[32mCREATE TABLE (85.0 rows, 7.6 KiB processed)[0m in 2.69s]
[0m14:41:32.983923 [info ] [Thread-1 (]: 1 of 5 OK created sql incremental model rizky_dwh_hailing_source.dim_customer .. [[32mMERGE (0.0 rows, 11.3 KiB processed)[0m in 2.70s]
[0m14:41:32.985374 [info ] [Thread-2 (]: 2 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [[32mCREATE TABLE (85.0 rows, 5.8 KiB processed)[0m in 2.70s]
[0m14:41:32.986774 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m14:41:32.988471 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m14:41:32.989649 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m14:41:32.991253 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m14:41:32.992971 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m14:41:32.998152 [info ] [Thread-3 (]: 5 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [RUN]
[0m14:41:32.999891 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_driver, now model.hailing_project.production_hailing_staging_vehicle)
[0m14:41:33.001443 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m14:41:33.006309 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m14:41:33.012812 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m14:41:33.018632 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m14:41:33.026081 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    );
  
[0m14:41:33.027480 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m14:41:33.445504 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:1f406ed8-eb49-4f20-8ddb-e942fe759251&page=queryresults
[0m14:41:35.264320 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1ab5ab76-602f-490b-9ba4-e7e7c6234b57', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e24932b90>]}
[0m14:41:35.265486 [info ] [Thread-3 (]: 5 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [[32mCREATE TABLE (85.0 rows, 4.7 KiB processed)[0m in 2.26s]
[0m14:41:35.267057 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m14:41:35.269033 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:41:35.271678 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:41:35.272376 [debug] [MainThread]: Connection 'model.hailing_project.dim_customer' was properly closed.
[0m14:41:35.273053 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m14:41:35.273719 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m14:41:35.274370 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m14:41:35.275248 [info ] [MainThread]: 
[0m14:41:35.276038 [info ] [MainThread]: Finished running 5 incremental models in 0 hours 0 minutes and 5.92 seconds (5.92s).
[0m14:41:35.277979 [debug] [MainThread]: Command end result
[0m14:41:35.316914 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m14:41:35.321489 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m14:41:35.329407 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m14:41:35.330107 [info ] [MainThread]: 
[0m14:41:35.331328 [info ] [MainThread]: [32mCompleted successfully[0m
[0m14:41:35.332309 [info ] [MainThread]: 
[0m14:41:35.333263 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
[0m14:41:35.334806 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 7.873193, "process_in_blocks": "0", "process_kernel_time": 0.202649, "process_mem_max_rss": "225936", "process_out_blocks": "0", "process_user_time": 4.204975}
[0m14:41:35.335685 [debug] [MainThread]: Command `dbt run` succeeded at 14:41:35.335587 after 7.87 seconds
[0m14:41:35.336505 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e4e9a3910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e4e9a38d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e52180b90>]}
[0m14:41:35.337285 [debug] [MainThread]: Flushing usage events
[0m14:41:39.340941 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:42:33.955316 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3954b33010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3954b876d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3954f2a110>]}


============================== 14:42:33.957805 | 7970e4f3-8290-4c4b-a5ef-3d6d0e944a99 ==============================
[0m14:42:33.957805 [info ] [MainThread]: Running with dbt=1.9.0
[0m14:42:33.959086 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt debug', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m14:42:33.965750 [info ] [MainThread]: dbt version: 1.9.0
[0m14:42:33.966747 [info ] [MainThread]: python version: 3.11.2
[0m14:42:33.967883 [info ] [MainThread]: python path: /usr/local/bin/python
[0m14:42:33.969116 [info ] [MainThread]: os info: Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.31
[0m14:42:34.483275 [info ] [MainThread]: Using profiles dir at /usr/app/dbt_project
[0m14:42:34.484327 [info ] [MainThread]: Using profiles.yml file at /usr/app/dbt_project/profiles.yml
[0m14:42:34.485337 [info ] [MainThread]: Using dbt_project.yml file at /usr/app/dbt_project/dbt_project.yml
[0m14:42:34.486220 [info ] [MainThread]: adapter type: bigquery
[0m14:42:34.487264 [info ] [MainThread]: adapter version: 1.9.0
[0m14:42:34.568520 [info ] [MainThread]: Configuration:
[0m14:42:34.569983 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m14:42:34.571251 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m14:42:34.572485 [info ] [MainThread]: Required dependencies:
[0m14:42:34.573636 [debug] [MainThread]: Executing "git --help"
[0m14:42:34.575601 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m14:42:34.576629 [debug] [MainThread]: STDERR: "b''"
[0m14:42:34.577336 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m14:42:34.578412 [info ] [MainThread]: Connection:
[0m14:42:34.580167 [info ] [MainThread]:   method: service-account
[0m14:42:34.581263 [info ] [MainThread]:   database: purwadika
[0m14:42:34.582474 [info ] [MainThread]:   execution_project: purwadika
[0m14:42:34.583483 [info ] [MainThread]:   schema: rizky_dwh_hailing_source
[0m14:42:34.584372 [info ] [MainThread]:   location: None
[0m14:42:34.585600 [info ] [MainThread]:   priority: None
[0m14:42:34.586468 [info ] [MainThread]:   maximum_bytes_billed: None
[0m14:42:34.587481 [info ] [MainThread]:   impersonate_service_account: None
[0m14:42:34.588654 [info ] [MainThread]:   job_retry_deadline_seconds: None
[0m14:42:34.589956 [info ] [MainThread]:   job_retries: 1
[0m14:42:34.591000 [info ] [MainThread]:   job_creation_timeout_seconds: None
[0m14:42:34.591929 [info ] [MainThread]:   job_execution_timeout_seconds: None
[0m14:42:34.592908 [info ] [MainThread]:   timeout_seconds: None
[0m14:42:34.593914 [info ] [MainThread]:   client_id: None
[0m14:42:34.594938 [info ] [MainThread]:   token_uri: None
[0m14:42:34.596028 [info ] [MainThread]:   dataproc_region: None
[0m14:42:34.597082 [info ] [MainThread]:   dataproc_cluster_name: None
[0m14:42:34.597866 [info ] [MainThread]:   gcs_bucket: None
[0m14:42:34.598686 [info ] [MainThread]:   dataproc_batch: None
[0m14:42:34.599723 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m14:42:34.653039 [debug] [MainThread]: Acquiring new bigquery connection 'debug'
[0m14:42:34.653907 [debug] [MainThread]: On debug: select 1 as id
[0m14:42:34.654642 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:42:35.248512 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:6c69fc97-627a-49b9-b9d5-add5e35a7982&page=queryresults
[0m14:42:35.979619 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m14:42:35.980957 [info ] [MainThread]: [32mAll checks passed![0m
[0m14:42:35.982931 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": true, "command_wall_clock_time": 2.0755594, "process_in_blocks": "0", "process_kernel_time": 0.24968, "process_mem_max_rss": "212356", "process_out_blocks": "0", "process_user_time": 2.596672}
[0m14:42:35.984119 [debug] [MainThread]: Command `dbt debug` succeeded at 14:42:35.984010 after 2.08 seconds
[0m14:42:35.985022 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m14:42:35.985841 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3926c89ed0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3954b38990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3926d65250>]}
[0m14:42:35.986660 [debug] [MainThread]: Flushing usage events
[0m14:42:37.040818 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:42:40.549746 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f86b1ccbb10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f86b1d17790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f86b1d17c90>]}


============================== 14:42:40.552986 | 2281f77f-dd31-4988-95e5-7840e93cfc2a ==============================
[0m14:42:40.552986 [info ] [MainThread]: Running with dbt=1.9.0
[0m14:42:40.554644 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'invocation_command': 'dbt run', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m14:42:41.127998 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '2281f77f-dd31-4988-95e5-7840e93cfc2a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8683fd2490>]}
[0m14:42:41.179905 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '2281f77f-dd31-4988-95e5-7840e93cfc2a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f86b3f79f10>]}
[0m14:42:41.181295 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m14:42:41.256574 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m14:42:41.325508 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m14:42:41.326788 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '2281f77f-dd31-4988-95e5-7840e93cfc2a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f86b23c29d0>]}
[0m14:42:42.384260 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.staging
- models.dbt_project.facts
[0m14:42:42.395888 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2281f77f-dd31-4988-95e5-7840e93cfc2a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8683a6bd50>]}
[0m14:42:42.466669 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m14:42:42.471706 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m14:42:42.486501 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2281f77f-dd31-4988-95e5-7840e93cfc2a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f868381ff10>]}
[0m14:42:42.487569 [info ] [MainThread]: Found 5 models, 8 sources, 488 macros
[0m14:42:42.488810 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2281f77f-dd31-4988-95e5-7840e93cfc2a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8683a1c990>]}
[0m14:42:42.491688 [info ] [MainThread]: 
[0m14:42:42.492807 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m14:42:42.493976 [info ] [MainThread]: 
[0m14:42:42.495322 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m14:42:42.500514 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m14:42:42.501396 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:42:43.062063 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m14:42:43.063118 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:42:43.328266 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2281f77f-dd31-4988-95e5-7840e93cfc2a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8683e07bd0>]}
[0m14:42:43.329555 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:42:43.336748 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m14:42:43.337101 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m14:42:43.337450 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m14:42:43.337804 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m14:42:43.338529 [info ] [Thread-1 (]: 1 of 5 START sql incremental model rizky_dwh_hailing_source.dim_customer ....... [RUN]
[0m14:42:43.339589 [info ] [Thread-2 (]: 2 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [RUN]
[0m14:42:43.340835 [info ] [Thread-3 (]: 3 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [RUN]
[0m14:42:43.341909 [info ] [Thread-4 (]: 4 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [RUN]
[0m14:42:43.343005 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.dim_customer)
[0m14:42:43.344366 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_customer'
[0m14:42:43.345375 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m14:42:43.346297 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m14:42:43.347137 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m14:42:43.347863 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m14:42:43.348649 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m14:42:43.349379 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m14:42:43.358945 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m14:42:43.362771 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m14:42:43.366823 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m14:42:43.371126 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m14:42:43.377489 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m14:42:43.377973 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m14:42:43.378421 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m14:42:43.384755 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m14:42:43.430010 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:42:43.431786 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m14:42:43.435445 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m14:42:43.438533 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m14:42:43.773267 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m14:42:43.776795 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m14:42:43.778731 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m14:42:43.780214 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m14:42:43.785943 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m14:42:43.786738 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m14:42:43.787518 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`dim_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`dim_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m14:42:43.788217 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m14:42:44.103321 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:5773aacd-e50f-49e1-a3b4-874238629c29&page=queryresults
[0m14:42:44.109139 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:5e9a4fa3-b2bb-44a3-927f-1c8316d46283&page=queryresults
[0m14:42:44.113337 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:39d97e41-180b-42d9-8f69-f5bfeb9fb494&page=queryresults
[0m14:42:44.116247 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:6b297844-f6ed-45f9-b197-9f2484341fe4&page=queryresults
[0m14:42:45.685656 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2281f77f-dd31-4988-95e5-7840e93cfc2a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8683a1c450>]}
[0m14:42:45.685988 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2281f77f-dd31-4988-95e5-7840e93cfc2a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8680713a10>]}
[0m14:42:45.686474 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2281f77f-dd31-4988-95e5-7840e93cfc2a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f868384ef90>]}
[0m14:42:45.687361 [info ] [Thread-2 (]: 2 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.34s]
[0m14:42:45.689201 [info ] [Thread-1 (]: 1 of 5 OK created sql incremental model rizky_dwh_hailing_source.dim_customer .. [[32mMERGE (0.0 rows, 11.3 KiB processed)[0m in 2.34s]
[0m14:42:45.691267 [info ] [Thread-4 (]: 4 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.34s]
[0m14:42:45.694692 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m14:42:45.695497 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2281f77f-dd31-4988-95e5-7840e93cfc2a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8680742190>]}
[0m14:42:45.696429 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m14:42:45.697535 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m14:42:45.698989 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m14:42:45.700682 [info ] [Thread-3 (]: 3 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.35s]
[0m14:42:45.703647 [info ] [Thread-2 (]: 5 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [RUN]
[0m14:42:45.705210 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m14:42:45.706288 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_customer, now model.hailing_project.production_hailing_staging_vehicle)
[0m14:42:45.708011 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m14:42:45.713103 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m14:42:45.720713 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m14:42:45.724886 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m14:42:45.989530 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m14:42:45.996473 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m14:42:46.267287 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:19e22eca-e201-4a10-b740-854a1b7c82c2&page=queryresults
[0m14:42:47.909078 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2281f77f-dd31-4988-95e5-7840e93cfc2a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8680438490>]}
[0m14:42:47.910300 [info ] [Thread-2 (]: 5 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.20s]
[0m14:42:47.911976 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m14:42:47.914091 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:42:47.916832 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:42:47.917396 [debug] [MainThread]: Connection 'model.hailing_project.dim_customer' was properly closed.
[0m14:42:47.918101 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m14:42:47.918785 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m14:42:47.919804 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m14:42:47.921057 [info ] [MainThread]: 
[0m14:42:47.922357 [info ] [MainThread]: Finished running 5 incremental models in 0 hours 0 minutes and 5.43 seconds (5.43s).
[0m14:42:47.924597 [debug] [MainThread]: Command end result
[0m14:42:47.961349 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m14:42:47.965948 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m14:42:47.974054 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m14:42:47.974984 [info ] [MainThread]: 
[0m14:42:47.976122 [info ] [MainThread]: [32mCompleted successfully[0m
[0m14:42:47.977225 [info ] [MainThread]: 
[0m14:42:47.978295 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
[0m14:42:47.979911 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 7.4806395, "process_in_blocks": "0", "process_kernel_time": 0.194092, "process_mem_max_rss": "227496", "process_out_blocks": "0", "process_user_time": 4.270027}
[0m14:42:47.980941 [debug] [MainThread]: Command `dbt run` succeeded at 14:42:47.980833 after 7.48 seconds
[0m14:42:47.981730 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f86b2180410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f86b5520c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f86b567c810>]}
[0m14:42:47.982550 [debug] [MainThread]: Flushing usage events
[0m14:42:49.331309 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:46:34.643144 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc94260f950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc94265f950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc94265f690>]}


============================== 14:46:34.646101 | 10bb215d-1733-4f55-b955-b6fdf6abed54 ==============================
[0m14:46:34.646101 [info ] [MainThread]: Running with dbt=1.9.0
[0m14:46:34.648646 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt run --select production_hailing_staging_customer', 'send_anonymous_usage_stats': 'True'}
[0m14:46:35.235979 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '10bb215d-1733-4f55-b955-b6fdf6abed54', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc9189bb290>]}
[0m14:46:35.280020 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '10bb215d-1733-4f55-b955-b6fdf6abed54', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc9448c6350>]}
[0m14:46:35.281589 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m14:46:35.347515 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m14:46:35.495509 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m14:46:35.496593 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/staging/production_hailing_staging_customer.sql
[0m14:46:35.734171 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.facts
- models.dbt_project.staging
[0m14:46:35.747844 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '10bb215d-1733-4f55-b955-b6fdf6abed54', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc918926dd0>]}
[0m14:46:35.821048 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m14:46:35.827609 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m14:46:35.842488 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '10bb215d-1733-4f55-b955-b6fdf6abed54', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc91812c850>]}
[0m14:46:35.843611 [info ] [MainThread]: Found 5 models, 8 sources, 488 macros
[0m14:46:35.845147 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '10bb215d-1733-4f55-b955-b6fdf6abed54', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc91841c6d0>]}
[0m14:46:35.847284 [info ] [MainThread]: 
[0m14:46:35.848246 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m14:46:35.849196 [info ] [MainThread]: 
[0m14:46:35.850369 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m14:46:35.852144 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m14:46:35.853747 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:46:36.501205 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m14:46:36.502151 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:46:36.774661 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '10bb215d-1733-4f55-b955-b6fdf6abed54', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc9184979d0>]}
[0m14:46:36.776096 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:46:36.780975 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m14:46:36.782003 [info ] [Thread-1 (]: 1 of 1 START sql view model rizky_dwh_hailing_source.production_hailing_staging_customer  [RUN]
[0m14:46:36.783113 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.production_hailing_staging_customer)
[0m14:46:36.784347 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m14:46:36.792187 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m14:46:36.797636 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m14:46:36.814812 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:46:36.821906 [debug] [Thread-1 (]: Compilation Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  Trying to create view `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`, but it currently exists as a table. Either drop `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` manually, or run dbt with `--full-refresh` and dbt will drop it for you.
  
  > in macro bigquery__handle_existing_table (macros/materializations/view.sql)
  > called by macro handle_existing_table (macros/relations/view/replace.sql)
  > called by macro bigquery__create_or_replace_view (macros/relations/view/replace.sql)
  > called by macro materialization_view_bigquery (macros/materializations/view.sql)
  > called by model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
[0m14:46:36.823797 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '10bb215d-1733-4f55-b955-b6fdf6abed54', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc91842b0d0>]}
[0m14:46:36.825003 [error] [Thread-1 (]: 1 of 1 ERROR creating sql view model rizky_dwh_hailing_source.production_hailing_staging_customer  [[31mERROR[0m in 0.04s]
[0m14:46:36.826435 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m14:46:36.827722 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.production_hailing_staging_customer' to be skipped because of status 'error'.  Reason: Compilation Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  Trying to create view `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`, but it currently exists as a table. Either drop `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` manually, or run dbt with `--full-refresh` and dbt will drop it for you.
  
  > in macro bigquery__handle_existing_table (macros/materializations/view.sql)
  > called by macro handle_existing_table (macros/relations/view/replace.sql)
  > called by macro bigquery__create_or_replace_view (macros/relations/view/replace.sql)
  > called by macro materialization_view_bigquery (macros/materializations/view.sql)
  > called by model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql).
[0m14:46:36.830718 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:46:36.834045 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:46:36.835098 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m14:46:36.835971 [info ] [MainThread]: 
[0m14:46:36.837017 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 0.99 seconds (0.99s).
[0m14:46:36.838483 [debug] [MainThread]: Command end result
[0m14:46:36.873323 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m14:46:36.878241 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m14:46:36.886010 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m14:46:36.886847 [info ] [MainThread]: 
[0m14:46:36.887832 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m14:46:36.888965 [info ] [MainThread]: 
[0m14:46:36.889966 [error] [MainThread]:   Compilation Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  Trying to create view `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`, but it currently exists as a table. Either drop `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` manually, or run dbt with `--full-refresh` and dbt will drop it for you.
  
  > in macro bigquery__handle_existing_table (macros/materializations/view.sql)
  > called by macro handle_existing_table (macros/relations/view/replace.sql)
  > called by macro bigquery__create_or_replace_view (macros/relations/view/replace.sql)
  > called by macro materialization_view_bigquery (macros/materializations/view.sql)
  > called by model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
[0m14:46:36.891178 [info ] [MainThread]: 
[0m14:46:36.892523 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m14:46:36.894281 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 2.3020587, "process_in_blocks": "0", "process_kernel_time": 0.22278, "process_mem_max_rss": "221712", "process_out_blocks": "0", "process_user_time": 3.199941}
[0m14:46:36.895630 [debug] [MainThread]: Command `dbt run` failed at 14:46:36.895500 after 2.30 seconds
[0m14:46:36.896651 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc94266b590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc94266b6d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc945fc5210>]}
[0m14:46:36.897542 [debug] [MainThread]: Flushing usage events
[0m14:46:38.536411 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:47:13.419972 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f31975777d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3197576610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3197577190>]}


============================== 14:47:13.422506 | 1be0a91f-3376-4cd6-8758-d567c37db97e ==============================
[0m14:47:13.422506 [info ] [MainThread]: Running with dbt=1.9.0
[0m14:47:13.425036 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --select production_hailing_staging_customer', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m14:47:14.029324 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1be0a91f-3376-4cd6-8758-d567c37db97e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f31705bf210>]}
[0m14:47:14.078991 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '1be0a91f-3376-4cd6-8758-d567c37db97e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f31997ca410>]}
[0m14:47:14.080118 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m14:47:14.154922 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m14:47:14.306195 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m14:47:14.307062 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/staging/production_hailing_staging_customer.sql
[0m14:47:14.542472 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.facts
- models.dbt_project.staging
[0m14:47:14.554774 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1be0a91f-3376-4cd6-8758-d567c37db97e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f316977c710>]}
[0m14:47:14.634255 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m14:47:14.639929 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m14:47:14.653891 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1be0a91f-3376-4cd6-8758-d567c37db97e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f316977f6d0>]}
[0m14:47:14.654928 [info ] [MainThread]: Found 5 models, 8 sources, 488 macros
[0m14:47:14.656275 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1be0a91f-3376-4cd6-8758-d567c37db97e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f31693b9090>]}
[0m14:47:14.658747 [info ] [MainThread]: 
[0m14:47:14.659697 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m14:47:14.660643 [info ] [MainThread]: 
[0m14:47:14.662056 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m14:47:14.663593 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m14:47:14.664574 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:47:15.205448 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m14:47:15.206406 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:47:15.468951 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1be0a91f-3376-4cd6-8758-d567c37db97e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3169717d10>]}
[0m14:47:15.470603 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:47:15.476724 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m14:47:15.477820 [info ] [Thread-1 (]: 1 of 1 START sql view model rizky_dwh_hailing_source.production_hailing_staging_customer  [RUN]
[0m14:47:15.478928 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.production_hailing_staging_customer)
[0m14:47:15.479832 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m14:47:15.487599 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m14:47:15.498526 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m14:47:15.517220 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:47:15.522732 [debug] [Thread-1 (]: Compilation Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  Trying to create view `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`, but it currently exists as a table. Either drop `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` manually, or run dbt with `--full-refresh` and dbt will drop it for you.
  
  > in macro bigquery__handle_existing_table (macros/materializations/view.sql)
  > called by macro handle_existing_table (macros/relations/view/replace.sql)
  > called by macro bigquery__create_or_replace_view (macros/relations/view/replace.sql)
  > called by macro materialization_view_bigquery (macros/materializations/view.sql)
  > called by model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
[0m14:47:15.525099 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1be0a91f-3376-4cd6-8758-d567c37db97e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f31680b0790>]}
[0m14:47:15.526766 [error] [Thread-1 (]: 1 of 1 ERROR creating sql view model rizky_dwh_hailing_source.production_hailing_staging_customer  [[31mERROR[0m in 0.05s]
[0m14:47:15.528251 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m14:47:15.529428 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.production_hailing_staging_customer' to be skipped because of status 'error'.  Reason: Compilation Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  Trying to create view `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`, but it currently exists as a table. Either drop `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` manually, or run dbt with `--full-refresh` and dbt will drop it for you.
  
  > in macro bigquery__handle_existing_table (macros/materializations/view.sql)
  > called by macro handle_existing_table (macros/relations/view/replace.sql)
  > called by macro bigquery__create_or_replace_view (macros/relations/view/replace.sql)
  > called by macro materialization_view_bigquery (macros/materializations/view.sql)
  > called by model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql).
[0m14:47:15.531912 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:47:15.534575 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:47:15.535453 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m14:47:15.536336 [info ] [MainThread]: 
[0m14:47:15.537729 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 0.87 seconds (0.87s).
[0m14:47:15.539345 [debug] [MainThread]: Command end result
[0m14:47:15.573509 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m14:47:15.577732 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m14:47:15.586736 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m14:47:15.587483 [info ] [MainThread]: 
[0m14:47:15.588536 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m14:47:15.589544 [info ] [MainThread]: 
[0m14:47:15.590548 [error] [MainThread]:   Compilation Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  Trying to create view `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`, but it currently exists as a table. Either drop `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` manually, or run dbt with `--full-refresh` and dbt will drop it for you.
  
  > in macro bigquery__handle_existing_table (macros/materializations/view.sql)
  > called by macro handle_existing_table (macros/relations/view/replace.sql)
  > called by macro bigquery__create_or_replace_view (macros/relations/view/replace.sql)
  > called by macro materialization_view_bigquery (macros/materializations/view.sql)
  > called by model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
[0m14:47:15.591460 [info ] [MainThread]: 
[0m14:47:15.592419 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m14:47:15.593906 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 2.222357, "process_in_blocks": "0", "process_kernel_time": 0.259944, "process_mem_max_rss": "217420", "process_out_blocks": "0", "process_user_time": 3.15932}
[0m14:47:15.594895 [debug] [MainThread]: Command `dbt run` failed at 14:47:15.594777 after 2.22 seconds
[0m14:47:15.595719 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f31973f79d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f31973f74d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3197672c10>]}
[0m14:47:15.596513 [debug] [MainThread]: Flushing usage events
[0m14:47:16.591356 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:50:31.881337 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc4e510b790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc4e5deb8d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc4e510b250>]}


============================== 14:50:31.883990 | b3e5adf5-74fc-4648-b3c2-3aa6b3354be7 ==============================
[0m14:50:31.883990 [info ] [MainThread]: Running with dbt=1.9.0
[0m14:50:31.885341 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'invocation_command': 'dbt debug', 'send_anonymous_usage_stats': 'True'}
[0m14:50:31.892821 [info ] [MainThread]: dbt version: 1.9.0
[0m14:50:31.893722 [info ] [MainThread]: python version: 3.11.2
[0m14:50:31.894858 [info ] [MainThread]: python path: /usr/local/bin/python
[0m14:50:31.896687 [info ] [MainThread]: os info: Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.31
[0m14:50:32.393368 [info ] [MainThread]: Using profiles dir at /usr/app/dbt_project
[0m14:50:32.395050 [info ] [MainThread]: Using profiles.yml file at /usr/app/dbt_project/profiles.yml
[0m14:50:32.396378 [info ] [MainThread]: Using dbt_project.yml file at /usr/app/dbt_project/dbt_project.yml
[0m14:50:32.397691 [info ] [MainThread]: adapter type: bigquery
[0m14:50:32.398905 [info ] [MainThread]: adapter version: 1.9.0
[0m14:50:32.475084 [info ] [MainThread]: Configuration:
[0m14:50:32.476602 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m14:50:32.477877 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m14:50:32.478854 [info ] [MainThread]: Required dependencies:
[0m14:50:32.479822 [debug] [MainThread]: Executing "git --help"
[0m14:50:32.481705 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m14:50:32.482513 [debug] [MainThread]: STDERR: "b''"
[0m14:50:32.483225 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m14:50:32.484010 [info ] [MainThread]: Connection:
[0m14:50:32.484976 [info ] [MainThread]:   method: service-account
[0m14:50:32.486510 [info ] [MainThread]:   database: purwadika
[0m14:50:32.487548 [info ] [MainThread]:   execution_project: purwadika
[0m14:50:32.488744 [info ] [MainThread]:   schema: rizky_dwh_hailing_source
[0m14:50:32.489982 [info ] [MainThread]:   location: None
[0m14:50:32.491640 [info ] [MainThread]:   priority: None
[0m14:50:32.492722 [info ] [MainThread]:   maximum_bytes_billed: None
[0m14:50:32.493684 [info ] [MainThread]:   impersonate_service_account: None
[0m14:50:32.494489 [info ] [MainThread]:   job_retry_deadline_seconds: None
[0m14:50:32.495266 [info ] [MainThread]:   job_retries: 1
[0m14:50:32.496292 [info ] [MainThread]:   job_creation_timeout_seconds: None
[0m14:50:32.497335 [info ] [MainThread]:   job_execution_timeout_seconds: None
[0m14:50:32.498371 [info ] [MainThread]:   timeout_seconds: None
[0m14:50:32.499354 [info ] [MainThread]:   client_id: None
[0m14:50:32.500156 [info ] [MainThread]:   token_uri: None
[0m14:50:32.500928 [info ] [MainThread]:   dataproc_region: None
[0m14:50:32.501661 [info ] [MainThread]:   dataproc_cluster_name: None
[0m14:50:32.502411 [info ] [MainThread]:   gcs_bucket: None
[0m14:50:32.503861 [info ] [MainThread]:   dataproc_batch: None
[0m14:50:32.505610 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m14:50:32.559900 [debug] [MainThread]: Acquiring new bigquery connection 'debug'
[0m14:50:32.560954 [debug] [MainThread]: On debug: select 1 as id
[0m14:50:32.561751 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:50:33.230982 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:edb4007d-8964-4e9a-9c73-0df99ce9298a&page=queryresults
[0m14:50:33.942307 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m14:50:33.943287 [info ] [MainThread]: [32mAll checks passed![0m
[0m14:50:33.945212 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": true, "command_wall_clock_time": 2.1210358, "process_in_blocks": "0", "process_kernel_time": 0.230108, "process_mem_max_rss": "216508", "process_out_blocks": "0", "process_user_time": 2.601223}
[0m14:50:33.946210 [debug] [MainThread]: Command `dbt debug` succeeded at 14:50:33.946102 after 2.12 seconds
[0m14:50:33.947037 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m14:50:33.948508 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc4e4f68a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc4e4f69f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc4e89c8a90>]}
[0m14:50:33.949362 [debug] [MainThread]: Flushing usage events
[0m14:50:35.186159 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:50:54.768595 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4cf4df2d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4cf4ddb50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4cf4decd0>]}


============================== 14:50:54.771172 | a2ff1450-8af9-455b-b7b7-c38843de779b ==============================
[0m14:50:54.771172 [info ] [MainThread]: Running with dbt=1.9.0
[0m14:50:54.772869 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'version_check': 'True', 'warn_error': 'None', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'invocation_command': 'dbt run', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m14:50:55.347976 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a2ff1450-8af9-455b-b7b7-c38843de779b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4cf4e2890>]}
[0m14:50:55.395601 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a2ff1450-8af9-455b-b7b7-c38843de779b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4d17508d0>]}
[0m14:50:55.398280 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m14:50:55.470862 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m14:50:55.540272 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m14:50:55.542162 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'a2ff1450-8af9-455b-b7b7-c38843de779b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4cfbca9d0>]}
[0m14:50:56.552038 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.staging
- models.dbt_project.facts
[0m14:50:56.564091 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a2ff1450-8af9-455b-b7b7-c38843de779b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4a154a990>]}
[0m14:50:56.642957 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m14:50:56.649684 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m14:50:56.668803 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a2ff1450-8af9-455b-b7b7-c38843de779b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4a1095010>]}
[0m14:50:56.670159 [info ] [MainThread]: Found 5 models, 8 sources, 488 macros
[0m14:50:56.671451 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a2ff1450-8af9-455b-b7b7-c38843de779b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4a12a8f10>]}
[0m14:50:56.673947 [info ] [MainThread]: 
[0m14:50:56.674974 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m14:50:56.675863 [info ] [MainThread]: 
[0m14:50:56.677004 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m14:50:56.681597 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m14:50:56.682497 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:50:57.298722 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m14:50:57.299625 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:50:57.566663 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a2ff1450-8af9-455b-b7b7-c38843de779b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4a168cc90>]}
[0m14:50:57.567753 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:50:57.572072 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m14:50:57.572412 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m14:50:57.572764 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m14:50:57.573128 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m14:50:57.573719 [info ] [Thread-1 (]: 1 of 5 START sql incremental model rizky_dwh_hailing_source.dim_customer ....... [RUN]
[0m14:50:57.574624 [info ] [Thread-2 (]: 2 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [RUN]
[0m14:50:57.575822 [info ] [Thread-3 (]: 3 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [RUN]
[0m14:50:57.576846 [info ] [Thread-4 (]: 4 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [RUN]
[0m14:50:57.577924 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.dim_customer)
[0m14:50:57.578891 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_customer'
[0m14:50:57.579966 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m14:50:57.581218 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m14:50:57.582214 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m14:50:57.583027 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m14:50:57.583911 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m14:50:57.584760 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m14:50:57.596166 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m14:50:57.600889 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m14:50:57.606153 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m14:50:57.610894 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m14:50:57.617772 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m14:50:57.618726 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m14:50:57.619249 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m14:50:57.619622 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m14:50:57.669905 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m14:50:57.671635 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:50:57.675408 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m14:50:57.678254 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m14:50:58.019698 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m14:50:58.021045 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m14:50:58.022661 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m14:50:58.023629 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m14:50:58.035248 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`dim_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`dim_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m14:50:58.036042 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m14:50:58.037211 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m14:50:58.039495 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m14:50:58.346302 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:653dbe29-baba-48eb-8784-73693c6b4666&page=queryresults
[0m14:50:58.365846 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:15cf562c-c8cf-4e07-af0a-55c4c3164163&page=queryresults
[0m14:50:58.392548 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:0c820435-5b76-4a56-99a5-c26a0b59d57b&page=queryresults
[0m14:50:58.425879 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:1b5416ce-91f4-44ec-9251-0e6fa77277c5&page=queryresults
[0m14:51:00.120795 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a2ff1450-8af9-455b-b7b7-c38843de779b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4a12d0c90>]}
[0m14:51:00.122185 [info ] [Thread-1 (]: 1 of 5 OK created sql incremental model rizky_dwh_hailing_source.dim_customer .. [[32mMERGE (0.0 rows, 11.3 KiB processed)[0m in 2.54s]
[0m14:51:00.124461 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m14:51:00.125697 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m14:51:00.126766 [info ] [Thread-1 (]: 5 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [RUN]
[0m14:51:00.128248 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.hailing_project.dim_customer, now model.hailing_project.production_hailing_staging_vehicle)
[0m14:51:00.129461 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m14:51:00.134553 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m14:51:00.142681 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m14:51:00.146331 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:51:00.206349 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a2ff1450-8af9-455b-b7b7-c38843de779b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4a110a390>]}
[0m14:51:00.208020 [info ] [Thread-2 (]: 2 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.63s]
[0m14:51:00.209976 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m14:51:00.227473 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a2ff1450-8af9-455b-b7b7-c38843de779b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4a1118e10>]}
[0m14:51:00.228915 [info ] [Thread-4 (]: 4 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.65s]
[0m14:51:00.230241 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m14:51:00.259012 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a2ff1450-8af9-455b-b7b7-c38843de779b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb499708a90>]}
[0m14:51:00.260339 [info ] [Thread-3 (]: 3 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.68s]
[0m14:51:00.261845 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m14:51:00.423886 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m14:51:00.429716 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m14:51:00.688653 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:5ebc8b07-25bf-4c76-8ec9-a24216c39fa7&page=queryresults
[0m14:51:02.534480 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a2ff1450-8af9-455b-b7b7-c38843de779b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4994b84d0>]}
[0m14:51:02.535701 [info ] [Thread-1 (]: 5 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.41s]
[0m14:51:02.536817 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m14:51:02.538800 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:51:02.541334 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:51:02.542104 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m14:51:02.542780 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m14:51:02.543465 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m14:51:02.544082 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m14:51:02.544864 [info ] [MainThread]: 
[0m14:51:02.545759 [info ] [MainThread]: Finished running 5 incremental models in 0 hours 0 minutes and 5.87 seconds (5.87s).
[0m14:51:02.548010 [debug] [MainThread]: Command end result
[0m14:51:02.583241 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m14:51:02.587289 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m14:51:02.596083 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m14:51:02.596955 [info ] [MainThread]: 
[0m14:51:02.598033 [info ] [MainThread]: [32mCompleted successfully[0m
[0m14:51:02.599090 [info ] [MainThread]: 
[0m14:51:02.599997 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
[0m14:51:02.601521 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 7.883269, "process_in_blocks": "0", "process_kernel_time": 0.230647, "process_mem_max_rss": "226976", "process_out_blocks": "0", "process_user_time": 4.141631}
[0m14:51:02.602831 [debug] [MainThread]: Command `dbt run` succeeded at 14:51:02.602710 after 7.88 seconds
[0m14:51:02.603565 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4cf8d6490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4cf531790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4d2cf8c10>]}
[0m14:51:02.604321 [debug] [MainThread]: Flushing usage events
[0m14:51:03.893149 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:10:36.327408 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2482e27b10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2482e249d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2482e26750>]}


============================== 02:10:36.331818 | d683627a-ccec-461c-99fa-e11171d0a5eb ==============================
[0m02:10:36.331818 [info ] [MainThread]: Running with dbt=1.9.0
[0m02:10:36.333274 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt debug', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m02:10:36.355487 [info ] [MainThread]: dbt version: 1.9.0
[0m02:10:36.357902 [info ] [MainThread]: python version: 3.11.2
[0m02:10:36.359103 [info ] [MainThread]: python path: /usr/local/bin/python
[0m02:10:36.360458 [info ] [MainThread]: os info: Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.31
[0m02:10:36.879415 [info ] [MainThread]: Using profiles dir at /usr/app/dbt_project
[0m02:10:36.880613 [info ] [MainThread]: Using profiles.yml file at /usr/app/dbt_project/profiles.yml
[0m02:10:36.881827 [info ] [MainThread]: Using dbt_project.yml file at /usr/app/dbt_project/dbt_project.yml
[0m02:10:36.884156 [info ] [MainThread]: adapter type: bigquery
[0m02:10:36.885808 [info ] [MainThread]: adapter version: 1.9.0
[0m02:10:36.965652 [info ] [MainThread]: Configuration:
[0m02:10:36.966885 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m02:10:36.968124 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m02:10:36.969337 [info ] [MainThread]: Required dependencies:
[0m02:10:36.970294 [debug] [MainThread]: Executing "git --help"
[0m02:10:36.987016 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m02:10:36.987826 [debug] [MainThread]: STDERR: "b''"
[0m02:10:36.988603 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m02:10:36.990094 [info ] [MainThread]: Connection:
[0m02:10:36.991000 [info ] [MainThread]:   method: service-account
[0m02:10:36.992036 [info ] [MainThread]:   database: purwadika
[0m02:10:36.993070 [info ] [MainThread]:   execution_project: purwadika
[0m02:10:36.994054 [info ] [MainThread]:   schema: rizky_dwh_hailing_source
[0m02:10:36.995241 [info ] [MainThread]:   location: None
[0m02:10:36.996224 [info ] [MainThread]:   priority: None
[0m02:10:36.997617 [info ] [MainThread]:   maximum_bytes_billed: None
[0m02:10:36.998830 [info ] [MainThread]:   impersonate_service_account: None
[0m02:10:36.999798 [info ] [MainThread]:   job_retry_deadline_seconds: None
[0m02:10:37.001099 [info ] [MainThread]:   job_retries: 1
[0m02:10:37.002331 [info ] [MainThread]:   job_creation_timeout_seconds: None
[0m02:10:37.003954 [info ] [MainThread]:   job_execution_timeout_seconds: None
[0m02:10:37.005128 [info ] [MainThread]:   timeout_seconds: None
[0m02:10:37.006228 [info ] [MainThread]:   client_id: None
[0m02:10:37.007089 [info ] [MainThread]:   token_uri: None
[0m02:10:37.008181 [info ] [MainThread]:   dataproc_region: None
[0m02:10:37.009223 [info ] [MainThread]:   dataproc_cluster_name: None
[0m02:10:37.010146 [info ] [MainThread]:   gcs_bucket: None
[0m02:10:37.011074 [info ] [MainThread]:   dataproc_batch: None
[0m02:10:37.012145 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m02:10:37.080429 [debug] [MainThread]: Acquiring new bigquery connection 'debug'
[0m02:10:37.081249 [debug] [MainThread]: On debug: select 1 as id
[0m02:10:37.082051 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:10:37.943055 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:aed2efae-e88a-4be5-a10a-1eaea2225369&page=queryresults
[0m02:10:38.697288 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m02:10:38.698914 [info ] [MainThread]: [32mAll checks passed![0m
[0m02:10:38.701888 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": true, "command_wall_clock_time": 2.4557347, "process_in_blocks": "5472", "process_kernel_time": 0.195529, "process_mem_max_rss": "212456", "process_out_blocks": "0", "process_user_time": 2.737414}
[0m02:10:38.703633 [debug] [MainThread]: Command `dbt debug` succeeded at 02:10:38.703511 after 2.46 seconds
[0m02:10:38.704529 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m02:10:38.705303 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2482e80b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2482e82050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f245904fa50>]}
[0m02:10:38.706118 [debug] [MainThread]: Flushing usage events
[0m02:10:39.799106 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:10:44.164395 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f13f1adb650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f13f1b23190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f13f1adb690>]}


============================== 02:10:44.166871 | 6cc69579-6e6d-44ad-9f90-9aa357bf3902 ==============================
[0m02:10:44.166871 [info ] [MainThread]: Running with dbt=1.9.0
[0m02:10:44.169732 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m02:10:44.734717 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '6cc69579-6e6d-44ad-9f90-9aa357bf3902', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f13f1b48350>]}
[0m02:10:44.780136 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '6cc69579-6e6d-44ad-9f90-9aa357bf3902', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f13f3d65750>]}
[0m02:10:44.781355 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m02:10:44.850621 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m02:10:45.067420 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m02:10:45.068373 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m02:10:45.073284 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.facts
- models.dbt_project.staging
[0m02:10:45.098604 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '6cc69579-6e6d-44ad-9f90-9aa357bf3902', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f13c3c12850>]}
[0m02:10:45.210696 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m02:10:45.216055 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m02:10:45.235108 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '6cc69579-6e6d-44ad-9f90-9aa357bf3902', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f13c3ddcf50>]}
[0m02:10:45.236311 [info ] [MainThread]: Found 5 models, 8 sources, 488 macros
[0m02:10:45.237569 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6cc69579-6e6d-44ad-9f90-9aa357bf3902', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f13c3932e10>]}
[0m02:10:45.240423 [info ] [MainThread]: 
[0m02:10:45.241538 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m02:10:45.242521 [info ] [MainThread]: 
[0m02:10:45.243961 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m02:10:45.248991 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m02:10:45.250022 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:10:45.772081 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m02:10:45.773862 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:10:45.990344 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6cc69579-6e6d-44ad-9f90-9aa357bf3902', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f13c82c4d50>]}
[0m02:10:45.991979 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:10:45.997879 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m02:10:45.998273 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m02:10:45.998632 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m02:10:45.998978 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m02:10:45.999511 [info ] [Thread-1 (]: 1 of 5 START sql incremental model rizky_dwh_hailing_source.dim_customer ....... [RUN]
[0m02:10:46.001280 [info ] [Thread-2 (]: 2 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [RUN]
[0m02:10:46.002507 [info ] [Thread-3 (]: 3 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [RUN]
[0m02:10:46.003812 [info ] [Thread-4 (]: 4 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [RUN]
[0m02:10:46.004978 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.dim_customer)
[0m02:10:46.006306 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_customer'
[0m02:10:46.007506 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m02:10:46.008588 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m02:10:46.009494 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m02:10:46.010789 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m02:10:46.012257 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m02:10:46.013260 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m02:10:46.029001 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m02:10:46.032676 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m02:10:46.036766 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m02:10:46.040937 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m02:10:46.047586 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m02:10:46.048234 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m02:10:46.054578 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m02:10:46.085718 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m02:10:46.093141 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m02:10:46.091023 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m02:10:46.095938 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m02:10:46.099475 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m02:10:46.394885 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m02:10:46.396477 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m02:10:46.398574 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m02:10:46.400131 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m02:10:46.406476 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m02:10:46.407392 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`dim_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`dim_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m02:10:46.412233 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m02:10:46.412983 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m02:10:47.026423 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:97f542b5-c20a-4f56-8be0-dd569945bdf7&page=queryresults
[0m02:10:47.261321 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:edf8b36f-16ae-4b86-8569-87beee01ab72&page=queryresults
[0m02:10:48.093517 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:348cc37a-3fb9-4377-81ec-724d61041f50&page=queryresults
[0m02:10:48.115214 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:516daaca-7943-49dd-972f-b15167e3b04b&page=queryresults
[0m02:10:48.704391 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6cc69579-6e6d-44ad-9f90-9aa357bf3902', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f13c38b7790>]}
[0m02:10:48.705596 [info ] [Thread-2 (]: 2 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.70s]
[0m02:10:48.707436 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m02:10:48.708806 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m02:10:48.710204 [info ] [Thread-2 (]: 5 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [RUN]
[0m02:10:48.711541 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_customer, now model.hailing_project.production_hailing_staging_vehicle)
[0m02:10:48.712519 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m02:10:48.717317 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m02:10:48.726097 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m02:10:48.729952 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m02:10:48.933726 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6cc69579-6e6d-44ad-9f90-9aa357bf3902', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f13c3bc3090>]}
[0m02:10:48.935218 [info ] [Thread-1 (]: 1 of 5 OK created sql incremental model rizky_dwh_hailing_source.dim_customer .. [[32mMERGE (0.0 rows, 11.3 KiB processed)[0m in 2.93s]
[0m02:10:48.936492 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m02:10:48.958160 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m02:10:48.967754 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m02:10:49.647248 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6cc69579-6e6d-44ad-9f90-9aa357bf3902', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f13c3823210>]}
[0m02:10:49.649361 [info ] [Thread-3 (]: 3 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 3.64s]
[0m02:10:49.651702 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m02:10:49.752537 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6cc69579-6e6d-44ad-9f90-9aa357bf3902', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f13c393c790>]}
[0m02:10:49.755418 [info ] [Thread-4 (]: 4 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 3.74s]
[0m02:10:49.758460 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m02:10:50.410219 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:f2a91f00-3156-460a-b32c-f53813cf18f2&page=queryresults
[0m02:10:52.324193 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6cc69579-6e6d-44ad-9f90-9aa357bf3902', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f13c043aad0>]}
[0m02:10:52.325590 [info ] [Thread-2 (]: 5 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 3.61s]
[0m02:10:52.329077 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m02:10:52.331875 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m02:10:52.334793 [debug] [MainThread]: Connection 'master' was properly closed.
[0m02:10:52.335477 [debug] [MainThread]: Connection 'model.hailing_project.dim_customer' was properly closed.
[0m02:10:52.336234 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m02:10:52.336905 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m02:10:52.337675 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m02:10:52.338445 [info ] [MainThread]: 
[0m02:10:52.339365 [info ] [MainThread]: Finished running 5 incremental models in 0 hours 0 minutes and 7.09 seconds (7.09s).
[0m02:10:52.341160 [debug] [MainThread]: Command end result
[0m02:10:52.378407 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m02:10:52.382634 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m02:10:52.391396 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m02:10:52.392173 [info ] [MainThread]: 
[0m02:10:52.393233 [info ] [MainThread]: [32mCompleted successfully[0m
[0m02:10:52.394350 [info ] [MainThread]: 
[0m02:10:52.395359 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
[0m02:10:52.396922 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 8.279099, "process_in_blocks": "3584", "process_kernel_time": 0.182669, "process_mem_max_rss": "221620", "process_out_blocks": "0", "process_user_time": 3.328637}
[0m02:10:52.397999 [debug] [MainThread]: Command `dbt run` succeeded at 02:10:52.397893 after 8.28 seconds
[0m02:10:52.398892 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f13f52d4b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f13f5459290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f13f5458950>]}
[0m02:10:52.399858 [debug] [MainThread]: Flushing usage events
[0m02:10:53.905083 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:11:26.029856 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3b340b2f90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3b34107610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3b34107210>]}


============================== 02:11:26.032427 | acd78ac1-732e-43b5-bb85-054270dab60f ==============================
[0m02:11:26.032427 [info ] [MainThread]: Running with dbt=1.9.0
[0m02:11:26.034673 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'log_format': 'default', 'invocation_command': 'dbt run', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m02:11:26.605387 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'acd78ac1-732e-43b5-bb85-054270dab60f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3b0cceedd0>]}
[0m02:11:26.648528 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'acd78ac1-732e-43b5-bb85-054270dab60f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3b36364ad0>]}
[0m02:11:26.650015 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m02:11:26.718735 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m02:11:26.786920 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m02:11:26.788731 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'acd78ac1-732e-43b5-bb85-054270dab60f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3b347aa8d0>]}
[0m02:11:27.751780 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.facts
- models.dbt_project.staging
[0m02:11:27.763809 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'acd78ac1-732e-43b5-bb85-054270dab60f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3b340caf10>]}
[0m02:11:27.848547 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m02:11:27.854500 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m02:11:27.872513 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'acd78ac1-732e-43b5-bb85-054270dab60f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3b05ca7f10>]}
[0m02:11:27.873852 [info ] [MainThread]: Found 5 models, 8 sources, 488 macros
[0m02:11:27.875350 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'acd78ac1-732e-43b5-bb85-054270dab60f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3b05ec7dd0>]}
[0m02:11:27.878443 [info ] [MainThread]: 
[0m02:11:27.879542 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m02:11:27.880441 [info ] [MainThread]: 
[0m02:11:27.881890 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m02:11:27.887380 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m02:11:27.888707 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:11:28.365102 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_staging)
[0m02:11:28.366511 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:11:28.564972 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'acd78ac1-732e-43b5-bb85-054270dab60f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3b060a46d0>]}
[0m02:11:28.565930 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:11:28.571444 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m02:11:28.571822 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m02:11:28.572173 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m02:11:28.572645 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m02:11:28.573300 [info ] [Thread-1 (]: 1 of 5 START sql incremental model rizky_dwh_hailing_staging.dim_customer ...... [RUN]
[0m02:11:28.574733 [info ] [Thread-2 (]: 2 of 5 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [RUN]
[0m02:11:28.575842 [info ] [Thread-3 (]: 3 of 5 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [RUN]
[0m02:11:28.577025 [info ] [Thread-4 (]: 4 of 5 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [RUN]
[0m02:11:28.578565 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_staging, now model.hailing_project.dim_customer)
[0m02:11:28.579483 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_customer'
[0m02:11:28.580690 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m02:11:28.581655 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m02:11:28.582422 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m02:11:28.583915 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m02:11:28.584852 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m02:11:28.585937 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m02:11:28.595584 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m02:11:28.599484 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m02:11:28.603628 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m02:11:28.608668 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m02:11:28.614559 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m02:11:28.615166 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m02:11:28.615843 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m02:11:28.627263 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m02:11:28.661050 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m02:11:28.663494 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m02:11:28.667176 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m02:11:28.670148 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m02:11:28.907828 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m02:11:28.916335 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`dim_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`dim_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m02:11:28.922643 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m02:11:28.930223 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m02:11:28.934048 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m02:11:28.939484 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m02:11:28.945347 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m02:11:28.950906 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m02:11:29.180886 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:9b3ac838-edc7-4a9b-878a-7d7dd9c123da&page=queryresults
[0m02:11:29.205660 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:2b1f2ec2-b9c6-4638-8c80-93f16e43ffeb&page=queryresults
[0m02:11:29.447817 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:da128dcd-5b2b-44d6-ad12-7aeca859fa95&page=queryresults
[0m02:11:29.472117 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:857ee306-e1d0-4552-8e74-3366d31ba073&page=queryresults
[0m02:11:30.783971 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'acd78ac1-732e-43b5-bb85-054270dab60f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3b05cecf90>]}
[0m02:11:30.785192 [info ] [Thread-4 (]: 4 of 5 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.20s]
[0m02:11:30.786612 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m02:11:30.787740 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m02:11:30.788724 [info ] [Thread-4 (]: 5 of 5 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [RUN]
[0m02:11:30.789865 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_ride, now model.hailing_project.production_hailing_staging_vehicle)
[0m02:11:30.790637 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m02:11:30.794638 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m02:11:30.801996 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m02:11:30.806809 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m02:11:30.958975 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'acd78ac1-732e-43b5-bb85-054270dab60f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3b040eaf10>]}
[0m02:11:30.960314 [info ] [Thread-2 (]: 2 of 5 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.38s]
[0m02:11:30.961751 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m02:11:31.033659 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'acd78ac1-732e-43b5-bb85-054270dab60f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3b05ccfe90>]}
[0m02:11:31.035394 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m02:11:31.036405 [info ] [Thread-3 (]: 3 of 5 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.45s]
[0m02:11:31.038500 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m02:11:31.043590 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m02:11:31.237824 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'acd78ac1-732e-43b5-bb85-054270dab60f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3b06086350>]}
[0m02:11:31.239061 [info ] [Thread-1 (]: 1 of 5 OK created sql incremental model rizky_dwh_hailing_staging.dim_customer . [[32mMERGE (0.0 rows, 11.3 KiB processed)[0m in 2.66s]
[0m02:11:31.240466 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m02:11:32.450687 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:14f79502-e60f-4ca8-96de-9ee4ed5415d7&page=queryresults
[0m02:11:34.278562 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'acd78ac1-732e-43b5-bb85-054270dab60f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3b05d010d0>]}
[0m02:11:34.279944 [info ] [Thread-4 (]: 5 of 5 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 3.49s]
[0m02:11:34.281758 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m02:11:34.284269 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m02:11:34.287412 [debug] [MainThread]: Connection 'master' was properly closed.
[0m02:11:34.288108 [debug] [MainThread]: Connection 'model.hailing_project.dim_customer' was properly closed.
[0m02:11:34.288894 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m02:11:34.289603 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m02:11:34.290298 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m02:11:34.291040 [info ] [MainThread]: 
[0m02:11:34.292262 [info ] [MainThread]: Finished running 5 incremental models in 0 hours 0 minutes and 6.41 seconds (6.41s).
[0m02:11:34.294364 [debug] [MainThread]: Command end result
[0m02:11:34.330217 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m02:11:34.334943 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m02:11:34.343244 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m02:11:34.343997 [info ] [MainThread]: 
[0m02:11:34.345006 [info ] [MainThread]: [32mCompleted successfully[0m
[0m02:11:34.346255 [info ] [MainThread]: 
[0m02:11:34.347173 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
[0m02:11:34.349281 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 8.365765, "process_in_blocks": "280", "process_kernel_time": 0.133668, "process_mem_max_rss": "227792", "process_out_blocks": "0", "process_user_time": 4.195144}
[0m02:11:34.350498 [debug] [MainThread]: Command `dbt run` succeeded at 02:11:34.350381 after 8.37 seconds
[0m02:11:34.351300 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3b3412f650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3b3412f6d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3b378e4c90>]}
[0m02:11:34.352143 [debug] [MainThread]: Flushing usage events
[0m02:11:35.637233 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:17:21.570401 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe67c2b7910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe67c6b2310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe67c2b6dd0>]}


============================== 02:17:21.574868 | 2ad818e6-6b33-45ee-8245-97c605127d51 ==============================
[0m02:17:21.574868 [info ] [MainThread]: Running with dbt=1.9.0
[0m02:17:21.576814 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt run', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m02:17:22.148150 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '2ad818e6-6b33-45ee-8245-97c605127d51', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe64e5fae50>]}
[0m02:17:22.194118 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '2ad818e6-6b33-45ee-8245-97c605127d51', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe67e52c990>]}
[0m02:17:22.195445 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m02:17:22.271832 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m02:17:22.339175 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m02:17:22.340418 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '2ad818e6-6b33-45ee-8245-97c605127d51', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe64e5bf3d0>]}
[0m02:17:23.350994 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.staging
- models.dbt_project.facts
[0m02:17:23.363854 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2ad818e6-6b33-45ee-8245-97c605127d51', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe64e5baed0>]}
[0m02:17:23.438461 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m02:17:23.443073 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m02:17:23.457865 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2ad818e6-6b33-45ee-8245-97c605127d51', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe64de93e90>]}
[0m02:17:23.458822 [info ] [MainThread]: Found 5 models, 8 sources, 488 macros
[0m02:17:23.459851 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2ad818e6-6b33-45ee-8245-97c605127d51', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe64dead1d0>]}
[0m02:17:23.462538 [info ] [MainThread]: 
[0m02:17:23.463795 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m02:17:23.464760 [info ] [MainThread]: 
[0m02:17:23.466074 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m02:17:23.470704 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m02:17:23.471538 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m02:17:23.472387 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:17:23.473173 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:17:24.452552 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now create_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_staging)
[0m02:17:24.453512 [debug] [ThreadPool]: Creating schema "database: "purwadika"
schema: "rizky_dwh_hailing_source_rizky_dwh_hailing_staging"
"
[0m02:17:24.461943 [debug] [ThreadPool]: On create_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_staging: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "connection_name": "create_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_staging"} */
create schema if not exists `purwadika`.`rizky_dwh_hailing_source_rizky_dwh_hailing_staging`
  
[0m02:17:24.462958 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:17:25.300177 [debug] [ThreadPool]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:45fe1c4b-cacd-494b-a720-a16137bf7142&page=queryresults
[0m02:17:26.222842 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_staging, now list_purwadika_rizky_dwh_hailing_source)
[0m02:17:26.223391 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_staging)
[0m02:17:26.224250 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:17:26.225212 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:17:26.801546 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2ad818e6-6b33-45ee-8245-97c605127d51', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe64e221ad0>]}
[0m02:17:26.802647 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:17:26.808812 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m02:17:26.809204 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m02:17:26.809561 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m02:17:26.810064 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m02:17:26.810719 [info ] [Thread-1 (]: 1 of 5 START sql incremental model rizky_dwh_hailing_source.dim_customer ....... [RUN]
[0m02:17:26.811927 [info ] [Thread-2 (]: 2 of 5 START sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_staging.production_hailing_staging_customer  [RUN]
[0m02:17:26.812867 [info ] [Thread-3 (]: 3 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [RUN]
[0m02:17:26.814108 [info ] [Thread-4 (]: 4 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [RUN]
[0m02:17:26.815240 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_staging, now model.hailing_project.dim_customer)
[0m02:17:26.816128 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.production_hailing_staging_customer)
[0m02:17:26.817162 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m02:17:26.818097 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m02:17:26.819009 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m02:17:26.819888 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m02:17:26.820721 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m02:17:26.821580 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m02:17:26.831860 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m02:17:26.835845 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m02:17:26.840509 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m02:17:26.844729 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m02:17:26.852817 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m02:17:26.853415 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m02:17:26.853872 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m02:17:26.859947 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m02:17:26.914765 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m02:17:26.928693 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m02:17:26.939838 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m02:17:26.943765 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m02:17:26.997636 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source_rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    );
  
[0m02:17:27.021971 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m02:17:27.251443 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m02:17:27.253090 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m02:17:27.255411 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m02:17:27.259881 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`dim_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`dim_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m02:17:27.260524 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m02:17:27.262658 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m02:17:27.318014 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:4e14d9fa-306e-4d77-b311-56c17f51f967&page=queryresults
[0m02:17:27.319142 [error] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:4e14d9fa-306e-4d77-b311-56c17f51f967&page=queryresults
[0m02:17:27.328956 [debug] [Thread-2 (]: Database Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_customer.sql
[0m02:17:27.331529 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2ad818e6-6b33-45ee-8245-97c605127d51', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe64cb8bd10>]}
[0m02:17:27.332655 [error] [Thread-2 (]: 2 of 5 ERROR creating sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_staging.production_hailing_staging_customer  [[31mERROR[0m in 0.51s]
[0m02:17:27.334014 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m02:17:27.335243 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m02:17:27.335805 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.production_hailing_staging_customer' to be skipped because of status 'error'.  Reason: Database Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_customer.sql.
[0m02:17:27.337093 [info ] [Thread-2 (]: 5 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [RUN]
[0m02:17:27.339886 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_customer, now model.hailing_project.production_hailing_staging_vehicle)
[0m02:17:27.341035 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m02:17:27.346598 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m02:17:27.352865 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m02:17:27.356838 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m02:17:27.516994 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:6416c4d4-4122-4f19-a380-d451daf20cfe&page=queryresults
[0m02:17:27.553366 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:27e3f992-a965-4bc2-ae0c-85a9486e25e8&page=queryresults
[0m02:17:27.587210 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m02:17:27.595234 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m02:17:27.810163 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:797c2fb9-38d1-43ce-bd63-635de56c8ff0&page=queryresults
[0m02:17:28.979978 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:14146503-2cf8-46f9-970a-d1644d6219dd&page=queryresults
[0m02:17:29.045941 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2ad818e6-6b33-45ee-8245-97c605127d51', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe64c01dd50>]}
[0m02:17:29.047816 [info ] [Thread-1 (]: 1 of 5 OK created sql incremental model rizky_dwh_hailing_source.dim_customer .. [[32mMERGE (0.0 rows, 11.3 KiB processed)[0m in 2.23s]
[0m02:17:29.049669 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m02:17:29.163170 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2ad818e6-6b33-45ee-8245-97c605127d51', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe64caf5450>]}
[0m02:17:29.164750 [info ] [Thread-4 (]: 4 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.35s]
[0m02:17:29.167497 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m02:17:29.343190 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2ad818e6-6b33-45ee-8245-97c605127d51', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe64cae3e10>]}
[0m02:17:29.344746 [info ] [Thread-3 (]: 3 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.53s]
[0m02:17:29.346137 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m02:17:30.522977 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2ad818e6-6b33-45ee-8245-97c605127d51', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe64ca188d0>]}
[0m02:17:30.524276 [info ] [Thread-2 (]: 5 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 3.18s]
[0m02:17:30.525409 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m02:17:30.527454 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m02:17:30.529826 [debug] [MainThread]: Connection 'master' was properly closed.
[0m02:17:30.530530 [debug] [MainThread]: Connection 'model.hailing_project.dim_customer' was properly closed.
[0m02:17:30.531328 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m02:17:30.531991 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m02:17:30.532574 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m02:17:30.533368 [info ] [MainThread]: 
[0m02:17:30.534169 [info ] [MainThread]: Finished running 5 incremental models in 0 hours 0 minutes and 7.07 seconds (7.07s).
[0m02:17:30.535979 [debug] [MainThread]: Command end result
[0m02:17:30.568403 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m02:17:30.572391 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m02:17:30.582117 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m02:17:30.583405 [info ] [MainThread]: 
[0m02:17:30.584508 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m02:17:30.585615 [info ] [MainThread]: 
[0m02:17:30.586726 [error] [MainThread]:   Database Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_customer.sql
[0m02:17:30.587926 [info ] [MainThread]: 
[0m02:17:30.588973 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=0 TOTAL=5
[0m02:17:30.590472 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 9.094556, "process_in_blocks": "576", "process_kernel_time": 0.22974, "process_mem_max_rss": "227476", "process_out_blocks": "0", "process_user_time": 4.315124}
[0m02:17:30.591569 [debug] [MainThread]: Command `dbt run` failed at 02:17:30.591452 after 9.10 seconds
[0m02:17:30.592399 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe67c2ea410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe67fc31390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe67fc30a10>]}
[0m02:17:30.593572 [debug] [MainThread]: Flushing usage events
[0m02:17:32.282315 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:22:34.102459 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faf8518b0d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faf85663950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faf85582650>]}


============================== 02:22:34.104859 | 9ca4a319-9d6f-472b-8715-0f7a75b2772a ==============================
[0m02:22:34.104859 [info ] [MainThread]: Running with dbt=1.9.0
[0m02:22:34.106676 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt debug', 'send_anonymous_usage_stats': 'True'}
[0m02:22:34.118936 [info ] [MainThread]: dbt version: 1.9.0
[0m02:22:34.120184 [info ] [MainThread]: python version: 3.11.2
[0m02:22:34.121137 [info ] [MainThread]: python path: /usr/local/bin/python
[0m02:22:34.122513 [info ] [MainThread]: os info: Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.31
[0m02:22:34.630392 [info ] [MainThread]: Using profiles dir at /usr/app/dbt_project
[0m02:22:34.631396 [info ] [MainThread]: Using profiles.yml file at /usr/app/dbt_project/profiles.yml
[0m02:22:34.632228 [info ] [MainThread]: Using dbt_project.yml file at /usr/app/dbt_project/dbt_project.yml
[0m02:22:34.632996 [info ] [MainThread]: adapter type: bigquery
[0m02:22:34.633809 [info ] [MainThread]: adapter version: 1.9.0
[0m02:22:34.708842 [info ] [MainThread]: Configuration:
[0m02:22:34.709922 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m02:22:34.710951 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m02:22:34.711943 [info ] [MainThread]: Required dependencies:
[0m02:22:34.712933 [debug] [MainThread]: Executing "git --help"
[0m02:22:34.715500 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m02:22:34.716329 [debug] [MainThread]: STDERR: "b''"
[0m02:22:34.717111 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m02:22:34.718084 [info ] [MainThread]: Connection:
[0m02:22:34.719179 [info ] [MainThread]:   method: service-account
[0m02:22:34.720307 [info ] [MainThread]:   database: purwadika
[0m02:22:34.721375 [info ] [MainThread]:   execution_project: purwadika
[0m02:22:34.722323 [info ] [MainThread]:   schema: rizky_dwh_hailing_source
[0m02:22:34.723139 [info ] [MainThread]:   location: None
[0m02:22:34.724089 [info ] [MainThread]:   priority: None
[0m02:22:34.725459 [info ] [MainThread]:   maximum_bytes_billed: None
[0m02:22:34.728646 [info ] [MainThread]:   impersonate_service_account: None
[0m02:22:34.730620 [info ] [MainThread]:   job_retry_deadline_seconds: None
[0m02:22:34.732770 [info ] [MainThread]:   job_retries: 1
[0m02:22:34.734752 [info ] [MainThread]:   job_creation_timeout_seconds: None
[0m02:22:34.736236 [info ] [MainThread]:   job_execution_timeout_seconds: None
[0m02:22:34.738268 [info ] [MainThread]:   timeout_seconds: None
[0m02:22:34.740278 [info ] [MainThread]:   client_id: None
[0m02:22:34.742060 [info ] [MainThread]:   token_uri: None
[0m02:22:34.744104 [info ] [MainThread]:   dataproc_region: None
[0m02:22:34.745413 [info ] [MainThread]:   dataproc_cluster_name: None
[0m02:22:34.746691 [info ] [MainThread]:   gcs_bucket: None
[0m02:22:34.748000 [info ] [MainThread]:   dataproc_batch: None
[0m02:22:34.750047 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m02:22:34.807477 [debug] [MainThread]: Acquiring new bigquery connection 'debug'
[0m02:22:34.808411 [debug] [MainThread]: On debug: select 1 as id
[0m02:22:34.809154 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:22:35.515508 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:c5cf89fd-cf71-4cdf-ac70-2d829ca6deda&page=queryresults
[0m02:22:36.332109 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m02:22:36.334707 [info ] [MainThread]: [32mAll checks passed![0m
[0m02:22:36.336755 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": true, "command_wall_clock_time": 2.280742, "process_in_blocks": "0", "process_kernel_time": 0.236359, "process_mem_max_rss": "214436", "process_out_blocks": "0", "process_user_time": 2.630787}
[0m02:22:36.337760 [debug] [MainThread]: Command `dbt debug` succeeded at 02:22:36.337637 after 2.28 seconds
[0m02:22:36.338763 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m02:22:36.339911 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faf572c6190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faf85580250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faf8897cc10>]}
[0m02:22:36.340768 [debug] [MainThread]: Flushing usage events
[0m02:22:37.698431 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:22:42.902639 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f38545f7090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f38545f71d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f38545f6fd0>]}


============================== 02:22:42.905224 | 03293c56-7bcb-4733-8ab2-56343b3cd326 ==============================
[0m02:22:42.905224 [info ] [MainThread]: Running with dbt=1.9.0
[0m02:22:42.906544 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'version_check': 'True', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt compile', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m02:22:43.464239 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '03293c56-7bcb-4733-8ab2-56343b3cd326', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f382677e290>]}
[0m02:22:43.508034 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '03293c56-7bcb-4733-8ab2-56343b3cd326', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f38269e8f10>]}
[0m02:22:43.509341 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m02:22:43.577778 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m02:22:43.761872 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m02:22:43.762785 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m02:22:43.767413 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.staging
- models.dbt_project.facts
[0m02:22:43.790618 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '03293c56-7bcb-4733-8ab2-56343b3cd326', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f382cc64f90>]}
[0m02:22:43.907492 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m02:22:43.912726 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m02:22:43.927689 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '03293c56-7bcb-4733-8ab2-56343b3cd326', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3826914590>]}
[0m02:22:43.928856 [info ] [MainThread]: Found 5 models, 8 sources, 488 macros
[0m02:22:43.929933 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '03293c56-7bcb-4733-8ab2-56343b3cd326', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f382ccab3d0>]}
[0m02:22:43.932569 [info ] [MainThread]: 
[0m02:22:43.933665 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m02:22:43.934659 [info ] [MainThread]: 
[0m02:22:43.935809 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m02:22:43.940170 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_source'
[0m02:22:43.940914 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_staging'
[0m02:22:43.941785 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:22:43.942738 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:22:44.488578 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '03293c56-7bcb-4733-8ab2-56343b3cd326', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f38268e4790>]}
[0m02:22:44.489537 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:22:44.495060 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m02:22:44.495409 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m02:22:44.495780 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m02:22:44.496144 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m02:22:44.497135 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_staging, now model.hailing_project.dim_customer)
[0m02:22:44.498188 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.production_hailing_staging_customer)
[0m02:22:44.499489 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m02:22:44.500475 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m02:22:44.501289 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m02:22:44.502386 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m02:22:44.503429 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m02:22:44.504564 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m02:22:44.521039 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m02:22:44.524394 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m02:22:44.528470 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m02:22:44.531949 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m02:22:44.537368 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m02:22:44.537897 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m02:22:44.539362 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m02:22:44.539789 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m02:22:44.540733 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m02:22:44.541268 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m02:22:44.542218 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m02:22:44.543969 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m02:22:44.546156 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m02:22:44.549255 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m02:22:44.550094 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m02:22:44.551643 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m02:22:44.553368 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m02:22:44.554689 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_driver, now model.hailing_project.production_hailing_staging_vehicle)
[0m02:22:44.556981 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m02:22:44.561858 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m02:22:44.569152 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m02:22:44.570379 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m02:22:44.575088 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m02:22:44.577301 [debug] [MainThread]: Connection 'master' was properly closed.
[0m02:22:44.578369 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m02:22:44.579352 [debug] [MainThread]: Connection 'model.hailing_project.dim_customer' was properly closed.
[0m02:22:44.580262 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m02:22:44.581374 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m02:22:44.583045 [debug] [MainThread]: Command end result
[0m02:22:44.623022 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m02:22:44.627722 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m02:22:44.636874 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m02:22:44.638129 [debug] [MainThread]: Resource report: {"command_name": "compile", "command_success": true, "command_wall_clock_time": 1.7960105, "process_in_blocks": "0", "process_kernel_time": 0.16216, "process_mem_max_rss": "214432", "process_out_blocks": "0", "process_user_time": 3.030382}
[0m02:22:44.639074 [debug] [MainThread]: Command `dbt compile` succeeded at 02:22:44.638966 after 1.80 seconds
[0m02:22:44.639826 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f38553a31d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f385464d190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3857de8c10>]}
[0m02:22:44.640694 [debug] [MainThread]: Flushing usage events
[0m02:22:45.653547 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:33:21.909961 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ef2277990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ef275b7d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ef22beb10>]}


============================== 02:33:21.912425 | 19fd3d24-093d-4274-a03e-4a209f1a03c3 ==============================
[0m02:33:21.912425 [info ] [MainThread]: Running with dbt=1.9.0
[0m02:33:21.914815 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'profiles_dir': '/usr/app/dbt_project', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt run', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m02:33:22.478493 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '19fd3d24-093d-4274-a03e-4a209f1a03c3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ec85e0110>]}
[0m02:33:22.528385 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '19fd3d24-093d-4274-a03e-4a209f1a03c3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ef44ecad0>]}
[0m02:33:22.529592 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m02:33:22.601453 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m02:33:22.753288 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m02:33:22.754483 [debug] [MainThread]: Partial parsing: added file: hailing_project://macros/generate_schema_name.sql
[0m02:33:22.757499 [info ] [MainThread]: Unable to do partial parsing because change detected to override macro. Starting full parse.
[0m02:33:23.662505 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.facts
- models.dbt_project.staging
[0m02:33:23.675251 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '19fd3d24-093d-4274-a03e-4a209f1a03c3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ec3f7c250>]}
[0m02:33:23.752712 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m02:33:23.758684 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m02:33:23.774686 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '19fd3d24-093d-4274-a03e-4a209f1a03c3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ec85a1950>]}
[0m02:33:23.775961 [info ] [MainThread]: Found 5 models, 8 sources, 489 macros
[0m02:33:23.777337 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '19fd3d24-093d-4274-a03e-4a209f1a03c3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ec826bc50>]}
[0m02:33:23.780003 [info ] [MainThread]: 
[0m02:33:23.781072 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m02:33:23.782004 [info ] [MainThread]: 
[0m02:33:23.783315 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m02:33:23.789173 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m02:33:23.789982 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m02:33:23.790761 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:33:23.791562 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:33:24.807726 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_staging)
[0m02:33:24.808309 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m02:33:24.809044 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:33:24.809863 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:33:25.043630 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '19fd3d24-093d-4274-a03e-4a209f1a03c3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ec8279690>]}
[0m02:33:25.045227 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:33:25.051708 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m02:33:25.052290 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m02:33:25.052786 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m02:33:25.053226 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m02:33:25.053939 [info ] [Thread-1 (]: 1 of 5 START sql incremental model rizky_dwh_hailing_source.dim_customer ....... [RUN]
[0m02:33:25.055398 [info ] [Thread-2 (]: 2 of 5 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [RUN]
[0m02:33:25.056923 [info ] [Thread-3 (]: 3 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [RUN]
[0m02:33:25.058780 [info ] [Thread-4 (]: 4 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [RUN]
[0m02:33:25.060814 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_staging, now model.hailing_project.dim_customer)
[0m02:33:25.063696 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.production_hailing_staging_customer)
[0m02:33:25.065441 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m02:33:25.066988 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m02:33:25.068489 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m02:33:25.069949 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m02:33:25.071445 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m02:33:25.073048 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m02:33:25.089767 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m02:33:25.093789 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m02:33:25.098515 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m02:33:25.102524 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m02:33:25.108022 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m02:33:25.108520 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m02:33:25.108928 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m02:33:25.114899 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m02:33:25.160739 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m02:33:25.161183 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m02:33:25.164409 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m02:33:25.168179 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m02:33:25.441257 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m02:33:25.442597 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m02:33:25.443646 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m02:33:25.448719 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m02:33:25.450049 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`dim_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`dim_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m02:33:25.450542 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m02:33:25.457451 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m02:33:25.465413 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m02:33:25.762392 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:15c1e607-c97b-4b6c-a94e-2cca849f84a7&page=queryresults
[0m02:33:26.020233 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:43dad530-b22e-40cd-b1e4-16d0d0b46692&page=queryresults
[0m02:33:26.043343 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:ba84851a-40e6-480a-8896-784603fe8b41&page=queryresults
[0m02:33:26.857897 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:db04bfab-fffa-4768-809a-89782af27b10&page=queryresults
[0m02:33:27.512598 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '19fd3d24-093d-4274-a03e-4a209f1a03c3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ec8106290>]}
[0m02:33:27.513870 [info ] [Thread-4 (]: 4 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.44s]
[0m02:33:27.514976 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m02:33:27.515715 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m02:33:27.516446 [info ] [Thread-4 (]: 5 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [RUN]
[0m02:33:27.517333 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_ride, now model.hailing_project.production_hailing_staging_vehicle)
[0m02:33:27.517971 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m02:33:27.521973 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m02:33:27.527404 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m02:33:27.531162 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m02:33:27.941008 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '19fd3d24-093d-4274-a03e-4a209f1a03c3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ec3eeb590>]}
[0m02:33:27.941776 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '19fd3d24-093d-4274-a03e-4a209f1a03c3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ec3f0fb10>]}
[0m02:33:27.943004 [info ] [Thread-3 (]: 3 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.88s]
[0m02:33:27.944087 [info ] [Thread-2 (]: 2 of 5 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.88s]
[0m02:33:27.945408 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m02:33:27.946353 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m02:33:28.138688 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m02:33:28.148522 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m02:33:28.435158 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:12e1789b-cc43-4647-924b-bc42aef657bd&page=queryresults
[0m02:33:28.441141 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '19fd3d24-093d-4274-a03e-4a209f1a03c3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ec3d4a950>]}
[0m02:33:28.442287 [info ] [Thread-1 (]: 1 of 5 OK created sql incremental model rizky_dwh_hailing_source.dim_customer .. [[32mMERGE (0.0 rows, 11.3 KiB processed)[0m in 3.38s]
[0m02:33:28.443742 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m02:33:29.934680 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '19fd3d24-093d-4274-a03e-4a209f1a03c3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ec02b0e10>]}
[0m02:33:29.935975 [info ] [Thread-4 (]: 5 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.42s]
[0m02:33:29.938471 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m02:33:29.940838 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m02:33:29.943218 [debug] [MainThread]: Connection 'master' was properly closed.
[0m02:33:29.943944 [debug] [MainThread]: Connection 'model.hailing_project.dim_customer' was properly closed.
[0m02:33:29.944596 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m02:33:29.945375 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m02:33:29.946299 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m02:33:29.947609 [info ] [MainThread]: 
[0m02:33:29.950035 [info ] [MainThread]: Finished running 5 incremental models in 0 hours 0 minutes and 6.16 seconds (6.16s).
[0m02:33:29.952356 [debug] [MainThread]: Command end result
[0m02:33:29.986587 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m02:33:29.991711 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m02:33:30.001430 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m02:33:30.002329 [info ] [MainThread]: 
[0m02:33:30.003603 [info ] [MainThread]: [32mCompleted successfully[0m
[0m02:33:30.004676 [info ] [MainThread]: 
[0m02:33:30.005757 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
[0m02:33:30.007350 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 8.143779, "process_in_blocks": "0", "process_kernel_time": 0.173195, "process_mem_max_rss": "228532", "process_out_blocks": "0", "process_user_time": 4.258565}
[0m02:33:30.008334 [debug] [MainThread]: Command `dbt run` succeeded at 02:33:30.008192 after 8.14 seconds
[0m02:33:30.009165 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ef26728d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ef5a6cc10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ef5bf0a10>]}
[0m02:33:30.010117 [debug] [MainThread]: Flushing usage events
[0m02:33:31.296171 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:36:41.821347 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbbe6df2450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbbe6df3f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbbe6df2c10>]}


============================== 02:36:41.823803 | 470704e4-5630-418b-b44e-67fe2a9a74c0 ==============================
[0m02:36:41.823803 [info ] [MainThread]: Running with dbt=1.9.0
[0m02:36:41.825035 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt run', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m02:36:42.386019 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '470704e4-5630-418b-b44e-67fe2a9a74c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbbbd142650>]}
[0m02:36:42.431335 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '470704e4-5630-418b-b44e-67fe2a9a74c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbbe90a1a50>]}
[0m02:36:42.432511 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m02:36:42.502714 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m02:36:42.570118 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m02:36:42.572317 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '470704e4-5630-418b-b44e-67fe2a9a74c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbbe74eaa50>]}
[0m02:36:43.553068 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.staging
- models.dbt_project.facts
[0m02:36:43.566309 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '470704e4-5630-418b-b44e-67fe2a9a74c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbbbcc88c50>]}
[0m02:36:43.636008 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m02:36:43.641330 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m02:36:43.657661 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '470704e4-5630-418b-b44e-67fe2a9a74c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbbbc9dcd90>]}
[0m02:36:43.658847 [info ] [MainThread]: Found 5 models, 8 sources, 489 macros
[0m02:36:43.659942 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '470704e4-5630-418b-b44e-67fe2a9a74c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbbbcdbc2d0>]}
[0m02:36:43.662320 [info ] [MainThread]: 
[0m02:36:43.663376 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m02:36:43.664337 [info ] [MainThread]: 
[0m02:36:43.665491 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m02:36:43.670051 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m02:36:43.671021 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:36:45.377120 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m02:36:45.378158 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:36:45.590818 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '470704e4-5630-418b-b44e-67fe2a9a74c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbbe6eeb290>]}
[0m02:36:45.593051 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:36:45.598551 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m02:36:45.598955 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m02:36:45.599361 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m02:36:45.599712 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m02:36:45.600606 [info ] [Thread-1 (]: 1 of 5 START sql incremental model rizky_dwh_hailing_source.dim_customer ....... [RUN]
[0m02:36:45.602472 [info ] [Thread-2 (]: 2 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [RUN]
[0m02:36:45.603774 [info ] [Thread-3 (]: 3 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [RUN]
[0m02:36:45.605000 [info ] [Thread-4 (]: 4 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [RUN]
[0m02:36:45.606240 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.dim_customer)
[0m02:36:45.607221 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_customer'
[0m02:36:45.608193 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m02:36:45.609339 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m02:36:45.610237 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m02:36:45.611071 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m02:36:45.611865 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m02:36:45.612672 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m02:36:45.621418 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m02:36:45.625265 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m02:36:45.629529 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m02:36:45.633483 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m02:36:45.640035 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m02:36:45.640563 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m02:36:45.640967 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m02:36:45.647436 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m02:36:45.682342 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m02:36:45.686525 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m02:36:45.689784 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m02:36:45.693159 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m02:36:45.974977 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m02:36:45.976100 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m02:36:45.981832 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m02:36:45.986548 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m02:36:45.987052 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m02:36:45.996144 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m02:36:45.998026 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m02:36:46.005142 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`dim_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`dim_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m02:36:46.261816 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:cb7bcdd0-d941-4556-bc15-ba1fb439fad2&page=queryresults
[0m02:36:46.267797 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:0170bc09-a95a-4042-a80e-cee82cbe31c2&page=queryresults
[0m02:36:46.269893 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:01d277b0-f6ed-4823-8795-c80fac2ab05a&page=queryresults
[0m02:36:46.520434 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:35ad6a63-3f78-4fab-9770-a940e02c8548&page=queryresults
[0m02:36:47.839279 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '470704e4-5630-418b-b44e-67fe2a9a74c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbbbca6e2d0>]}
[0m02:36:47.839623 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '470704e4-5630-418b-b44e-67fe2a9a74c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbbe6e22f50>]}
[0m02:36:47.840534 [info ] [Thread-4 (]: 4 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.23s]
[0m02:36:47.841923 [info ] [Thread-2 (]: 2 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.23s]
[0m02:36:47.843332 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m02:36:47.844440 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m02:36:47.845385 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m02:36:47.847069 [info ] [Thread-4 (]: 5 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [RUN]
[0m02:36:47.848043 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_ride, now model.hailing_project.production_hailing_staging_vehicle)
[0m02:36:47.849199 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m02:36:47.853907 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m02:36:47.862012 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m02:36:47.866195 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m02:36:48.027740 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '470704e4-5630-418b-b44e-67fe2a9a74c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbbbcab1d10>]}
[0m02:36:48.029426 [info ] [Thread-3 (]: 3 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.42s]
[0m02:36:48.031038 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m02:36:48.078414 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '470704e4-5630-418b-b44e-67fe2a9a74c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbbbc0ac150>]}
[0m02:36:48.079492 [info ] [Thread-1 (]: 1 of 5 OK created sql incremental model rizky_dwh_hailing_source.dim_customer .. [[32mMERGE (0.0 rows, 11.3 KiB processed)[0m in 2.47s]
[0m02:36:48.080800 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m02:36:48.097232 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m02:36:48.105245 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m02:36:48.366640 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:ff2c8b8d-dda4-475c-95bf-e484b75576a9&page=queryresults
[0m02:36:49.889472 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '470704e4-5630-418b-b44e-67fe2a9a74c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbbb4d9cfd0>]}
[0m02:36:49.890814 [info ] [Thread-4 (]: 5 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.04s]
[0m02:36:49.892603 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m02:36:49.895455 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m02:36:49.899091 [debug] [MainThread]: Connection 'master' was properly closed.
[0m02:36:49.899971 [debug] [MainThread]: Connection 'model.hailing_project.dim_customer' was properly closed.
[0m02:36:49.900874 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m02:36:49.901919 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m02:36:49.903091 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m02:36:49.904028 [info ] [MainThread]: 
[0m02:36:49.905018 [info ] [MainThread]: Finished running 5 incremental models in 0 hours 0 minutes and 6.24 seconds (6.24s).
[0m02:36:49.907401 [debug] [MainThread]: Command end result
[0m02:36:49.940060 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m02:36:49.945423 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m02:36:49.954249 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m02:36:49.955067 [info ] [MainThread]: 
[0m02:36:49.956135 [info ] [MainThread]: [32mCompleted successfully[0m
[0m02:36:49.957323 [info ] [MainThread]: 
[0m02:36:49.958273 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
[0m02:36:49.959745 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 8.185252, "process_in_blocks": "0", "process_kernel_time": 0.255493, "process_mem_max_rss": "226948", "process_out_blocks": "0", "process_user_time": 4.057232}
[0m02:36:49.960724 [debug] [MainThread]: Command `dbt run` succeeded at 02:36:49.960599 after 8.19 seconds
[0m02:36:49.961573 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbbe6e47d50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbbe6e4bd50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbbea7a5010>]}
[0m02:36:49.962387 [debug] [MainThread]: Flushing usage events
[0m02:36:51.527674 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:40:03.813667 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f79a3923890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f79a39667d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f79a3d1e150>]}


============================== 02:40:03.816561 | 6323024f-9293-4b07-a0da-60267872d72b ==============================
[0m02:40:03.816561 [info ] [MainThread]: Running with dbt=1.9.0
[0m02:40:03.818786 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt debug', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m02:40:03.830515 [info ] [MainThread]: dbt version: 1.9.0
[0m02:40:03.831396 [info ] [MainThread]: python version: 3.11.2
[0m02:40:03.833761 [info ] [MainThread]: python path: /usr/local/bin/python
[0m02:40:03.835840 [info ] [MainThread]: os info: Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.31
[0m02:40:04.314337 [info ] [MainThread]: Using profiles dir at /usr/app/dbt_project
[0m02:40:04.315818 [info ] [MainThread]: Using profiles.yml file at /usr/app/dbt_project/profiles.yml
[0m02:40:04.317569 [info ] [MainThread]: Using dbt_project.yml file at /usr/app/dbt_project/dbt_project.yml
[0m02:40:04.318850 [info ] [MainThread]: adapter type: bigquery
[0m02:40:04.320833 [info ] [MainThread]: adapter version: 1.9.0
[0m02:40:04.398822 [info ] [MainThread]: Configuration:
[0m02:40:04.399947 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m02:40:04.400879 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m02:40:04.401873 [info ] [MainThread]: Required dependencies:
[0m02:40:04.402823 [debug] [MainThread]: Executing "git --help"
[0m02:40:04.404899 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m02:40:04.405594 [debug] [MainThread]: STDERR: "b''"
[0m02:40:04.406270 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m02:40:04.407231 [info ] [MainThread]: Connection:
[0m02:40:04.408463 [info ] [MainThread]:   method: service-account
[0m02:40:04.410058 [info ] [MainThread]:   database: purwadika
[0m02:40:04.411303 [info ] [MainThread]:   execution_project: purwadika
[0m02:40:04.412210 [info ] [MainThread]:   schema: rizky_dwh_hailing_source
[0m02:40:04.413274 [info ] [MainThread]:   location: None
[0m02:40:04.414121 [info ] [MainThread]:   priority: None
[0m02:40:04.414954 [info ] [MainThread]:   maximum_bytes_billed: None
[0m02:40:04.416128 [info ] [MainThread]:   impersonate_service_account: None
[0m02:40:04.417230 [info ] [MainThread]:   job_retry_deadline_seconds: None
[0m02:40:04.418222 [info ] [MainThread]:   job_retries: 1
[0m02:40:04.419223 [info ] [MainThread]:   job_creation_timeout_seconds: None
[0m02:40:04.420322 [info ] [MainThread]:   job_execution_timeout_seconds: None
[0m02:40:04.421251 [info ] [MainThread]:   timeout_seconds: None
[0m02:40:04.422149 [info ] [MainThread]:   client_id: None
[0m02:40:04.423157 [info ] [MainThread]:   token_uri: None
[0m02:40:04.424332 [info ] [MainThread]:   dataproc_region: None
[0m02:40:04.425252 [info ] [MainThread]:   dataproc_cluster_name: None
[0m02:40:04.426317 [info ] [MainThread]:   gcs_bucket: None
[0m02:40:04.427865 [info ] [MainThread]:   dataproc_batch: None
[0m02:40:04.429191 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m02:40:04.482867 [debug] [MainThread]: Acquiring new bigquery connection 'debug'
[0m02:40:04.483910 [debug] [MainThread]: On debug: select 1 as id
[0m02:40:04.484933 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:40:05.206577 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:e30beb94-084b-41e7-a5c3-8fadc0e892fb&page=queryresults
[0m02:40:05.933864 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m02:40:05.937402 [info ] [MainThread]: [32mAll checks passed![0m
[0m02:40:05.939213 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": true, "command_wall_clock_time": 2.169973, "process_in_blocks": "0", "process_kernel_time": 0.183383, "process_mem_max_rss": "212540", "process_out_blocks": "0", "process_user_time": 2.608118}
[0m02:40:05.940290 [debug] [MainThread]: Command `dbt debug` succeeded at 02:40:05.940175 after 2.17 seconds
[0m02:40:05.941081 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m02:40:05.941902 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f79a3955290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f79a3928610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f79a3a1a9d0>]}
[0m02:40:05.942673 [debug] [MainThread]: Flushing usage events
[0m02:40:07.040937 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:40:14.013600 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2d9a6b2d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2d9a7071d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2d9a6b39d0>]}


============================== 02:40:14.016013 | 84ef3dfc-0ed5-4ab0-8521-d0df65337454 ==============================
[0m02:40:14.016013 [info ] [MainThread]: Running with dbt=1.9.0
[0m02:40:14.018438 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt clean', 'send_anonymous_usage_stats': 'True'}
[0m02:40:14.098597 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '84ef3dfc-0ed5-4ab0-8521-d0df65337454', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2d9a5b7f90>]}
[0m02:40:14.163057 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.19643295, "process_in_blocks": "16", "process_kernel_time": 0.07158, "process_mem_max_rss": "90112", "process_out_blocks": "0", "process_user_time": 0.910097}
[0m02:40:14.164050 [debug] [MainThread]: Command `dbt clean` succeeded at 02:40:14.163941 after 0.20 seconds
[0m02:40:14.164726 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2d9ded4c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2d9e031350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2d9e0310d0>]}
[0m02:40:14.165460 [debug] [MainThread]: Flushing usage events
[0m02:40:15.152785 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:40:16.273776 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdce1cdbbd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdce21e89d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdce1d2f1d0>]}


============================== 02:40:16.276964 | 1df149ad-c3f0-413f-b4a6-38aedc60b0ae ==============================
[0m02:40:16.276964 [info ] [MainThread]: Running with dbt=1.9.0
[0m02:40:16.278464 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt deps', 'send_anonymous_usage_stats': 'True'}
[0m02:40:16.362501 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1df149ad-c3f0-413f-b4a6-38aedc60b0ae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdce1b9ced0>]}
[0m02:40:16.380425 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m02:40:16.383902 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m02:40:16.385453 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.16651388, "process_in_blocks": "248", "process_kernel_time": 0.102933, "process_mem_max_rss": "90104", "process_out_blocks": "0", "process_user_time": 0.967572}
[0m02:40:16.386506 [debug] [MainThread]: Command `dbt deps` succeeded at 02:40:16.386386 after 0.17 seconds
[0m02:40:16.387348 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdce1d0d850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdce1c0c810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdce56290d0>]}
[0m02:40:16.388190 [debug] [MainThread]: Flushing usage events
[0m02:40:17.414525 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:40:24.986706 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9604f50490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96044e3390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f960415f610>]}


============================== 02:40:24.990308 | 8951e679-14fb-4492-927e-165b8d5f369e ==============================
[0m02:40:24.990308 [info ] [MainThread]: Running with dbt=1.9.0
[0m02:40:24.991667 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'invocation_command': 'dbt run', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m02:40:25.598271 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '8951e679-14fb-4492-927e-165b8d5f369e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f95d7d0edd0>]}
[0m02:40:25.642464 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '8951e679-14fb-4492-927e-165b8d5f369e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f960637e1d0>]}
[0m02:40:25.643462 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m02:40:25.714671 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m02:40:25.716835 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m02:40:25.717955 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '8951e679-14fb-4492-927e-165b8d5f369e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f95d627bd90>]}
[0m02:40:26.740359 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8951e679-14fb-4492-927e-165b8d5f369e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f95d5ed5b50>]}
[0m02:40:26.808388 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m02:40:26.814471 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m02:40:26.830413 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '8951e679-14fb-4492-927e-165b8d5f369e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f95d5cd5090>]}
[0m02:40:26.831859 [info ] [MainThread]: Found 5 models, 8 sources, 489 macros
[0m02:40:26.832999 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8951e679-14fb-4492-927e-165b8d5f369e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f95d5e03f10>]}
[0m02:40:26.835588 [info ] [MainThread]: 
[0m02:40:26.836836 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m02:40:26.838044 [info ] [MainThread]: 
[0m02:40:26.839527 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m02:40:26.843766 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m02:40:26.844452 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m02:40:26.845233 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:40:26.846081 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:40:27.846493 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_facts)
[0m02:40:27.847130 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_staging)
[0m02:40:27.847938 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:40:27.848930 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:40:28.096808 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8951e679-14fb-4492-927e-165b8d5f369e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f95d60566d0>]}
[0m02:40:28.097782 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:40:28.103408 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m02:40:28.103839 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m02:40:28.104224 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m02:40:28.104679 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m02:40:28.105376 [info ] [Thread-1 (]: 1 of 5 START sql incremental model rizky_dwh_hailing_facts.dim_customer ........ [RUN]
[0m02:40:28.106653 [info ] [Thread-2 (]: 2 of 5 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [RUN]
[0m02:40:28.108077 [info ] [Thread-3 (]: 3 of 5 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [RUN]
[0m02:40:28.109202 [info ] [Thread-4 (]: 4 of 5 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [RUN]
[0m02:40:28.110249 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_facts, now model.hailing_project.dim_customer)
[0m02:40:28.111388 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_staging, now model.hailing_project.production_hailing_staging_customer)
[0m02:40:28.112563 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m02:40:28.113499 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m02:40:28.114321 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m02:40:28.115263 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m02:40:28.116174 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m02:40:28.117010 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m02:40:28.125863 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m02:40:28.131164 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m02:40:28.135456 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m02:40:28.139412 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m02:40:28.152182 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m02:40:28.152918 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m02:40:28.164308 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m02:40:28.196639 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m02:40:28.199174 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m02:40:28.217612 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m02:40:28.220249 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m02:40:28.224275 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m02:40:28.306832 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    );
  
[0m02:40:28.308012 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m02:40:28.533599 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m02:40:28.534842 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m02:40:28.535984 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m02:40:28.541706 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m02:40:28.544261 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m02:40:28.546777 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m02:40:28.707486 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:5f264828-b286-4675-aabc-3a34f8bb533d&page=queryresults
[0m02:40:28.788486 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:50a516ff-955d-4355-98c2-f6bd11f2e723&page=queryresults
[0m02:40:29.087247 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:2db72773-b20b-4f48-98f7-630a233d754a&page=queryresults
[0m02:40:29.089825 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:1ec5eab9-6e68-4f01-9cd1-a6e8ce856abb&page=queryresults
[0m02:40:30.662022 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8951e679-14fb-4492-927e-165b8d5f369e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f95d43752d0>]}
[0m02:40:30.663798 [info ] [Thread-1 (]: 1 of 5 OK created sql incremental model rizky_dwh_hailing_facts.dim_customer ... [[32mCREATE TABLE (85.0 rows, 5.7 KiB processed)[0m in 2.55s]
[0m02:40:30.665271 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m02:40:30.666348 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m02:40:30.667325 [info ] [Thread-1 (]: 5 of 5 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [RUN]
[0m02:40:30.668394 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.hailing_project.dim_customer, now model.hailing_project.production_hailing_staging_vehicle)
[0m02:40:30.669345 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m02:40:30.674328 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m02:40:30.680939 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m02:40:30.685337 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m02:40:30.929964 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m02:40:30.936852 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m02:40:31.023408 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8951e679-14fb-4492-927e-165b8d5f369e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f95d5d74810>]}
[0m02:40:31.025149 [info ] [Thread-2 (]: 2 of 5 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.91s]
[0m02:40:31.026435 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m02:40:31.199711 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:bdc9a943-3f69-4cba-90f2-148689175577&page=queryresults
[0m02:40:31.446520 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8951e679-14fb-4492-927e-165b8d5f369e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f95d4373f90>]}
[0m02:40:31.447917 [info ] [Thread-4 (]: 4 of 5 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 3.33s]
[0m02:40:31.449167 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m02:40:32.799178 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8951e679-14fb-4492-927e-165b8d5f369e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f95d5e01150>]}
[0m02:40:32.801853 [info ] [Thread-3 (]: 3 of 5 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 4.69s]
[0m02:40:32.803153 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m02:40:32.998282 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8951e679-14fb-4492-927e-165b8d5f369e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f95d43ddc10>]}
[0m02:40:32.999817 [info ] [Thread-1 (]: 5 of 5 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.33s]
[0m02:40:33.001293 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m02:40:33.003850 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m02:40:33.006838 [debug] [MainThread]: Connection 'master' was properly closed.
[0m02:40:33.007621 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m02:40:33.008491 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m02:40:33.009834 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m02:40:33.010749 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m02:40:33.011568 [info ] [MainThread]: 
[0m02:40:33.012515 [info ] [MainThread]: Finished running 5 incremental models in 0 hours 0 minutes and 6.17 seconds (6.17s).
[0m02:40:33.014488 [debug] [MainThread]: Command end result
[0m02:40:33.049963 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m02:40:33.054551 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m02:40:33.064703 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m02:40:33.065497 [info ] [MainThread]: 
[0m02:40:33.066567 [info ] [MainThread]: [32mCompleted successfully[0m
[0m02:40:33.067772 [info ] [MainThread]: 
[0m02:40:33.068976 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
[0m02:40:33.070993 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 8.133492, "process_in_blocks": "0", "process_kernel_time": 0.25069, "process_mem_max_rss": "226520", "process_out_blocks": "0", "process_user_time": 4.231647}
[0m02:40:33.072248 [debug] [MainThread]: Command `dbt run` succeeded at 02:40:33.072062 after 8.13 seconds
[0m02:40:33.073335 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9604183610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f960415f7d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96078fcc90>]}
[0m02:40:33.074301 [debug] [MainThread]: Flushing usage events
[0m02:40:34.356001 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:42:19.390060 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2da202bdd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2da202be90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2da23d2290>]}


============================== 02:42:19.392662 | c6a5d014-8302-41d6-b1f3-5d38dac10cc0 ==============================
[0m02:42:19.392662 [info ] [MainThread]: Running with dbt=1.9.0
[0m02:42:19.393856 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m02:42:19.945795 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'c6a5d014-8302-41d6-b1f3-5d38dac10cc0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2d7827f4d0>]}
[0m02:42:19.994337 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'c6a5d014-8302-41d6-b1f3-5d38dac10cc0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2da425e150>]}
[0m02:42:19.995639 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m02:42:20.063565 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m02:42:20.219830 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m02:42:20.221222 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m02:42:20.250536 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c6a5d014-8302-41d6-b1f3-5d38dac10cc0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2d73f98350>]}
[0m02:42:20.359655 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m02:42:20.366829 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m02:42:20.382239 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c6a5d014-8302-41d6-b1f3-5d38dac10cc0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2d78350f10>]}
[0m02:42:20.383350 [info ] [MainThread]: Found 5 models, 8 sources, 489 macros
[0m02:42:20.384427 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c6a5d014-8302-41d6-b1f3-5d38dac10cc0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2d78340f90>]}
[0m02:42:20.387059 [info ] [MainThread]: 
[0m02:42:20.388166 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m02:42:20.389339 [info ] [MainThread]: 
[0m02:42:20.390703 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m02:42:20.395815 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m02:42:20.396574 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m02:42:20.397535 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:42:20.398406 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:42:21.248870 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now create_purwadika_rizky_dwh_hailing_facts)
[0m02:42:21.249408 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now create_purwadika_rizky_dwh_hailing_staging)
[0m02:42:21.250258 [debug] [ThreadPool]: Creating schema "database: "purwadika"
schema: "rizky_dwh_hailing_facts"
"
[0m02:42:21.252177 [debug] [ThreadPool]: Creating schema "database: "purwadika"
schema: "rizky_dwh_hailing_staging"
"
[0m02:42:21.262902 [debug] [ThreadPool]: On create_purwadika_rizky_dwh_hailing_facts: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "connection_name": "create_purwadika_rizky_dwh_hailing_facts"} */
create schema if not exists `purwadika`.`rizky_dwh_hailing_facts`
  
[0m02:42:21.265037 [debug] [ThreadPool]: On create_purwadika_rizky_dwh_hailing_staging: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "connection_name": "create_purwadika_rizky_dwh_hailing_staging"} */
create schema if not exists `purwadika`.`rizky_dwh_hailing_staging`
  
[0m02:42:21.266065 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:42:21.266941 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:42:22.125183 [debug] [ThreadPool]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:77109f8f-29c2-4aed-b18a-fc8c5f1bf5d0&page=queryresults
[0m02:42:22.718227 [debug] [ThreadPool]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:a10252c5-d2bb-4d8e-a092-1ed785647aa5&page=queryresults
[0m02:42:23.599187 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_purwadika_rizky_dwh_hailing_facts, now list_purwadika_rizky_dwh_hailing_facts)
[0m02:42:23.599775 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_purwadika_rizky_dwh_hailing_staging, now list_purwadika_rizky_dwh_hailing_staging)
[0m02:42:23.601416 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:42:23.602405 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:42:24.120206 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c6a5d014-8302-41d6-b1f3-5d38dac10cc0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2d7878d290>]}
[0m02:42:24.121165 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:42:24.126019 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m02:42:24.126382 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m02:42:24.126754 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m02:42:24.127207 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m02:42:24.127787 [info ] [Thread-1 (]: 1 of 5 START sql incremental model rizky_dwh_hailing_facts.dim_customer ........ [RUN]
[0m02:42:24.129547 [info ] [Thread-2 (]: 2 of 5 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [RUN]
[0m02:42:24.131101 [info ] [Thread-3 (]: 3 of 5 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [RUN]
[0m02:42:24.132327 [info ] [Thread-4 (]: 4 of 5 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [RUN]
[0m02:42:24.133580 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_staging, now model.hailing_project.dim_customer)
[0m02:42:24.134572 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_facts, now model.hailing_project.production_hailing_staging_customer)
[0m02:42:24.135857 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m02:42:24.136888 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m02:42:24.137877 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m02:42:24.138960 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m02:42:24.140203 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m02:42:24.141208 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m02:42:24.152498 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m02:42:24.156391 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m02:42:24.160042 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m02:42:24.164726 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m02:42:24.171916 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m02:42:24.172414 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m02:42:24.172858 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m02:42:24.178969 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m02:42:24.251893 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m02:42:24.259683 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m02:42:24.261594 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m02:42:24.265329 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m02:42:24.270511 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    );
  
[0m02:42:24.272515 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m02:42:24.273081 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    );
  
[0m02:42:24.273802 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    );
  
[0m02:42:24.275249 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    );
  
[0m02:42:24.276807 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m02:42:24.278977 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m02:42:24.301576 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m02:42:24.572758 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:8f87c786-27fc-4c39-bfbf-bb226287b2d9&page=queryresults
[0m02:42:24.573748 [error] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:8f87c786-27fc-4c39-bfbf-bb226287b2d9&page=queryresults
[0m02:42:24.579718 [debug] [Thread-4 (]: Database Error in model production_hailing_staging_ride (models/staging/production_hailing_staging_ride.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_ride.sql
[0m02:42:24.582501 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c6a5d014-8302-41d6-b1f3-5d38dac10cc0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2d72ac7cd0>]}
[0m02:42:24.584164 [error] [Thread-4 (]: 4 of 5 ERROR creating sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [[31mERROR[0m in 0.44s]
[0m02:42:24.585345 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m02:42:24.586485 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m02:42:24.587003 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.production_hailing_staging_ride' to be skipped because of status 'error'.  Reason: Database Error in model production_hailing_staging_ride (models/staging/production_hailing_staging_ride.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_ride.sql.
[0m02:42:24.588071 [info ] [Thread-4 (]: 5 of 5 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [RUN]
[0m02:42:24.590590 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_ride, now model.hailing_project.production_hailing_staging_vehicle)
[0m02:42:24.591742 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m02:42:24.596695 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m02:42:24.604078 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m02:42:24.610682 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m02:42:24.611785 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:e9c20031-7fee-4318-a1ae-89ae57b260a0&page=queryresults
[0m02:42:24.613278 [error] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:e9c20031-7fee-4318-a1ae-89ae57b260a0&page=queryresults
[0m02:42:24.617319 [debug] [Thread-3 (]: Database Error in model production_hailing_staging_driver (models/staging/production_hailing_staging_driver.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_driver.sql
[0m02:42:24.618369 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:2521dbca-7b1a-4ebf-a69d-75585f71d661&page=queryresults
[0m02:42:24.619347 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c6a5d014-8302-41d6-b1f3-5d38dac10cc0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2d78367210>]}
[0m02:42:24.621660 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    );
  
[0m02:42:24.621132 [error] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:2521dbca-7b1a-4ebf-a69d-75585f71d661&page=queryresults
[0m02:42:24.623373 [error] [Thread-3 (]: 3 of 5 ERROR creating sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [[31mERROR[0m in 0.48s]
[0m02:42:24.624804 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m02:42:24.633736 [debug] [Thread-2 (]: Database Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_customer.sql
[0m02:42:24.636428 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m02:42:24.638805 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c6a5d014-8302-41d6-b1f3-5d38dac10cc0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2d73f6f910>]}
[0m02:42:24.642669 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.production_hailing_staging_driver' to be skipped because of status 'error'.  Reason: Database Error in model production_hailing_staging_driver (models/staging/production_hailing_staging_driver.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_driver.sql.
[0m02:42:24.670883 [error] [Thread-2 (]: 2 of 5 ERROR creating sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [[31mERROR[0m in 0.50s]
[0m02:42:24.672878 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m02:42:24.673779 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.production_hailing_staging_customer' to be skipped because of status 'error'.  Reason: Database Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_customer.sql.
[0m02:42:24.958003 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:16a68a8b-8f27-4193-a58e-2fac44c79ef7&page=queryresults
[0m02:42:24.961531 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:16a68a8b-8f27-4193-a58e-2fac44c79ef7&page=queryresults
[0m02:42:24.966591 [debug] [Thread-1 (]: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Table purwadika:rizky_dwh_hailing_staging.production_hailing_staging_customer was not found in location US
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m02:42:24.967768 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c6a5d014-8302-41d6-b1f3-5d38dac10cc0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2d73fc3490>]}
[0m02:42:24.969289 [error] [Thread-1 (]: 1 of 5 ERROR creating sql incremental model rizky_dwh_hailing_facts.dim_customer  [[31mERROR[0m in 0.83s]
[0m02:42:24.971894 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m02:42:24.973531 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.dim_customer' to be skipped because of status 'error'.  Reason: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Table purwadika:rizky_dwh_hailing_staging.production_hailing_staging_customer was not found in location US
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql.
[0m02:42:24.976170 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:9032a92f-2cc4-4a7d-9221-636367d9bcea&page=queryresults
[0m02:42:24.977561 [error] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:9032a92f-2cc4-4a7d-9221-636367d9bcea&page=queryresults
[0m02:42:24.980759 [debug] [Thread-4 (]: Database Error in model production_hailing_staging_vehicle (models/staging/production_hailing_staging_vehicle.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_vehicle.sql
[0m02:42:24.981801 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c6a5d014-8302-41d6-b1f3-5d38dac10cc0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2d72a71d50>]}
[0m02:42:24.983056 [error] [Thread-4 (]: 5 of 5 ERROR creating sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [[31mERROR[0m in 0.39s]
[0m02:42:24.984640 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m02:42:24.985760 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.production_hailing_staging_vehicle' to be skipped because of status 'error'.  Reason: Database Error in model production_hailing_staging_vehicle (models/staging/production_hailing_staging_vehicle.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_vehicle.sql.
[0m02:42:24.988009 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m02:42:24.991143 [debug] [MainThread]: Connection 'master' was properly closed.
[0m02:42:24.991821 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m02:42:24.992524 [debug] [MainThread]: Connection 'model.hailing_project.dim_customer' was properly closed.
[0m02:42:24.993179 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m02:42:24.994022 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m02:42:24.995012 [info ] [MainThread]: 
[0m02:42:24.996152 [info ] [MainThread]: Finished running 5 incremental models in 0 hours 0 minutes and 4.60 seconds (4.60s).
[0m02:42:24.998313 [debug] [MainThread]: Command end result
[0m02:42:25.032230 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m02:42:25.036584 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m02:42:25.044153 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m02:42:25.045027 [info ] [MainThread]: 
[0m02:42:25.046160 [info ] [MainThread]: [31mCompleted with 5 errors, 0 partial successes, and 0 warnings:[0m
[0m02:42:25.047191 [info ] [MainThread]: 
[0m02:42:25.048379 [error] [MainThread]:   Database Error in model production_hailing_staging_ride (models/staging/production_hailing_staging_ride.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_ride.sql
[0m02:42:25.049468 [info ] [MainThread]: 
[0m02:42:25.050584 [error] [MainThread]:   Database Error in model production_hailing_staging_driver (models/staging/production_hailing_staging_driver.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_driver.sql
[0m02:42:25.051805 [info ] [MainThread]: 
[0m02:42:25.052860 [error] [MainThread]:   Database Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_customer.sql
[0m02:42:25.054195 [info ] [MainThread]: 
[0m02:42:25.055497 [error] [MainThread]:   Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Table purwadika:rizky_dwh_hailing_staging.production_hailing_staging_customer was not found in location US
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m02:42:25.056366 [info ] [MainThread]: 
[0m02:42:25.057727 [error] [MainThread]:   Database Error in model production_hailing_staging_vehicle (models/staging/production_hailing_staging_vehicle.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_vehicle.sql
[0m02:42:25.059255 [info ] [MainThread]: 
[0m02:42:25.060213 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=5 SKIP=0 TOTAL=5
[0m02:42:25.061673 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 5.718776, "process_in_blocks": "0", "process_kernel_time": 0.316244, "process_mem_max_rss": "221940", "process_out_blocks": "0", "process_user_time": 3.315464}
[0m02:42:25.062507 [debug] [MainThread]: Command `dbt run` failed at 02:42:25.062403 after 5.72 seconds
[0m02:42:25.063275 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2da1e4f690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2da1e4f610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2da59510d0>]}
[0m02:42:25.064278 [debug] [MainThread]: Flushing usage events
[0m02:42:26.384703 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:44:38.818697 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4817a0b1d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4817ec0490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4817a0bdd0>]}


============================== 02:44:38.821606 | ac1e74d4-d2b2-40ad-82a1-243837fa6df1 ==============================
[0m02:44:38.821606 [info ] [MainThread]: Running with dbt=1.9.0
[0m02:44:38.823227 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m02:44:39.370338 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ac1e74d4-d2b2-40ad-82a1-243837fa6df1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47e9baab90>]}
[0m02:44:39.413971 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ac1e74d4-d2b2-40ad-82a1-243837fa6df1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4819c7cfd0>]}
[0m02:44:39.415407 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m02:44:39.480838 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m02:44:39.631579 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m02:44:39.632536 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m02:44:39.658904 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ac1e74d4-d2b2-40ad-82a1-243837fa6df1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47e9a500d0>]}
[0m02:44:39.777831 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m02:44:39.782715 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m02:44:39.798921 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ac1e74d4-d2b2-40ad-82a1-243837fa6df1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47e9b9ccd0>]}
[0m02:44:39.800087 [info ] [MainThread]: Found 5 models, 8 sources, 489 macros
[0m02:44:39.801211 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ac1e74d4-d2b2-40ad-82a1-243837fa6df1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47e9d3de10>]}
[0m02:44:39.803623 [info ] [MainThread]: 
[0m02:44:39.804713 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m02:44:39.805628 [info ] [MainThread]: 
[0m02:44:39.806843 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m02:44:39.811753 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m02:44:39.812513 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m02:44:39.813200 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:44:39.814038 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:44:41.243929 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_facts)
[0m02:44:41.244524 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_staging)
[0m02:44:41.245260 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:44:41.246979 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:44:41.766181 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ac1e74d4-d2b2-40ad-82a1-243837fa6df1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47ea38b6d0>]}
[0m02:44:41.768611 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:44:41.775243 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m02:44:41.775622 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m02:44:41.776031 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m02:44:41.776373 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m02:44:41.777283 [info ] [Thread-1 (]: 1 of 5 START sql incremental model rizky_dwh_hailing_facts.dim_customer ........ [RUN]
[0m02:44:41.779119 [info ] [Thread-2 (]: 2 of 5 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [RUN]
[0m02:44:41.782101 [info ] [Thread-3 (]: 3 of 5 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [RUN]
[0m02:44:41.783441 [info ] [Thread-4 (]: 4 of 5 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [RUN]
[0m02:44:41.785481 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_staging, now model.hailing_project.dim_customer)
[0m02:44:41.786654 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_facts, now model.hailing_project.production_hailing_staging_customer)
[0m02:44:41.787835 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m02:44:41.789368 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m02:44:41.790789 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m02:44:41.791771 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m02:44:41.792824 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m02:44:41.793810 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m02:44:41.806524 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m02:44:41.810117 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m02:44:41.814282 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m02:44:41.818580 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m02:44:41.823897 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m02:44:41.830157 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m02:44:41.835939 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m02:44:41.836268 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m02:44:41.940252 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m02:44:41.941853 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m02:44:41.945716 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m02:44:41.948722 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m02:44:41.954469 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    );
  
[0m02:44:41.955160 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    );
  
[0m02:44:41.955761 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    );
  
[0m02:44:41.956217 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    );
  
[0m02:44:41.956737 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m02:44:41.957512 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m02:44:41.958320 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m02:44:41.959067 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m02:44:42.213332 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:230e3561-f3cf-4e97-ae34-33fcec1eb9fe&page=queryresults
[0m02:44:42.214552 [error] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:230e3561-f3cf-4e97-ae34-33fcec1eb9fe&page=queryresults
[0m02:44:42.218968 [debug] [Thread-2 (]: Database Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_customer.sql
[0m02:44:42.220905 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ac1e74d4-d2b2-40ad-82a1-243837fa6df1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4817a21050>]}
[0m02:44:42.221933 [error] [Thread-2 (]: 2 of 5 ERROR creating sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [[31mERROR[0m in 0.43s]
[0m02:44:42.223048 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m02:44:42.224522 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m02:44:42.225056 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.production_hailing_staging_customer' to be skipped because of status 'error'.  Reason: Database Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_customer.sql.
[0m02:44:42.225940 [info ] [Thread-2 (]: 5 of 5 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [RUN]
[0m02:44:42.229278 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_customer, now model.hailing_project.production_hailing_staging_vehicle)
[0m02:44:42.230476 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m02:44:42.235128 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m02:44:42.241114 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:7b784960-7f88-4f4f-8fcb-0617e7e3e354&page=queryresults
[0m02:44:42.242518 [error] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:7b784960-7f88-4f4f-8fcb-0617e7e3e354&page=queryresults
[0m02:44:42.244298 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m02:44:42.246709 [debug] [Thread-3 (]: Database Error in model production_hailing_staging_driver (models/staging/production_hailing_staging_driver.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_driver.sql
[0m02:44:42.250813 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m02:44:42.251775 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ac1e74d4-d2b2-40ad-82a1-243837fa6df1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47e9859a10>]}
[0m02:44:42.253416 [error] [Thread-3 (]: 3 of 5 ERROR creating sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [[31mERROR[0m in 0.46s]
[0m02:44:42.254830 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m02:44:42.256204 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.production_hailing_staging_driver' to be skipped because of status 'error'.  Reason: Database Error in model production_hailing_staging_driver (models/staging/production_hailing_staging_driver.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_driver.sql.
[0m02:44:42.260281 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    );
  
[0m02:44:42.260937 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:82f3946d-264f-4b19-b3a4-94cfd442425a&page=queryresults
[0m02:44:42.261667 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m02:44:42.262883 [error] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:82f3946d-264f-4b19-b3a4-94cfd442425a&page=queryresults
[0m02:44:42.267760 [debug] [Thread-4 (]: Database Error in model production_hailing_staging_ride (models/staging/production_hailing_staging_ride.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_ride.sql
[0m02:44:42.292535 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ac1e74d4-d2b2-40ad-82a1-243837fa6df1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47e9bd2d10>]}
[0m02:44:42.294465 [error] [Thread-4 (]: 4 of 5 ERROR creating sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [[31mERROR[0m in 0.50s]
[0m02:44:42.295952 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m02:44:42.298089 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.production_hailing_staging_ride' to be skipped because of status 'error'.  Reason: Database Error in model production_hailing_staging_ride (models/staging/production_hailing_staging_ride.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_ride.sql.
[0m02:44:42.509701 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:2e6ef395-f65e-40ec-95a0-4bee5eae6403&page=queryresults
[0m02:44:42.510755 [error] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:2e6ef395-f65e-40ec-95a0-4bee5eae6403&page=queryresults
[0m02:44:42.513957 [debug] [Thread-2 (]: Database Error in model production_hailing_staging_vehicle (models/staging/production_hailing_staging_vehicle.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_vehicle.sql
[0m02:44:42.514993 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ac1e74d4-d2b2-40ad-82a1-243837fa6df1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47e9a7ae10>]}
[0m02:44:42.516013 [error] [Thread-2 (]: 5 of 5 ERROR creating sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [[31mERROR[0m in 0.29s]
[0m02:44:42.517237 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m02:44:42.518236 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.production_hailing_staging_vehicle' to be skipped because of status 'error'.  Reason: Database Error in model production_hailing_staging_vehicle (models/staging/production_hailing_staging_vehicle.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_vehicle.sql.
[0m02:44:42.593792 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:cc163388-d04a-4a68-80ae-1bbd1f336b18&page=queryresults
[0m02:44:42.595795 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:cc163388-d04a-4a68-80ae-1bbd1f336b18&page=queryresults
[0m02:44:42.599609 [debug] [Thread-1 (]: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Table purwadika:rizky_dwh_hailing_staging.production_hailing_staging_customer was not found in location US
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m02:44:42.600949 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ac1e74d4-d2b2-40ad-82a1-243837fa6df1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47e866b010>]}
[0m02:44:42.602061 [error] [Thread-1 (]: 1 of 5 ERROR creating sql incremental model rizky_dwh_hailing_facts.dim_customer  [[31mERROR[0m in 0.82s]
[0m02:44:42.603142 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m02:44:42.604110 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.dim_customer' to be skipped because of status 'error'.  Reason: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Table purwadika:rizky_dwh_hailing_staging.production_hailing_staging_customer was not found in location US
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql.
[0m02:44:42.605952 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m02:44:42.608581 [debug] [MainThread]: Connection 'master' was properly closed.
[0m02:44:42.609546 [debug] [MainThread]: Connection 'model.hailing_project.dim_customer' was properly closed.
[0m02:44:42.610318 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m02:44:42.611207 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m02:44:42.611951 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m02:44:42.613102 [info ] [MainThread]: 
[0m02:44:42.614237 [info ] [MainThread]: Finished running 5 incremental models in 0 hours 0 minutes and 2.81 seconds (2.81s).
[0m02:44:42.615776 [debug] [MainThread]: Command end result
[0m02:44:42.649976 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m02:44:42.655272 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m02:44:42.662876 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m02:44:42.663650 [info ] [MainThread]: 
[0m02:44:42.664706 [info ] [MainThread]: [31mCompleted with 5 errors, 0 partial successes, and 0 warnings:[0m
[0m02:44:42.665849 [info ] [MainThread]: 
[0m02:44:42.666860 [error] [MainThread]:   Database Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_customer.sql
[0m02:44:42.667823 [info ] [MainThread]: 
[0m02:44:42.668851 [error] [MainThread]:   Database Error in model production_hailing_staging_driver (models/staging/production_hailing_staging_driver.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_driver.sql
[0m02:44:42.669712 [info ] [MainThread]: 
[0m02:44:42.670641 [error] [MainThread]:   Database Error in model production_hailing_staging_ride (models/staging/production_hailing_staging_ride.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_ride.sql
[0m02:44:42.672671 [info ] [MainThread]: 
[0m02:44:42.673955 [error] [MainThread]:   Database Error in model production_hailing_staging_vehicle (models/staging/production_hailing_staging_vehicle.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_vehicle.sql
[0m02:44:42.675180 [info ] [MainThread]: 
[0m02:44:42.676200 [error] [MainThread]:   Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Table purwadika:rizky_dwh_hailing_staging.production_hailing_staging_customer was not found in location US
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m02:44:42.677243 [info ] [MainThread]: 
[0m02:44:42.678204 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=5 SKIP=0 TOTAL=5
[0m02:44:42.679751 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 3.9110105, "process_in_blocks": "0", "process_kernel_time": 0.250394, "process_mem_max_rss": "218580", "process_out_blocks": "0", "process_user_time": 3.305208}
[0m02:44:42.680911 [debug] [MainThread]: Command `dbt run` failed at 02:44:42.680759 after 3.91 seconds
[0m02:44:42.681712 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4817a87a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4817a87790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4817a87b10>]}
[0m02:44:42.682714 [debug] [MainThread]: Flushing usage events
[0m02:44:43.970455 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:45:59.695588 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff15ca6f590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff15cab2c50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff15ca6f090>]}


============================== 02:45:59.698073 | b9b24c18-3b4f-4399-83fa-4b94694dabb7 ==============================
[0m02:45:59.698073 [info ] [MainThread]: Running with dbt=1.9.0
[0m02:45:59.700607 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m02:46:00.265271 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b9b24c18-3b4f-4399-83fa-4b94694dabb7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff12ec45710>]}
[0m02:46:00.310865 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b9b24c18-3b4f-4399-83fa-4b94694dabb7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff15ecc2690>]}
[0m02:46:00.311930 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m02:46:00.379438 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m02:46:00.532428 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m02:46:00.533399 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m02:46:00.560106 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b9b24c18-3b4f-4399-83fa-4b94694dabb7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff12eab9990>]}
[0m02:46:00.676502 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m02:46:00.681807 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m02:46:00.696733 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b9b24c18-3b4f-4399-83fa-4b94694dabb7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff12ec01c50>]}
[0m02:46:00.698844 [info ] [MainThread]: Found 5 models, 8 sources, 489 macros
[0m02:46:00.700700 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b9b24c18-3b4f-4399-83fa-4b94694dabb7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff12ebf4590>]}
[0m02:46:00.703304 [info ] [MainThread]: 
[0m02:46:00.704345 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m02:46:00.705334 [info ] [MainThread]: 
[0m02:46:00.706484 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m02:46:00.711368 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m02:46:00.712287 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m02:46:00.713141 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:46:00.714063 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:46:02.679198 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_facts)
[0m02:46:02.679760 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_staging)
[0m02:46:02.680469 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:46:02.683015 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:46:02.983644 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b9b24c18-3b4f-4399-83fa-4b94694dabb7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff15d87f690>]}
[0m02:46:02.987329 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:46:02.993035 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m02:46:02.993428 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m02:46:02.993797 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m02:46:02.994116 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m02:46:02.994769 [info ] [Thread-1 (]: 1 of 5 START sql incremental model rizky_dwh_hailing_facts.dim_customer ........ [RUN]
[0m02:46:02.995970 [info ] [Thread-2 (]: 2 of 5 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [RUN]
[0m02:46:02.997359 [info ] [Thread-3 (]: 3 of 5 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [RUN]
[0m02:46:02.998492 [info ] [Thread-4 (]: 4 of 5 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [RUN]
[0m02:46:03.000558 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_staging, now model.hailing_project.dim_customer)
[0m02:46:03.001639 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_facts, now model.hailing_project.production_hailing_staging_customer)
[0m02:46:03.002641 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m02:46:03.003499 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m02:46:03.004416 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m02:46:03.005346 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m02:46:03.006342 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m02:46:03.007225 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m02:46:03.020576 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m02:46:03.024818 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m02:46:03.030485 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m02:46:03.034845 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m02:46:03.040240 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m02:46:03.040786 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m02:46:03.041245 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m02:46:03.047296 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m02:46:03.130626 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m02:46:03.132859 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m02:46:03.127671 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m02:46:03.136705 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m02:46:03.143802 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    );
  
[0m02:46:03.144393 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    );
  
[0m02:46:03.147053 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m02:46:03.145856 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m02:46:03.144808 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    );
  
[0m02:46:03.147785 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    );
  
[0m02:46:03.149791 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m02:46:03.173957 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m02:46:03.629817 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:6b9afd9b-bd2b-4b5f-85aa-9f3fd6921778&page=queryresults
[0m02:46:03.630939 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:6b9afd9b-bd2b-4b5f-85aa-9f3fd6921778&page=queryresults
[0m02:46:03.635208 [debug] [Thread-1 (]: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Table purwadika:rizky_dwh_hailing_staging.production_hailing_staging_customer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m02:46:03.637287 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b9b24c18-3b4f-4399-83fa-4b94694dabb7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff12e97b450>]}
[0m02:46:03.638543 [error] [Thread-1 (]: 1 of 5 ERROR creating sql incremental model rizky_dwh_hailing_facts.dim_customer  [[31mERROR[0m in 0.64s]
[0m02:46:03.640269 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m02:46:03.641984 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m02:46:03.642484 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.dim_customer' to be skipped because of status 'error'.  Reason: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Table purwadika:rizky_dwh_hailing_staging.production_hailing_staging_customer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql.
[0m02:46:03.643545 [info ] [Thread-1 (]: 5 of 5 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [RUN]
[0m02:46:03.646166 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.hailing_project.dim_customer, now model.hailing_project.production_hailing_staging_vehicle)
[0m02:46:03.647102 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m02:46:03.651657 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m02:46:03.659144 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m02:46:03.662635 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m02:46:03.669483 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    );
  
[0m02:46:03.670835 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m02:46:03.844409 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:9b169be5-a9ca-42b9-bc9c-467cba949065&page=queryresults
[0m02:46:04.114569 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:df35397d-e85f-4c44-888b-983c561e35e2&page=queryresults
[0m02:46:04.273102 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:ea597ff5-9804-45d0-8e27-779aec8b0cca&page=queryresults
[0m02:46:04.947982 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:9a559f7b-c151-4718-96c0-ee3847a8d8fc&page=queryresults
[0m02:46:05.898872 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b9b24c18-3b4f-4399-83fa-4b94694dabb7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff12c5caa90>]}
[0m02:46:05.899977 [info ] [Thread-4 (]: 4 of 5 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [[32mCREATE TABLE (85.0 rows, 7.6 KiB processed)[0m in 2.90s]
[0m02:46:05.902330 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m02:46:06.291664 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b9b24c18-3b4f-4399-83fa-4b94694dabb7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff12ec2eb90>]}
[0m02:46:06.293693 [info ] [Thread-1 (]: 5 of 5 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [[32mCREATE TABLE (85.0 rows, 4.7 KiB processed)[0m in 2.65s]
[0m02:46:06.295811 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m02:46:06.397760 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b9b24c18-3b4f-4399-83fa-4b94694dabb7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff12e947050>]}
[0m02:46:06.399117 [info ] [Thread-3 (]: 3 of 5 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [[32mCREATE TABLE (85.0 rows, 5.8 KiB processed)[0m in 3.40s]
[0m02:46:06.400642 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m02:46:06.898035 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b9b24c18-3b4f-4399-83fa-4b94694dabb7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff12c5b5350>]}
[0m02:46:06.899707 [info ] [Thread-2 (]: 2 of 5 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [[32mCREATE TABLE (85.0 rows, 5.8 KiB processed)[0m in 3.90s]
[0m02:46:06.901410 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m02:46:06.903755 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m02:46:06.907521 [debug] [MainThread]: Connection 'master' was properly closed.
[0m02:46:06.908244 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m02:46:06.909204 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m02:46:06.909880 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m02:46:06.910539 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m02:46:06.911218 [info ] [MainThread]: 
[0m02:46:06.912139 [info ] [MainThread]: Finished running 5 incremental models in 0 hours 0 minutes and 6.20 seconds (6.20s).
[0m02:46:06.913825 [debug] [MainThread]: Command end result
[0m02:46:06.950467 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m02:46:06.954648 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m02:46:06.963251 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m02:46:06.963992 [info ] [MainThread]: 
[0m02:46:06.965029 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m02:46:06.966728 [info ] [MainThread]: 
[0m02:46:06.967715 [error] [MainThread]:   Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Table purwadika:rizky_dwh_hailing_staging.production_hailing_staging_customer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m02:46:06.968612 [info ] [MainThread]: 
[0m02:46:06.969697 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=0 TOTAL=5
[0m02:46:06.971473 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 7.320235, "process_in_blocks": "0", "process_kernel_time": 0.174671, "process_mem_max_rss": "225608", "process_out_blocks": "0", "process_user_time": 3.39069}
[0m02:46:06.972571 [debug] [MainThread]: Command `dbt run` failed at 02:46:06.972439 after 7.32 seconds
[0m02:46:06.973477 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff15caca3d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff1603bd610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff1603bd250>]}
[0m02:46:06.974458 [debug] [MainThread]: Flushing usage events
[0m02:46:08.282549 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:47:36.910123 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd90bb27010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd90bb7b950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd90bb7b550>]}


============================== 02:47:36.913020 | 4e23a428-a996-42d2-93f7-789c2aa93d58 ==============================
[0m02:47:36.913020 [info ] [MainThread]: Running with dbt=1.9.0
[0m02:47:36.915283 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --select dim_customer', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m02:47:37.516889 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '4e23a428-a996-42d2-93f7-789c2aa93d58', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd8ddcec6d0>]}
[0m02:47:37.559618 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '4e23a428-a996-42d2-93f7-789c2aa93d58', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd90dd9ca90>]}
[0m02:47:37.560845 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m02:47:37.627315 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m02:47:37.778761 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m02:47:37.779454 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m02:47:37.805183 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4e23a428-a996-42d2-93f7-789c2aa93d58', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd8df30cdd0>]}
[0m02:47:37.913706 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m02:47:37.919057 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m02:47:37.934014 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4e23a428-a996-42d2-93f7-789c2aa93d58', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd8ddeada50>]}
[0m02:47:37.934902 [info ] [MainThread]: Found 5 models, 8 sources, 489 macros
[0m02:47:37.936297 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4e23a428-a996-42d2-93f7-789c2aa93d58', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd8dde9dd10>]}
[0m02:47:37.938387 [info ] [MainThread]: 
[0m02:47:37.939721 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m02:47:37.940955 [info ] [MainThread]: 
[0m02:47:37.942649 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m02:47:37.944747 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m02:47:37.945876 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:47:38.660348 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_facts)
[0m02:47:38.660962 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_staging'
[0m02:47:38.662946 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:47:38.664459 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:47:38.901437 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4e23a428-a996-42d2-93f7-789c2aa93d58', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd90d9e7810>]}
[0m02:47:38.902808 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:47:38.907169 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m02:47:38.907955 [info ] [Thread-1 (]: 1 of 1 START sql incremental model rizky_dwh_hailing_facts.dim_customer ........ [RUN]
[0m02:47:38.909049 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_facts, now model.hailing_project.dim_customer)
[0m02:47:38.909947 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m02:47:38.923298 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m02:47:38.929352 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m02:47:38.994316 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m02:47:39.001328 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    );
  
[0m02:47:39.002385 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m02:47:39.370377 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:99619465-0287-4353-819e-059fe9c79f4c&page=queryresults
[0m02:47:41.239719 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4e23a428-a996-42d2-93f7-789c2aa93d58', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd90c275f50>]}
[0m02:47:41.240753 [info ] [Thread-1 (]: 1 of 1 OK created sql incremental model rizky_dwh_hailing_facts.dim_customer ... [[32mCREATE TABLE (85.0 rows, 5.7 KiB processed)[0m in 2.33s]
[0m02:47:41.243909 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m02:47:41.246365 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m02:47:41.249179 [debug] [MainThread]: Connection 'master' was properly closed.
[0m02:47:41.250190 [debug] [MainThread]: Connection 'model.hailing_project.dim_customer' was properly closed.
[0m02:47:41.251171 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_staging' was properly closed.
[0m02:47:41.252189 [info ] [MainThread]: 
[0m02:47:41.253426 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 3.31 seconds (3.31s).
[0m02:47:41.255531 [debug] [MainThread]: Command end result
[0m02:47:41.290240 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m02:47:41.295011 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m02:47:41.302242 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m02:47:41.303441 [info ] [MainThread]: 
[0m02:47:41.304536 [info ] [MainThread]: [32mCompleted successfully[0m
[0m02:47:41.305489 [info ] [MainThread]: 
[0m02:47:41.306700 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m02:47:41.308217 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 4.4489694, "process_in_blocks": "0", "process_kernel_time": 0.214428, "process_mem_max_rss": "220036", "process_out_blocks": "0", "process_user_time": 3.175581}
[0m02:47:41.309330 [debug] [MainThread]: Command `dbt run` succeeded at 02:47:41.309222 after 4.45 seconds
[0m02:47:41.310252 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd90bf228d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd90f31cc50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd8ddb5e950>]}
[0m02:47:41.311131 [debug] [MainThread]: Flushing usage events
[0m02:47:42.600073 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:47:53.018259 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3bdbfa3710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3bdc39e750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3bdbfa3310>]}


============================== 02:47:53.020973 | 5674e5ae-01ea-4c69-8796-fa6290ecdb56 ==============================
[0m02:47:53.020973 [info ] [MainThread]: Running with dbt=1.9.0
[0m02:47:53.022830 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt run', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m02:47:53.573306 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5674e5ae-01ea-4c69-8796-fa6290ecdb56', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3bdc01fdd0>]}
[0m02:47:53.617936 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '5674e5ae-01ea-4c69-8796-fa6290ecdb56', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3bae28b5d0>]}
[0m02:47:53.619013 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m02:47:53.688111 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m02:47:53.838010 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m02:47:53.839341 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m02:47:53.867949 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5674e5ae-01ea-4c69-8796-fa6290ecdb56', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3badfc6490>]}
[0m02:47:53.994582 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m02:47:53.999642 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m02:47:54.012936 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5674e5ae-01ea-4c69-8796-fa6290ecdb56', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3bae30f1d0>]}
[0m02:47:54.014786 [info ] [MainThread]: Found 5 models, 8 sources, 489 macros
[0m02:47:54.018037 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5674e5ae-01ea-4c69-8796-fa6290ecdb56', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3bae2fcd50>]}
[0m02:47:54.021498 [info ] [MainThread]: 
[0m02:47:54.022821 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m02:47:54.024070 [info ] [MainThread]: 
[0m02:47:54.025593 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m02:47:54.030244 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m02:47:54.030981 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m02:47:54.031726 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:47:54.032709 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:47:56.121240 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_staging)
[0m02:47:56.121892 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_facts)
[0m02:47:56.122752 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:47:56.124379 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:47:56.364896 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5674e5ae-01ea-4c69-8796-fa6290ecdb56', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3bbad89d50>]}
[0m02:47:56.365856 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:47:56.370851 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m02:47:56.371178 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m02:47:56.371560 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m02:47:56.372752 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m02:47:56.373482 [info ] [Thread-1 (]: 1 of 5 START sql incremental model rizky_dwh_hailing_facts.dim_customer ........ [RUN]
[0m02:47:56.374920 [info ] [Thread-2 (]: 2 of 5 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [RUN]
[0m02:47:56.376203 [info ] [Thread-3 (]: 3 of 5 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [RUN]
[0m02:47:56.377311 [info ] [Thread-4 (]: 4 of 5 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [RUN]
[0m02:47:56.378486 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_staging, now model.hailing_project.dim_customer)
[0m02:47:56.379441 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_facts, now model.hailing_project.production_hailing_staging_customer)
[0m02:47:56.380349 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m02:47:56.381367 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m02:47:56.382257 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m02:47:56.383115 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m02:47:56.383924 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m02:47:56.384770 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m02:47:56.399496 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m02:47:56.403361 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m02:47:56.407341 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m02:47:56.411647 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m02:47:56.418865 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m02:47:56.419356 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m02:47:56.419742 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m02:47:56.426095 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m02:47:56.469393 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m02:47:56.467888 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m02:47:56.472565 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m02:47:56.476383 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m02:47:56.753698 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m02:47:56.755028 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m02:47:56.756817 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m02:47:56.766104 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m02:47:56.766677 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m02:47:56.769139 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m02:47:56.773439 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m02:47:56.780516 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m02:47:57.012152 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:5e2071c3-e70e-49b4-96cb-9f44f58b8c47&page=queryresults
[0m02:47:57.013452 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:d7a68dcd-e736-47ad-a8b5-814e388c18ce&page=queryresults
[0m02:47:57.016364 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:1b6d14c0-8b6c-4bc9-aba3-9ce2bdaad3d9&page=queryresults
[0m02:47:58.127694 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:f3e54ada-0fd2-4487-ab07-552f379597cd&page=queryresults
[0m02:47:58.532268 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5674e5ae-01ea-4c69-8796-fa6290ecdb56', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3badffdc10>]}
[0m02:47:58.533413 [info ] [Thread-2 (]: 2 of 5 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.15s]
[0m02:47:58.535156 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m02:47:58.536636 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m02:47:58.537756 [info ] [Thread-2 (]: 5 of 5 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [RUN]
[0m02:47:58.538982 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_customer, now model.hailing_project.production_hailing_staging_vehicle)
[0m02:47:58.539917 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m02:47:58.544734 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m02:47:58.551195 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m02:47:58.555782 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m02:47:58.583999 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5674e5ae-01ea-4c69-8796-fa6290ecdb56', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3bae1adc90>]}
[0m02:47:58.585299 [info ] [Thread-1 (]: 1 of 5 OK created sql incremental model rizky_dwh_hailing_facts.dim_customer ... [[32mMERGE (0.0 rows, 11.3 KiB processed)[0m in 2.21s]
[0m02:47:58.586501 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m02:47:58.775203 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m02:47:58.782184 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m02:47:58.796726 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5674e5ae-01ea-4c69-8796-fa6290ecdb56', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3badf53b10>]}
[0m02:47:58.797882 [info ] [Thread-4 (]: 4 of 5 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.42s]
[0m02:47:58.799135 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m02:47:58.992795 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:878235f9-b32c-40dc-ba8a-6646cb82795c&page=queryresults
[0m02:47:59.639698 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5674e5ae-01ea-4c69-8796-fa6290ecdb56', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3bae199350>]}
[0m02:47:59.641161 [info ] [Thread-3 (]: 3 of 5 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 3.26s]
[0m02:47:59.642843 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m02:48:00.809855 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5674e5ae-01ea-4c69-8796-fa6290ecdb56', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3bae3275d0>]}
[0m02:48:00.811403 [info ] [Thread-2 (]: 5 of 5 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.27s]
[0m02:48:00.812819 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m02:48:00.815315 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m02:48:00.818603 [debug] [MainThread]: Connection 'master' was properly closed.
[0m02:48:00.819433 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m02:48:00.820400 [debug] [MainThread]: Connection 'model.hailing_project.dim_customer' was properly closed.
[0m02:48:00.821429 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m02:48:00.822332 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m02:48:00.823478 [info ] [MainThread]: 
[0m02:48:00.824368 [info ] [MainThread]: Finished running 5 incremental models in 0 hours 0 minutes and 6.80 seconds (6.80s).
[0m02:48:00.826467 [debug] [MainThread]: Command end result
[0m02:48:00.861271 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m02:48:00.866037 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m02:48:00.874226 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m02:48:00.874999 [info ] [MainThread]: 
[0m02:48:00.876031 [info ] [MainThread]: [32mCompleted successfully[0m
[0m02:48:00.877052 [info ] [MainThread]: 
[0m02:48:00.878054 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
[0m02:48:00.879544 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 7.9075284, "process_in_blocks": "0", "process_kernel_time": 0.181158, "process_mem_max_rss": "221960", "process_out_blocks": "0", "process_user_time": 3.371561}
[0m02:48:00.880629 [debug] [MainThread]: Command `dbt run` succeeded at 02:48:00.880495 after 7.91 seconds
[0m02:48:00.881534 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3bdc01f950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3bdfacd7d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3bdf7fcb90>]}
[0m02:48:00.882441 [debug] [MainThread]: Flushing usage events
[0m02:48:02.386003 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:34:54.167562 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb972f23bd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb9732ce110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb972f23b50>]}


============================== 03:34:54.170793 | 88ff593e-8a87-45e0-8114-ff6dcb7cf5c3 ==============================
[0m03:34:54.170793 [info ] [MainThread]: Running with dbt=1.9.0
[0m03:34:54.172355 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt run', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m03:34:54.719262 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '88ff593e-8a87-45e0-8114-ff6dcb7cf5c3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb949337fd0>]}
[0m03:34:54.766928 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '88ff593e-8a87-45e0-8114-ff6dcb7cf5c3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb975159dd0>]}
[0m03:34:54.768368 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m03:34:54.836268 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m03:34:55.018931 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m03:34:55.022421 [debug] [MainThread]: Partial parsing: added file: hailing_project://models/facts/dim_driver.sql
[0m03:34:55.265941 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '88ff593e-8a87-45e0-8114-ff6dcb7cf5c3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb94923f0d0>]}
[0m03:34:55.337865 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m03:34:55.344810 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m03:34:55.362706 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '88ff593e-8a87-45e0-8114-ff6dcb7cf5c3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb93355fc50>]}
[0m03:34:55.363925 [info ] [MainThread]: Found 6 models, 8 sources, 489 macros
[0m03:34:55.365042 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '88ff593e-8a87-45e0-8114-ff6dcb7cf5c3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb9490cde10>]}
[0m03:34:55.367564 [info ] [MainThread]: 
[0m03:34:55.368581 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m03:34:55.369816 [info ] [MainThread]: 
[0m03:34:55.371349 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m03:34:55.375692 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m03:34:55.376344 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m03:34:55.377213 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m03:34:55.378134 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m03:34:56.332850 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_staging)
[0m03:34:56.333470 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_facts)
[0m03:34:56.334189 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m03:34:56.336701 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m03:34:56.626505 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '88ff593e-8a87-45e0-8114-ff6dcb7cf5c3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb948e5ef50>]}
[0m03:34:56.628072 [debug] [MainThread]: Opening a new connection, currently in state init
[0m03:34:56.633268 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m03:34:56.633672 [debug] [Thread-2 (]: Began running node model.hailing_project.dim_driver
[0m03:34:56.634310 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m03:34:56.634768 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m03:34:56.635314 [info ] [Thread-1 (]: 1 of 6 START sql incremental model rizky_dwh_hailing_facts.dim_customer ........ [RUN]
[0m03:34:56.636567 [info ] [Thread-2 (]: 2 of 6 START sql incremental model rizky_dwh_hailing_facts.dim_driver .......... [RUN]
[0m03:34:56.637638 [info ] [Thread-3 (]: 3 of 6 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [RUN]
[0m03:34:56.638869 [info ] [Thread-4 (]: 4 of 6 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [RUN]
[0m03:34:56.640314 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_staging, now model.hailing_project.dim_customer)
[0m03:34:56.641803 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_facts, now model.hailing_project.dim_driver)
[0m03:34:56.643024 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_customer'
[0m03:34:56.644088 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m03:34:56.644872 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m03:34:56.645692 [debug] [Thread-2 (]: Began compiling node model.hailing_project.dim_driver
[0m03:34:56.646469 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m03:34:56.647423 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m03:34:56.661401 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m03:34:56.666436 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.dim_driver"
[0m03:34:56.674903 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m03:34:56.681259 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m03:34:56.688962 [debug] [Thread-2 (]: Began executing node model.hailing_project.dim_driver
[0m03:34:56.691827 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m03:34:56.692440 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m03:34:56.704447 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m03:34:56.746573 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m03:34:56.764888 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m03:34:56.775958 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.dim_driver"
[0m03:34:56.778704 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m03:34:56.832243 [debug] [Thread-2 (]: On model.hailing_project.dim_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_driver"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      


WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)
    );
  
[0m03:34:56.854832 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m03:34:57.122762 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m03:34:57.124196 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m03:34:57.125577 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m03:34:57.131574 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m03:34:57.132247 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m03:34:57.132734 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m03:34:57.408105 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:38a329f1-37f4-4d61-ade7-5de53258df41&page=queryresults
[0m03:34:57.409189 [error] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:38a329f1-37f4-4d61-ade7-5de53258df41&page=queryresults
[0m03:34:57.413959 [debug] [Thread-2 (]: Database Error in model dim_driver (models/facts/dim_driver.sql)
  Syntax error: Unexpected ")" at [31:5]
  compiled code at target/run/hailing_project/models/facts/dim_driver.sql
[0m03:34:57.415745 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '88ff593e-8a87-45e0-8114-ff6dcb7cf5c3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb93357c990>]}
[0m03:34:57.416782 [error] [Thread-2 (]: 2 of 6 ERROR creating sql incremental model rizky_dwh_hailing_facts.dim_driver . [[31mERROR[0m in 0.77s]
[0m03:34:57.418185 [debug] [Thread-2 (]: Finished running node model.hailing_project.dim_driver
[0m03:34:57.419306 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m03:34:57.419923 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.dim_driver' to be skipped because of status 'error'.  Reason: Database Error in model dim_driver (models/facts/dim_driver.sql)
  Syntax error: Unexpected ")" at [31:5]
  compiled code at target/run/hailing_project/models/facts/dim_driver.sql.
[0m03:34:57.420705 [info ] [Thread-2 (]: 5 of 6 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [RUN]
[0m03:34:57.422764 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.hailing_project.dim_driver, now model.hailing_project.production_hailing_staging_ride)
[0m03:34:57.423515 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m03:34:57.428145 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m03:34:57.435009 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m03:34:57.439021 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m03:34:57.467952 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:9ecb6c41-e63e-4c5e-8d58-ab807ccbd019&page=queryresults
[0m03:34:57.468880 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:f3986c98-c3b8-4b38-a89d-1e568b7f2fb2&page=queryresults
[0m03:34:57.720449 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m03:34:57.728070 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m03:34:58.032081 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:9731574c-8980-4b46-a45c-38aa42e5a80b&page=queryresults
[0m03:34:58.588068 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:514298be-1db1-40b7-a55f-5ac62489dc5a&page=queryresults
[0m03:34:59.149333 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '88ff593e-8a87-45e0-8114-ff6dcb7cf5c3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb9335702d0>]}
[0m03:34:59.151479 [info ] [Thread-1 (]: 1 of 6 OK created sql incremental model rizky_dwh_hailing_facts.dim_customer ... [[32mMERGE (0.0 rows, 11.3 KiB processed)[0m in 2.51s]
[0m03:34:59.153458 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m03:34:59.154795 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m03:34:59.156266 [info ] [Thread-1 (]: 6 of 6 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [RUN]
[0m03:34:59.159979 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.hailing_project.dim_customer, now model.hailing_project.production_hailing_staging_vehicle)
[0m03:34:59.160995 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m03:34:59.166585 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m03:34:59.174410 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m03:34:59.178452 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m03:34:59.324574 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '88ff593e-8a87-45e0-8114-ff6dcb7cf5c3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb93036d0d0>]}
[0m03:34:59.325859 [info ] [Thread-4 (]: 4 of 6 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.68s]
[0m03:34:59.327569 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m03:34:59.439441 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m03:34:59.448149 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m03:34:59.754490 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:128c49c1-80bd-4d4d-8626-784ad0ea5a49&page=queryresults
[0m03:34:59.916036 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '88ff593e-8a87-45e0-8114-ff6dcb7cf5c3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb92b596d10>]}
[0m03:34:59.918347 [info ] [Thread-2 (]: 5 of 6 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.49s]
[0m03:34:59.921416 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m03:35:00.134135 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '88ff593e-8a87-45e0-8114-ff6dcb7cf5c3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb93047d750>]}
[0m03:35:00.136071 [info ] [Thread-3 (]: 3 of 6 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 3.49s]
[0m03:35:00.137788 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m03:35:01.322382 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '88ff593e-8a87-45e0-8114-ff6dcb7cf5c3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb92b59abd0>]}
[0m03:35:01.323760 [info ] [Thread-1 (]: 6 of 6 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.16s]
[0m03:35:01.325235 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m03:35:01.328197 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m03:35:01.332418 [debug] [MainThread]: Connection 'master' was properly closed.
[0m03:35:01.333571 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m03:35:01.334713 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m03:35:01.335713 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m03:35:01.336736 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m03:35:01.338317 [info ] [MainThread]: 
[0m03:35:01.339621 [info ] [MainThread]: Finished running 6 incremental models in 0 hours 0 minutes and 5.97 seconds (5.97s).
[0m03:35:01.341851 [debug] [MainThread]: Command end result
[0m03:35:01.377666 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m03:35:01.381552 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m03:35:01.390273 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m03:35:01.391694 [info ] [MainThread]: 
[0m03:35:01.392982 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m03:35:01.394087 [info ] [MainThread]: 
[0m03:35:01.395235 [error] [MainThread]:   Database Error in model dim_driver (models/facts/dim_driver.sql)
  Syntax error: Unexpected ")" at [31:5]
  compiled code at target/run/hailing_project/models/facts/dim_driver.sql
[0m03:35:01.396137 [info ] [MainThread]: 
[0m03:35:01.397533 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=1 SKIP=0 TOTAL=6
[0m03:35:01.400109 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 7.3017387, "process_in_blocks": "200", "process_kernel_time": 0.231657, "process_mem_max_rss": "229440", "process_out_blocks": "0", "process_user_time": 3.575587}
[0m03:35:01.401402 [debug] [MainThread]: Command `dbt run` failed at 03:35:01.401245 after 7.30 seconds
[0m03:35:01.402607 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb973388350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb972f49210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb972f4b5d0>]}
[0m03:35:01.403974 [debug] [MainThread]: Flushing usage events
[0m03:35:02.705627 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:52:24.009387 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa80d412a10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa80d413490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa80d412a50>]}


============================== 03:52:24.011977 | 153982ef-b29e-485c-a6a1-a4323e74a1cf ==============================
[0m03:52:24.011977 [info ] [MainThread]: Running with dbt=1.9.0
[0m03:52:24.014208 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'invocation_command': 'dbt run', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m03:52:24.562759 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '153982ef-b29e-485c-a6a1-a4323e74a1cf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa7df7b1ed0>]}
[0m03:52:24.605908 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '153982ef-b29e-485c-a6a1-a4323e74a1cf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa80f6c4850>]}
[0m03:52:24.607225 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m03:52:24.672475 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m03:52:24.832758 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m03:52:24.833897 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/facts/dim_driver.sql
[0m03:52:25.078914 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '153982ef-b29e-485c-a6a1-a4323e74a1cf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa80d41a910>]}
[0m03:52:25.153169 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m03:52:25.158872 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m03:52:25.173723 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '153982ef-b29e-485c-a6a1-a4323e74a1cf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa7df125390>]}
[0m03:52:25.175229 [info ] [MainThread]: Found 6 models, 8 sources, 489 macros
[0m03:52:25.177212 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '153982ef-b29e-485c-a6a1-a4323e74a1cf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa7df405090>]}
[0m03:52:25.180294 [info ] [MainThread]: 
[0m03:52:25.181414 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m03:52:25.182698 [info ] [MainThread]: 
[0m03:52:25.183934 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m03:52:25.188506 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m03:52:25.189205 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m03:52:25.189950 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m03:52:25.190874 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m03:52:26.746071 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_facts)
[0m03:52:26.746756 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_staging)
[0m03:52:26.747428 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m03:52:26.752045 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m03:52:27.051138 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '153982ef-b29e-485c-a6a1-a4323e74a1cf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa7df595350>]}
[0m03:52:27.054147 [debug] [MainThread]: Opening a new connection, currently in state init
[0m03:52:27.060543 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m03:52:27.060915 [debug] [Thread-2 (]: Began running node model.hailing_project.dim_driver
[0m03:52:27.061338 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m03:52:27.061957 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m03:52:27.062658 [info ] [Thread-1 (]: 1 of 6 START sql incremental model rizky_dwh_hailing_facts.dim_customer ........ [RUN]
[0m03:52:27.064034 [info ] [Thread-2 (]: 2 of 6 START sql incremental model rizky_dwh_hailing_facts.dim_driver .......... [RUN]
[0m03:52:27.065599 [info ] [Thread-3 (]: 3 of 6 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [RUN]
[0m03:52:27.066669 [info ] [Thread-4 (]: 4 of 6 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [RUN]
[0m03:52:27.068186 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_facts, now model.hailing_project.dim_customer)
[0m03:52:27.069433 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_staging, now model.hailing_project.dim_driver)
[0m03:52:27.070585 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_customer'
[0m03:52:27.072583 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m03:52:27.074613 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m03:52:27.076641 [debug] [Thread-2 (]: Began compiling node model.hailing_project.dim_driver
[0m03:52:27.078002 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m03:52:27.079500 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m03:52:27.090381 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m03:52:27.096665 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.dim_driver"
[0m03:52:27.101616 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m03:52:27.107119 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m03:52:27.114054 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m03:52:27.114687 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m03:52:27.115369 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m03:52:27.116082 [debug] [Thread-2 (]: Began executing node model.hailing_project.dim_driver
[0m03:52:27.168701 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m03:52:27.170366 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m03:52:27.172906 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m03:52:27.202606 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.dim_driver"
[0m03:52:27.277867 [debug] [Thread-2 (]: On model.hailing_project.dim_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_driver"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      


WITH driver AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver`

),

vehicle AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle`
)

SELECT
    driver.id,
    driver.name as driver_name,
    driver.phone_number as phone_number,
    driver.email as email
    vehicle.vehicle_type,
    vehicle.license_plate,
    vehicle.year as vehicle_production_year,
    vehicle.brand as vehicle_brand,
    driver.created_at
FROM driver
LEFT JOIN vehicle
on driver.driver_id = vehicle.vehicle_id

SELECT * FROM cleaned

    );
  
[0m03:52:27.278927 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m03:52:27.513666 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m03:52:27.514962 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m03:52:27.516043 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m03:52:27.520693 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m03:52:27.521369 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m03:52:27.522040 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m03:52:27.783833 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:2ae00ba8-be91-4932-853d-7816c74bab3f&page=queryresults
[0m03:52:27.784858 [error] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:2ae00ba8-be91-4932-853d-7816c74bab3f&page=queryresults
[0m03:52:27.790155 [debug] [Thread-2 (]: Database Error in model dim_driver (models/facts/dim_driver.sql)
  Syntax error: Expected ")" but got identifier "vehicle" at [32:5]
  compiled code at target/run/hailing_project/models/facts/dim_driver.sql
[0m03:52:27.792153 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '153982ef-b29e-485c-a6a1-a4323e74a1cf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa7df24b210>]}
[0m03:52:27.793240 [error] [Thread-2 (]: 2 of 6 ERROR creating sql incremental model rizky_dwh_hailing_facts.dim_driver . [[31mERROR[0m in 0.72s]
[0m03:52:27.794478 [debug] [Thread-2 (]: Finished running node model.hailing_project.dim_driver
[0m03:52:27.795655 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m03:52:27.796222 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.dim_driver' to be skipped because of status 'error'.  Reason: Database Error in model dim_driver (models/facts/dim_driver.sql)
  Syntax error: Expected ")" but got identifier "vehicle" at [32:5]
  compiled code at target/run/hailing_project/models/facts/dim_driver.sql.
[0m03:52:27.797413 [info ] [Thread-2 (]: 5 of 6 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [RUN]
[0m03:52:27.800220 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.hailing_project.dim_driver, now model.hailing_project.production_hailing_staging_ride)
[0m03:52:27.801476 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m03:52:27.805693 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m03:52:27.811518 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m03:52:27.815649 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m03:52:27.847386 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:d242e63c-74f6-4fe3-af28-af964e8dcde6&page=queryresults
[0m03:52:27.848761 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:4d45b910-058a-48a9-a624-feaa71953969&page=queryresults
[0m03:52:27.854140 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:5acdda52-85ad-4c31-ba99-1a58b59c576d&page=queryresults
[0m03:52:28.057302 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m03:52:28.063732 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m03:52:28.327893 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:6f86c974-367e-4205-9ea8-f53bb05a4550&page=queryresults
[0m03:52:29.456623 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '153982ef-b29e-485c-a6a1-a4323e74a1cf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa7df164490>]}
[0m03:52:29.458336 [info ] [Thread-3 (]: 3 of 6 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.39s]
[0m03:52:29.460495 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m03:52:29.461637 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m03:52:29.462898 [info ] [Thread-3 (]: 6 of 6 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [RUN]
[0m03:52:29.464630 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_customer, now model.hailing_project.production_hailing_staging_vehicle)
[0m03:52:29.465826 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m03:52:29.470629 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m03:52:29.473674 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '153982ef-b29e-485c-a6a1-a4323e74a1cf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa7df193110>]}
[0m03:52:29.475227 [info ] [Thread-4 (]: 4 of 6 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.40s]
[0m03:52:29.477281 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m03:52:29.483413 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m03:52:29.486387 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m03:52:29.522430 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '153982ef-b29e-485c-a6a1-a4323e74a1cf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa7df717ad0>]}
[0m03:52:29.523511 [info ] [Thread-1 (]: 1 of 6 OK created sql incremental model rizky_dwh_hailing_facts.dim_customer ... [[32mMERGE (0.0 rows, 11.3 KiB processed)[0m in 2.45s]
[0m03:52:29.524609 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m03:52:29.851836 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m03:52:29.859497 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m03:52:29.872787 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '153982ef-b29e-485c-a6a1-a4323e74a1cf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa7c732ca50>]}
[0m03:52:29.874722 [info ] [Thread-2 (]: 5 of 6 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.07s]
[0m03:52:29.876314 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m03:52:30.153534 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:185c6217-28d4-4ab3-aa5c-163148948018&page=queryresults
[0m03:52:31.699232 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '153982ef-b29e-485c-a6a1-a4323e74a1cf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa7df1cac10>]}
[0m03:52:31.700697 [info ] [Thread-3 (]: 6 of 6 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.23s]
[0m03:52:31.702715 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m03:52:31.704941 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m03:52:31.707325 [debug] [MainThread]: Connection 'master' was properly closed.
[0m03:52:31.708122 [debug] [MainThread]: Connection 'model.hailing_project.dim_customer' was properly closed.
[0m03:52:31.708858 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m03:52:31.709577 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m03:52:31.710266 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m03:52:31.711049 [info ] [MainThread]: 
[0m03:52:31.712258 [info ] [MainThread]: Finished running 6 incremental models in 0 hours 0 minutes and 6.53 seconds (6.53s).
[0m03:52:31.714442 [debug] [MainThread]: Command end result
[0m03:52:31.748795 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m03:52:31.753072 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m03:52:31.762001 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m03:52:31.762972 [info ] [MainThread]: 
[0m03:52:31.764267 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m03:52:31.765666 [info ] [MainThread]: 
[0m03:52:31.767051 [error] [MainThread]:   Database Error in model dim_driver (models/facts/dim_driver.sql)
  Syntax error: Expected ")" but got identifier "vehicle" at [32:5]
  compiled code at target/run/hailing_project/models/facts/dim_driver.sql
[0m03:52:31.768040 [info ] [MainThread]: 
[0m03:52:31.769018 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=1 SKIP=0 TOTAL=6
[0m03:52:31.770908 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 7.808884, "process_in_blocks": "0", "process_kernel_time": 0.183053, "process_mem_max_rss": "227456", "process_out_blocks": "0", "process_user_time": 3.569547}
[0m03:52:31.772019 [debug] [MainThread]: Command `dbt run` failed at 03:52:31.771874 after 7.81 seconds
[0m03:52:31.773071 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa80d48f850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa80e11b410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa80d470a50>]}
[0m03:52:31.774612 [debug] [MainThread]: Flushing usage events
[0m03:52:33.388748 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:54:07.259821 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f62c65eba10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f62c66339d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f62c7a90390>]}


============================== 03:54:07.262318 | 907bc332-d776-4c5c-94f6-8f79fc20f430 ==============================
[0m03:54:07.262318 [info ] [MainThread]: Running with dbt=1.9.0
[0m03:54:07.264657 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt run --select dim_driver', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m03:54:07.823247 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '907bc332-d776-4c5c-94f6-8f79fc20f430', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f629cf7de50>]}
[0m03:54:07.872691 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '907bc332-d776-4c5c-94f6-8f79fc20f430', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f62c8872050>]}
[0m03:54:07.874037 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m03:54:07.945154 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m03:54:08.103641 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m03:54:08.105009 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/facts/dim_driver.sql
[0m03:54:08.352391 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '907bc332-d776-4c5c-94f6-8f79fc20f430', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f629c988310>]}
[0m03:54:08.424504 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m03:54:08.431950 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m03:54:08.446498 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '907bc332-d776-4c5c-94f6-8f79fc20f430', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f629c2eddd0>]}
[0m03:54:08.447591 [info ] [MainThread]: Found 6 models, 8 sources, 489 macros
[0m03:54:08.448916 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '907bc332-d776-4c5c-94f6-8f79fc20f430', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f629c2a6050>]}
[0m03:54:08.451236 [info ] [MainThread]: 
[0m03:54:08.452308 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m03:54:08.453178 [info ] [MainThread]: 
[0m03:54:08.454363 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m03:54:08.456087 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m03:54:08.456992 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m03:54:08.962655 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_staging)
[0m03:54:08.963328 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_facts'
[0m03:54:08.964223 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m03:54:08.965400 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m03:54:09.232281 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '907bc332-d776-4c5c-94f6-8f79fc20f430', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f629c762b50>]}
[0m03:54:09.233782 [debug] [MainThread]: Opening a new connection, currently in state init
[0m03:54:09.238271 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_driver
[0m03:54:09.239672 [info ] [Thread-1 (]: 1 of 1 START sql incremental model rizky_dwh_hailing_facts.dim_driver .......... [RUN]
[0m03:54:09.241442 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_staging, now model.hailing_project.dim_driver)
[0m03:54:09.242597 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_driver
[0m03:54:09.250554 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_driver"
[0m03:54:09.259693 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_driver
[0m03:54:09.325980 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_driver"
[0m03:54:09.335059 [debug] [Thread-1 (]: On model.hailing_project.dim_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_driver"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      


WITH driver AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver`

),

vehicle AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle`
)

SELECT
    driver.id,
    driver.name as driver_name,
    driver.phone_number as phone_number,
    driver.email as email
    vehicle.vehicle_type,
    vehicle.license_plate,
    vehicle.year as vehicle_production_year,
    vehicle.brand as vehicle_brand,
    driver.created_at
FROM driver
LEFT JOIN vehicle
on driver.driver_id = vehicle.vehicle_id


    );
  
[0m03:54:09.336256 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m03:54:10.320401 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:a6ce2bf3-a20a-4c76-889d-4ef962a5b5b3&page=queryresults
[0m03:54:10.321910 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:a6ce2bf3-a20a-4c76-889d-4ef962a5b5b3&page=queryresults
[0m03:54:10.328443 [debug] [Thread-1 (]: Database Error in model dim_driver (models/facts/dim_driver.sql)
  Syntax error: Expected ")" but got identifier "vehicle" at [32:5]
  compiled code at target/run/hailing_project/models/facts/dim_driver.sql
[0m03:54:10.331095 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '907bc332-d776-4c5c-94f6-8f79fc20f430', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f629c35f1d0>]}
[0m03:54:10.332889 [error] [Thread-1 (]: 1 of 1 ERROR creating sql incremental model rizky_dwh_hailing_facts.dim_driver . [[31mERROR[0m in 1.09s]
[0m03:54:10.334846 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_driver
[0m03:54:10.336238 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.dim_driver' to be skipped because of status 'error'.  Reason: Database Error in model dim_driver (models/facts/dim_driver.sql)
  Syntax error: Expected ")" but got identifier "vehicle" at [32:5]
  compiled code at target/run/hailing_project/models/facts/dim_driver.sql.
[0m03:54:10.339833 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m03:54:10.344167 [debug] [MainThread]: Connection 'master' was properly closed.
[0m03:54:10.345526 [debug] [MainThread]: Connection 'model.hailing_project.dim_driver' was properly closed.
[0m03:54:10.346457 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_facts' was properly closed.
[0m03:54:10.347356 [info ] [MainThread]: 
[0m03:54:10.348458 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 1.89 seconds (1.89s).
[0m03:54:10.350111 [debug] [MainThread]: Command end result
[0m03:54:10.389126 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m03:54:10.392799 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m03:54:10.400151 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m03:54:10.400779 [info ] [MainThread]: 
[0m03:54:10.401758 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m03:54:10.402760 [info ] [MainThread]: 
[0m03:54:10.404120 [error] [MainThread]:   Database Error in model dim_driver (models/facts/dim_driver.sql)
  Syntax error: Expected ")" but got identifier "vehicle" at [32:5]
  compiled code at target/run/hailing_project/models/facts/dim_driver.sql
[0m03:54:10.405239 [info ] [MainThread]: 
[0m03:54:10.406583 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m03:54:10.408627 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 3.193945, "process_in_blocks": "0", "process_kernel_time": 0.256559, "process_mem_max_rss": "220320", "process_out_blocks": "0", "process_user_time": 3.191598}
[0m03:54:10.409977 [debug] [MainThread]: Command `dbt run` failed at 03:54:10.409777 after 3.20 seconds
[0m03:54:10.410876 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f62c6643d10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f62ca0dd910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f62c9f692d0>]}
[0m03:54:10.411729 [debug] [MainThread]: Flushing usage events
[0m03:54:11.672933 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:54:47.305132 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f336901b910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3368fc3190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3368fc2d50>]}


============================== 03:54:47.307891 | 01a47711-d4a1-4af5-9bb6-d1a40e76aa48 ==============================
[0m03:54:47.307891 [info ] [MainThread]: Running with dbt=1.9.0
[0m03:54:47.310333 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt run --select dim_driver', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m03:54:47.891313 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '01a47711-d4a1-4af5-9bb6-d1a40e76aa48', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f333b16edd0>]}
[0m03:54:47.933743 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '01a47711-d4a1-4af5-9bb6-d1a40e76aa48', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f333b2caf10>]}
[0m03:54:47.935343 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m03:54:48.000278 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m03:54:48.154713 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m03:54:48.156535 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/facts/dim_driver.sql
[0m03:54:48.405934 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '01a47711-d4a1-4af5-9bb6-d1a40e76aa48', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f333b17f150>]}
[0m03:54:48.474712 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m03:54:48.479871 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m03:54:48.494788 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '01a47711-d4a1-4af5-9bb6-d1a40e76aa48', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f333acd9510>]}
[0m03:54:48.496074 [info ] [MainThread]: Found 6 models, 8 sources, 489 macros
[0m03:54:48.497143 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '01a47711-d4a1-4af5-9bb6-d1a40e76aa48', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f333afc3e50>]}
[0m03:54:48.499183 [info ] [MainThread]: 
[0m03:54:48.500188 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m03:54:48.501138 [info ] [MainThread]: 
[0m03:54:48.502303 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m03:54:48.503760 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m03:54:48.504522 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m03:54:49.016799 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_staging)
[0m03:54:49.017354 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_facts'
[0m03:54:49.017988 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m03:54:49.018720 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m03:54:49.276759 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '01a47711-d4a1-4af5-9bb6-d1a40e76aa48', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f333b14f510>]}
[0m03:54:49.278398 [debug] [MainThread]: Opening a new connection, currently in state init
[0m03:54:49.283031 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_driver
[0m03:54:49.285179 [info ] [Thread-1 (]: 1 of 1 START sql incremental model rizky_dwh_hailing_facts.dim_driver .......... [RUN]
[0m03:54:49.287346 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_staging, now model.hailing_project.dim_driver)
[0m03:54:49.288716 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_driver
[0m03:54:49.298247 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_driver"
[0m03:54:49.305613 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_driver
[0m03:54:49.365969 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_driver"
[0m03:54:49.371943 [debug] [Thread-1 (]: On model.hailing_project.dim_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_driver"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      


WITH driver AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver`

),

vehicle AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle`
)

SELECT
    driver.id,
    driver.name as driver_name,
    driver.phone_number as phone_number,
    driver.email as email,
    vehicle.vehicle_type,
    vehicle.license_plate,
    vehicle.year as vehicle_production_year,
    vehicle.brand as vehicle_brand,
    driver.created_at
FROM driver
LEFT JOIN vehicle
on driver.driver_id = vehicle.vehicle_id


    );
  
[0m03:54:49.372896 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m03:54:49.880754 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:8f06bbcb-6426-4ec7-8c14-4de0897565c2&page=queryresults
[0m03:54:49.952669 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:8f06bbcb-6426-4ec7-8c14-4de0897565c2&page=queryresults
[0m03:54:49.958264 [debug] [Thread-1 (]: Database Error in model dim_driver (models/facts/dim_driver.sql)
  Name id not found inside driver at [28:12]
  compiled code at target/run/hailing_project/models/facts/dim_driver.sql
[0m03:54:49.960672 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '01a47711-d4a1-4af5-9bb6-d1a40e76aa48', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f333ad225d0>]}
[0m03:54:49.961730 [error] [Thread-1 (]: 1 of 1 ERROR creating sql incremental model rizky_dwh_hailing_facts.dim_driver . [[31mERROR[0m in 0.67s]
[0m03:54:49.963258 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_driver
[0m03:54:49.964825 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.dim_driver' to be skipped because of status 'error'.  Reason: Database Error in model dim_driver (models/facts/dim_driver.sql)
  Name id not found inside driver at [28:12]
  compiled code at target/run/hailing_project/models/facts/dim_driver.sql.
[0m03:54:49.967667 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m03:54:49.972155 [debug] [MainThread]: Connection 'master' was properly closed.
[0m03:54:49.973097 [debug] [MainThread]: Connection 'model.hailing_project.dim_driver' was properly closed.
[0m03:54:49.973994 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_facts' was properly closed.
[0m03:54:49.974822 [info ] [MainThread]: 
[0m03:54:49.975920 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 1.47 seconds (1.47s).
[0m03:54:49.977302 [debug] [MainThread]: Command end result
[0m03:54:50.009816 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m03:54:50.013990 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m03:54:50.021271 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m03:54:50.021953 [info ] [MainThread]: 
[0m03:54:50.023028 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m03:54:50.024254 [info ] [MainThread]: 
[0m03:54:50.025299 [error] [MainThread]:   Database Error in model dim_driver (models/facts/dim_driver.sql)
  Name id not found inside driver at [28:12]
  compiled code at target/run/hailing_project/models/facts/dim_driver.sql
[0m03:54:50.026188 [info ] [MainThread]: 
[0m03:54:50.027116 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m03:54:50.028941 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 2.772105, "process_in_blocks": "0", "process_kernel_time": 0.173367, "process_mem_max_rss": "218932", "process_out_blocks": "0", "process_user_time": 3.273578}
[0m03:54:50.030442 [debug] [MainThread]: Command `dbt run` failed at 03:54:50.030216 after 2.77 seconds
[0m03:54:50.031674 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f336901e9d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f336901f9d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f333b14dd90>]}
[0m03:54:50.032669 [debug] [MainThread]: Flushing usage events
[0m03:54:51.237289 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:56:52.423614 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f31bfb2fa90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f31bfb2dbd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f31bfb2ec90>]}


============================== 03:56:52.426398 | c810cd32-3329-4924-80e5-2f7a50074dc4 ==============================
[0m03:56:52.426398 [info ] [MainThread]: Running with dbt=1.9.0
[0m03:56:52.428051 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt run --select dim_driver', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m03:56:53.025163 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'c810cd32-3329-4924-80e5-2f7a50074dc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3192424950>]}
[0m03:56:53.070626 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'c810cd32-3329-4924-80e5-2f7a50074dc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f31c1dde590>]}
[0m03:56:53.071920 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m03:56:53.137994 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m03:56:53.307802 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m03:56:53.308653 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/facts/dim_driver.sql
[0m03:56:53.554722 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c810cd32-3329-4924-80e5-2f7a50074dc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3191abca50>]}
[0m03:56:53.617070 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m03:56:53.623485 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m03:56:53.638962 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c810cd32-3329-4924-80e5-2f7a50074dc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3191976950>]}
[0m03:56:53.639993 [info ] [MainThread]: Found 6 models, 8 sources, 489 macros
[0m03:56:53.641048 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c810cd32-3329-4924-80e5-2f7a50074dc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3191944550>]}
[0m03:56:53.643152 [info ] [MainThread]: 
[0m03:56:53.644218 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m03:56:53.645568 [info ] [MainThread]: 
[0m03:56:53.646859 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m03:56:53.648508 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m03:56:53.649348 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m03:56:54.188564 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_staging)
[0m03:56:54.189316 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_facts'
[0m03:56:54.190479 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m03:56:54.191661 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m03:56:54.418630 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c810cd32-3329-4924-80e5-2f7a50074dc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3191e19ed0>]}
[0m03:56:54.420153 [debug] [MainThread]: Opening a new connection, currently in state init
[0m03:56:54.426424 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_driver
[0m03:56:54.427344 [info ] [Thread-1 (]: 1 of 1 START sql incremental model rizky_dwh_hailing_facts.dim_driver .......... [RUN]
[0m03:56:54.428460 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_facts, now model.hailing_project.dim_driver)
[0m03:56:54.429162 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_driver
[0m03:56:54.437195 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_driver"
[0m03:56:54.442353 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_driver
[0m03:56:54.506238 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_driver"
[0m03:56:54.512046 [debug] [Thread-1 (]: On model.hailing_project.dim_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_driver"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      


WITH driver AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver`

),

vehicle AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle`
)

SELECT
    driver.driver_id,
    vehicle.vehicle_id,
    driver.name as driver_name,
    driver.phone_number as phone_number,
    driver.email as email,
    vehicle.vehicle_type,
    vehicle.brand as vehicle_brand,
    vehicle.year as vehicle_production_year,
    vehicle.license_plate,
    driver.created_at
FROM driver
LEFT JOIN vehicle
on driver.driver_id = vehicle.vehicle_id


    );
  
[0m03:56:54.512894 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m03:56:54.926032 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:40b8ee3b-5c33-4455-8090-ffadaebed153&page=queryresults
[0m03:56:56.890643 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c810cd32-3329-4924-80e5-2f7a50074dc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3191aecd50>]}
[0m03:56:56.891896 [info ] [Thread-1 (]: 1 of 1 OK created sql incremental model rizky_dwh_hailing_facts.dim_driver ..... [[32mCREATE TABLE (85.0 rows, 9.0 KiB processed)[0m in 2.46s]
[0m03:56:56.893333 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_driver
[0m03:56:56.895486 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m03:56:56.898100 [debug] [MainThread]: Connection 'master' was properly closed.
[0m03:56:56.898795 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_staging' was properly closed.
[0m03:56:56.899471 [debug] [MainThread]: Connection 'model.hailing_project.dim_driver' was properly closed.
[0m03:56:56.900297 [info ] [MainThread]: 
[0m03:56:56.901146 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 3.25 seconds (3.25s).
[0m03:56:56.903027 [debug] [MainThread]: Command end result
[0m03:56:56.938007 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m03:56:56.941876 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m03:56:56.949545 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m03:56:56.950397 [info ] [MainThread]: 
[0m03:56:56.952239 [info ] [MainThread]: [32mCompleted successfully[0m
[0m03:56:56.953184 [info ] [MainThread]: 
[0m03:56:56.954082 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m03:56:56.955463 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 4.581288, "process_in_blocks": "0", "process_kernel_time": 0.241443, "process_mem_max_rss": "222432", "process_out_blocks": "0", "process_user_time": 3.299729}
[0m03:56:56.956415 [debug] [MainThread]: Command `dbt run` succeeded at 03:56:56.956308 after 4.58 seconds
[0m03:56:56.957145 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f31c0048c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f31c3659950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f31c3446710>]}
[0m03:56:56.958052 [debug] [MainThread]: Flushing usage events
[0m03:56:58.264872 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m04:48:38.604446 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8fc9da7210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8fc9dfff50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8fc9da7c10>]}


============================== 04:48:38.606945 | 1fdcd880-ba96-412d-9c06-29ef2c32b785 ==============================
[0m04:48:38.606945 [info ] [MainThread]: Running with dbt=1.9.0
[0m04:48:38.608337 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'profiles_dir': '/usr/app/dbt_project', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt run --select group_1', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m04:48:39.162604 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1fdcd880-ba96-412d-9c06-29ef2c32b785', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8f9bf3fa10>]}
[0m04:48:39.206770 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '1fdcd880-ba96-412d-9c06-29ef2c32b785', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8fcc018e50>]}
[0m04:48:39.208233 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m04:48:39.276813 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m04:48:39.340670 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m04:48:39.342226 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '1fdcd880-ba96-412d-9c06-29ef2c32b785', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8fcaba8390>]}
[0m04:48:40.332897 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1fdcd880-ba96-412d-9c06-29ef2c32b785', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8f9bd8ed90>]}
[0m04:48:40.399208 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m04:48:40.404694 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m04:48:40.423266 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1fdcd880-ba96-412d-9c06-29ef2c32b785', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8f9b925a90>]}
[0m04:48:40.424300 [info ] [MainThread]: Found 6 models, 8 sources, 489 macros
[0m04:48:40.425530 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1fdcd880-ba96-412d-9c06-29ef2c32b785', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8f9bb52c10>]}
[0m04:48:40.426947 [warn ] [MainThread]: The selection criterion 'group_1' does not match any enabled nodes
[0m04:48:40.428911 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m04:48:40.430219 [debug] [MainThread]: Command end result
[0m04:48:40.463962 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m04:48:40.468096 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m04:48:40.473234 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m04:48:40.474596 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 1.9166095, "process_in_blocks": "0", "process_kernel_time": 0.200588, "process_mem_max_rss": "216544", "process_out_blocks": "0", "process_user_time": 3.660736}
[0m04:48:40.475607 [debug] [MainThread]: Command `dbt run` succeeded at 04:48:40.475484 after 1.92 seconds
[0m04:48:40.476478 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8fca25c490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8fc9e27a10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8fcd59cc50>]}
[0m04:48:40.477340 [debug] [MainThread]: Flushing usage events
[0m04:48:41.764404 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m04:49:13.035778 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faaf0fd6950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faaf101bc90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faaf101b3d0>]}


============================== 04:49:13.038336 | fd16f72e-17f3-4a5c-af5b-51bd1714c447 ==============================
[0m04:49:13.038336 [info ] [MainThread]: Running with dbt=1.9.0
[0m04:49:13.039939 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt run --select group_1', 'send_anonymous_usage_stats': 'True'}
[0m04:49:13.605684 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'fd16f72e-17f3-4a5c-af5b-51bd1714c447', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faac38a9490>]}
[0m04:49:13.649561 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'fd16f72e-17f3-4a5c-af5b-51bd1714c447', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faaf322d8d0>]}
[0m04:49:13.650946 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m04:49:13.717875 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m04:49:13.782457 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m04:49:13.784742 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'fd16f72e-17f3-4a5c-af5b-51bd1714c447', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faaf16beb50>]}
[0m04:49:14.761195 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'fd16f72e-17f3-4a5c-af5b-51bd1714c447', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faac2d048d0>]}
[0m04:49:14.825274 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m04:49:14.832130 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m04:49:14.847762 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'fd16f72e-17f3-4a5c-af5b-51bd1714c447', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faac2b0d5d0>]}
[0m04:49:14.848887 [info ] [MainThread]: Found 6 models, 8 sources, 489 macros
[0m04:49:14.850232 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'fd16f72e-17f3-4a5c-af5b-51bd1714c447', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faac2d40f10>]}
[0m04:49:14.851655 [warn ] [MainThread]: The selection criterion 'group_1' does not match any enabled nodes
[0m04:49:14.853599 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m04:49:14.855281 [debug] [MainThread]: Command end result
[0m04:49:14.885875 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m04:49:14.889370 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m04:49:14.894887 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m04:49:14.896648 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 1.9093758, "process_in_blocks": "0", "process_kernel_time": 0.221267, "process_mem_max_rss": "216300", "process_out_blocks": "0", "process_user_time": 3.610689}
[0m04:49:14.898035 [debug] [MainThread]: Command `dbt run` succeeded at 04:49:14.897884 after 1.91 seconds
[0m04:49:14.898968 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faaf0e53dd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faac2e993d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faaf479ce50>]}
[0m04:49:14.900179 [debug] [MainThread]: Flushing usage events
[0m04:49:15.883720 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m04:49:38.210617 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f11d5c67750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f11d5cb7f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f11d5c66610>]}


============================== 04:49:38.213481 | 1e65d204-889e-4d0a-b1c7-f0196bdb8b92 ==============================
[0m04:49:38.213481 [info ] [MainThread]: Running with dbt=1.9.0
[0m04:49:38.215035 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt clean', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m04:49:38.294393 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1e65d204-889e-4d0a-b1c7-f0196bdb8b92', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f11d605e110>]}
[0m04:49:38.355311 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.19624841, "process_in_blocks": "0", "process_kernel_time": 0.088908, "process_mem_max_rss": "90156", "process_out_blocks": "0", "process_user_time": 0.9286}
[0m04:49:38.356371 [debug] [MainThread]: Command `dbt clean` succeeded at 04:49:38.356244 after 0.20 seconds
[0m04:49:38.357060 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f11d5cb7f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f11d6089fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f11d94bcb90>]}
[0m04:49:38.357800 [debug] [MainThread]: Flushing usage events
[0m04:49:39.563080 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m04:49:40.769424 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb22220ab10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb22220a710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb22220a8d0>]}


============================== 04:49:40.772606 | cca82c34-9ba3-4443-8d20-e412a36b8c38 ==============================
[0m04:49:40.772606 [info ] [MainThread]: Running with dbt=1.9.0
[0m04:49:40.773871 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt deps', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m04:49:40.868642 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'cca82c34-9ba3-4443-8d20-e412a36b8c38', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb222283250>]}
[0m04:49:40.880221 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m04:49:40.883069 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m04:49:40.884673 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.17200167, "process_in_blocks": "0", "process_kernel_time": 0.129697, "process_mem_max_rss": "90096", "process_out_blocks": "0", "process_user_time": 1.00765}
[0m04:49:40.885720 [debug] [MainThread]: Command `dbt deps` succeeded at 04:49:40.885594 after 0.17 seconds
[0m04:49:40.886490 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb225b22710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb222f13590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb2222628d0>]}
[0m04:49:40.887614 [debug] [MainThread]: Flushing usage events
[0m04:49:41.948938 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m04:51:15.724887 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f27e2388e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f27e23894d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f27e238ac90>]}


============================== 04:51:15.727426 | f7c0d671-3acd-47ac-83f9-f4a6f4d19311 ==============================
[0m04:51:15.727426 [info ] [MainThread]: Running with dbt=1.9.0
[0m04:51:15.729179 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --select dim_customer', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m04:51:16.301153 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f7c0d671-3acd-47ac-83f9-f4a6f4d19311', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f27b8756f90>]}
[0m04:51:16.345860 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f7c0d671-3acd-47ac-83f9-f4a6f4d19311', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f27e4639d10>]}
[0m04:51:16.347426 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m04:51:16.414067 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m04:51:16.416027 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m04:51:16.417096 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'f7c0d671-3acd-47ac-83f9-f4a6f4d19311', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f27e2aa6390>]}
[0m04:51:17.399425 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f7c0d671-3acd-47ac-83f9-f4a6f4d19311', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f27b83d93d0>]}
[0m04:51:17.465069 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m04:51:17.472535 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m04:51:17.488449 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f7c0d671-3acd-47ac-83f9-f4a6f4d19311', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f27b813f810>]}
[0m04:51:17.489575 [info ] [MainThread]: Found 6 models, 8 sources, 489 macros
[0m04:51:17.490883 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f7c0d671-3acd-47ac-83f9-f4a6f4d19311', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f27b81a8e90>]}
[0m04:51:17.493300 [info ] [MainThread]: 
[0m04:51:17.494525 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m04:51:17.495689 [info ] [MainThread]: 
[0m04:51:17.497466 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m04:51:17.499811 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m04:51:17.501139 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:51:18.059306 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_staging)
[0m04:51:18.059957 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_facts'
[0m04:51:18.060710 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m04:51:18.062193 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:51:18.313704 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f7c0d671-3acd-47ac-83f9-f4a6f4d19311', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f27b82fc2d0>]}
[0m04:51:18.314842 [debug] [MainThread]: Opening a new connection, currently in state init
[0m04:51:18.319814 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m04:51:18.320793 [info ] [Thread-1 (]: 1 of 1 START sql incremental model rizky_dwh_hailing_facts.dim_customer ........ [RUN]
[0m04:51:18.321923 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_facts, now model.hailing_project.dim_customer)
[0m04:51:18.322933 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m04:51:18.334681 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m04:51:18.348915 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m04:51:18.385123 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:51:18.644105 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m04:51:18.660013 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
),


SELECT * FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m04:51:19.017471 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:01bd5ef4-72de-4c04-9e59-695f97e59933&page=queryresults
[0m04:51:19.018520 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:01bd5ef4-72de-4c04-9e59-695f97e59933&page=queryresults
[0m04:51:19.026221 [debug] [Thread-1 (]: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Syntax error: Trailing comma after the WITH clause before the main query is not allowed at [22:1]
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m04:51:19.028490 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f7c0d671-3acd-47ac-83f9-f4a6f4d19311', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f27b845e710>]}
[0m04:51:19.029771 [error] [Thread-1 (]: 1 of 1 ERROR creating sql incremental model rizky_dwh_hailing_facts.dim_customer  [[31mERROR[0m in 0.71s]
[0m04:51:19.031052 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m04:51:19.032740 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.dim_customer' to be skipped because of status 'error'.  Reason: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Syntax error: Trailing comma after the WITH clause before the main query is not allowed at [22:1]
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql.
[0m04:51:19.035432 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m04:51:19.038705 [debug] [MainThread]: Connection 'master' was properly closed.
[0m04:51:19.039654 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_staging' was properly closed.
[0m04:51:19.042256 [debug] [MainThread]: Connection 'model.hailing_project.dim_customer' was properly closed.
[0m04:51:19.043666 [info ] [MainThread]: 
[0m04:51:19.044633 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 1.55 seconds (1.55s).
[0m04:51:19.046147 [debug] [MainThread]: Command end result
[0m04:51:19.081184 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m04:51:19.085409 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m04:51:19.093009 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m04:51:19.093850 [info ] [MainThread]: 
[0m04:51:19.095041 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m04:51:19.096210 [info ] [MainThread]: 
[0m04:51:19.097348 [error] [MainThread]:   Database Error in model dim_customer (models/facts/dim_customer.sql)
  Syntax error: Trailing comma after the WITH clause before the main query is not allowed at [22:1]
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m04:51:19.098427 [info ] [MainThread]: 
[0m04:51:19.099353 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m04:51:19.101094 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 3.4247143, "process_in_blocks": "0", "process_kernel_time": 0.181031, "process_mem_max_rss": "220692", "process_out_blocks": "0", "process_user_time": 3.892174}
[0m04:51:19.102496 [debug] [MainThread]: Command `dbt run` failed at 04:51:19.102310 after 3.43 seconds
[0m04:51:19.103572 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f27e240ba90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f27e240b990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f27e5d411d0>]}
[0m04:51:19.104493 [debug] [MainThread]: Flushing usage events
[0m04:51:20.170064 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m04:51:38.379332 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5b8a16f950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5b8a1b7c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5b8a1b7110>]}


============================== 04:51:38.382437 | 7ffbebd6-8a0d-42c1-a581-e9e743c6ad10 ==============================
[0m04:51:38.382437 [info ] [MainThread]: Running with dbt=1.9.0
[0m04:51:38.384157 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt run --select dim_customer', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m04:51:38.998237 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '7ffbebd6-8a0d-42c1-a581-e9e743c6ad10', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5b604c9110>]}
[0m04:51:39.050056 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '7ffbebd6-8a0d-42c1-a581-e9e743c6ad10', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5b603c0550>]}
[0m04:51:39.051552 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m04:51:39.120880 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m04:51:39.296206 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m04:51:39.297253 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/facts/dim_customer.sql
[0m04:51:39.563065 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7ffbebd6-8a0d-42c1-a581-e9e743c6ad10', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5b60508910>]}
[0m04:51:39.636987 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m04:51:39.642721 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m04:51:39.657843 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7ffbebd6-8a0d-42c1-a581-e9e743c6ad10', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5b6013a410>]}
[0m04:51:39.659388 [info ] [MainThread]: Found 6 models, 8 sources, 489 macros
[0m04:51:39.662022 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7ffbebd6-8a0d-42c1-a581-e9e743c6ad10', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5b604cb350>]}
[0m04:51:39.664105 [info ] [MainThread]: 
[0m04:51:39.665115 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m04:51:39.666426 [info ] [MainThread]: 
[0m04:51:39.668095 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m04:51:39.670466 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m04:51:39.671479 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:51:40.216573 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_facts)
[0m04:51:40.217226 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_staging'
[0m04:51:40.218111 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m04:51:40.219251 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:51:40.427544 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7ffbebd6-8a0d-42c1-a581-e9e743c6ad10', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5b6047f250>]}
[0m04:51:40.428508 [debug] [MainThread]: Opening a new connection, currently in state init
[0m04:51:40.434129 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m04:51:40.435105 [info ] [Thread-1 (]: 1 of 1 START sql incremental model rizky_dwh_hailing_facts.dim_customer ........ [RUN]
[0m04:51:40.436408 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_staging, now model.hailing_project.dim_customer)
[0m04:51:40.437335 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m04:51:40.447998 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m04:51:40.454217 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m04:51:40.491115 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:51:40.727899 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m04:51:40.733908 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
)


SELECT * FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m04:51:41.077304 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:01902c3c-5e4a-402d-83ce-7b91415faa86&page=queryresults
[0m04:51:42.777896 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7ffbebd6-8a0d-42c1-a581-e9e743c6ad10', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5b6014b610>]}
[0m04:51:42.779622 [info ] [Thread-1 (]: 1 of 1 OK created sql incremental model rizky_dwh_hailing_facts.dim_customer ... [[32mMERGE (0.0 rows, 11.3 KiB processed)[0m in 2.34s]
[0m04:51:42.782045 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m04:51:42.785196 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m04:51:42.788865 [debug] [MainThread]: Connection 'master' was properly closed.
[0m04:51:42.789743 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_facts' was properly closed.
[0m04:51:42.790756 [debug] [MainThread]: Connection 'model.hailing_project.dim_customer' was properly closed.
[0m04:51:42.791949 [info ] [MainThread]: 
[0m04:51:42.793160 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 3.12 seconds (3.12s).
[0m04:51:42.794545 [debug] [MainThread]: Command end result
[0m04:51:42.828519 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m04:51:42.833278 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m04:51:42.842606 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m04:51:42.843504 [info ] [MainThread]: 
[0m04:51:42.844577 [info ] [MainThread]: [32mCompleted successfully[0m
[0m04:51:42.845629 [info ] [MainThread]: 
[0m04:51:42.846700 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m04:51:42.848754 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 4.5308037, "process_in_blocks": "0", "process_kernel_time": 0.195168, "process_mem_max_rss": "221772", "process_out_blocks": "0", "process_user_time": 3.493522}
[0m04:51:42.850062 [debug] [MainThread]: Command `dbt run` succeeded at 04:51:42.849901 after 4.53 seconds
[0m04:51:42.851049 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5b8d968e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5b8daed550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5b8daed450>]}
[0m04:51:42.852110 [debug] [MainThread]: Flushing usage events
[0m04:51:43.868533 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m04:52:40.518022 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa9135cb710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa91361ff50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa9142a7310>]}


============================== 04:52:40.520415 | f729b583-ddca-4455-bd11-a81af54a8d06 ==============================
[0m04:52:40.520415 [info ] [MainThread]: Running with dbt=1.9.0
[0m04:52:40.521786 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'invocation_command': 'dbt run --select dim_customer', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m04:52:41.094555 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f729b583-ddca-4455-bd11-a81af54a8d06', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa9135cb590>]}
[0m04:52:41.140064 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f729b583-ddca-4455-bd11-a81af54a8d06', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa915818dd0>]}
[0m04:52:41.141232 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m04:52:41.212124 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m04:52:41.367374 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m04:52:41.368890 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/facts/dim_customer.sql
[0m04:52:41.611150 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f729b583-ddca-4455-bd11-a81af54a8d06', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa8e94ed690>]}
[0m04:52:41.678911 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m04:52:41.683794 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m04:52:41.698065 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f729b583-ddca-4455-bd11-a81af54a8d06', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa8e923ab10>]}
[0m04:52:41.699144 [info ] [MainThread]: Found 6 models, 8 sources, 489 macros
[0m04:52:41.700211 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f729b583-ddca-4455-bd11-a81af54a8d06', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa8e93e97d0>]}
[0m04:52:41.702214 [info ] [MainThread]: 
[0m04:52:41.703210 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m04:52:41.704185 [info ] [MainThread]: 
[0m04:52:41.705324 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m04:52:41.707055 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m04:52:41.708059 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:52:42.180963 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_staging)
[0m04:52:42.182563 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m04:52:42.181661 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_facts'
[0m04:52:42.186545 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:52:42.397059 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f729b583-ddca-4455-bd11-a81af54a8d06', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa8e95b27d0>]}
[0m04:52:42.398574 [debug] [MainThread]: Opening a new connection, currently in state init
[0m04:52:42.404098 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m04:52:42.405544 [info ] [Thread-1 (]: 1 of 1 START sql incremental model rizky_dwh_hailing_facts.dim_customer ........ [RUN]
[0m04:52:42.407292 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_facts, now model.hailing_project.dim_customer)
[0m04:52:42.408386 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m04:52:42.417900 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m04:52:42.426866 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m04:52:42.465953 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:52:42.706810 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m04:52:42.714195 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
)

SELECT * FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m04:52:43.027890 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:f41202f0-45d3-4133-9404-766ee8320c6f&page=queryresults
[0m04:52:44.613713 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f729b583-ddca-4455-bd11-a81af54a8d06', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa8e9426b50>]}
[0m04:52:44.614804 [info ] [Thread-1 (]: 1 of 1 OK created sql incremental model rizky_dwh_hailing_facts.dim_customer ... [[32mMERGE (0.0 rows, 11.3 KiB processed)[0m in 2.21s]
[0m04:52:44.616119 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m04:52:44.618965 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m04:52:44.622091 [debug] [MainThread]: Connection 'master' was properly closed.
[0m04:52:44.622971 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_staging' was properly closed.
[0m04:52:44.624098 [debug] [MainThread]: Connection 'model.hailing_project.dim_customer' was properly closed.
[0m04:52:44.625277 [info ] [MainThread]: 
[0m04:52:44.626588 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 2.92 seconds (2.92s).
[0m04:52:44.628029 [debug] [MainThread]: Command end result
[0m04:52:44.662867 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m04:52:44.667374 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m04:52:44.674905 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m04:52:44.675687 [info ] [MainThread]: 
[0m04:52:44.676671 [info ] [MainThread]: [32mCompleted successfully[0m
[0m04:52:44.677650 [info ] [MainThread]: 
[0m04:52:44.678934 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m04:52:44.680464 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 4.2075906, "process_in_blocks": "0", "process_kernel_time": 0.165407, "process_mem_max_rss": "222576", "process_out_blocks": "0", "process_user_time": 3.318494}
[0m04:52:44.681425 [debug] [MainThread]: Command `dbt run` succeeded at 04:52:44.681313 after 4.21 seconds
[0m04:52:44.682189 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa9139be650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa913447f90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa916db8e90>]}
[0m04:52:44.683064 [debug] [MainThread]: Flushing usage events
[0m04:52:46.001881 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m04:54:06.239445 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd45b0777d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd45b077110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd45b076d50>]}


============================== 04:54:06.242201 | 3a9b997b-d0c9-4977-bf56-3c0db54e948c ==============================
[0m04:54:06.242201 [info ] [MainThread]: Running with dbt=1.9.0
[0m04:54:06.243279 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m04:54:06.798132 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '3a9b997b-d0c9-4977-bf56-3c0db54e948c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd45bd57ad0>]}
[0m04:54:06.845142 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '3a9b997b-d0c9-4977-bf56-3c0db54e948c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd45d2ee310>]}
[0m04:54:06.846275 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m04:54:06.915141 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m04:54:07.079566 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m04:54:07.081026 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/facts/dim_driver.sql
[0m04:54:07.323104 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3a9b997b-d0c9-4977-bf56-3c0db54e948c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd431031090>]}
[0m04:54:07.390837 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m04:54:07.396496 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m04:54:07.411177 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3a9b997b-d0c9-4977-bf56-3c0db54e948c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd430d95b50>]}
[0m04:54:07.412189 [info ] [MainThread]: Found 6 models, 8 sources, 489 macros
[0m04:54:07.413299 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3a9b997b-d0c9-4977-bf56-3c0db54e948c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd45b0e4190>]}
[0m04:54:07.415682 [info ] [MainThread]: 
[0m04:54:07.416665 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m04:54:07.417729 [info ] [MainThread]: 
[0m04:54:07.419044 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m04:54:07.423797 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m04:54:07.424706 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m04:54:07.425331 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:54:07.426114 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:54:08.320977 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_facts)
[0m04:54:08.321543 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_staging)
[0m04:54:08.323221 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m04:54:08.324416 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m04:54:08.531578 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3a9b997b-d0c9-4977-bf56-3c0db54e948c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd431367190>]}
[0m04:54:08.533514 [debug] [MainThread]: Opening a new connection, currently in state init
[0m04:54:08.538036 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m04:54:08.538395 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m04:54:08.538829 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m04:54:08.539180 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m04:54:08.540013 [info ] [Thread-1 (]: 1 of 6 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [RUN]
[0m04:54:08.542297 [info ] [Thread-2 (]: 2 of 6 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [RUN]
[0m04:54:08.544436 [info ] [Thread-3 (]: 3 of 6 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [RUN]
[0m04:54:08.546582 [info ] [Thread-4 (]: 4 of 6 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [RUN]
[0m04:54:08.548976 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_staging, now model.hailing_project.production_hailing_staging_customer)
[0m04:54:08.550771 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_facts, now model.hailing_project.production_hailing_staging_driver)
[0m04:54:08.554559 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m04:54:08.555863 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_vehicle'
[0m04:54:08.556919 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m04:54:08.558036 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m04:54:08.558920 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m04:54:08.559859 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m04:54:08.567664 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m04:54:08.572464 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m04:54:08.576715 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m04:54:08.580861 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m04:54:08.589051 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m04:54:08.613136 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m04:54:08.624719 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m04:54:08.625167 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m04:54:08.682041 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m04:54:08.684242 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m04:54:08.685061 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m04:54:08.687990 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m04:54:08.695154 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    );
  
[0m04:54:08.696262 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m04:54:08.697386 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    );
  
[0m04:54:08.698752 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:54:08.699183 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    );
  
[0m04:54:08.703869 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    );
  
[0m04:54:08.727535 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m04:54:08.752512 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m04:54:09.104237 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:7fcaa499-d0c2-4ab3-87fa-aa2c3e5bf706&page=queryresults
[0m04:54:09.106745 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:d95007a6-d35c-4012-b81f-97ae25c43eb9&page=queryresults
[0m04:54:09.184772 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:6bca408c-143b-4db1-bdda-afab920a0949&page=queryresults
[0m04:54:09.221402 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:6513d06a-7f36-4ba7-b3ed-44266f619a09&page=queryresults
[0m04:54:11.046807 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3a9b997b-d0c9-4977-bf56-3c0db54e948c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd430e08b10>]}
[0m04:54:11.049411 [info ] [Thread-1 (]: 1 of 6 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [[32mCREATE TABLE (85.0 rows, 5.8 KiB processed)[0m in 2.50s]
[0m04:54:11.051423 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m04:54:11.053213 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m04:54:11.054372 [info ] [Thread-1 (]: 5 of 6 START sql incremental model rizky_dwh_hailing_facts.dim_customer ........ [RUN]
[0m04:54:11.055827 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_customer, now model.hailing_project.dim_customer)
[0m04:54:11.057235 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m04:54:11.062187 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m04:54:11.071969 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m04:54:11.076854 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m04:54:11.085700 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
)

SELECT * FROM source

    );
  
[0m04:54:11.086924 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:54:11.123532 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3a9b997b-d0c9-4977-bf56-3c0db54e948c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd4301be6d0>]}
[0m04:54:11.124592 [info ] [Thread-4 (]: 4 of 6 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [[32mCREATE TABLE (85.0 rows, 4.7 KiB processed)[0m in 2.57s]
[0m04:54:11.125700 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m04:54:11.158973 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3a9b997b-d0c9-4977-bf56-3c0db54e948c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd430dc0850>]}
[0m04:54:11.160220 [info ] [Thread-3 (]: 3 of 6 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [[32mCREATE TABLE (85.0 rows, 7.6 KiB processed)[0m in 2.60s]
[0m04:54:11.161285 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m04:54:11.443232 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:05621e3d-957b-4c21-b7f7-34f209c7c28d&page=queryresults
[0m04:54:11.583217 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3a9b997b-d0c9-4977-bf56-3c0db54e948c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd430df89d0>]}
[0m04:54:11.584540 [info ] [Thread-2 (]: 2 of 6 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [[32mCREATE TABLE (85.0 rows, 5.8 KiB processed)[0m in 3.03s]
[0m04:54:11.585802 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m04:54:11.587205 [debug] [Thread-4 (]: Began running node model.hailing_project.dim_driver
[0m04:54:11.588424 [info ] [Thread-4 (]: 6 of 6 START sql incremental model rizky_dwh_hailing_facts.dim_driver .......... [RUN]
[0m04:54:11.589626 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_vehicle, now model.hailing_project.dim_driver)
[0m04:54:11.590628 [debug] [Thread-4 (]: Began compiling node model.hailing_project.dim_driver
[0m04:54:11.596098 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.dim_driver"
[0m04:54:11.604322 [debug] [Thread-4 (]: Began executing node model.hailing_project.dim_driver
[0m04:54:11.608036 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.dim_driver"
[0m04:54:11.614115 [debug] [Thread-4 (]: On model.hailing_project.dim_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_driver"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      


WITH driver AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver`

),

vehicle AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle`
)

SELECT
    driver.driver_id,
    vehicle.vehicle_id,
    driver.name as driver_name,
    driver.phone_number as phone_number,
    driver.email as email,
    vehicle.vehicle_type,
    vehicle.brand as vehicle_brand,
    vehicle.year as vehicle_production_year,
    vehicle.license_plate,
    driver.created_at
FROM driver
LEFT JOIN vehicle
on driver.driver_id = vehicle.vehicle_id


    );
  
[0m04:54:11.615417 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m04:54:12.019746 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:cd1396ec-22ae-4ddb-bd70-1a69e547969a&page=queryresults
[0m04:54:13.384117 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3a9b997b-d0c9-4977-bf56-3c0db54e948c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd4303ebd50>]}
[0m04:54:13.385863 [info ] [Thread-1 (]: 5 of 6 OK created sql incremental model rizky_dwh_hailing_facts.dim_customer ... [[32mCREATE TABLE (85.0 rows, 5.7 KiB processed)[0m in 2.33s]
[0m04:54:13.389457 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m04:54:13.659059 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3a9b997b-d0c9-4977-bf56-3c0db54e948c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd430dfae50>]}
[0m04:54:13.660387 [info ] [Thread-4 (]: 6 of 6 OK created sql incremental model rizky_dwh_hailing_facts.dim_driver ..... [[32mCREATE TABLE (85.0 rows, 9.0 KiB processed)[0m in 2.07s]
[0m04:54:13.661735 [debug] [Thread-4 (]: Finished running node model.hailing_project.dim_driver
[0m04:54:13.664497 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m04:54:13.668006 [debug] [MainThread]: Connection 'master' was properly closed.
[0m04:54:13.669029 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m04:54:13.669772 [debug] [MainThread]: Connection 'model.hailing_project.dim_customer' was properly closed.
[0m04:54:13.670785 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m04:54:13.672022 [debug] [MainThread]: Connection 'model.hailing_project.dim_driver' was properly closed.
[0m04:54:13.673336 [info ] [MainThread]: 
[0m04:54:13.674596 [info ] [MainThread]: Finished running 6 incremental models in 0 hours 0 minutes and 6.25 seconds (6.25s).
[0m04:54:13.677279 [debug] [MainThread]: Command end result
[0m04:54:13.718143 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m04:54:13.722374 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m04:54:13.730745 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m04:54:13.731613 [info ] [MainThread]: 
[0m04:54:13.732816 [info ] [MainThread]: [32mCompleted successfully[0m
[0m04:54:13.734333 [info ] [MainThread]: 
[0m04:54:13.735393 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=0 SKIP=0 TOTAL=6
[0m04:54:13.737169 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 7.5424175, "process_in_blocks": "0", "process_kernel_time": 0.192944, "process_mem_max_rss": "226344", "process_out_blocks": "0", "process_user_time": 3.696402}
[0m04:54:13.738235 [debug] [MainThread]: Command `dbt run` succeeded at 04:54:13.738120 after 7.54 seconds
[0m04:54:13.739307 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd45b4724d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd45e86cc10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd45be3bd10>]}
[0m04:54:13.740306 [debug] [MainThread]: Flushing usage events
[0m04:54:15.077763 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m07:01:38.360182 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa5e9fd3a50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa5ea013850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa5eacaf310>]}


============================== 07:01:38.363383 | bf54cb7a-56c7-4f1c-ac7f-cf3a39dcb4af ==============================
[0m07:01:38.363383 [info ] [MainThread]: Running with dbt=1.9.0
[0m07:01:38.366396 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'invocation_command': 'dbt debug', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m07:01:38.375366 [info ] [MainThread]: dbt version: 1.9.0
[0m07:01:38.379560 [info ] [MainThread]: python version: 3.11.2
[0m07:01:38.380647 [info ] [MainThread]: python path: /usr/local/bin/python
[0m07:01:38.381854 [info ] [MainThread]: os info: Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.31
[0m07:01:38.858948 [info ] [MainThread]: Using profiles dir at /usr/app/dbt_project
[0m07:01:38.860760 [info ] [MainThread]: Using profiles.yml file at /usr/app/dbt_project/profiles.yml
[0m07:01:38.862279 [info ] [MainThread]: Using dbt_project.yml file at /usr/app/dbt_project/dbt_project.yml
[0m07:01:38.863563 [info ] [MainThread]: adapter type: bigquery
[0m07:01:38.864679 [info ] [MainThread]: adapter version: 1.9.0
[0m07:01:38.939961 [info ] [MainThread]: Configuration:
[0m07:01:38.940976 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m07:01:38.942182 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m07:01:38.943214 [info ] [MainThread]: Required dependencies:
[0m07:01:38.944133 [debug] [MainThread]: Executing "git --help"
[0m07:01:38.948420 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m07:01:38.949487 [debug] [MainThread]: STDERR: "b''"
[0m07:01:38.950414 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m07:01:38.951761 [info ] [MainThread]: Connection:
[0m07:01:38.953086 [info ] [MainThread]:   method: service-account
[0m07:01:38.954747 [info ] [MainThread]:   database: purwadika
[0m07:01:38.955920 [info ] [MainThread]:   execution_project: purwadika
[0m07:01:38.956810 [info ] [MainThread]:   schema: rizky_dwh_hailing_source
[0m07:01:38.957851 [info ] [MainThread]:   location: None
[0m07:01:38.958979 [info ] [MainThread]:   priority: None
[0m07:01:38.960050 [info ] [MainThread]:   maximum_bytes_billed: None
[0m07:01:38.960986 [info ] [MainThread]:   impersonate_service_account: None
[0m07:01:38.961972 [info ] [MainThread]:   job_retry_deadline_seconds: None
[0m07:01:38.963107 [info ] [MainThread]:   job_retries: 1
[0m07:01:38.964092 [info ] [MainThread]:   job_creation_timeout_seconds: None
[0m07:01:38.965017 [info ] [MainThread]:   job_execution_timeout_seconds: None
[0m07:01:38.966089 [info ] [MainThread]:   timeout_seconds: None
[0m07:01:38.967305 [info ] [MainThread]:   client_id: None
[0m07:01:38.968170 [info ] [MainThread]:   token_uri: None
[0m07:01:38.969081 [info ] [MainThread]:   dataproc_region: None
[0m07:01:38.970004 [info ] [MainThread]:   dataproc_cluster_name: None
[0m07:01:38.970807 [info ] [MainThread]:   gcs_bucket: None
[0m07:01:38.971622 [info ] [MainThread]:   dataproc_batch: None
[0m07:01:38.972527 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m07:01:39.028576 [debug] [MainThread]: Acquiring new bigquery connection 'debug'
[0m07:01:39.029511 [debug] [MainThread]: On debug: select 1 as id
[0m07:01:39.030203 [debug] [MainThread]: Opening a new connection, currently in state init
[0m07:01:39.718676 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:66185b59-d725-4114-9252-26b1f343e9f1&page=queryresults
[0m07:01:40.521490 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m07:01:40.523283 [info ] [MainThread]: [32mAll checks passed![0m
[0m07:01:40.526247 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": true, "command_wall_clock_time": 2.2137094, "process_in_blocks": "0", "process_kernel_time": 0.11141, "process_mem_max_rss": "212168", "process_out_blocks": "0", "process_user_time": 2.673857}
[0m07:01:40.527639 [debug] [MainThread]: Command `dbt debug` succeeded at 07:01:40.527461 after 2.22 seconds
[0m07:01:40.528777 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m07:01:40.529919 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa5ea01f650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa5e9ffe290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa5ed7c0c10>]}
[0m07:01:40.531089 [debug] [MainThread]: Flushing usage events
[0m07:01:41.847205 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m07:01:48.017339 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8f6ef63190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8f6ef63f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8f6ef62fd0>]}


============================== 07:01:48.019846 | cb6ef904-08a0-467e-9e0d-a71eb007c053 ==============================
[0m07:01:48.019846 [info ] [MainThread]: Running with dbt=1.9.0
[0m07:01:48.022155 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt run --select fact_hailing_rides', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m07:01:48.605685 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'cb6ef904-08a0-467e-9e0d-a71eb007c053', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8f6efdff90>]}
[0m07:01:48.656541 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'cb6ef904-08a0-467e-9e0d-a71eb007c053', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8f711d9d90>]}
[0m07:01:48.658134 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m07:01:48.729372 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m07:01:48.901190 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 1 files changed.
[0m07:01:48.902035 [debug] [MainThread]: Partial parsing: added file: hailing_project://models/facts/fact_hailing_rides.sql
[0m07:01:48.902815 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/facts/dim_driver.sql
[0m07:01:49.151658 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'cb6ef904-08a0-467e-9e0d-a71eb007c053', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8f6fd9a6d0>]}
[0m07:01:49.213217 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m07:01:49.220092 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m07:01:49.236368 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'cb6ef904-08a0-467e-9e0d-a71eb007c053', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8f44c7e0d0>]}
[0m07:01:49.237720 [info ] [MainThread]: Found 7 models, 8 sources, 489 macros
[0m07:01:49.238996 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'cb6ef904-08a0-467e-9e0d-a71eb007c053', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8f44d3d510>]}
[0m07:01:49.241092 [info ] [MainThread]: 
[0m07:01:49.242128 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m07:01:49.243180 [info ] [MainThread]: 
[0m07:01:49.244499 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m07:01:49.246113 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m07:01:49.247262 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:01:50.077765 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_staging)
[0m07:01:50.078568 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_facts'
[0m07:01:50.079232 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m07:01:50.081033 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:01:50.370828 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'cb6ef904-08a0-467e-9e0d-a71eb007c053', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8f4518fa10>]}
[0m07:01:50.372136 [debug] [MainThread]: Opening a new connection, currently in state init
[0m07:01:50.376669 [debug] [Thread-1 (]: Began running node model.hailing_project.fact_hailing_rides
[0m07:01:50.377687 [info ] [Thread-1 (]: 1 of 1 START sql incremental model rizky_dwh_hailing_facts.fact_hailing_rides .. [RUN]
[0m07:01:50.379498 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_facts, now model.hailing_project.fact_hailing_rides)
[0m07:01:50.380407 [debug] [Thread-1 (]: Began compiling node model.hailing_project.fact_hailing_rides
[0m07:01:50.389361 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.fact_hailing_rides"
[0m07:01:50.395806 [debug] [Thread-1 (]: Began executing node model.hailing_project.fact_hailing_rides
[0m07:01:50.455954 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.fact_hailing_rides"
[0m07:01:50.462219 [debug] [Thread-1 (]: On model.hailing_project.fact_hailing_rides: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.fact_hailing_rides"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH dim_driver AS (

    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
),

dim_customer AS (

    SELECT * 
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer`
)

ride_staging AS (

    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride`
)

SELECT
ride_staging.ride_id,
ride_staging.cust_id.
dim_customer.name as cust_name,
dim_customer.phone_number as cust_phone_number,
dim_customer.email as cust_email,
ride_staging.driver_id,
dim_driver.name AS driver_name,
dim_driver.phone_number AS driver_phone_number,
dim_driver.email AS driver_email,
dim_driver.vehicle_id,
dim_driver.vehicle_type,
dim_driver.vehicle_brand,
dim_driver.vehicle_production_year,
dim_driver.license_plate,
ride_staging.created_at

FROM ride

LEFT JOIN dim_customer
on ride_staging.cust_id = dim_customer.cust_id

LEFT JOIN dim_driver
on ride_staging.driver_id = dim_driver.driver_id


    );
  
[0m07:01:50.463433 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m07:01:50.966442 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:e50fd214-f214-4ea6-a35e-1d8f0285408c&page=queryresults
[0m07:01:50.967449 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:e50fd214-f214-4ea6-a35e-1d8f0285408c&page=queryresults
[0m07:01:50.973763 [debug] [Thread-1 (]: Database Error in model fact_hailing_rides (models/facts/fact_hailing_rides.sql)
  Syntax error: Unexpected identifier "ride_staging" at [27:1]
  compiled code at target/run/hailing_project/models/facts/fact_hailing_rides.sql
[0m07:01:50.975529 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cb6ef904-08a0-467e-9e0d-a71eb007c053', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8f44ce8f50>]}
[0m07:01:50.976593 [error] [Thread-1 (]: 1 of 1 ERROR creating sql incremental model rizky_dwh_hailing_facts.fact_hailing_rides  [[31mERROR[0m in 0.60s]
[0m07:01:50.977756 [debug] [Thread-1 (]: Finished running node model.hailing_project.fact_hailing_rides
[0m07:01:50.978960 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.fact_hailing_rides' to be skipped because of status 'error'.  Reason: Database Error in model fact_hailing_rides (models/facts/fact_hailing_rides.sql)
  Syntax error: Unexpected identifier "ride_staging" at [27:1]
  compiled code at target/run/hailing_project/models/facts/fact_hailing_rides.sql.
[0m07:01:50.982149 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m07:01:50.985901 [debug] [MainThread]: Connection 'master' was properly closed.
[0m07:01:50.986629 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_staging' was properly closed.
[0m07:01:50.987523 [debug] [MainThread]: Connection 'model.hailing_project.fact_hailing_rides' was properly closed.
[0m07:01:50.988414 [info ] [MainThread]: 
[0m07:01:50.989352 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 1.74 seconds (1.74s).
[0m07:01:50.990762 [debug] [MainThread]: Command end result
[0m07:01:51.034158 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m07:01:51.041278 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m07:01:51.051722 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m07:01:51.052454 [info ] [MainThread]: 
[0m07:01:51.053533 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m07:01:51.054529 [info ] [MainThread]: 
[0m07:01:51.055524 [error] [MainThread]:   Database Error in model fact_hailing_rides (models/facts/fact_hailing_rides.sql)
  Syntax error: Unexpected identifier "ride_staging" at [27:1]
  compiled code at target/run/hailing_project/models/facts/fact_hailing_rides.sql
[0m07:01:51.056464 [info ] [MainThread]: 
[0m07:01:51.057398 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m07:01:51.058794 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 3.088611, "process_in_blocks": "0", "process_kernel_time": 0.242202, "process_mem_max_rss": "218156", "process_out_blocks": "0", "process_user_time": 3.25964}
[0m07:01:51.059755 [debug] [MainThread]: Command `dbt run` failed at 07:01:51.059633 after 3.09 seconds
[0m07:01:51.060511 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8f6efdd210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8f6efdf7d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8f4518c910>]}
[0m07:01:51.061329 [debug] [MainThread]: Flushing usage events
[0m07:01:52.263399 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m07:02:22.448718 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f00799d7690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f00799d7610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f00799d6490>]}


============================== 07:02:22.451282 | 2bff015c-0e41-4803-8dbb-eaff68e5dd55 ==============================
[0m07:02:22.451282 [info ] [MainThread]: Running with dbt=1.9.0
[0m07:02:22.453893 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt run --select fact_hailing_rides', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m07:02:23.007650 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '2bff015c-0e41-4803-8dbb-eaff68e5dd55', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f004bca3350>]}
[0m07:02:23.055530 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '2bff015c-0e41-4803-8dbb-eaff68e5dd55', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f007a776250>]}
[0m07:02:23.057147 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m07:02:23.123287 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m07:02:23.288532 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m07:02:23.291298 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/facts/fact_hailing_rides.sql
[0m07:02:23.534718 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2bff015c-0e41-4803-8dbb-eaff68e5dd55', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f004bce35d0>]}
[0m07:02:23.604276 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m07:02:23.610252 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m07:02:23.625878 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2bff015c-0e41-4803-8dbb-eaff68e5dd55', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f004b78a5d0>]}
[0m07:02:23.626877 [info ] [MainThread]: Found 7 models, 8 sources, 489 macros
[0m07:02:23.627937 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2bff015c-0e41-4803-8dbb-eaff68e5dd55', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f004baf4610>]}
[0m07:02:23.630300 [info ] [MainThread]: 
[0m07:02:23.631499 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m07:02:23.632498 [info ] [MainThread]: 
[0m07:02:23.633652 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m07:02:23.635973 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m07:02:23.637085 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:02:24.250639 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_staging)
[0m07:02:24.251284 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_facts'
[0m07:02:24.252068 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m07:02:24.253424 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:02:24.508255 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2bff015c-0e41-4803-8dbb-eaff68e5dd55', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f004b77a510>]}
[0m07:02:24.509389 [debug] [MainThread]: Opening a new connection, currently in state init
[0m07:02:24.515195 [debug] [Thread-1 (]: Began running node model.hailing_project.fact_hailing_rides
[0m07:02:24.516279 [info ] [Thread-1 (]: 1 of 1 START sql incremental model rizky_dwh_hailing_facts.fact_hailing_rides .. [RUN]
[0m07:02:24.517316 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_facts, now model.hailing_project.fact_hailing_rides)
[0m07:02:24.518156 [debug] [Thread-1 (]: Began compiling node model.hailing_project.fact_hailing_rides
[0m07:02:24.525524 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.fact_hailing_rides"
[0m07:02:24.532396 [debug] [Thread-1 (]: Began executing node model.hailing_project.fact_hailing_rides
[0m07:02:24.592095 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.fact_hailing_rides"
[0m07:02:24.602922 [debug] [Thread-1 (]: On model.hailing_project.fact_hailing_rides: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.fact_hailing_rides"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH dim_driver AS (

    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
),

dim_customer AS (

    SELECT * 
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer`
),

ride_staging AS (

    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride`
)

SELECT
ride_staging.ride_id,
ride_staging.cust_id.
dim_customer.name as cust_name,
dim_customer.phone_number as cust_phone_number,
dim_customer.email as cust_email,
ride_staging.driver_id,
dim_driver.name AS driver_name,
dim_driver.phone_number AS driver_phone_number,
dim_driver.email AS driver_email,
dim_driver.vehicle_id,
dim_driver.vehicle_type,
dim_driver.vehicle_brand,
dim_driver.vehicle_production_year,
dim_driver.license_plate,
ride_staging.created_at

FROM ride

LEFT JOIN dim_customer
on ride_staging.cust_id = dim_customer.cust_id

LEFT JOIN dim_driver
on ride_staging.driver_id = dim_driver.driver_id


    );
  
[0m07:02:24.604439 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m07:02:24.958865 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:37ccb4c1-8c6e-4cd3-a7e2-646353514929&page=queryresults
[0m07:02:24.960302 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:37ccb4c1-8c6e-4cd3-a7e2-646353514929&page=queryresults
[0m07:02:24.965550 [debug] [Thread-1 (]: Database Error in model fact_hailing_rides (models/facts/fact_hailing_rides.sql)
  Table "ride" must be qualified with a dataset (e.g. dataset.table).
  compiled code at target/run/hailing_project/models/facts/fact_hailing_rides.sql
[0m07:02:24.967452 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2bff015c-0e41-4803-8dbb-eaff68e5dd55', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f004b751390>]}
[0m07:02:24.968565 [error] [Thread-1 (]: 1 of 1 ERROR creating sql incremental model rizky_dwh_hailing_facts.fact_hailing_rides  [[31mERROR[0m in 0.45s]
[0m07:02:24.969642 [debug] [Thread-1 (]: Finished running node model.hailing_project.fact_hailing_rides
[0m07:02:24.970720 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.fact_hailing_rides' to be skipped because of status 'error'.  Reason: Database Error in model fact_hailing_rides (models/facts/fact_hailing_rides.sql)
  Table "ride" must be qualified with a dataset (e.g. dataset.table).
  compiled code at target/run/hailing_project/models/facts/fact_hailing_rides.sql.
[0m07:02:24.973013 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m07:02:24.976050 [debug] [MainThread]: Connection 'master' was properly closed.
[0m07:02:24.976912 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_staging' was properly closed.
[0m07:02:24.977652 [debug] [MainThread]: Connection 'model.hailing_project.fact_hailing_rides' was properly closed.
[0m07:02:24.978351 [info ] [MainThread]: 
[0m07:02:24.979325 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 1.34 seconds (1.34s).
[0m07:02:24.980609 [debug] [MainThread]: Command end result
[0m07:02:25.012714 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m07:02:25.016499 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m07:02:25.024199 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m07:02:25.025002 [info ] [MainThread]: 
[0m07:02:25.025962 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m07:02:25.027057 [info ] [MainThread]: 
[0m07:02:25.028167 [error] [MainThread]:   Database Error in model fact_hailing_rides (models/facts/fact_hailing_rides.sql)
  Table "ride" must be qualified with a dataset (e.g. dataset.table).
  compiled code at target/run/hailing_project/models/facts/fact_hailing_rides.sql
[0m07:02:25.029141 [info ] [MainThread]: 
[0m07:02:25.030253 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m07:02:25.031934 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 2.6333654, "process_in_blocks": "0", "process_kernel_time": 0.209212, "process_mem_max_rss": "219408", "process_out_blocks": "0", "process_user_time": 3.178031}
[0m07:02:25.033428 [debug] [MainThread]: Command `dbt run` failed at 07:02:25.033227 after 2.63 seconds
[0m07:02:25.034493 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f007a0c1f50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0079a53990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0079a53710>]}
[0m07:02:25.035363 [debug] [MainThread]: Flushing usage events
[0m07:02:26.248121 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m07:03:04.833271 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5481ca6850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5481db5c90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5481ca7410>]}


============================== 07:03:04.835977 | 640e6b89-6f4f-40e9-93f6-5b25fda3d3d5 ==============================
[0m07:03:04.835977 [info ] [MainThread]: Running with dbt=1.9.0
[0m07:03:04.838405 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'log_format': 'default', 'invocation_command': 'dbt run --select fact_hailing_rides', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m07:03:05.425854 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '640e6b89-6f4f-40e9-93f6-5b25fda3d3d5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5453e10d90>]}
[0m07:03:05.471193 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '640e6b89-6f4f-40e9-93f6-5b25fda3d3d5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5483f288d0>]}
[0m07:03:05.473233 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m07:03:05.541211 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m07:03:05.724739 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m07:03:05.726242 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/facts/fact_hailing_rides.sql
[0m07:03:05.991212 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '640e6b89-6f4f-40e9-93f6-5b25fda3d3d5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5453a537d0>]}
[0m07:03:06.060852 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m07:03:06.066450 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m07:03:06.083428 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '640e6b89-6f4f-40e9-93f6-5b25fda3d3d5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5453a81f90>]}
[0m07:03:06.084798 [info ] [MainThread]: Found 7 models, 8 sources, 489 macros
[0m07:03:06.086254 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '640e6b89-6f4f-40e9-93f6-5b25fda3d3d5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5453a5d490>]}
[0m07:03:06.088429 [info ] [MainThread]: 
[0m07:03:06.089539 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m07:03:06.090753 [info ] [MainThread]: 
[0m07:03:06.092537 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m07:03:06.094432 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m07:03:06.095248 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:03:06.654623 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_staging)
[0m07:03:06.655227 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_facts'
[0m07:03:06.656287 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m07:03:06.657092 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:03:06.947540 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '640e6b89-6f4f-40e9-93f6-5b25fda3d3d5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f545391f110>]}
[0m07:03:06.949199 [debug] [MainThread]: Opening a new connection, currently in state init
[0m07:03:06.954726 [debug] [Thread-1 (]: Began running node model.hailing_project.fact_hailing_rides
[0m07:03:06.955917 [info ] [Thread-1 (]: 1 of 1 START sql incremental model rizky_dwh_hailing_facts.fact_hailing_rides .. [RUN]
[0m07:03:06.957056 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_facts, now model.hailing_project.fact_hailing_rides)
[0m07:03:06.958030 [debug] [Thread-1 (]: Began compiling node model.hailing_project.fact_hailing_rides
[0m07:03:06.967436 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.fact_hailing_rides"
[0m07:03:06.975434 [debug] [Thread-1 (]: Began executing node model.hailing_project.fact_hailing_rides
[0m07:03:07.050967 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.fact_hailing_rides"
[0m07:03:07.059272 [debug] [Thread-1 (]: On model.hailing_project.fact_hailing_rides: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.fact_hailing_rides"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH dim_driver AS (

    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
),

dim_customer AS (

    SELECT * 
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer`
),

ride_staging AS (

    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride`
)

SELECT
ride_staging.ride_id,
ride_staging.cust_id.
dim_customer.name as cust_name,
dim_customer.phone_number as cust_phone_number,
dim_customer.email as cust_email,
ride_staging.driver_id,
dim_driver.name AS driver_name,
dim_driver.phone_number AS driver_phone_number,
dim_driver.email AS driver_email,
dim_driver.vehicle_id,
dim_driver.vehicle_type,
dim_driver.vehicle_brand,
dim_driver.vehicle_production_year,
dim_driver.license_plate,
ride_staging.created_at

FROM ride_staging

LEFT JOIN dim_customer
on ride_staging.cust_id = dim_customer.cust_id

LEFT JOIN dim_driver
on ride_staging.driver_id = dim_driver.driver_id


    );
  
[0m07:03:07.060545 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m07:03:07.598808 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:90d33cda-570b-4dd4-95f2-34773734d662&page=queryresults
[0m07:03:07.738230 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:90d33cda-570b-4dd4-95f2-34773734d662&page=queryresults
[0m07:03:07.742828 [debug] [Thread-1 (]: Database Error in model fact_hailing_rides (models/facts/fact_hailing_rides.sql)
  Cannot access field dim_customer on a value with type INT64 at [36:1]
  compiled code at target/run/hailing_project/models/facts/fact_hailing_rides.sql
[0m07:03:07.745047 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '640e6b89-6f4f-40e9-93f6-5b25fda3d3d5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5453a757d0>]}
[0m07:03:07.747170 [error] [Thread-1 (]: 1 of 1 ERROR creating sql incremental model rizky_dwh_hailing_facts.fact_hailing_rides  [[31mERROR[0m in 0.79s]
[0m07:03:07.749300 [debug] [Thread-1 (]: Finished running node model.hailing_project.fact_hailing_rides
[0m07:03:07.750884 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.fact_hailing_rides' to be skipped because of status 'error'.  Reason: Database Error in model fact_hailing_rides (models/facts/fact_hailing_rides.sql)
  Cannot access field dim_customer on a value with type INT64 at [36:1]
  compiled code at target/run/hailing_project/models/facts/fact_hailing_rides.sql.
[0m07:03:07.753614 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m07:03:07.757378 [debug] [MainThread]: Connection 'master' was properly closed.
[0m07:03:07.758987 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_staging' was properly closed.
[0m07:03:07.759927 [debug] [MainThread]: Connection 'model.hailing_project.fact_hailing_rides' was properly closed.
[0m07:03:07.760830 [info ] [MainThread]: 
[0m07:03:07.762169 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 1.67 seconds (1.67s).
[0m07:03:07.763846 [debug] [MainThread]: Command end result
[0m07:03:07.800556 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m07:03:07.804220 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m07:03:07.811447 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m07:03:07.812234 [info ] [MainThread]: 
[0m07:03:07.813215 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m07:03:07.814233 [info ] [MainThread]: 
[0m07:03:07.815138 [error] [MainThread]:   Database Error in model fact_hailing_rides (models/facts/fact_hailing_rides.sql)
  Cannot access field dim_customer on a value with type INT64 at [36:1]
  compiled code at target/run/hailing_project/models/facts/fact_hailing_rides.sql
[0m07:03:07.816022 [info ] [MainThread]: 
[0m07:03:07.816874 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m07:03:07.818286 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 3.030307, "process_in_blocks": "0", "process_kernel_time": 0.132297, "process_mem_max_rss": "218404", "process_out_blocks": "0", "process_user_time": 3.388862}
[0m07:03:07.819212 [debug] [MainThread]: Command `dbt run` failed at 07:03:07.819098 after 3.03 seconds
[0m07:03:07.820075 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5481cffa90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f54823b6550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5483f155d0>]}
[0m07:03:07.820977 [debug] [MainThread]: Flushing usage events
[0m07:03:09.191122 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m07:04:27.133877 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd69b202910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd69b203a10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd69b202a50>]}


============================== 07:04:27.136475 | 53abc3b8-c905-4817-b4c4-a2276e9039b9 ==============================
[0m07:04:27.136475 [info ] [MainThread]: Running with dbt=1.9.0
[0m07:04:27.138243 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'invocation_command': 'dbt run --select fact_hailing_rides', 'send_anonymous_usage_stats': 'True'}
[0m07:04:27.754393 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '53abc3b8-c905-4817-b4c4-a2276e9039b9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd66d54b9d0>]}
[0m07:04:27.799928 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '53abc3b8-c905-4817-b4c4-a2276e9039b9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd69d47cd50>]}
[0m07:04:27.801303 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m07:04:27.863305 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m07:04:28.049266 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m07:04:28.050675 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/facts/fact_hailing_rides.sql
[0m07:04:28.316326 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '53abc3b8-c905-4817-b4c4-a2276e9039b9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd66d121350>]}
[0m07:04:28.388568 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m07:04:28.394601 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m07:04:28.411584 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '53abc3b8-c905-4817-b4c4-a2276e9039b9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd66cf2e7d0>]}
[0m07:04:28.412600 [info ] [MainThread]: Found 7 models, 8 sources, 489 macros
[0m07:04:28.413712 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '53abc3b8-c905-4817-b4c4-a2276e9039b9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd66d018850>]}
[0m07:04:28.416775 [info ] [MainThread]: 
[0m07:04:28.418331 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m07:04:28.419325 [info ] [MainThread]: 
[0m07:04:28.420800 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m07:04:28.422473 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m07:04:28.423969 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:04:28.974739 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_staging)
[0m07:04:28.975722 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_facts'
[0m07:04:28.976654 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m07:04:28.977927 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:04:29.253845 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '53abc3b8-c905-4817-b4c4-a2276e9039b9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd66d367a10>]}
[0m07:04:29.255555 [debug] [MainThread]: Opening a new connection, currently in state init
[0m07:04:29.260326 [debug] [Thread-1 (]: Began running node model.hailing_project.fact_hailing_rides
[0m07:04:29.261617 [info ] [Thread-1 (]: 1 of 1 START sql incremental model rizky_dwh_hailing_facts.fact_hailing_rides .. [RUN]
[0m07:04:29.262714 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_staging, now model.hailing_project.fact_hailing_rides)
[0m07:04:29.263810 [debug] [Thread-1 (]: Began compiling node model.hailing_project.fact_hailing_rides
[0m07:04:29.271679 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.fact_hailing_rides"
[0m07:04:29.279079 [debug] [Thread-1 (]: Began executing node model.hailing_project.fact_hailing_rides
[0m07:04:29.341713 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.fact_hailing_rides"
[0m07:04:29.349852 [debug] [Thread-1 (]: On model.hailing_project.fact_hailing_rides: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.fact_hailing_rides"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH dim_driver AS (

    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
),

dim_customer AS (

    SELECT * 
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer`
),

ride_staging AS (

    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride`
)

SELECT
ride_staging.ride_id,
dim_customer.cust_id.
dim_customer.name as cust_name,
dim_customer.phone_number as cust_phone_number,
dim_customer.email as cust_email,
dim_driver.driver_id,
dim_driver.name AS driver_name,
dim_driver.phone_number AS driver_phone_number,
dim_driver.email AS driver_email,
dim_driver.vehicle_id,
dim_driver.vehicle_type,
dim_driver.vehicle_brand,
dim_driver.vehicle_production_year,
dim_driver.license_plate,
ride_staging.created_at

FROM ride_staging

LEFT JOIN dim_customer
on ride_staging.cust_id = dim_customer.cust_id

LEFT JOIN dim_driver
on ride_staging.driver_id = dim_driver.driver_id


    );
  
[0m07:04:29.350999 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m07:04:29.855898 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:3db9b6ea-bb9a-4110-b9f9-14235fec4c41&page=queryresults
[0m07:04:29.989229 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:3db9b6ea-bb9a-4110-b9f9-14235fec4c41&page=queryresults
[0m07:04:29.995067 [debug] [Thread-1 (]: Database Error in model fact_hailing_rides (models/facts/fact_hailing_rides.sql)
  Cannot access field dim_customer on a value with type INT64 at [36:1]
  compiled code at target/run/hailing_project/models/facts/fact_hailing_rides.sql
[0m07:04:29.997684 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '53abc3b8-c905-4817-b4c4-a2276e9039b9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd66cf2d1d0>]}
[0m07:04:30.000960 [error] [Thread-1 (]: 1 of 1 ERROR creating sql incremental model rizky_dwh_hailing_facts.fact_hailing_rides  [[31mERROR[0m in 0.73s]
[0m07:04:30.002692 [debug] [Thread-1 (]: Finished running node model.hailing_project.fact_hailing_rides
[0m07:04:30.003576 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.fact_hailing_rides' to be skipped because of status 'error'.  Reason: Database Error in model fact_hailing_rides (models/facts/fact_hailing_rides.sql)
  Cannot access field dim_customer on a value with type INT64 at [36:1]
  compiled code at target/run/hailing_project/models/facts/fact_hailing_rides.sql.
[0m07:04:30.006592 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m07:04:30.009690 [debug] [MainThread]: Connection 'master' was properly closed.
[0m07:04:30.010927 [debug] [MainThread]: Connection 'model.hailing_project.fact_hailing_rides' was properly closed.
[0m07:04:30.011764 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_facts' was properly closed.
[0m07:04:30.012702 [info ] [MainThread]: 
[0m07:04:30.013757 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 1.59 seconds (1.59s).
[0m07:04:30.015495 [debug] [MainThread]: Command end result
[0m07:04:30.049712 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m07:04:30.053621 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m07:04:30.062443 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m07:04:30.063123 [info ] [MainThread]: 
[0m07:04:30.064094 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m07:04:30.065069 [info ] [MainThread]: 
[0m07:04:30.066107 [error] [MainThread]:   Database Error in model fact_hailing_rides (models/facts/fact_hailing_rides.sql)
  Cannot access field dim_customer on a value with type INT64 at [36:1]
  compiled code at target/run/hailing_project/models/facts/fact_hailing_rides.sql
[0m07:04:30.067052 [info ] [MainThread]: 
[0m07:04:30.067976 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m07:04:30.069519 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 2.994978, "process_in_blocks": "0", "process_kernel_time": 0.179811, "process_mem_max_rss": "217848", "process_out_blocks": "0", "process_user_time": 3.41642}
[0m07:04:30.070375 [debug] [MainThread]: Command `dbt run` failed at 07:04:30.070278 after 3.00 seconds
[0m07:04:30.071363 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd69b27d8d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd69b27fb10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd66c45e610>]}
[0m07:04:30.072276 [debug] [MainThread]: Flushing usage events
[0m07:04:31.166493 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m07:06:12.257349 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f72b3082c90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f72b30dbfd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f72b3d67450>]}


============================== 07:06:12.260077 | 17cba8eb-1e93-4f37-9b42-3c9053b8edb1 ==============================
[0m07:06:12.260077 [info ] [MainThread]: Running with dbt=1.9.0
[0m07:06:12.261433 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'version_check': 'True', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt run --select fact_hailing_rides', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m07:06:12.813271 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '17cba8eb-1e93-4f37-9b42-3c9053b8edb1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f72b3103a50>]}
[0m07:06:12.861208 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '17cba8eb-1e93-4f37-9b42-3c9053b8edb1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f72b52fe4d0>]}
[0m07:06:12.862187 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m07:06:12.928929 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m07:06:13.103214 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m07:06:13.104331 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/facts/fact_hailing_rides.sql
[0m07:06:13.343540 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '17cba8eb-1e93-4f37-9b42-3c9053b8edb1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f728901e250>]}
[0m07:06:13.410696 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m07:06:13.419071 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m07:06:13.432687 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '17cba8eb-1e93-4f37-9b42-3c9053b8edb1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7288dafed0>]}
[0m07:06:13.433898 [info ] [MainThread]: Found 7 models, 8 sources, 489 macros
[0m07:06:13.434988 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '17cba8eb-1e93-4f37-9b42-3c9053b8edb1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f728901ad10>]}
[0m07:06:13.436985 [info ] [MainThread]: 
[0m07:06:13.437996 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m07:06:13.439070 [info ] [MainThread]: 
[0m07:06:13.440518 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m07:06:13.442468 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m07:06:13.443395 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:06:14.001109 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_staging)
[0m07:06:14.002048 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_facts'
[0m07:06:14.003260 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m07:06:14.004565 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:06:14.251650 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '17cba8eb-1e93-4f37-9b42-3c9053b8edb1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f728901bc90>]}
[0m07:06:14.253437 [debug] [MainThread]: Opening a new connection, currently in state init
[0m07:06:14.258995 [debug] [Thread-1 (]: Began running node model.hailing_project.fact_hailing_rides
[0m07:06:14.260033 [info ] [Thread-1 (]: 1 of 1 START sql incremental model rizky_dwh_hailing_facts.fact_hailing_rides .. [RUN]
[0m07:06:14.261835 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_facts, now model.hailing_project.fact_hailing_rides)
[0m07:06:14.262897 [debug] [Thread-1 (]: Began compiling node model.hailing_project.fact_hailing_rides
[0m07:06:14.270660 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.fact_hailing_rides"
[0m07:06:14.278182 [debug] [Thread-1 (]: Began executing node model.hailing_project.fact_hailing_rides
[0m07:06:14.341781 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.fact_hailing_rides"
[0m07:06:14.349299 [debug] [Thread-1 (]: On model.hailing_project.fact_hailing_rides: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.fact_hailing_rides"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH dim_driver AS (

    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
),

dim_customer AS (

    SELECT * 
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer`
),

ride_staging AS (

    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride`
)

SELECT
ride_staging.ride_id,
dim_customer.cust_id,
dim_customer.name AS cust_name,
dim_customer.phone_number AS cust_phone_number,
dim_customer.email AS cust_email,
dim_driver.driver_id,
dim_driver.name AS driver_name,
dim_driver.phone_number AS driver_phone_number,
dim_driver.email AS driver_email,
dim_driver.vehicle_id,
dim_driver.vehicle_type,
dim_driver.vehicle_brand,
dim_driver.vehicle_production_year,
dim_driver.license_plate,
ride_staging.created_at

FROM ride_staging

LEFT JOIN dim_customer
on ride_staging.cust_id = dim_customer.cust_id

LEFT JOIN dim_driver
on ride_staging.driver_id = dim_driver.driver_id


    );
  
[0m07:06:14.350353 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m07:06:14.845835 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:5aa50adb-ef16-4757-867e-bfb7097f57b7&page=queryresults
[0m07:06:14.968887 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:5aa50adb-ef16-4757-867e-bfb7097f57b7&page=queryresults
[0m07:06:14.974316 [debug] [Thread-1 (]: Database Error in model fact_hailing_rides (models/facts/fact_hailing_rides.sql)
  Name name not found inside dim_driver at [40:12]
  compiled code at target/run/hailing_project/models/facts/fact_hailing_rides.sql
[0m07:06:14.977074 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '17cba8eb-1e93-4f37-9b42-3c9053b8edb1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7288dba1d0>]}
[0m07:06:14.978521 [error] [Thread-1 (]: 1 of 1 ERROR creating sql incremental model rizky_dwh_hailing_facts.fact_hailing_rides  [[31mERROR[0m in 0.71s]
[0m07:06:14.980248 [debug] [Thread-1 (]: Finished running node model.hailing_project.fact_hailing_rides
[0m07:06:14.988736 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.fact_hailing_rides' to be skipped because of status 'error'.  Reason: Database Error in model fact_hailing_rides (models/facts/fact_hailing_rides.sql)
  Name name not found inside dim_driver at [40:12]
  compiled code at target/run/hailing_project/models/facts/fact_hailing_rides.sql.
[0m07:06:14.991782 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m07:06:14.994899 [debug] [MainThread]: Connection 'master' was properly closed.
[0m07:06:14.995676 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_staging' was properly closed.
[0m07:06:14.996531 [debug] [MainThread]: Connection 'model.hailing_project.fact_hailing_rides' was properly closed.
[0m07:06:14.997572 [info ] [MainThread]: 
[0m07:06:14.998570 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 1.56 seconds (1.56s).
[0m07:06:14.999998 [debug] [MainThread]: Command end result
[0m07:06:15.037677 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m07:06:15.041430 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m07:06:15.049145 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m07:06:15.049984 [info ] [MainThread]: 
[0m07:06:15.051194 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m07:06:15.052195 [info ] [MainThread]: 
[0m07:06:15.053392 [error] [MainThread]:   Database Error in model fact_hailing_rides (models/facts/fact_hailing_rides.sql)
  Name name not found inside dim_driver at [40:12]
  compiled code at target/run/hailing_project/models/facts/fact_hailing_rides.sql
[0m07:06:15.054538 [info ] [MainThread]: 
[0m07:06:15.055637 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m07:06:15.057269 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 2.8518689, "process_in_blocks": "0", "process_kernel_time": 0.172286, "process_mem_max_rss": "218088", "process_out_blocks": "0", "process_user_time": 3.395065}
[0m07:06:15.058205 [debug] [MainThread]: Command `dbt run` failed at 07:06:15.058098 after 2.85 seconds
[0m07:06:15.059075 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f72b31038d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f72b347e650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f72b69fd350>]}
[0m07:06:15.059899 [debug] [MainThread]: Flushing usage events
[0m07:06:16.319520 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m07:09:03.616158 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f82e537ff90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f82e537fcd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f82e5324f10>]}


============================== 07:09:03.619194 | 3dc5bba2-e234-411e-9e8f-c52dba73e684 ==============================
[0m07:09:03.619194 [info ] [MainThread]: Running with dbt=1.9.0
[0m07:09:03.621083 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt run --select fact_hailing_rides', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m07:09:04.218859 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '3dc5bba2-e234-411e-9e8f-c52dba73e684', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f82b74aa890>]}
[0m07:09:04.262128 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '3dc5bba2-e234-411e-9e8f-c52dba73e684', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f82b7db8990>]}
[0m07:09:04.263082 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m07:09:04.326524 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m07:09:04.497997 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m07:09:04.499303 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/facts/fact_hailing_rides.sql
[0m07:09:04.756489 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3dc5bba2-e234-411e-9e8f-c52dba73e684', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f82b7279b10>]}
[0m07:09:04.829277 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m07:09:04.834949 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m07:09:04.852277 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3dc5bba2-e234-411e-9e8f-c52dba73e684', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f82b7015e50>]}
[0m07:09:04.853745 [info ] [MainThread]: Found 7 models, 8 sources, 489 macros
[0m07:09:04.855428 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3dc5bba2-e234-411e-9e8f-c52dba73e684', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f82b70945d0>]}
[0m07:09:04.857825 [info ] [MainThread]: 
[0m07:09:04.859072 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m07:09:04.860473 [info ] [MainThread]: 
[0m07:09:04.862093 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m07:09:04.863786 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m07:09:04.864657 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:09:05.398586 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_facts)
[0m07:09:05.399230 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_staging'
[0m07:09:05.400011 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m07:09:05.401166 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:09:05.662911 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3dc5bba2-e234-411e-9e8f-c52dba73e684', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f82b7027b50>]}
[0m07:09:05.664495 [debug] [MainThread]: Opening a new connection, currently in state init
[0m07:09:05.673433 [debug] [Thread-1 (]: Began running node model.hailing_project.fact_hailing_rides
[0m07:09:05.674352 [info ] [Thread-1 (]: 1 of 1 START sql incremental model rizky_dwh_hailing_facts.fact_hailing_rides .. [RUN]
[0m07:09:05.675486 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_facts, now model.hailing_project.fact_hailing_rides)
[0m07:09:05.676488 [debug] [Thread-1 (]: Began compiling node model.hailing_project.fact_hailing_rides
[0m07:09:05.684891 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.fact_hailing_rides"
[0m07:09:05.691753 [debug] [Thread-1 (]: Began executing node model.hailing_project.fact_hailing_rides
[0m07:09:05.765106 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.fact_hailing_rides"
[0m07:09:05.772220 [debug] [Thread-1 (]: On model.hailing_project.fact_hailing_rides: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.fact_hailing_rides"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH dim_driver AS (

    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
),

dim_customer AS (

    SELECT * 
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer`
),

ride_staging AS (

    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride`
)

SELECT
ride_staging.ride_id,
ride_staging.start_time AS ride_start_time,
ride_staging.end_time AS ride_end_time,
ride_staging.distance_km,
ride_staging.fare,
dim_customer.cust_id,
dim_customer.name AS cust_name,
dim_customer.phone_number AS cust_phone_number,
dim_customer.email AS cust_email,
dim_driver.driver_id,
dim_driver.driver_name,
dim_driver.phone_number AS driver_phone_number,
dim_driver.email AS driver_email,
dim_driver.vehicle_id,
dim_driver.vehicle_type,
dim_driver.vehicle_brand,
dim_driver.vehicle_production_year,
dim_driver.license_plate,
ride_staging.created_at

FROM ride_staging

LEFT JOIN dim_customer
on ride_staging.cust_id = dim_customer.cust_id

LEFT JOIN dim_driver
on ride_staging.driver_id = dim_driver.driver_id


    );
  
[0m07:09:05.773373 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m07:09:06.292298 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:03289e7f-0ada-4036-974a-250f590f1576&page=queryresults
[0m07:09:08.606363 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3dc5bba2-e234-411e-9e8f-c52dba73e684', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f82b751eed0>]}
[0m07:09:08.607535 [info ] [Thread-1 (]: 1 of 1 OK created sql incremental model rizky_dwh_hailing_facts.fact_hailing_rides  [[32mCREATE TABLE (85.0 rows, 20.0 KiB processed)[0m in 2.93s]
[0m07:09:08.609522 [debug] [Thread-1 (]: Finished running node model.hailing_project.fact_hailing_rides
[0m07:09:08.612565 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m07:09:08.615064 [debug] [MainThread]: Connection 'master' was properly closed.
[0m07:09:08.615793 [debug] [MainThread]: Connection 'model.hailing_project.fact_hailing_rides' was properly closed.
[0m07:09:08.616545 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_staging' was properly closed.
[0m07:09:08.617495 [info ] [MainThread]: 
[0m07:09:08.618451 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 3.76 seconds (3.76s).
[0m07:09:08.620041 [debug] [MainThread]: Command end result
[0m07:09:08.657533 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m07:09:08.662438 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m07:09:08.670690 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m07:09:08.671426 [info ] [MainThread]: 
[0m07:09:08.673000 [info ] [MainThread]: [32mCompleted successfully[0m
[0m07:09:08.674006 [info ] [MainThread]: 
[0m07:09:08.675055 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m07:09:08.676642 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 5.1161566, "process_in_blocks": "0", "process_kernel_time": 0.240091, "process_mem_max_rss": "223080", "process_out_blocks": "0", "process_user_time": 3.301251}
[0m07:09:08.677620 [debug] [MainThread]: Command `dbt run` succeeded at 07:09:08.677493 after 5.12 seconds
[0m07:09:08.678462 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f82e57261d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f82e8b20d50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f82e8ca49d0>]}
[0m07:09:08.679323 [debug] [MainThread]: Flushing usage events
[0m07:09:09.938943 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m07:41:26.627918 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa05aaddc10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa05aaddb90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa05aadf850>]}


============================== 07:41:26.630583 | 4f226548-9a4a-42fa-a665-ab770824281a ==============================
[0m07:41:26.630583 [info ] [MainThread]: Running with dbt=1.9.0
[0m07:41:26.634501 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'invocation_command': 'dbt run --select fact_hailing_rides', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m07:41:27.208203 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '4f226548-9a4a-42fa-a665-ab770824281a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa030cb3f50>]}
[0m07:41:27.252186 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '4f226548-9a4a-42fa-a665-ab770824281a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa030d47590>]}
[0m07:41:27.253652 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m07:41:27.325111 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m07:41:27.392494 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m07:41:27.394936 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '4f226548-9a4a-42fa-a665-ab770824281a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa05b1caa90>]}
[0m07:41:28.451471 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4f226548-9a4a-42fa-a665-ab770824281a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa030944ad0>]}
[0m07:41:28.517096 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m07:41:28.526837 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m07:41:28.543383 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4f226548-9a4a-42fa-a665-ab770824281a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa022fe6a90>]}
[0m07:41:28.544677 [info ] [MainThread]: Found 8 models, 8 sources, 489 macros
[0m07:41:28.545734 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4f226548-9a4a-42fa-a665-ab770824281a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa030a37fd0>]}
[0m07:41:28.548283 [info ] [MainThread]: 
[0m07:41:28.549443 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m07:41:28.550387 [info ] [MainThread]: 
[0m07:41:28.551950 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m07:41:28.554222 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m07:41:28.555642 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:41:29.229663 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_staging)
[0m07:41:29.230313 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_facts'
[0m07:41:29.231133 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_marts'
[0m07:41:29.231725 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m07:41:29.233405 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:41:29.234600 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:41:29.549610 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4f226548-9a4a-42fa-a665-ab770824281a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa030dce5d0>]}
[0m07:41:29.551746 [debug] [MainThread]: Opening a new connection, currently in state init
[0m07:41:29.557369 [debug] [Thread-1 (]: Began running node model.hailing_project.fact_hailing_rides
[0m07:41:29.558522 [info ] [Thread-1 (]: 1 of 1 START sql incremental model rizky_dwh_hailing_facts.fact_hailing_rides .. [RUN]
[0m07:41:29.560569 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_marts, now model.hailing_project.fact_hailing_rides)
[0m07:41:29.561851 [debug] [Thread-1 (]: Began compiling node model.hailing_project.fact_hailing_rides
[0m07:41:29.574651 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.fact_hailing_rides"
[0m07:41:29.581787 [debug] [Thread-1 (]: Began executing node model.hailing_project.fact_hailing_rides
[0m07:41:29.620147 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m07:41:29.929386 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.fact_hailing_rides"
[0m07:41:29.937459 [debug] [Thread-1 (]: On model.hailing_project.fact_hailing_rides: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.fact_hailing_rides"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides` as DBT_INTERNAL_DEST
        using (

WITH dim_driver AS (

    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
),

dim_customer AS (

    SELECT * 
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer`
),

ride_staging AS (

    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride`
)

SELECT
    ride_staging.ride_id,
    ride_staging.start_time AS ride_start_time,
    ride_staging.end_time AS ride_end_time,
    ride_staging.distance_km,
    ride_staging.fare,
    ride_staging.ride_status,
    dim_customer.cust_id,
    dim_customer.name AS cust_name,
    dim_customer.phone_number AS cust_phone_number,
    dim_customer.email AS cust_email,
    dim_driver.driver_id,
    dim_driver.driver_name,
    dim_driver.phone_number AS driver_phone_number,
    dim_driver.email AS driver_email,
    dim_driver.vehicle_id,
    dim_driver.vehicle_type,
    dim_driver.vehicle_brand,
    dim_driver.vehicle_production_year,
    dim_driver.license_plate,
    ride_staging.created_at

FROM ride_staging

LEFT JOIN dim_customer
on ride_staging.cust_id = dim_customer.cust_id

LEFT JOIN dim_driver
on ride_staging.driver_id = dim_driver.driver_id


    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`ride_start_time` = DBT_INTERNAL_SOURCE.`ride_start_time`,`ride_end_time` = DBT_INTERNAL_SOURCE.`ride_end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`cust_name` = DBT_INTERNAL_SOURCE.`cust_name`,`cust_phone_number` = DBT_INTERNAL_SOURCE.`cust_phone_number`,`cust_email` = DBT_INTERNAL_SOURCE.`cust_email`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`driver_name` = DBT_INTERNAL_SOURCE.`driver_name`,`driver_phone_number` = DBT_INTERNAL_SOURCE.`driver_phone_number`,`driver_email` = DBT_INTERNAL_SOURCE.`driver_email`,`vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`vehicle_brand` = DBT_INTERNAL_SOURCE.`vehicle_brand`,`vehicle_production_year` = DBT_INTERNAL_SOURCE.`vehicle_production_year`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `ride_start_time`, `ride_end_time`, `distance_km`, `fare`, `cust_id`, `cust_name`, `cust_phone_number`, `cust_email`, `driver_id`, `driver_name`, `driver_phone_number`, `driver_email`, `vehicle_id`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)
    values
        (`ride_id`, `ride_start_time`, `ride_end_time`, `distance_km`, `fare`, `cust_id`, `cust_name`, `cust_phone_number`, `cust_email`, `driver_id`, `driver_name`, `driver_phone_number`, `driver_email`, `vehicle_id`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)


    
[0m07:41:30.314132 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:631503c2-54ef-4511-a506-0bc81898c3e0&page=queryresults
[0m07:41:30.411747 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:631503c2-54ef-4511-a506-0bc81898c3e0&page=queryresults
[0m07:41:30.417543 [debug] [Thread-1 (]: Database Error in model fact_hailing_rides (models/facts/fact_hailing_rides.sql)
  Column name created_at is ambiguous at [65:11]
  compiled code at target/run/hailing_project/models/facts/fact_hailing_rides.sql
[0m07:41:30.419586 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4f226548-9a4a-42fa-a665-ab770824281a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa0308ec990>]}
[0m07:41:30.420580 [error] [Thread-1 (]: 1 of 1 ERROR creating sql incremental model rizky_dwh_hailing_facts.fact_hailing_rides  [[31mERROR[0m in 0.86s]
[0m07:41:30.422407 [debug] [Thread-1 (]: Finished running node model.hailing_project.fact_hailing_rides
[0m07:41:30.424002 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.fact_hailing_rides' to be skipped because of status 'error'.  Reason: Database Error in model fact_hailing_rides (models/facts/fact_hailing_rides.sql)
  Column name created_at is ambiguous at [65:11]
  compiled code at target/run/hailing_project/models/facts/fact_hailing_rides.sql.
[0m07:41:30.428881 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m07:41:30.432631 [debug] [MainThread]: Connection 'master' was properly closed.
[0m07:41:30.433522 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_staging' was properly closed.
[0m07:41:30.434353 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_facts' was properly closed.
[0m07:41:30.435095 [debug] [MainThread]: Connection 'model.hailing_project.fact_hailing_rides' was properly closed.
[0m07:41:30.435898 [info ] [MainThread]: 
[0m07:41:30.436874 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 1.88 seconds (1.88s).
[0m07:41:30.438428 [debug] [MainThread]: Command end result
[0m07:41:30.476032 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m07:41:30.480058 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m07:41:30.487440 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m07:41:30.488325 [info ] [MainThread]: 
[0m07:41:30.489360 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m07:41:30.490354 [info ] [MainThread]: 
[0m07:41:30.491394 [error] [MainThread]:   Database Error in model fact_hailing_rides (models/facts/fact_hailing_rides.sql)
  Column name created_at is ambiguous at [65:11]
  compiled code at target/run/hailing_project/models/facts/fact_hailing_rides.sql
[0m07:41:30.492455 [info ] [MainThread]: 
[0m07:41:30.493604 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m07:41:30.495285 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 3.9147673, "process_in_blocks": "0", "process_kernel_time": 0.210743, "process_mem_max_rss": "222968", "process_out_blocks": "0", "process_user_time": 4.024193}
[0m07:41:30.496321 [debug] [MainThread]: Command `dbt run` failed at 07:41:30.496120 after 3.92 seconds
[0m07:41:30.497061 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa05e455310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa05e4551d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa05e455590>]}
[0m07:41:30.497931 [debug] [MainThread]: Flushing usage events
[0m07:41:31.917448 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m07:42:01.642721 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f48976c3010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f48976c2b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f48976c31d0>]}


============================== 07:42:01.646508 | 71451356-7c10-4e79-9d31-aca138fe3c34 ==============================
[0m07:42:01.646508 [info ] [MainThread]: Running with dbt=1.9.0
[0m07:42:01.648116 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'invocation_command': 'dbt run --select fact_hailing_rides', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m07:42:02.259292 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '71451356-7c10-4e79-9d31-aca138fe3c34', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f486eebedd0>]}
[0m07:42:02.314291 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '71451356-7c10-4e79-9d31-aca138fe3c34', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4871980110>]}
[0m07:42:02.315555 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m07:42:02.399305 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m07:42:02.587920 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m07:42:02.589483 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/facts/fact_hailing_rides.sql
[0m07:42:02.848207 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '71451356-7c10-4e79-9d31-aca138fe3c34', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f486d74dd90>]}
[0m07:42:02.916532 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m07:42:02.922443 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m07:42:02.938064 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '71451356-7c10-4e79-9d31-aca138fe3c34', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f486d3fb550>]}
[0m07:42:02.939049 [info ] [MainThread]: Found 8 models, 8 sources, 489 macros
[0m07:42:02.940581 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '71451356-7c10-4e79-9d31-aca138fe3c34', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f486d884190>]}
[0m07:42:02.943132 [info ] [MainThread]: 
[0m07:42:02.944334 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m07:42:02.945311 [info ] [MainThread]: 
[0m07:42:02.947021 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m07:42:02.948785 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m07:42:02.949687 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:42:03.478533 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_marts)
[0m07:42:03.479213 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_facts'
[0m07:42:03.480402 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_staging'
[0m07:42:03.480954 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m07:42:03.482114 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:42:03.483604 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:42:03.783818 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '71451356-7c10-4e79-9d31-aca138fe3c34', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f486db97310>]}
[0m07:42:03.785432 [debug] [MainThread]: Opening a new connection, currently in state init
[0m07:42:03.790656 [debug] [Thread-1 (]: Began running node model.hailing_project.fact_hailing_rides
[0m07:42:03.792128 [info ] [Thread-1 (]: 1 of 1 START sql incremental model rizky_dwh_hailing_facts.fact_hailing_rides .. [RUN]
[0m07:42:03.793567 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_staging, now model.hailing_project.fact_hailing_rides)
[0m07:42:03.794791 [debug] [Thread-1 (]: Began compiling node model.hailing_project.fact_hailing_rides
[0m07:42:03.807234 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.fact_hailing_rides"
[0m07:42:03.816321 [debug] [Thread-1 (]: Began executing node model.hailing_project.fact_hailing_rides
[0m07:42:03.859924 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m07:42:04.155000 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.fact_hailing_rides"
[0m07:42:04.162829 [debug] [Thread-1 (]: On model.hailing_project.fact_hailing_rides: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.fact_hailing_rides"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides` as DBT_INTERNAL_DEST
        using (

WITH dim_driver AS (

    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
),

dim_customer AS (

    SELECT * 
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer`
),

ride_staging AS (

    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride`
)

SELECT
ride_staging.ride_id,
ride_staging.start_time AS ride_start_time,
ride_staging.end_time AS ride_end_time,
ride_staging.distance_km,
ride_staging.fare,
ride_staging.ride_status,
dim_customer.cust_id,
dim_customer.name AS cust_name,
dim_customer.phone_number AS cust_phone_number,
dim_customer.email AS cust_email,
dim_driver.driver_id,
dim_driver.driver_name,
dim_driver.phone_number AS driver_phone_number,
dim_driver.email AS driver_email,
dim_driver.vehicle_id,
dim_driver.vehicle_type,
dim_driver.vehicle_brand,
dim_driver.vehicle_production_year,
dim_driver.license_plate,
ride_staging.created_at

FROM ride_staging

LEFT JOIN dim_customer
on ride_staging.cust_id = dim_customer.cust_id

LEFT JOIN dim_driver
on ride_staging.driver_id = dim_driver.driver_id


    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`ride_start_time` = DBT_INTERNAL_SOURCE.`ride_start_time`,`ride_end_time` = DBT_INTERNAL_SOURCE.`ride_end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`cust_name` = DBT_INTERNAL_SOURCE.`cust_name`,`cust_phone_number` = DBT_INTERNAL_SOURCE.`cust_phone_number`,`cust_email` = DBT_INTERNAL_SOURCE.`cust_email`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`driver_name` = DBT_INTERNAL_SOURCE.`driver_name`,`driver_phone_number` = DBT_INTERNAL_SOURCE.`driver_phone_number`,`driver_email` = DBT_INTERNAL_SOURCE.`driver_email`,`vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`vehicle_brand` = DBT_INTERNAL_SOURCE.`vehicle_brand`,`vehicle_production_year` = DBT_INTERNAL_SOURCE.`vehicle_production_year`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `ride_start_time`, `ride_end_time`, `distance_km`, `fare`, `cust_id`, `cust_name`, `cust_phone_number`, `cust_email`, `driver_id`, `driver_name`, `driver_phone_number`, `driver_email`, `vehicle_id`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)
    values
        (`ride_id`, `ride_start_time`, `ride_end_time`, `distance_km`, `fare`, `cust_id`, `cust_name`, `cust_phone_number`, `cust_email`, `driver_id`, `driver_name`, `driver_phone_number`, `driver_email`, `vehicle_id`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)


    
[0m07:42:04.511086 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:f9515f00-0d80-4c2e-8e74-4774c16dd268&page=queryresults
[0m07:42:04.634361 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:f9515f00-0d80-4c2e-8e74-4774c16dd268&page=queryresults
[0m07:42:04.646594 [debug] [Thread-1 (]: Database Error in model fact_hailing_rides (models/facts/fact_hailing_rides.sql)
  Column name created_at is ambiguous at [65:11]
  compiled code at target/run/hailing_project/models/facts/fact_hailing_rides.sql
[0m07:42:04.650077 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '71451356-7c10-4e79-9d31-aca138fe3c34', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f486d8cbcd0>]}
[0m07:42:04.652000 [error] [Thread-1 (]: 1 of 1 ERROR creating sql incremental model rizky_dwh_hailing_facts.fact_hailing_rides  [[31mERROR[0m in 0.86s]
[0m07:42:04.653875 [debug] [Thread-1 (]: Finished running node model.hailing_project.fact_hailing_rides
[0m07:42:04.655325 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.fact_hailing_rides' to be skipped because of status 'error'.  Reason: Database Error in model fact_hailing_rides (models/facts/fact_hailing_rides.sql)
  Column name created_at is ambiguous at [65:11]
  compiled code at target/run/hailing_project/models/facts/fact_hailing_rides.sql.
[0m07:42:04.658356 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m07:42:04.662097 [debug] [MainThread]: Connection 'master' was properly closed.
[0m07:42:04.662917 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_marts' was properly closed.
[0m07:42:04.663695 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_facts' was properly closed.
[0m07:42:04.664745 [debug] [MainThread]: Connection 'model.hailing_project.fact_hailing_rides' was properly closed.
[0m07:42:04.666787 [info ] [MainThread]: 
[0m07:42:04.668213 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 1.72 seconds (1.72s).
[0m07:42:04.670027 [debug] [MainThread]: Command end result
[0m07:42:04.713894 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m07:42:04.718616 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m07:42:04.730275 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m07:42:04.731481 [info ] [MainThread]: 
[0m07:42:04.733245 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m07:42:04.734618 [info ] [MainThread]: 
[0m07:42:04.736154 [error] [MainThread]:   Database Error in model fact_hailing_rides (models/facts/fact_hailing_rides.sql)
  Column name created_at is ambiguous at [65:11]
  compiled code at target/run/hailing_project/models/facts/fact_hailing_rides.sql
[0m07:42:04.737760 [info ] [MainThread]: 
[0m07:42:04.738868 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m07:42:04.741408 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 3.1509664, "process_in_blocks": "448", "process_kernel_time": 0.280725, "process_mem_max_rss": "218812", "process_out_blocks": "0", "process_user_time": 3.328601}
[0m07:42:04.743362 [debug] [MainThread]: Command `dbt run` failed at 07:42:04.743123 after 3.15 seconds
[0m07:42:04.744860 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f486d703f50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4897abe6d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f48984abd10>]}
[0m07:42:04.745999 [debug] [MainThread]: Flushing usage events
[0m07:42:05.956200 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m07:43:11.992186 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd9b793f3d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd9b7997610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd9b793f750>]}


============================== 07:43:11.994513 | 38392f31-17df-4a73-8cc4-284396cdd7ff ==============================
[0m07:43:11.994513 [info ] [MainThread]: Running with dbt=1.9.0
[0m07:43:11.995560 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'profiles_dir': '/usr/app/dbt_project', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'invocation_command': 'dbt run --select fact_hailing_rides', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m07:43:12.608478 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '38392f31-17df-4a73-8cc4-284396cdd7ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd989af3750>]}
[0m07:43:12.656739 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '38392f31-17df-4a73-8cc4-284396cdd7ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd989c49f10>]}
[0m07:43:12.658029 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m07:43:12.731575 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m07:43:12.897003 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m07:43:12.898081 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/facts/fact_hailing_rides.sql
[0m07:43:13.150899 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '38392f31-17df-4a73-8cc4-284396cdd7ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd989730a10>]}
[0m07:43:13.217608 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m07:43:13.223324 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m07:43:13.238311 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '38392f31-17df-4a73-8cc4-284396cdd7ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd98967b710>]}
[0m07:43:13.239211 [info ] [MainThread]: Found 8 models, 8 sources, 489 macros
[0m07:43:13.240501 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '38392f31-17df-4a73-8cc4-284396cdd7ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd989614710>]}
[0m07:43:13.242802 [info ] [MainThread]: 
[0m07:43:13.243847 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m07:43:13.244779 [info ] [MainThread]: 
[0m07:43:13.245970 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m07:43:13.247691 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m07:43:13.248886 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:43:13.803518 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_staging)
[0m07:43:13.804123 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_facts'
[0m07:43:13.808010 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:43:13.806312 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m07:43:13.805235 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_marts'
[0m07:43:13.832975 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:43:14.102140 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '38392f31-17df-4a73-8cc4-284396cdd7ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd98986ad50>]}
[0m07:43:14.103448 [debug] [MainThread]: Opening a new connection, currently in state init
[0m07:43:14.109189 [debug] [Thread-1 (]: Began running node model.hailing_project.fact_hailing_rides
[0m07:43:14.110398 [info ] [Thread-1 (]: 1 of 1 START sql incremental model rizky_dwh_hailing_facts.fact_hailing_rides .. [RUN]
[0m07:43:14.112957 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_marts, now model.hailing_project.fact_hailing_rides)
[0m07:43:14.113886 [debug] [Thread-1 (]: Began compiling node model.hailing_project.fact_hailing_rides
[0m07:43:14.123542 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.fact_hailing_rides"
[0m07:43:14.128811 [debug] [Thread-1 (]: Began executing node model.hailing_project.fact_hailing_rides
[0m07:43:14.166236 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m07:43:14.469332 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.fact_hailing_rides"
[0m07:43:14.475703 [debug] [Thread-1 (]: On model.hailing_project.fact_hailing_rides: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.fact_hailing_rides"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides` as DBT_INTERNAL_DEST
        using (

WITH dim_driver AS (

    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
),

dim_customer AS (

    SELECT * 
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer`
),

ride_staging AS (

    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride`
)

SELECT
ride_staging.ride_id,
ride_staging.start_time AS ride_start_time,
ride_staging.end_time AS ride_end_time,
ride_staging.distance_km,
ride_staging.fare,
ride_staging.ride_status,
dim_customer.cust_id,
dim_customer.name AS cust_name,
dim_customer.phone_number AS cust_phone_number,
dim_customer.email AS cust_email,
dim_driver.driver_id,
dim_driver.driver_name,
dim_driver.phone_number AS driver_phone_number,
dim_driver.email AS driver_email,
dim_driver.vehicle_id,
dim_driver.vehicle_type,
dim_driver.vehicle_brand,
dim_driver.vehicle_production_year,
dim_driver.license_plate,
ride_staging.created_at AS created_at

FROM ride_staging

LEFT JOIN dim_customer
on ride_staging.cust_id = dim_customer.cust_id

LEFT JOIN dim_driver
on ride_staging.driver_id = dim_driver.driver_id


    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`ride_start_time` = DBT_INTERNAL_SOURCE.`ride_start_time`,`ride_end_time` = DBT_INTERNAL_SOURCE.`ride_end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`cust_name` = DBT_INTERNAL_SOURCE.`cust_name`,`cust_phone_number` = DBT_INTERNAL_SOURCE.`cust_phone_number`,`cust_email` = DBT_INTERNAL_SOURCE.`cust_email`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`driver_name` = DBT_INTERNAL_SOURCE.`driver_name`,`driver_phone_number` = DBT_INTERNAL_SOURCE.`driver_phone_number`,`driver_email` = DBT_INTERNAL_SOURCE.`driver_email`,`vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`vehicle_brand` = DBT_INTERNAL_SOURCE.`vehicle_brand`,`vehicle_production_year` = DBT_INTERNAL_SOURCE.`vehicle_production_year`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `ride_start_time`, `ride_end_time`, `distance_km`, `fare`, `cust_id`, `cust_name`, `cust_phone_number`, `cust_email`, `driver_id`, `driver_name`, `driver_phone_number`, `driver_email`, `vehicle_id`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)
    values
        (`ride_id`, `ride_start_time`, `ride_end_time`, `distance_km`, `fare`, `cust_id`, `cust_name`, `cust_phone_number`, `cust_email`, `driver_id`, `driver_name`, `driver_phone_number`, `driver_email`, `vehicle_id`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)


    
[0m07:43:14.862032 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:fffbfd7a-1cbe-40e4-95a8-f4e59cdb4fd6&page=queryresults
[0m07:43:15.075404 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:fffbfd7a-1cbe-40e4-95a8-f4e59cdb4fd6&page=queryresults
[0m07:43:15.082331 [debug] [Thread-1 (]: Database Error in model fact_hailing_rides (models/facts/fact_hailing_rides.sql)
  Column name created_at is ambiguous at [65:11]
  compiled code at target/run/hailing_project/models/facts/fact_hailing_rides.sql
[0m07:43:15.084820 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '38392f31-17df-4a73-8cc4-284396cdd7ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd9896b39d0>]}
[0m07:43:15.086410 [error] [Thread-1 (]: 1 of 1 ERROR creating sql incremental model rizky_dwh_hailing_facts.fact_hailing_rides  [[31mERROR[0m in 0.97s]
[0m07:43:15.089218 [debug] [Thread-1 (]: Finished running node model.hailing_project.fact_hailing_rides
[0m07:43:15.091190 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.fact_hailing_rides' to be skipped because of status 'error'.  Reason: Database Error in model fact_hailing_rides (models/facts/fact_hailing_rides.sql)
  Column name created_at is ambiguous at [65:11]
  compiled code at target/run/hailing_project/models/facts/fact_hailing_rides.sql.
[0m07:43:15.095091 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m07:43:15.099336 [debug] [MainThread]: Connection 'master' was properly closed.
[0m07:43:15.100663 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_staging' was properly closed.
[0m07:43:15.101728 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_facts' was properly closed.
[0m07:43:15.102712 [debug] [MainThread]: Connection 'model.hailing_project.fact_hailing_rides' was properly closed.
[0m07:43:15.103867 [info ] [MainThread]: 
[0m07:43:15.105126 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 1.86 seconds (1.86s).
[0m07:43:15.107252 [debug] [MainThread]: Command end result
[0m07:43:15.144388 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m07:43:15.148374 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m07:43:15.156339 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m07:43:15.157065 [info ] [MainThread]: 
[0m07:43:15.158031 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m07:43:15.159078 [info ] [MainThread]: 
[0m07:43:15.159920 [error] [MainThread]:   Database Error in model fact_hailing_rides (models/facts/fact_hailing_rides.sql)
  Column name created_at is ambiguous at [65:11]
  compiled code at target/run/hailing_project/models/facts/fact_hailing_rides.sql
[0m07:43:15.160857 [info ] [MainThread]: 
[0m07:43:15.161753 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m07:43:15.163353 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 3.222274, "process_in_blocks": "0", "process_kernel_time": 0.202607, "process_mem_max_rss": "218628", "process_out_blocks": "0", "process_user_time": 3.383539}
[0m07:43:15.164408 [debug] [MainThread]: Command `dbt run` failed at 07:43:15.164240 after 3.22 seconds
[0m07:43:15.165463 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd9b799add0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd9b7987f50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd9bb2b91d0>]}
[0m07:43:15.166473 [debug] [MainThread]: Flushing usage events
[0m07:43:16.246317 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m07:43:55.693332 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f11b28d7190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f11b28d7b10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f11b28d7510>]}


============================== 07:43:55.696127 | 3471b0a9-02ca-493e-bff9-b1a7b5bcb4f5 ==============================
[0m07:43:55.696127 [info ] [MainThread]: Running with dbt=1.9.0
[0m07:43:55.697412 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt run --select fact_hailing_rides', 'send_anonymous_usage_stats': 'True'}
[0m07:43:56.280342 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '3471b0a9-02ca-493e-bff9-b1a7b5bcb4f5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1188a8ad10>]}
[0m07:43:56.324960 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '3471b0a9-02ca-493e-bff9-b1a7b5bcb4f5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f11b4b44f90>]}
[0m07:43:56.326443 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m07:43:56.403147 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m07:43:56.580349 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m07:43:56.581741 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/facts/fact_hailing_rides.sql
[0m07:43:56.834684 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3471b0a9-02ca-493e-bff9-b1a7b5bcb4f5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1188771a90>]}
[0m07:43:56.904851 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m07:43:56.910721 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m07:43:56.926054 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3471b0a9-02ca-493e-bff9-b1a7b5bcb4f5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f11886f6950>]}
[0m07:43:56.927284 [info ] [MainThread]: Found 8 models, 8 sources, 489 macros
[0m07:43:56.928511 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3471b0a9-02ca-493e-bff9-b1a7b5bcb4f5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f118856c890>]}
[0m07:43:56.930907 [info ] [MainThread]: 
[0m07:43:56.932072 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m07:43:56.933070 [info ] [MainThread]: 
[0m07:43:56.934242 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m07:43:56.936311 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m07:43:56.937564 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:43:57.534539 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_marts)
[0m07:43:57.535148 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_facts'
[0m07:43:57.535698 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_staging'
[0m07:43:57.536382 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m07:43:57.537046 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:43:57.537896 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:43:57.837708 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3471b0a9-02ca-493e-bff9-b1a7b5bcb4f5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f118857d610>]}
[0m07:43:57.838587 [debug] [MainThread]: Opening a new connection, currently in state init
[0m07:43:57.842907 [debug] [Thread-1 (]: Began running node model.hailing_project.fact_hailing_rides
[0m07:43:57.843697 [info ] [Thread-1 (]: 1 of 1 START sql incremental model rizky_dwh_hailing_facts.fact_hailing_rides .. [RUN]
[0m07:43:57.844712 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_facts, now model.hailing_project.fact_hailing_rides)
[0m07:43:57.845758 [debug] [Thread-1 (]: Began compiling node model.hailing_project.fact_hailing_rides
[0m07:43:57.856133 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.fact_hailing_rides"
[0m07:43:57.863854 [debug] [Thread-1 (]: Began executing node model.hailing_project.fact_hailing_rides
[0m07:43:57.898907 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m07:43:58.189960 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.fact_hailing_rides"
[0m07:43:58.198020 [debug] [Thread-1 (]: On model.hailing_project.fact_hailing_rides: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.fact_hailing_rides"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides` as DBT_INTERNAL_DEST
        using (

WITH dim_driver AS (

    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
),

dim_customer AS (

    SELECT * 
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer`
),

ride_staging AS (

    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride`
)

SELECT
ride_staging.ride_id,
ride_staging.start_time AS ride_start_time,
ride_staging.end_time AS ride_end_time,
ride_staging.distance_km,
ride_staging.fare,
ride_staging.ride_status,
dim_customer.cust_id,
dim_customer.name AS cust_name,
dim_customer.phone_number AS cust_phone_number,
dim_customer.email AS cust_email,
dim_driver.driver_id,
dim_driver.driver_name,
dim_driver.phone_number AS driver_phone_number,
dim_driver.email AS driver_email,
dim_driver.vehicle_id,
dim_driver.vehicle_type,
dim_driver.vehicle_brand,
dim_driver.vehicle_production_year,
dim_driver.license_plate,
ride_staging.created_at

FROM ride_staging

LEFT JOIN dim_customer
on ride_staging.cust_id = dim_customer.cust_id

LEFT JOIN dim_driver
on ride_staging.driver_id = dim_driver.driver_id


    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`ride_start_time` = DBT_INTERNAL_SOURCE.`ride_start_time`,`ride_end_time` = DBT_INTERNAL_SOURCE.`ride_end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`cust_name` = DBT_INTERNAL_SOURCE.`cust_name`,`cust_phone_number` = DBT_INTERNAL_SOURCE.`cust_phone_number`,`cust_email` = DBT_INTERNAL_SOURCE.`cust_email`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`driver_name` = DBT_INTERNAL_SOURCE.`driver_name`,`driver_phone_number` = DBT_INTERNAL_SOURCE.`driver_phone_number`,`driver_email` = DBT_INTERNAL_SOURCE.`driver_email`,`vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`vehicle_brand` = DBT_INTERNAL_SOURCE.`vehicle_brand`,`vehicle_production_year` = DBT_INTERNAL_SOURCE.`vehicle_production_year`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `ride_start_time`, `ride_end_time`, `distance_km`, `fare`, `cust_id`, `cust_name`, `cust_phone_number`, `cust_email`, `driver_id`, `driver_name`, `driver_phone_number`, `driver_email`, `vehicle_id`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)
    values
        (`ride_id`, `ride_start_time`, `ride_end_time`, `distance_km`, `fare`, `cust_id`, `cust_name`, `cust_phone_number`, `cust_email`, `driver_id`, `driver_name`, `driver_phone_number`, `driver_email`, `vehicle_id`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)


    
[0m07:43:58.556731 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:49ba3d6b-454d-4561-a4df-de1d81b3684c&page=queryresults
[0m07:43:58.751302 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:49ba3d6b-454d-4561-a4df-de1d81b3684c&page=queryresults
[0m07:43:58.758622 [debug] [Thread-1 (]: Database Error in model fact_hailing_rides (models/facts/fact_hailing_rides.sql)
  Column name created_at is ambiguous at [65:11]
  compiled code at target/run/hailing_project/models/facts/fact_hailing_rides.sql
[0m07:43:58.761240 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3471b0a9-02ca-493e-bff9-b1a7b5bcb4f5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1188a94490>]}
[0m07:43:58.762734 [error] [Thread-1 (]: 1 of 1 ERROR creating sql incremental model rizky_dwh_hailing_facts.fact_hailing_rides  [[31mERROR[0m in 0.92s]
[0m07:43:58.764132 [debug] [Thread-1 (]: Finished running node model.hailing_project.fact_hailing_rides
[0m07:43:58.765789 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.fact_hailing_rides' to be skipped because of status 'error'.  Reason: Database Error in model fact_hailing_rides (models/facts/fact_hailing_rides.sql)
  Column name created_at is ambiguous at [65:11]
  compiled code at target/run/hailing_project/models/facts/fact_hailing_rides.sql.
[0m07:43:58.769392 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m07:43:58.773393 [debug] [MainThread]: Connection 'master' was properly closed.
[0m07:43:58.774470 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_marts' was properly closed.
[0m07:43:58.775544 [debug] [MainThread]: Connection 'model.hailing_project.fact_hailing_rides' was properly closed.
[0m07:43:58.776721 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_staging' was properly closed.
[0m07:43:58.777706 [info ] [MainThread]: 
[0m07:43:58.778790 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 1.84 seconds (1.84s).
[0m07:43:58.780582 [debug] [MainThread]: Command end result
[0m07:43:58.824708 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m07:43:58.830025 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m07:43:58.839244 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m07:43:58.839982 [info ] [MainThread]: 
[0m07:43:58.841118 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m07:43:58.842498 [info ] [MainThread]: 
[0m07:43:58.843700 [error] [MainThread]:   Database Error in model fact_hailing_rides (models/facts/fact_hailing_rides.sql)
  Column name created_at is ambiguous at [65:11]
  compiled code at target/run/hailing_project/models/facts/fact_hailing_rides.sql
[0m07:43:58.844795 [info ] [MainThread]: 
[0m07:43:58.846146 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m07:43:58.847943 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 3.205133, "process_in_blocks": "0", "process_kernel_time": 0.294949, "process_mem_max_rss": "218140", "process_out_blocks": "0", "process_user_time": 3.325809}
[0m07:43:58.849254 [debug] [MainThread]: Command `dbt run` failed at 07:43:58.849108 after 3.21 seconds
[0m07:43:58.850125 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f11b292e050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f11b292c8d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f11b4b35b10>]}
[0m07:43:58.851031 [debug] [MainThread]: Flushing usage events
[0m07:44:00.051584 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m07:48:31.437175 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8245c773d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8245cc7e10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8246072b10>]}


============================== 07:48:31.441258 | a7051b33-29e1-4e53-a4ce-1cc05229496b ==============================
[0m07:48:31.441258 [info ] [MainThread]: Running with dbt=1.9.0
[0m07:48:31.442413 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'invocation_command': 'dbt clean', 'send_anonymous_usage_stats': 'True'}
[0m07:48:31.527588 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a7051b33-29e1-4e53-a4ce-1cc05229496b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8245ca6650>]}
[0m07:48:31.586625 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.20878123, "process_in_blocks": "0", "process_kernel_time": 0.06897, "process_mem_max_rss": "89916", "process_out_blocks": "0", "process_user_time": 0.985294}
[0m07:48:31.587540 [debug] [MainThread]: Command `dbt clean` succeeded at 07:48:31.587442 after 0.21 seconds
[0m07:48:31.588369 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f824618cbd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8245d81f50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8245cccd10>]}
[0m07:48:31.589113 [debug] [MainThread]: Flushing usage events
[0m07:48:32.847278 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m07:48:33.969968 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b569b4dd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b56dae4d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b56dae110>]}


============================== 07:48:33.973102 | c06ef087-e05b-4cff-a840-65f79effe172 ==============================
[0m07:48:33.973102 [info ] [MainThread]: Running with dbt=1.9.0
[0m07:48:33.974485 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'invocation_command': 'dbt deps', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m07:48:34.058651 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'c06ef087-e05b-4cff-a840-65f79effe172', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b569b6590>]}
[0m07:49:39.967592 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4c853f3210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4c85443450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4c853f2310>]}


============================== 07:49:39.970275 | b7b7c425-7b08-43bd-ad51-a0e23287d5a3 ==============================
[0m07:49:39.970275 [info ] [MainThread]: Running with dbt=1.9.0
[0m07:49:39.971449 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'invocation_command': 'dbt debug', 'send_anonymous_usage_stats': 'True'}
[0m07:49:39.978375 [info ] [MainThread]: dbt version: 1.9.0
[0m07:49:39.979218 [info ] [MainThread]: python version: 3.11.2
[0m07:49:39.980410 [info ] [MainThread]: python path: /usr/local/bin/python
[0m07:49:39.981662 [info ] [MainThread]: os info: Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.31
[0m07:49:40.552106 [info ] [MainThread]: Using profiles dir at /usr/app/dbt_project
[0m07:49:40.553661 [info ] [MainThread]: Using profiles.yml file at /usr/app/dbt_project/profiles.yml
[0m07:49:40.554700 [info ] [MainThread]: Using dbt_project.yml file at /usr/app/dbt_project/dbt_project.yml
[0m07:49:40.556008 [info ] [MainThread]: adapter type: bigquery
[0m07:49:40.557014 [info ] [MainThread]: adapter version: 1.9.0
[0m07:49:40.642615 [info ] [MainThread]: Configuration:
[0m07:49:40.643810 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m07:49:40.644957 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m07:49:40.646016 [info ] [MainThread]: Required dependencies:
[0m07:49:40.647047 [debug] [MainThread]: Executing "git --help"
[0m07:49:40.651164 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m07:49:40.652169 [debug] [MainThread]: STDERR: "b''"
[0m07:49:40.652946 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m07:49:40.653774 [info ] [MainThread]: Connection:
[0m07:49:40.654961 [info ] [MainThread]:   method: service-account
[0m07:49:40.656023 [info ] [MainThread]:   database: purwadika
[0m07:49:40.657043 [info ] [MainThread]:   execution_project: purwadika
[0m07:49:40.658052 [info ] [MainThread]:   schema: rizky_dwh_hailing_source
[0m07:49:40.659299 [info ] [MainThread]:   location: None
[0m07:49:40.660606 [info ] [MainThread]:   priority: None
[0m07:49:40.661918 [info ] [MainThread]:   maximum_bytes_billed: None
[0m07:49:40.663276 [info ] [MainThread]:   impersonate_service_account: None
[0m07:49:40.664738 [info ] [MainThread]:   job_retry_deadline_seconds: None
[0m07:49:40.665742 [info ] [MainThread]:   job_retries: 1
[0m07:49:40.666849 [info ] [MainThread]:   job_creation_timeout_seconds: None
[0m07:49:40.667808 [info ] [MainThread]:   job_execution_timeout_seconds: None
[0m07:49:40.668801 [info ] [MainThread]:   timeout_seconds: None
[0m07:49:40.669802 [info ] [MainThread]:   client_id: None
[0m07:49:40.671006 [info ] [MainThread]:   token_uri: None
[0m07:49:40.672354 [info ] [MainThread]:   dataproc_region: None
[0m07:49:40.673421 [info ] [MainThread]:   dataproc_cluster_name: None
[0m07:49:40.674529 [info ] [MainThread]:   gcs_bucket: None
[0m07:49:40.675505 [info ] [MainThread]:   dataproc_batch: None
[0m07:49:40.676991 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m07:49:40.741538 [debug] [MainThread]: Acquiring new bigquery connection 'debug'
[0m07:49:40.742790 [debug] [MainThread]: On debug: select 1 as id
[0m07:49:40.743911 [debug] [MainThread]: Opening a new connection, currently in state init
[0m07:49:41.525781 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:f43f4655-87d8-4add-bd3f-9d472540b06f&page=queryresults
[0m07:49:42.313435 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m07:49:42.315562 [info ] [MainThread]: [32mAll checks passed![0m
[0m07:49:42.318442 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": true, "command_wall_clock_time": 2.4041407, "process_in_blocks": "0", "process_kernel_time": 0.217717, "process_mem_max_rss": "212360", "process_out_blocks": "0", "process_user_time": 2.671984}
[0m07:49:42.319840 [debug] [MainThread]: Command `dbt debug` succeeded at 07:49:42.319719 after 2.41 seconds
[0m07:49:42.321230 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m07:49:42.322520 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4c85422590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4c85421a10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4c853f8550>]}
[0m07:49:42.323667 [debug] [MainThread]: Flushing usage events
[0m07:49:43.598205 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m07:49:52.191345 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb286da7d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb28ad0290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb286db390>]}


============================== 07:49:52.194082 | 5689684c-0d7b-462c-9adf-5092c0000335 ==============================
[0m07:49:52.194082 [info ] [MainThread]: Running with dbt=1.9.0
[0m07:49:52.195252 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'warn_error': 'None', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt run --select fact_hailing_rides', 'send_anonymous_usage_stats': 'True'}
[0m07:49:52.762147 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5689684c-0d7b-462c-9adf-5092c0000335', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdafa9bb110>]}
[0m07:49:52.809131 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '5689684c-0d7b-462c-9adf-5092c0000335', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb2a9309d0>]}
[0m07:49:52.811570 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m07:49:52.875079 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m07:49:52.877734 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m07:49:52.878629 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '5689684c-0d7b-462c-9adf-5092c0000335', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdafae81f90>]}
[0m07:49:53.943025 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5689684c-0d7b-462c-9adf-5092c0000335', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdafa65dc10>]}
[0m07:49:54.020813 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m07:49:54.027704 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m07:49:54.042959 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5689684c-0d7b-462c-9adf-5092c0000335', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdaf8aa4290>]}
[0m07:49:54.044054 [info ] [MainThread]: Found 8 models, 8 sources, 489 macros
[0m07:49:54.045132 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5689684c-0d7b-462c-9adf-5092c0000335', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdaf8a3b950>]}
[0m07:49:54.047667 [info ] [MainThread]: 
[0m07:49:54.048899 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m07:49:54.050009 [info ] [MainThread]: 
[0m07:49:54.051378 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m07:49:54.052855 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m07:49:54.053847 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:49:54.588823 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_facts)
[0m07:49:54.590019 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_marts'
[0m07:49:54.590644 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_staging'
[0m07:49:54.591389 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m07:49:54.593615 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:49:54.596039 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:49:54.925376 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5689684c-0d7b-462c-9adf-5092c0000335', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdaf8bda750>]}
[0m07:49:54.926477 [debug] [MainThread]: Opening a new connection, currently in state init
[0m07:49:54.931434 [debug] [Thread-1 (]: Began running node model.hailing_project.fact_hailing_rides
[0m07:49:54.932370 [info ] [Thread-1 (]: 1 of 1 START sql incremental model rizky_dwh_hailing_facts.fact_hailing_rides .. [RUN]
[0m07:49:54.933460 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_staging, now model.hailing_project.fact_hailing_rides)
[0m07:49:54.934267 [debug] [Thread-1 (]: Began compiling node model.hailing_project.fact_hailing_rides
[0m07:49:54.943098 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.fact_hailing_rides"
[0m07:49:54.956490 [debug] [Thread-1 (]: Began executing node model.hailing_project.fact_hailing_rides
[0m07:49:55.021237 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.fact_hailing_rides"
[0m07:49:55.034769 [debug] [Thread-1 (]: On model.hailing_project.fact_hailing_rides: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.fact_hailing_rides"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH dim_driver AS (

    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
),

dim_customer AS (

    SELECT * 
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer`
),

ride_staging AS (

    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride`
)

SELECT
ride_staging.ride_id,
ride_staging.start_time AS ride_start_time,
ride_staging.end_time AS ride_end_time,
ride_staging.distance_km,
ride_staging.fare,
ride_staging.ride_status,
dim_customer.cust_id,
dim_customer.name AS cust_name,
dim_customer.phone_number AS cust_phone_number,
dim_customer.email AS cust_email,
dim_driver.driver_id,
dim_driver.driver_name,
dim_driver.phone_number AS driver_phone_number,
dim_driver.email AS driver_email,
dim_driver.vehicle_id,
dim_driver.vehicle_type,
dim_driver.vehicle_brand,
dim_driver.vehicle_production_year,
dim_driver.license_plate,
ride_staging.created_at

FROM ride_staging

LEFT JOIN dim_customer
on ride_staging.cust_id = dim_customer.cust_id

LEFT JOIN dim_driver
on ride_staging.driver_id = dim_driver.driver_id


    );
  
[0m07:49:55.035934 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m07:49:55.549768 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:c4fc93d3-18cd-4e2f-a519-a83fea6c81d9&page=queryresults
[0m07:49:57.268167 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5689684c-0d7b-462c-9adf-5092c0000335', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdac0dd8d50>]}
[0m07:49:57.269754 [info ] [Thread-1 (]: 1 of 1 OK created sql incremental model rizky_dwh_hailing_facts.fact_hailing_rides  [[32mCREATE TABLE (85.0 rows, 20.9 KiB processed)[0m in 2.33s]
[0m07:49:57.271424 [debug] [Thread-1 (]: Finished running node model.hailing_project.fact_hailing_rides
[0m07:49:57.273683 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m07:49:57.276441 [debug] [MainThread]: Connection 'master' was properly closed.
[0m07:49:57.277405 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_facts' was properly closed.
[0m07:49:57.278230 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_marts' was properly closed.
[0m07:49:57.278977 [debug] [MainThread]: Connection 'model.hailing_project.fact_hailing_rides' was properly closed.
[0m07:49:57.279831 [info ] [MainThread]: 
[0m07:49:57.280865 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 3.23 seconds (3.23s).
[0m07:49:57.283094 [debug] [MainThread]: Command end result
[0m07:49:57.319727 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m07:49:57.323350 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m07:49:57.331110 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m07:49:57.332552 [info ] [MainThread]: 
[0m07:49:57.333949 [info ] [MainThread]: [32mCompleted successfully[0m
[0m07:49:57.335195 [info ] [MainThread]: 
[0m07:49:57.336304 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m07:49:57.338460 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 5.194402, "process_in_blocks": "0", "process_kernel_time": 0.198686, "process_mem_max_rss": "223408", "process_out_blocks": "0", "process_user_time": 3.993594}
[0m07:49:57.339585 [debug] [MainThread]: Command `dbt run` succeeded at 07:49:57.339462 after 5.20 seconds
[0m07:49:57.340521 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb2855bdd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb2855bc50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb2beccd90>]}
[0m07:49:57.341670 [debug] [MainThread]: Flushing usage events
[0m07:49:58.346192 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m08:54:56.287366 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff2cd1eba50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff2cd243ad0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff2cd1eaed0>]}


============================== 08:54:56.289908 | e255b18d-f335-4338-9f11-a5c7bbb0cb82 ==============================
[0m08:54:56.289908 [info ] [MainThread]: Running with dbt=1.9.0
[0m08:54:56.291278 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'invocation_command': 'dbt run --select mart_cust_rides_daily', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m08:54:56.856674 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e255b18d-f335-4338-9f11-a5c7bbb0cb82', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff29f505f90>]}
[0m08:54:56.902367 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e255b18d-f335-4338-9f11-a5c7bbb0cb82', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff2cf43db50>]}
[0m08:54:56.903882 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m08:54:56.968268 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m08:54:57.156606 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m08:54:57.157679 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/marts/mart_cust_rides_daily.sql
[0m08:54:57.425236 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e255b18d-f335-4338-9f11-a5c7bbb0cb82', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff29f18add0>]}
[0m08:54:57.509103 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m08:54:57.515799 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m08:54:57.535883 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e255b18d-f335-4338-9f11-a5c7bbb0cb82', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff29d70bf90>]}
[0m08:54:57.537179 [info ] [MainThread]: Found 8 models, 8 sources, 489 macros
[0m08:54:57.538682 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e255b18d-f335-4338-9f11-a5c7bbb0cb82', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff29f35b150>]}
[0m08:54:57.541435 [info ] [MainThread]: 
[0m08:54:57.542687 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m08:54:57.543671 [info ] [MainThread]: 
[0m08:54:57.545049 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m08:54:57.546866 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m08:54:57.547941 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:54:58.193983 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_marts)
[0m08:54:58.194617 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_staging'
[0m08:54:58.197061 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:54:58.196013 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:54:58.195408 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_facts'
[0m08:54:58.223728 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:54:58.511896 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e255b18d-f335-4338-9f11-a5c7bbb0cb82', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff29f18ba50>]}
[0m08:54:58.513750 [debug] [MainThread]: Opening a new connection, currently in state init
[0m08:54:58.518264 [debug] [Thread-1 (]: Began running node model.hailing_project.mart_cust_rides_daily
[0m08:54:58.519141 [info ] [Thread-1 (]: 1 of 1 START sql table model rizky_dwh_hailing_marts.mart_cust_rides_daily ..... [RUN]
[0m08:54:58.520380 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_facts, now model.hailing_project.mart_cust_rides_daily)
[0m08:54:58.521352 [debug] [Thread-1 (]: Began compiling node model.hailing_project.mart_cust_rides_daily
[0m08:54:58.528760 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.mart_cust_rides_daily"
[0m08:54:58.538703 [debug] [Thread-1 (]: Began executing node model.hailing_project.mart_cust_rides_daily
[0m08:54:58.580078 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.mart_cust_rides_daily"
[0m08:54:58.588340 [debug] [Thread-1 (]: On model.hailing_project.mart_cust_rides_daily: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.mart_cust_rides_daily"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_marts`.`mart_cust_rides_daily`
      
    partition by timestamp_trunc(ride_date, day)
    

    OPTIONS()
    as (
      


WITH fact_rides AS(

    SELECT * 
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
)

SELECT (

    fact_rides.cust_id,
    fact_rides.cust_name,
    fact_rides.cust_email,
    fact_rides.cust_phone_number,
    DATE(fact_rides.created_at) AS ride_date,
    COUNT(fact_rides.ride_id) AS no_of_rides,
    SUM(TIMESTAMP_DIFF(TIMESTAMP('fact_rides.end_time'), TIMESTAMP('fact_rides.start_time'), MINUTES) as total_ride_duration_min),
    SUM(fact_rides.fare) AS total_fare,
    SUM(fact_rides.distance_km) as total_distance_km,
    fact_rides.total_distance_km-fact_rides.total_fare AS rev_opportunity_loss
    
FROM fact_rides

)
    );
  
[0m08:54:58.589590 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m08:54:59.121798 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:3d043045-a551-49eb-b2eb-40437464e03f&page=queryresults
[0m08:54:59.122861 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:3d043045-a551-49eb-b2eb-40437464e03f&page=queryresults
[0m08:54:59.127467 [debug] [Thread-1 (]: Database Error in model mart_cust_rides_daily (models/marts/mart_cust_rides_daily.sql)
  Syntax error: Expected ")" or "," but got keyword AS at [28:33]
  compiled code at target/run/hailing_project/models/marts/mart_cust_rides_daily.sql
[0m08:54:59.129421 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e255b18d-f335-4338-9f11-a5c7bbb0cb82', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff29d73a5d0>]}
[0m08:54:59.130706 [error] [Thread-1 (]: 1 of 1 ERROR creating sql table model rizky_dwh_hailing_marts.mart_cust_rides_daily  [[31mERROR[0m in 0.61s]
[0m08:54:59.131768 [debug] [Thread-1 (]: Finished running node model.hailing_project.mart_cust_rides_daily
[0m08:54:59.133170 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.mart_cust_rides_daily' to be skipped because of status 'error'.  Reason: Database Error in model mart_cust_rides_daily (models/marts/mart_cust_rides_daily.sql)
  Syntax error: Expected ")" or "," but got keyword AS at [28:33]
  compiled code at target/run/hailing_project/models/marts/mart_cust_rides_daily.sql.
[0m08:54:59.135758 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m08:54:59.139637 [debug] [MainThread]: Connection 'master' was properly closed.
[0m08:54:59.141360 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_marts' was properly closed.
[0m08:54:59.142404 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_staging' was properly closed.
[0m08:54:59.143647 [debug] [MainThread]: Connection 'model.hailing_project.mart_cust_rides_daily' was properly closed.
[0m08:54:59.144548 [info ] [MainThread]: 
[0m08:54:59.145519 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 1.60 seconds (1.60s).
[0m08:54:59.146868 [debug] [MainThread]: Command end result
[0m08:54:59.182678 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m08:54:59.187083 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m08:54:59.194607 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m08:54:59.195284 [info ] [MainThread]: 
[0m08:54:59.196369 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m08:54:59.197563 [info ] [MainThread]: 
[0m08:54:59.198709 [error] [MainThread]:   Database Error in model mart_cust_rides_daily (models/marts/mart_cust_rides_daily.sql)
  Syntax error: Expected ")" or "," but got keyword AS at [28:33]
  compiled code at target/run/hailing_project/models/marts/mart_cust_rides_daily.sql
[0m08:54:59.199686 [info ] [MainThread]: 
[0m08:54:59.200614 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m08:54:59.202397 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 2.9732583, "process_in_blocks": "0", "process_kernel_time": 0.200282, "process_mem_max_rss": "217308", "process_out_blocks": "0", "process_user_time": 3.304665}
[0m08:54:59.203613 [debug] [MainThread]: Command `dbt run` failed at 08:54:59.203471 after 2.97 seconds
[0m08:54:59.204584 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff2d0b39310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff2d0b392d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff2d0b38990>]}
[0m08:54:59.205501 [debug] [MainThread]: Flushing usage events
[0m08:55:00.524968 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m08:58:29.580521 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1bc1dd090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1bc694350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1bc1df6d0>]}


============================== 08:58:29.583462 | 95aef471-a1ab-4741-85f9-f37185681e3b ==============================
[0m08:58:29.583462 [info ] [MainThread]: Running with dbt=1.9.0
[0m08:58:29.585240 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt run --select mart_cust_rides_daily', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m08:58:30.198274 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '95aef471-a1ab-4741-85f9-f37185681e3b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe194749a90>]}
[0m08:58:30.260703 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '95aef471-a1ab-4741-85f9-f37185681e3b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1be462450>]}
[0m08:58:30.262278 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m08:58:30.332289 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m08:58:30.538209 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m08:58:30.539295 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/marts/mart_cust_rides_daily.sql
[0m08:58:30.823921 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '95aef471-a1ab-4741-85f9-f37185681e3b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe18e3971d0>]}
[0m08:58:30.897982 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m08:58:30.905104 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m08:58:30.922493 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '95aef471-a1ab-4741-85f9-f37185681e3b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe18c6e7d10>]}
[0m08:58:30.924223 [info ] [MainThread]: Found 8 models, 8 sources, 489 macros
[0m08:58:30.925778 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '95aef471-a1ab-4741-85f9-f37185681e3b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe18e19ea10>]}
[0m08:58:30.928446 [info ] [MainThread]: 
[0m08:58:30.929709 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m08:58:30.931369 [info ] [MainThread]: 
[0m08:58:30.933240 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m08:58:30.935485 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m08:58:30.936430 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:58:31.603820 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_marts)
[0m08:58:31.604643 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_staging'
[0m08:58:31.605300 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_facts'
[0m08:58:31.605826 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:58:31.606599 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:58:31.607278 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:58:31.930392 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '95aef471-a1ab-4741-85f9-f37185681e3b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe18e027350>]}
[0m08:58:31.932586 [debug] [MainThread]: Opening a new connection, currently in state init
[0m08:58:31.939726 [debug] [Thread-1 (]: Began running node model.hailing_project.mart_cust_rides_daily
[0m08:58:31.941582 [info ] [Thread-1 (]: 1 of 1 START sql table model rizky_dwh_hailing_marts.mart_cust_rides_daily ..... [RUN]
[0m08:58:31.943404 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_staging, now model.hailing_project.mart_cust_rides_daily)
[0m08:58:31.944934 [debug] [Thread-1 (]: Began compiling node model.hailing_project.mart_cust_rides_daily
[0m08:58:31.955802 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.mart_cust_rides_daily"
[0m08:58:31.963054 [debug] [Thread-1 (]: Began executing node model.hailing_project.mart_cust_rides_daily
[0m08:58:32.008326 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.mart_cust_rides_daily"
[0m08:58:32.014599 [debug] [Thread-1 (]: On model.hailing_project.mart_cust_rides_daily: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.mart_cust_rides_daily"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_marts`.`mart_cust_rides_daily`
      
    partition by timestamp_trunc(ride_date, day)
    

    OPTIONS()
    as (
      


WITH fact_rides AS(

    SELECT * 
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
)

SELECT (

    fact_rides.cust_id,
    fact_rides.cust_name,
    fact_rides.cust_email,
    fact_rides.cust_phone_number,
    DATE(fact_rides.created_at) AS ride_date,
    COUNT(fact_rides.ride_id) AS no_of_rides,
    SUM(TIMESTAMP_DIFF(TIMESTAMP('fact_rides.end_time'), TIMESTAMP('fact_rides.start_time'), MINUTES) AS total_ride_duration_min,
    SUM(fact_rides.fare) AS total_fare,
    SUM(fact_rides.distance_km) as total_distance_km,
    fact_rides.total_distance_km-fact_rides.total_fare AS rev_opportunity_loss
    
FROM fact_rides

)
    );
  
[0m08:58:32.016675 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m08:58:32.547094 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:98b5e179-d8b5-4f0f-87d8-120e9a922775&page=queryresults
[0m08:58:32.548033 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:98b5e179-d8b5-4f0f-87d8-120e9a922775&page=queryresults
[0m08:58:32.552930 [debug] [Thread-1 (]: Database Error in model mart_cust_rides_daily (models/marts/mart_cust_rides_daily.sql)
  Syntax error: Expected ")" or "," but got keyword AS at [28:33]
  compiled code at target/run/hailing_project/models/marts/mart_cust_rides_daily.sql
[0m08:58:32.554678 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '95aef471-a1ab-4741-85f9-f37185681e3b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe18c6f1a50>]}
[0m08:58:32.556013 [error] [Thread-1 (]: 1 of 1 ERROR creating sql table model rizky_dwh_hailing_marts.mart_cust_rides_daily  [[31mERROR[0m in 0.61s]
[0m08:58:32.557107 [debug] [Thread-1 (]: Finished running node model.hailing_project.mart_cust_rides_daily
[0m08:58:32.558105 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.mart_cust_rides_daily' to be skipped because of status 'error'.  Reason: Database Error in model mart_cust_rides_daily (models/marts/mart_cust_rides_daily.sql)
  Syntax error: Expected ")" or "," but got keyword AS at [28:33]
  compiled code at target/run/hailing_project/models/marts/mart_cust_rides_daily.sql.
[0m08:58:32.560297 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m08:58:32.563493 [debug] [MainThread]: Connection 'master' was properly closed.
[0m08:58:32.564532 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_marts' was properly closed.
[0m08:58:32.565456 [debug] [MainThread]: Connection 'model.hailing_project.mart_cust_rides_daily' was properly closed.
[0m08:58:32.566403 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_facts' was properly closed.
[0m08:58:32.567463 [info ] [MainThread]: 
[0m08:58:32.568577 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 1.63 seconds (1.63s).
[0m08:58:32.570009 [debug] [MainThread]: Command end result
[0m08:58:32.605155 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m08:58:32.610543 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m08:58:32.620291 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m08:58:32.621160 [info ] [MainThread]: 
[0m08:58:32.622363 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m08:58:32.623627 [info ] [MainThread]: 
[0m08:58:32.624825 [error] [MainThread]:   Database Error in model mart_cust_rides_daily (models/marts/mart_cust_rides_daily.sql)
  Syntax error: Expected ")" or "," but got keyword AS at [28:33]
  compiled code at target/run/hailing_project/models/marts/mart_cust_rides_daily.sql
[0m08:58:32.626050 [info ] [MainThread]: 
[0m08:58:32.627757 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m08:58:32.630325 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 3.1032898, "process_in_blocks": "0", "process_kernel_time": 0.163113, "process_mem_max_rss": "217408", "process_out_blocks": "0", "process_user_time": 3.435587}
[0m08:58:32.631923 [debug] [MainThread]: Command `dbt run` failed at 08:58:32.631705 after 3.11 seconds
[0m08:58:32.633025 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1bc233f50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1bfb5d350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1bfb5d450>]}
[0m08:58:32.634153 [debug] [MainThread]: Flushing usage events
[0m08:58:33.720702 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m08:59:28.699326 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff1ee6eb090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff1ee743cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff1ee6ea850>]}


============================== 08:59:28.702370 | 9c12d656-7315-4714-b6f9-e12a6c495618 ==============================
[0m08:59:28.702370 [info ] [MainThread]: Running with dbt=1.9.0
[0m08:59:28.704818 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'version_check': 'True', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt run --select mart_cust_rides_daily', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m08:59:29.262063 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '9c12d656-7315-4714-b6f9-e12a6c495618', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff1c5a39d50>]}
[0m08:59:29.305304 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '9c12d656-7315-4714-b6f9-e12a6c495618', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff1ef47a510>]}
[0m08:59:29.306439 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m08:59:29.368849 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m08:59:29.557705 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m08:59:29.559099 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/marts/mart_cust_rides_daily.sql
[0m08:59:29.806811 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9c12d656-7315-4714-b6f9-e12a6c495618', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff1c4900ad0>]}
[0m08:59:29.873049 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m08:59:29.881893 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m08:59:29.897627 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9c12d656-7315-4714-b6f9-e12a6c495618', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff1bebc7490>]}
[0m08:59:29.898845 [info ] [MainThread]: Found 8 models, 8 sources, 489 macros
[0m08:59:29.901225 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9c12d656-7315-4714-b6f9-e12a6c495618', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff1c468db90>]}
[0m08:59:29.903619 [info ] [MainThread]: 
[0m08:59:29.904692 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m08:59:29.905742 [info ] [MainThread]: 
[0m08:59:29.907421 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m08:59:29.909400 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m08:59:29.910724 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:59:30.485878 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_marts)
[0m08:59:30.486525 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_facts'
[0m08:59:30.487078 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_staging'
[0m08:59:30.488462 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:59:30.490212 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:59:30.491556 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:59:30.820282 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9c12d656-7315-4714-b6f9-e12a6c495618', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff1c45f27d0>]}
[0m08:59:30.821725 [debug] [MainThread]: Opening a new connection, currently in state init
[0m08:59:30.826957 [debug] [Thread-1 (]: Began running node model.hailing_project.mart_cust_rides_daily
[0m08:59:30.827867 [info ] [Thread-1 (]: 1 of 1 START sql table model rizky_dwh_hailing_marts.mart_cust_rides_daily ..... [RUN]
[0m08:59:30.829368 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_marts, now model.hailing_project.mart_cust_rides_daily)
[0m08:59:30.830828 [debug] [Thread-1 (]: Began compiling node model.hailing_project.mart_cust_rides_daily
[0m08:59:30.839552 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.mart_cust_rides_daily"
[0m08:59:30.845923 [debug] [Thread-1 (]: Began executing node model.hailing_project.mart_cust_rides_daily
[0m08:59:30.885431 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.mart_cust_rides_daily"
[0m08:59:30.890592 [debug] [Thread-1 (]: On model.hailing_project.mart_cust_rides_daily: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.mart_cust_rides_daily"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_marts`.`mart_cust_rides_daily`
      
    partition by timestamp_trunc(ride_date, day)
    

    OPTIONS()
    as (
      


WITH fact_rides AS(

    SELECT * 
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
)

SELECT (

    fact_rides.cust_id,
    fact_rides.cust_name,
    fact_rides.cust_email,
    fact_rides.cust_phone_number,
    DATE(fact_rides.created_at) AS ride_date,
    COUNT(fact_rides.ride_id) AS no_of_rides,
    SUM(TIMESTAMP_DIFF(TIMESTAMP('fact_rides.end_time'), TIMESTAMP('fact_rides.start_time'), MINUTES)) AS total_ride_duration_min,
    SUM(fact_rides.fare) AS total_fare,
    SUM(fact_rides.distance_km) as total_distance_km,
    fact_rides.total_distance_km-fact_rides.total_fare AS rev_opportunity_loss
    
FROM fact_rides

)
    );
  
[0m08:59:30.891512 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m08:59:31.379740 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:ce3bef7c-4aa3-48fc-b02d-12bde51b142a&page=queryresults
[0m08:59:31.381022 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:ce3bef7c-4aa3-48fc-b02d-12bde51b142a&page=queryresults
[0m08:59:31.386178 [debug] [Thread-1 (]: Database Error in model mart_cust_rides_daily (models/marts/mart_cust_rides_daily.sql)
  Syntax error: Expected ")" or "," but got keyword AS at [28:33]
  compiled code at target/run/hailing_project/models/marts/mart_cust_rides_daily.sql
[0m08:59:31.388305 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9c12d656-7315-4714-b6f9-e12a6c495618', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff1c49f0b10>]}
[0m08:59:31.389651 [error] [Thread-1 (]: 1 of 1 ERROR creating sql table model rizky_dwh_hailing_marts.mart_cust_rides_daily  [[31mERROR[0m in 0.56s]
[0m08:59:31.391712 [debug] [Thread-1 (]: Finished running node model.hailing_project.mart_cust_rides_daily
[0m08:59:31.393164 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.mart_cust_rides_daily' to be skipped because of status 'error'.  Reason: Database Error in model mart_cust_rides_daily (models/marts/mart_cust_rides_daily.sql)
  Syntax error: Expected ")" or "," but got keyword AS at [28:33]
  compiled code at target/run/hailing_project/models/marts/mart_cust_rides_daily.sql.
[0m08:59:31.395819 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m08:59:31.398554 [debug] [MainThread]: Connection 'master' was properly closed.
[0m08:59:31.399258 [debug] [MainThread]: Connection 'model.hailing_project.mart_cust_rides_daily' was properly closed.
[0m08:59:31.400341 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_facts' was properly closed.
[0m08:59:31.401564 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_staging' was properly closed.
[0m08:59:31.402545 [info ] [MainThread]: 
[0m08:59:31.403806 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 1.50 seconds (1.50s).
[0m08:59:31.405329 [debug] [MainThread]: Command end result
[0m08:59:31.441269 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m08:59:31.445668 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m08:59:31.453913 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m08:59:31.455046 [info ] [MainThread]: 
[0m08:59:31.456206 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m08:59:31.457244 [info ] [MainThread]: 
[0m08:59:31.458332 [error] [MainThread]:   Database Error in model mart_cust_rides_daily (models/marts/mart_cust_rides_daily.sql)
  Syntax error: Expected ")" or "," but got keyword AS at [28:33]
  compiled code at target/run/hailing_project/models/marts/mart_cust_rides_daily.sql
[0m08:59:31.459495 [info ] [MainThread]: 
[0m08:59:31.460541 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m08:59:31.462279 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 2.8095517, "process_in_blocks": "0", "process_kernel_time": 0.307772, "process_mem_max_rss": "220492", "process_out_blocks": "0", "process_user_time": 3.139274}
[0m08:59:31.463497 [debug] [MainThread]: Command `dbt run` failed at 08:59:31.463321 after 2.81 seconds
[0m08:59:31.464763 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff1ee7462d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff1eeb9c350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff1f21ad890>]}
[0m08:59:31.466908 [debug] [MainThread]: Flushing usage events
[0m08:59:32.453612 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m09:00:18.356624 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe9b00df9d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe9b0137cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe9b00ddb10>]}


============================== 09:00:18.359139 | 6c9dab4d-9166-4ebd-b743-0907aed9379a ==============================
[0m09:00:18.359139 [info ] [MainThread]: Running with dbt=1.9.0
[0m09:00:18.360726 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt run --select mart_cust_rides_daily', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m09:00:18.904438 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '6c9dab4d-9166-4ebd-b743-0907aed9379a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe98227bbd0>]}
[0m09:00:18.950657 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '6c9dab4d-9166-4ebd-b743-0907aed9379a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe9b2338d50>]}
[0m09:00:18.951828 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m09:00:19.015225 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m09:00:19.195917 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m09:00:19.197320 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/marts/mart_cust_rides_daily.sql
[0m09:00:19.452743 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '6c9dab4d-9166-4ebd-b743-0907aed9379a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe982074050>]}
[0m09:00:19.527345 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m09:00:19.532666 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m09:00:19.547999 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '6c9dab4d-9166-4ebd-b743-0907aed9379a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe9805ac510>]}
[0m09:00:19.549158 [info ] [MainThread]: Found 8 models, 8 sources, 489 macros
[0m09:00:19.550500 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6c9dab4d-9166-4ebd-b743-0907aed9379a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe980563010>]}
[0m09:00:19.552681 [info ] [MainThread]: 
[0m09:00:19.554134 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m09:00:19.555358 [info ] [MainThread]: 
[0m09:00:19.556796 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m09:00:19.558932 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m09:00:19.559849 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:00:20.117289 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_staging)
[0m09:00:20.117938 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_marts'
[0m09:00:20.118504 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_facts'
[0m09:00:20.119457 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m09:00:20.121628 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:00:20.122839 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:00:20.413866 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6c9dab4d-9166-4ebd-b743-0907aed9379a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe982322b50>]}
[0m09:00:20.415614 [debug] [MainThread]: Opening a new connection, currently in state init
[0m09:00:20.421388 [debug] [Thread-1 (]: Began running node model.hailing_project.mart_cust_rides_daily
[0m09:00:20.423012 [info ] [Thread-1 (]: 1 of 1 START sql table model rizky_dwh_hailing_marts.mart_cust_rides_daily ..... [RUN]
[0m09:00:20.424941 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_facts, now model.hailing_project.mart_cust_rides_daily)
[0m09:00:20.425784 [debug] [Thread-1 (]: Began compiling node model.hailing_project.mart_cust_rides_daily
[0m09:00:20.433451 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.mart_cust_rides_daily"
[0m09:00:20.440931 [debug] [Thread-1 (]: Began executing node model.hailing_project.mart_cust_rides_daily
[0m09:00:20.485647 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.mart_cust_rides_daily"
[0m09:00:20.492958 [debug] [Thread-1 (]: On model.hailing_project.mart_cust_rides_daily: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.mart_cust_rides_daily"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_marts`.`mart_cust_rides_daily`
      
    partition by timestamp_trunc(ride_date, day)
    

    OPTIONS()
    as (
      


WITH fact_rides AS(

    SELECT * 
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
),

SELECT (

    fact_rides.cust_id,
    fact_rides.cust_name,
    fact_rides.cust_email,
    fact_rides.cust_phone_number,
    DATE(fact_rides.created_at) AS ride_date,
    COUNT(fact_rides.ride_id) AS no_of_rides,
    SUM(TIMESTAMP_DIFF(TIMESTAMP('fact_rides.end_time'), TIMESTAMP('fact_rides.start_time'), MINUTES)) AS total_ride_duration_min,
    SUM(fact_rides.fare) AS total_fare,
    SUM(fact_rides.distance_km) as total_distance_km,
    fact_rides.total_distance_km-fact_rides.total_fare AS rev_opportunity_loss
    
FROM fact_rides

)
    );
  
[0m09:00:20.494112 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m09:00:21.030305 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:b70f3bb3-f431-4f4b-b816-e5bf596ffcec&page=queryresults
[0m09:00:21.031492 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:b70f3bb3-f431-4f4b-b816-e5bf596ffcec&page=queryresults
[0m09:00:21.036595 [debug] [Thread-1 (]: Database Error in model mart_cust_rides_daily (models/marts/mart_cust_rides_daily.sql)
  Syntax error: Trailing comma after the WITH clause before the main query is not allowed at [22:1]
  compiled code at target/run/hailing_project/models/marts/mart_cust_rides_daily.sql
[0m09:00:21.038979 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6c9dab4d-9166-4ebd-b743-0907aed9379a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe9822dc410>]}
[0m09:00:21.040481 [error] [Thread-1 (]: 1 of 1 ERROR creating sql table model rizky_dwh_hailing_marts.mart_cust_rides_daily  [[31mERROR[0m in 0.61s]
[0m09:00:21.041917 [debug] [Thread-1 (]: Finished running node model.hailing_project.mart_cust_rides_daily
[0m09:00:21.042999 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.mart_cust_rides_daily' to be skipped because of status 'error'.  Reason: Database Error in model mart_cust_rides_daily (models/marts/mart_cust_rides_daily.sql)
  Syntax error: Trailing comma after the WITH clause before the main query is not allowed at [22:1]
  compiled code at target/run/hailing_project/models/marts/mart_cust_rides_daily.sql.
[0m09:00:21.045191 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m09:00:21.048489 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:00:21.049097 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_staging' was properly closed.
[0m09:00:21.049779 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_marts' was properly closed.
[0m09:00:21.050560 [debug] [MainThread]: Connection 'model.hailing_project.mart_cust_rides_daily' was properly closed.
[0m09:00:21.051367 [info ] [MainThread]: 
[0m09:00:21.052321 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 1.49 seconds (1.49s).
[0m09:00:21.053667 [debug] [MainThread]: Command end result
[0m09:00:21.090838 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m09:00:21.094712 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m09:00:21.102840 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m09:00:21.103514 [info ] [MainThread]: 
[0m09:00:21.104821 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m09:00:21.105949 [info ] [MainThread]: 
[0m09:00:21.107235 [error] [MainThread]:   Database Error in model mart_cust_rides_daily (models/marts/mart_cust_rides_daily.sql)
  Syntax error: Trailing comma after the WITH clause before the main query is not allowed at [22:1]
  compiled code at target/run/hailing_project/models/marts/mart_cust_rides_daily.sql
[0m09:00:21.108662 [info ] [MainThread]: 
[0m09:00:21.109756 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m09:00:21.111470 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 2.8051348, "process_in_blocks": "0", "process_kernel_time": 0.183697, "process_mem_max_rss": "217488", "process_out_blocks": "0", "process_user_time": 3.275947}
[0m09:00:21.112481 [debug] [MainThread]: Command `dbt run` failed at 09:00:21.112356 after 2.81 seconds
[0m09:00:21.113293 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe9aff5f9d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe9aff5f690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe9aff5fb90>]}
[0m09:00:21.114069 [debug] [MainThread]: Flushing usage events
[0m09:00:22.353214 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m09:02:13.649966 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdc8fc3b850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdc8fc3ab90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdc8fc3bad0>]}


============================== 09:02:13.652616 | ee771080-7b00-45bb-b3ee-13f304823129 ==============================
[0m09:02:13.652616 [info ] [MainThread]: Running with dbt=1.9.0
[0m09:02:13.655506 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run --select mart_cust_rides_daily', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m09:02:14.220109 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ee771080-7b00-45bb-b3ee-13f304823129', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdc61fd04d0>]}
[0m09:02:14.264308 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ee771080-7b00-45bb-b3ee-13f304823129', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdc61e83590>]}
[0m09:02:14.266083 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m09:02:14.329903 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m09:02:14.522551 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m09:02:14.523978 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/marts/mart_cust_rides_daily.sql
[0m09:02:14.771624 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ee771080-7b00-45bb-b3ee-13f304823129', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdc61dfed90>]}
[0m09:02:14.840998 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m09:02:14.847419 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m09:02:14.862721 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ee771080-7b00-45bb-b3ee-13f304823129', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdc60147e90>]}
[0m09:02:14.863951 [info ] [MainThread]: Found 8 models, 8 sources, 489 macros
[0m09:02:14.865494 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ee771080-7b00-45bb-b3ee-13f304823129', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdc61dc0690>]}
[0m09:02:14.867780 [info ] [MainThread]: 
[0m09:02:14.868977 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m09:02:14.870057 [info ] [MainThread]: 
[0m09:02:14.871325 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m09:02:14.873572 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m09:02:14.874597 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:02:15.416472 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_facts)
[0m09:02:15.417154 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_marts'
[0m09:02:15.417741 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_staging'
[0m09:02:15.418649 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m09:02:15.419500 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:02:15.420565 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:02:15.763253 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ee771080-7b00-45bb-b3ee-13f304823129', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdc61e5ba10>]}
[0m09:02:15.764507 [debug] [MainThread]: Opening a new connection, currently in state init
[0m09:02:15.769321 [debug] [Thread-1 (]: Began running node model.hailing_project.mart_cust_rides_daily
[0m09:02:15.770176 [info ] [Thread-1 (]: 1 of 1 START sql table model rizky_dwh_hailing_marts.mart_cust_rides_daily ..... [RUN]
[0m09:02:15.771392 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_marts, now model.hailing_project.mart_cust_rides_daily)
[0m09:02:15.772339 [debug] [Thread-1 (]: Began compiling node model.hailing_project.mart_cust_rides_daily
[0m09:02:15.779595 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.mart_cust_rides_daily"
[0m09:02:15.784855 [debug] [Thread-1 (]: Began executing node model.hailing_project.mart_cust_rides_daily
[0m09:02:15.824223 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.mart_cust_rides_daily"
[0m09:02:15.829623 [debug] [Thread-1 (]: On model.hailing_project.mart_cust_rides_daily: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.mart_cust_rides_daily"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_marts`.`mart_cust_rides_daily`
      
    partition by timestamp_trunc(ride_date, day)
    

    OPTIONS()
    as (
      


WITH fact_rides AS(

    SELECT * 
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
)

SELECT 

    fact_rides.cust_id,
    fact_rides.cust_name,
    fact_rides.cust_email,
    fact_rides.cust_phone_number,
    DATE(fact_rides.created_at) AS ride_date,
    COUNT(fact_rides.ride_id) AS no_of_rides,
    SUM(TIMESTAMP_DIFF(TIMESTAMP('fact_rides.end_time'), TIMESTAMP('fact_rides.start_time'), MINUTES)) AS total_ride_duration_min,
    SUM(fact_rides.fare) AS total_fare,
    SUM(fact_rides.distance_km) as total_distance_km,
    fact_rides.total_distance_km-fact_rides.total_fare AS rev_opportunity_loss
    
FROM fact_rides
    );
  
[0m09:02:15.830777 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m09:02:16.357605 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:d0c2708f-46e4-483a-9bd4-eac1455c0fcf&page=queryresults
[0m09:02:16.453089 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:d0c2708f-46e4-483a-9bd4-eac1455c0fcf&page=queryresults
[0m09:02:16.468848 [debug] [Thread-1 (]: Database Error in model mart_cust_rides_daily (models/marts/mart_cust_rides_daily.sql)
  A valid date part name is required but found MINUTES at [30:94]
  compiled code at target/run/hailing_project/models/marts/mart_cust_rides_daily.sql
[0m09:02:16.472330 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ee771080-7b00-45bb-b3ee-13f304823129', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdc60147c10>]}
[0m09:02:16.473744 [error] [Thread-1 (]: 1 of 1 ERROR creating sql table model rizky_dwh_hailing_marts.mart_cust_rides_daily  [[31mERROR[0m in 0.70s]
[0m09:02:16.475250 [debug] [Thread-1 (]: Finished running node model.hailing_project.mart_cust_rides_daily
[0m09:02:16.476937 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.mart_cust_rides_daily' to be skipped because of status 'error'.  Reason: Database Error in model mart_cust_rides_daily (models/marts/mart_cust_rides_daily.sql)
  A valid date part name is required but found MINUTES at [30:94]
  compiled code at target/run/hailing_project/models/marts/mart_cust_rides_daily.sql.
[0m09:02:16.479262 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m09:02:16.482233 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:02:16.483373 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_facts' was properly closed.
[0m09:02:16.484105 [debug] [MainThread]: Connection 'model.hailing_project.mart_cust_rides_daily' was properly closed.
[0m09:02:16.484792 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_staging' was properly closed.
[0m09:02:16.485514 [info ] [MainThread]: 
[0m09:02:16.486272 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 1.61 seconds (1.61s).
[0m09:02:16.487713 [debug] [MainThread]: Command end result
[0m09:02:16.520122 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m09:02:16.524807 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m09:02:16.532501 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m09:02:16.533306 [info ] [MainThread]: 
[0m09:02:16.534528 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m09:02:16.535498 [info ] [MainThread]: 
[0m09:02:16.536529 [error] [MainThread]:   Database Error in model mart_cust_rides_daily (models/marts/mart_cust_rides_daily.sql)
  A valid date part name is required but found MINUTES at [30:94]
  compiled code at target/run/hailing_project/models/marts/mart_cust_rides_daily.sql
[0m09:02:16.537467 [info ] [MainThread]: 
[0m09:02:16.538722 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m09:02:16.540758 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 2.9364827, "process_in_blocks": "0", "process_kernel_time": 0.144166, "process_mem_max_rss": "220100", "process_out_blocks": "0", "process_user_time": 3.326126}
[0m09:02:16.542421 [debug] [MainThread]: Command `dbt run` failed at 09:02:16.542159 after 2.94 seconds
[0m09:02:16.544238 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdc61e6df90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdc935f1210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdc61b60a50>]}
[0m09:02:16.545428 [debug] [MainThread]: Flushing usage events
[0m09:02:17.609328 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m09:02:59.909602 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbd1baafa50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbd1bb07cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbd1c797590>]}


============================== 09:02:59.912225 | 455d3bf7-4991-4287-a790-f8f26a1e552c ==============================
[0m09:02:59.912225 [info ] [MainThread]: Running with dbt=1.9.0
[0m09:02:59.914172 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --select mart_cust_rides_daily', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m09:03:00.470835 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '455d3bf7-4991-4287-a790-f8f26a1e552c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbcedc7ee90>]}
[0m09:03:00.519410 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '455d3bf7-4991-4287-a790-f8f26a1e552c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbd1dd36390>]}
[0m09:03:00.520689 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m09:03:00.587506 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m09:03:00.773740 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m09:03:00.774880 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/marts/mart_cust_rides_daily.sql
[0m09:03:01.021366 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '455d3bf7-4991-4287-a790-f8f26a1e552c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbcede313d0>]}
[0m09:03:01.091010 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m09:03:01.096737 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m09:03:01.110798 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '455d3bf7-4991-4287-a790-f8f26a1e552c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbcbff9f590>]}
[0m09:03:01.111900 [info ] [MainThread]: Found 8 models, 8 sources, 489 macros
[0m09:03:01.113147 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '455d3bf7-4991-4287-a790-f8f26a1e552c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbced940650>]}
[0m09:03:01.115570 [info ] [MainThread]: 
[0m09:03:01.116916 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m09:03:01.117934 [info ] [MainThread]: 
[0m09:03:01.119278 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m09:03:01.120934 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m09:03:01.122011 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:03:01.727672 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_facts)
[0m09:03:01.728306 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_marts'
[0m09:03:01.728800 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_staging'
[0m09:03:01.729481 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m09:03:01.730649 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:03:01.731669 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:03:02.014443 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '455d3bf7-4991-4287-a790-f8f26a1e552c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbd1c87b5d0>]}
[0m09:03:02.015357 [debug] [MainThread]: Opening a new connection, currently in state init
[0m09:03:02.019797 [debug] [Thread-1 (]: Began running node model.hailing_project.mart_cust_rides_daily
[0m09:03:02.020847 [info ] [Thread-1 (]: 1 of 1 START sql table model rizky_dwh_hailing_marts.mart_cust_rides_daily ..... [RUN]
[0m09:03:02.022321 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_staging, now model.hailing_project.mart_cust_rides_daily)
[0m09:03:02.023092 [debug] [Thread-1 (]: Began compiling node model.hailing_project.mart_cust_rides_daily
[0m09:03:02.030709 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.mart_cust_rides_daily"
[0m09:03:02.037338 [debug] [Thread-1 (]: Began executing node model.hailing_project.mart_cust_rides_daily
[0m09:03:02.076912 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.mart_cust_rides_daily"
[0m09:03:02.082522 [debug] [Thread-1 (]: On model.hailing_project.mart_cust_rides_daily: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.mart_cust_rides_daily"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_marts`.`mart_cust_rides_daily`
      
    partition by timestamp_trunc(ride_date, day)
    

    OPTIONS()
    as (
      


WITH fact_rides AS(

    SELECT * 
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
)

SELECT 

    fact_rides.cust_id,
    fact_rides.cust_name,
    fact_rides.cust_email,
    fact_rides.cust_phone_number,
    DATE(fact_rides.created_at) AS ride_date,
    COUNT(fact_rides.ride_id) AS no_of_rides,
    SUM(TIMESTAMP_DIFF(TIMESTAMP('fact_rides.ride_end_time'), TIMESTAMP('fact_rides.ride_start_time'), MINUTES)) AS total_ride_duration_min,
    SUM(fact_rides.fare) AS total_fare,
    SUM(fact_rides.distance_km) as total_distance_km,
    fact_rides.total_distance_km-fact_rides.total_fare AS rev_opportunity_loss
    
FROM fact_rides
    );
  
[0m09:03:02.083499 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m09:03:02.503603 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:b29b31c0-6b21-4e2d-b23a-90850d989754&page=queryresults
[0m09:03:02.576416 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:b29b31c0-6b21-4e2d-b23a-90850d989754&page=queryresults
[0m09:03:02.581297 [debug] [Thread-1 (]: Database Error in model mart_cust_rides_daily (models/marts/mart_cust_rides_daily.sql)
  A valid date part name is required but found MINUTES at [30:104]
  compiled code at target/run/hailing_project/models/marts/mart_cust_rides_daily.sql
[0m09:03:02.583251 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '455d3bf7-4991-4287-a790-f8f26a1e552c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbcedd6f750>]}
[0m09:03:02.584441 [error] [Thread-1 (]: 1 of 1 ERROR creating sql table model rizky_dwh_hailing_marts.mart_cust_rides_daily  [[31mERROR[0m in 0.56s]
[0m09:03:02.585674 [debug] [Thread-1 (]: Finished running node model.hailing_project.mart_cust_rides_daily
[0m09:03:02.587003 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.mart_cust_rides_daily' to be skipped because of status 'error'.  Reason: Database Error in model mart_cust_rides_daily (models/marts/mart_cust_rides_daily.sql)
  A valid date part name is required but found MINUTES at [30:104]
  compiled code at target/run/hailing_project/models/marts/mart_cust_rides_daily.sql.
[0m09:03:02.590252 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m09:03:02.594328 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:03:02.595139 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_facts' was properly closed.
[0m09:03:02.595912 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_marts' was properly closed.
[0m09:03:02.596600 [debug] [MainThread]: Connection 'model.hailing_project.mart_cust_rides_daily' was properly closed.
[0m09:03:02.597224 [info ] [MainThread]: 
[0m09:03:02.598249 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 1.48 seconds (1.48s).
[0m09:03:02.599583 [debug] [MainThread]: Command end result
[0m09:03:02.635234 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m09:03:02.640321 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m09:03:02.648048 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m09:03:02.648819 [info ] [MainThread]: 
[0m09:03:02.649821 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m09:03:02.650749 [info ] [MainThread]: 
[0m09:03:02.651993 [error] [MainThread]:   Database Error in model mart_cust_rides_daily (models/marts/mart_cust_rides_daily.sql)
  A valid date part name is required but found MINUTES at [30:104]
  compiled code at target/run/hailing_project/models/marts/mart_cust_rides_daily.sql
[0m09:03:02.653207 [info ] [MainThread]: 
[0m09:03:02.654175 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m09:03:02.656094 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 2.7936306, "process_in_blocks": "0", "process_kernel_time": 0.209759, "process_mem_max_rss": "217424", "process_out_blocks": "0", "process_user_time": 3.256266}
[0m09:03:02.657369 [debug] [MainThread]: Command `dbt run` failed at 09:03:02.657158 after 2.80 seconds
[0m09:03:02.658238 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbd1bb08dd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbd1f5a1890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbd1bac56d0>]}
[0m09:03:02.659128 [debug] [MainThread]: Flushing usage events
[0m09:03:03.879757 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m09:04:43.857188 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7febf0abbfd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7febf0abb950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7febf0abb550>]}


============================== 09:04:43.859688 | 5331e2a1-04ba-429b-844f-e186022123df ==============================
[0m09:04:43.859688 [info ] [MainThread]: Running with dbt=1.9.0
[0m09:04:43.863360 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'log_format': 'default', 'invocation_command': 'dbt run --select mart_cust_rides_daily', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m09:04:44.435512 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5331e2a1-04ba-429b-844f-e186022123df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7febc33f3750>]}
[0m09:04:44.485262 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '5331e2a1-04ba-429b-844f-e186022123df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7febf0aaa550>]}
[0m09:04:44.486511 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m09:04:44.555426 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m09:04:44.743057 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m09:04:44.744390 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/marts/mart_cust_rides_daily.sql
[0m09:04:44.990601 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5331e2a1-04ba-429b-844f-e186022123df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7febc825ee90>]}
[0m09:04:45.063321 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m09:04:45.070003 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m09:04:45.084651 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5331e2a1-04ba-429b-844f-e186022123df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7febc0f67e90>]}
[0m09:04:45.085813 [info ] [MainThread]: Found 8 models, 8 sources, 489 macros
[0m09:04:45.086847 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5331e2a1-04ba-429b-844f-e186022123df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7febc285f1d0>]}
[0m09:04:45.088993 [info ] [MainThread]: 
[0m09:04:45.090020 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m09:04:45.091392 [info ] [MainThread]: 
[0m09:04:45.092903 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m09:04:45.094882 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m09:04:45.095980 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:04:45.717453 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_marts)
[0m09:04:45.718851 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_facts'
[0m09:04:45.719670 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_staging'
[0m09:04:45.720022 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m09:04:45.721119 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:04:45.722911 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:04:46.012452 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5331e2a1-04ba-429b-844f-e186022123df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7febf0a630d0>]}
[0m09:04:46.013648 [debug] [MainThread]: Opening a new connection, currently in state init
[0m09:04:46.018599 [debug] [Thread-1 (]: Began running node model.hailing_project.mart_cust_rides_daily
[0m09:04:46.019515 [info ] [Thread-1 (]: 1 of 1 START sql table model rizky_dwh_hailing_marts.mart_cust_rides_daily ..... [RUN]
[0m09:04:46.020482 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_facts, now model.hailing_project.mart_cust_rides_daily)
[0m09:04:46.021313 [debug] [Thread-1 (]: Began compiling node model.hailing_project.mart_cust_rides_daily
[0m09:04:46.029134 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.mart_cust_rides_daily"
[0m09:04:46.034734 [debug] [Thread-1 (]: Began executing node model.hailing_project.mart_cust_rides_daily
[0m09:04:46.073790 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.mart_cust_rides_daily"
[0m09:04:46.080222 [debug] [Thread-1 (]: On model.hailing_project.mart_cust_rides_daily: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.mart_cust_rides_daily"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_marts`.`mart_cust_rides_daily`
      
    partition by timestamp_trunc(ride_date, day)
    

    OPTIONS()
    as (
      


WITH fact_rides AS(

    SELECT * 
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
)

SELECT 

    fact_rides.cust_id,
    fact_rides.cust_name,
    fact_rides.cust_email,
    fact_rides.cust_phone_number,
    DATE(fact_rides.created_at) AS ride_date,
    COUNT(fact_rides.ride_id) AS no_of_rides,
    SUM(TIMESTAMP_DIFF(fact_rides.ride_end_time, fact_rides.ride_start_time, MINUTES)) AS total_ride_duration_min,
    SUM(fact_rides.fare) AS total_fare,
    SUM(fact_rides.distance_km) as total_distance_km,
    fact_rides.total_distance_km-fact_rides.total_fare AS rev_opportunity_loss
    
FROM fact_rides
    );
  
[0m09:04:46.081354 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m09:04:46.547513 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:d3f0dd0f-b2f0-461b-8a26-d7a641718fae&page=queryresults
[0m09:04:46.669839 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:d3f0dd0f-b2f0-461b-8a26-d7a641718fae&page=queryresults
[0m09:04:46.674456 [debug] [Thread-1 (]: Database Error in model mart_cust_rides_daily (models/marts/mart_cust_rides_daily.sql)
  A valid date part name is required but found MINUTES at [30:78]
  compiled code at target/run/hailing_project/models/marts/mart_cust_rides_daily.sql
[0m09:04:46.676080 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5331e2a1-04ba-429b-844f-e186022123df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7febc0f70510>]}
[0m09:04:46.677214 [error] [Thread-1 (]: 1 of 1 ERROR creating sql table model rizky_dwh_hailing_marts.mart_cust_rides_daily  [[31mERROR[0m in 0.65s]
[0m09:04:46.678418 [debug] [Thread-1 (]: Finished running node model.hailing_project.mart_cust_rides_daily
[0m09:04:46.679696 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.mart_cust_rides_daily' to be skipped because of status 'error'.  Reason: Database Error in model mart_cust_rides_daily (models/marts/mart_cust_rides_daily.sql)
  A valid date part name is required but found MINUTES at [30:78]
  compiled code at target/run/hailing_project/models/marts/mart_cust_rides_daily.sql.
[0m09:04:46.682262 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m09:04:46.685164 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:04:46.685952 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_marts' was properly closed.
[0m09:04:46.687039 [debug] [MainThread]: Connection 'model.hailing_project.mart_cust_rides_daily' was properly closed.
[0m09:04:46.688405 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_staging' was properly closed.
[0m09:04:46.689855 [info ] [MainThread]: 
[0m09:04:46.690926 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 1.60 seconds (1.60s).
[0m09:04:46.692500 [debug] [MainThread]: Command end result
[0m09:04:46.728173 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m09:04:46.732979 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m09:04:46.741041 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m09:04:46.741993 [info ] [MainThread]: 
[0m09:04:46.743033 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m09:04:46.744015 [info ] [MainThread]: 
[0m09:04:46.744949 [error] [MainThread]:   Database Error in model mart_cust_rides_daily (models/marts/mart_cust_rides_daily.sql)
  A valid date part name is required but found MINUTES at [30:78]
  compiled code at target/run/hailing_project/models/marts/mart_cust_rides_daily.sql
[0m09:04:46.746027 [info ] [MainThread]: 
[0m09:04:46.747017 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m09:04:46.748532 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 2.9386985, "process_in_blocks": "0", "process_kernel_time": 0.194374, "process_mem_max_rss": "217328", "process_out_blocks": "0", "process_user_time": 3.324833}
[0m09:04:46.749657 [debug] [MainThread]: Command `dbt run` failed at 09:04:46.749541 after 2.94 seconds
[0m09:04:46.750578 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7febf0add1d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7febf0adf590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7febc965be50>]}
[0m09:04:46.751373 [debug] [MainThread]: Flushing usage events
[0m09:04:48.022052 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m09:05:09.943525 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f10054d2950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f10054d37d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f10054d3750>]}


============================== 09:05:09.946760 | afed5b1c-2008-4702-8400-a2d33683b914 ==============================
[0m09:05:09.946760 [info ] [MainThread]: Running with dbt=1.9.0
[0m09:05:09.949319 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt run --select mart_cust_rides_daily', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m09:05:10.530911 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'afed5b1c-2008-4702-8400-a2d33683b914', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0fd77eea10>]}
[0m09:05:10.577301 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'afed5b1c-2008-4702-8400-a2d33683b914', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f100774e490>]}
[0m09:05:10.578323 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m09:05:10.642029 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m09:05:10.829867 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m09:05:10.830931 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/marts/mart_cust_rides_daily.sql
[0m09:05:11.072794 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'afed5b1c-2008-4702-8400-a2d33683b914', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0fd75f2690>]}
[0m09:05:11.142240 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m09:05:11.147681 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m09:05:11.164048 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'afed5b1c-2008-4702-8400-a2d33683b914', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0fd5908450>]}
[0m09:05:11.165196 [info ] [MainThread]: Found 8 models, 8 sources, 489 macros
[0m09:05:11.166580 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'afed5b1c-2008-4702-8400-a2d33683b914', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0fd75e1ad0>]}
[0m09:05:11.168904 [info ] [MainThread]: 
[0m09:05:11.170350 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m09:05:11.171532 [info ] [MainThread]: 
[0m09:05:11.172924 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m09:05:11.174652 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m09:05:11.175779 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:05:11.679360 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_staging)
[0m09:05:11.680037 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_marts'
[0m09:05:11.680666 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_facts'
[0m09:05:11.681603 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m09:05:11.682458 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:05:11.683667 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:05:11.945476 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'afed5b1c-2008-4702-8400-a2d33683b914', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0fd77154d0>]}
[0m09:05:11.946747 [debug] [MainThread]: Opening a new connection, currently in state init
[0m09:05:11.952640 [debug] [Thread-1 (]: Began running node model.hailing_project.mart_cust_rides_daily
[0m09:05:11.954762 [info ] [Thread-1 (]: 1 of 1 START sql table model rizky_dwh_hailing_marts.mart_cust_rides_daily ..... [RUN]
[0m09:05:11.957082 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_facts, now model.hailing_project.mart_cust_rides_daily)
[0m09:05:11.958432 [debug] [Thread-1 (]: Began compiling node model.hailing_project.mart_cust_rides_daily
[0m09:05:11.966897 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.mart_cust_rides_daily"
[0m09:05:11.974917 [debug] [Thread-1 (]: Began executing node model.hailing_project.mart_cust_rides_daily
[0m09:05:12.021698 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.mart_cust_rides_daily"
[0m09:05:12.030390 [debug] [Thread-1 (]: On model.hailing_project.mart_cust_rides_daily: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.mart_cust_rides_daily"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_marts`.`mart_cust_rides_daily`
      
    partition by timestamp_trunc(ride_date, day)
    

    OPTIONS()
    as (
      


WITH fact_rides AS(

    SELECT * 
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
)

SELECT 

    fact_rides.cust_id,
    fact_rides.cust_name,
    fact_rides.cust_email,
    fact_rides.cust_phone_number,
    DATE(fact_rides.created_at) AS ride_date,
    COUNT(fact_rides.ride_id) AS no_of_rides,
    SUM(TIMESTAMP_DIFF(fact_rides.ride_end_time, fact_rides.ride_start_time, MINUTE)) AS total_ride_duration_min,
    SUM(fact_rides.fare) AS total_fare,
    SUM(fact_rides.distance_km) as total_distance_km,
    fact_rides.total_distance_km-fact_rides.total_fare AS rev_opportunity_loss
    
FROM fact_rides
    );
  
[0m09:05:12.031701 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m09:05:12.530956 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:20f68bd4-b397-4338-84d2-db1a572c17a6&page=queryresults
[0m09:05:12.648755 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:20f68bd4-b397-4338-84d2-db1a572c17a6&page=queryresults
[0m09:05:12.655629 [debug] [Thread-1 (]: Database Error in model mart_cust_rides_daily (models/marts/mart_cust_rides_daily.sql)
  Name total_distance_km not found inside fact_rides at [33:16]
  compiled code at target/run/hailing_project/models/marts/mart_cust_rides_daily.sql
[0m09:05:12.657519 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'afed5b1c-2008-4702-8400-a2d33683b914', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0fd7649910>]}
[0m09:05:12.658760 [error] [Thread-1 (]: 1 of 1 ERROR creating sql table model rizky_dwh_hailing_marts.mart_cust_rides_daily  [[31mERROR[0m in 0.70s]
[0m09:05:12.660169 [debug] [Thread-1 (]: Finished running node model.hailing_project.mart_cust_rides_daily
[0m09:05:12.661754 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.mart_cust_rides_daily' to be skipped because of status 'error'.  Reason: Database Error in model mart_cust_rides_daily (models/marts/mart_cust_rides_daily.sql)
  Name total_distance_km not found inside fact_rides at [33:16]
  compiled code at target/run/hailing_project/models/marts/mart_cust_rides_daily.sql.
[0m09:05:12.664351 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m09:05:12.667227 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:05:12.667931 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_staging' was properly closed.
[0m09:05:12.668957 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_marts' was properly closed.
[0m09:05:12.670164 [debug] [MainThread]: Connection 'model.hailing_project.mart_cust_rides_daily' was properly closed.
[0m09:05:12.671498 [info ] [MainThread]: 
[0m09:05:12.672842 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 1.50 seconds (1.50s).
[0m09:05:12.674796 [debug] [MainThread]: Command end result
[0m09:05:12.708335 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m09:05:12.713256 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m09:05:12.720708 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m09:05:12.721495 [info ] [MainThread]: 
[0m09:05:12.722591 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m09:05:12.723795 [info ] [MainThread]: 
[0m09:05:12.724971 [error] [MainThread]:   Database Error in model mart_cust_rides_daily (models/marts/mart_cust_rides_daily.sql)
  Name total_distance_km not found inside fact_rides at [33:16]
  compiled code at target/run/hailing_project/models/marts/mart_cust_rides_daily.sql
[0m09:05:12.725940 [info ] [MainThread]: 
[0m09:05:12.726933 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m09:05:12.728844 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 2.8322031, "process_in_blocks": "0", "process_kernel_time": 0.222608, "process_mem_max_rss": "220576", "process_out_blocks": "0", "process_user_time": 3.308778}
[0m09:05:12.730023 [debug] [MainThread]: Command `dbt run` failed at 09:05:12.729881 after 2.83 seconds
[0m09:05:12.731396 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1008e4d310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1008e4d590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1008e4d1d0>]}
[0m09:05:12.732274 [debug] [MainThread]: Flushing usage events
[0m09:05:13.937232 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m09:07:17.337451 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f807734bb10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8077742350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f807734b690>]}


============================== 09:07:17.339863 | d6f70a92-dd04-43c3-b08e-052bba939595 ==============================
[0m09:07:17.339863 [info ] [MainThread]: Running with dbt=1.9.0
[0m09:07:17.341567 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'warn_error': 'None', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --select mart_cust_daily_rides', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m09:07:17.901902 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd6f70a92-dd04-43c3-b08e-052bba939595', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f804d5d3cd0>]}
[0m09:07:17.948698 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd6f70a92-dd04-43c3-b08e-052bba939595', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f804d663f10>]}
[0m09:07:17.949941 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m09:07:18.013260 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m09:07:18.203582 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m09:07:18.204660 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/marts/mart_cust_rides_daily.sql
[0m09:07:18.445028 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd6f70a92-dd04-43c3-b08e-052bba939595', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f804d796510>]}
[0m09:07:18.518716 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m09:07:18.524744 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m09:07:18.541719 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd6f70a92-dd04-43c3-b08e-052bba939595', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f802f774490>]}
[0m09:07:18.542699 [info ] [MainThread]: Found 8 models, 8 sources, 489 macros
[0m09:07:18.543631 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd6f70a92-dd04-43c3-b08e-052bba939595', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f802f766050>]}
[0m09:07:18.544946 [warn ] [MainThread]: The selection criterion 'mart_cust_daily_rides' does not match any enabled nodes
[0m09:07:18.546845 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m09:07:18.548269 [debug] [MainThread]: Command end result
[0m09:07:18.581382 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m09:07:18.586972 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m09:07:18.593838 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m09:07:18.595465 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 1.3056635, "process_in_blocks": "0", "process_kernel_time": 0.248854, "process_mem_max_rss": "216396", "process_out_blocks": "0", "process_user_time": 2.946441}
[0m09:07:18.596614 [debug] [MainThread]: Command `dbt run` succeeded at 09:07:18.596482 after 1.31 seconds
[0m09:07:18.597485 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f80777fc350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f80771cd450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f804d355610>]}
[0m09:07:18.598313 [debug] [MainThread]: Flushing usage events
[0m09:07:19.860964 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m09:07:41.570864 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f224e57ed90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f224e5d3f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f224e5d3f50>]}


============================== 09:07:41.573573 | 2c201564-cdd3-4086-93c7-81f2db3bd79e ==============================
[0m09:07:41.573573 [info ] [MainThread]: Running with dbt=1.9.0
[0m09:07:41.575840 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --select mart_cust_rides_daily', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m09:07:42.150658 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '2c201564-cdd3-4086-93c7-81f2db3bd79e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f222474fad0>]}
[0m09:07:42.198510 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '2c201564-cdd3-4086-93c7-81f2db3bd79e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f22507fa4d0>]}
[0m09:07:42.199532 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m09:07:42.264634 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m09:07:42.460754 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m09:07:42.461787 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m09:07:42.494966 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2c201564-cdd3-4086-93c7-81f2db3bd79e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f222441e9d0>]}
[0m09:07:42.615667 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m09:07:42.623431 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m09:07:42.637649 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2c201564-cdd3-4086-93c7-81f2db3bd79e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f22245c1510>]}
[0m09:07:42.639114 [info ] [MainThread]: Found 8 models, 8 sources, 489 macros
[0m09:07:42.640251 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2c201564-cdd3-4086-93c7-81f2db3bd79e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2225965290>]}
[0m09:07:42.643045 [info ] [MainThread]: 
[0m09:07:42.644119 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m09:07:42.645254 [info ] [MainThread]: 
[0m09:07:42.647026 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m09:07:42.652615 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m09:07:42.654519 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:07:43.172866 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_marts)
[0m09:07:43.173468 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_staging'
[0m09:07:43.173990 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_facts'
[0m09:07:43.174818 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m09:07:43.176508 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:07:43.177522 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:07:43.429538 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2c201564-cdd3-4086-93c7-81f2db3bd79e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2224597a90>]}
[0m09:07:43.430575 [debug] [MainThread]: Opening a new connection, currently in state init
[0m09:07:43.435228 [debug] [Thread-1 (]: Began running node model.hailing_project.mart_cust_rides_daily
[0m09:07:43.436018 [info ] [Thread-1 (]: 1 of 1 START sql table model rizky_dwh_hailing_marts.mart_cust_rides_daily ..... [RUN]
[0m09:07:43.437118 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_facts, now model.hailing_project.mart_cust_rides_daily)
[0m09:07:43.437996 [debug] [Thread-1 (]: Began compiling node model.hailing_project.mart_cust_rides_daily
[0m09:07:43.448875 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.mart_cust_rides_daily"
[0m09:07:43.456700 [debug] [Thread-1 (]: Began executing node model.hailing_project.mart_cust_rides_daily
[0m09:07:43.497683 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.mart_cust_rides_daily"
[0m09:07:43.503322 [debug] [Thread-1 (]: On model.hailing_project.mart_cust_rides_daily: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.mart_cust_rides_daily"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_marts`.`mart_cust_rides_daily`
      
    partition by timestamp_trunc(ride_date, day)
    

    OPTIONS()
    as (
      


WITH fact_rides AS(

    SELECT * 
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
)

SELECT 

    fact_rides.cust_id,
    fact_rides.cust_name,
    fact_rides.cust_email,
    fact_rides.cust_phone_number,
    DATE(fact_rides.created_at) AS ride_date,
    COUNT(fact_rides.ride_id) AS no_of_rides,
    SUM(TIMESTAMP_DIFF(fact_rides.ride_end_time, fact_rides.ride_start_time, MINUTE)) AS total_ride_duration_min,
    SUM(fact_rides.fare) AS total_fare,
    SUM(fact_rides.distance_km) as total_distance_km,
    SUM(fact_rides.distance_km)-SUM(fact_rides.total_fare) AS rev_opportunity_loss
    
FROM fact_rides
    );
  
[0m09:07:43.504251 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m09:07:43.900076 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:5b7c1541-3423-4e95-92f9-3d33e5cf9f24&page=queryresults
[0m09:07:44.082637 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:5b7c1541-3423-4e95-92f9-3d33e5cf9f24&page=queryresults
[0m09:07:44.090153 [debug] [Thread-1 (]: Database Error in model mart_cust_rides_daily (models/marts/mart_cust_rides_daily.sql)
  Name total_fare not found inside fact_rides at [33:48]
  compiled code at target/run/hailing_project/models/marts/mart_cust_rides_daily.sql
[0m09:07:44.092623 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2c201564-cdd3-4086-93c7-81f2db3bd79e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f22248bc710>]}
[0m09:07:44.096329 [error] [Thread-1 (]: 1 of 1 ERROR creating sql table model rizky_dwh_hailing_marts.mart_cust_rides_daily  [[31mERROR[0m in 0.65s]
[0m09:07:44.098538 [debug] [Thread-1 (]: Finished running node model.hailing_project.mart_cust_rides_daily
[0m09:07:44.099760 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.mart_cust_rides_daily' to be skipped because of status 'error'.  Reason: Database Error in model mart_cust_rides_daily (models/marts/mart_cust_rides_daily.sql)
  Name total_fare not found inside fact_rides at [33:48]
  compiled code at target/run/hailing_project/models/marts/mart_cust_rides_daily.sql.
[0m09:07:44.102823 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m09:07:44.108527 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:07:44.109453 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_marts' was properly closed.
[0m09:07:44.110346 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_staging' was properly closed.
[0m09:07:44.111904 [debug] [MainThread]: Connection 'model.hailing_project.mart_cust_rides_daily' was properly closed.
[0m09:07:44.113198 [info ] [MainThread]: 
[0m09:07:44.114204 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 1.47 seconds (1.47s).
[0m09:07:44.115946 [debug] [MainThread]: Command end result
[0m09:07:44.152678 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m09:07:44.157594 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m09:07:44.166220 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m09:07:44.166982 [info ] [MainThread]: 
[0m09:07:44.167957 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m09:07:44.168929 [info ] [MainThread]: 
[0m09:07:44.169893 [error] [MainThread]:   Database Error in model mart_cust_rides_daily (models/marts/mart_cust_rides_daily.sql)
  Name total_fare not found inside fact_rides at [33:48]
  compiled code at target/run/hailing_project/models/marts/mart_cust_rides_daily.sql
[0m09:07:44.170714 [info ] [MainThread]: 
[0m09:07:44.171787 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m09:07:44.173466 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 2.650082, "process_in_blocks": "0", "process_kernel_time": 0.371775, "process_mem_max_rss": "215308", "process_out_blocks": "0", "process_user_time": 2.974203}
[0m09:07:44.174932 [debug] [MainThread]: Command `dbt run` failed at 09:07:44.174719 after 2.65 seconds
[0m09:07:44.175977 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2251ef9450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2251ef91d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f224f3272d0>]}
[0m09:07:44.176881 [debug] [MainThread]: Flushing usage events
[0m09:07:45.380545 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m09:08:09.949147 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fec40ed3b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fec41276a50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fec40e7ac50>]}


============================== 09:08:09.952698 | 7fe45d33-ec55-4b8c-b194-9df957d74555 ==============================
[0m09:08:09.952698 [info ] [MainThread]: Running with dbt=1.9.0
[0m09:08:09.955003 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --select mart_cust_rides_daily', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m09:08:10.522584 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '7fe45d33-ec55-4b8c-b194-9df957d74555', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fec18bfae50>]}
[0m09:08:10.571115 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '7fe45d33-ec55-4b8c-b194-9df957d74555', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fec430ee9d0>]}
[0m09:08:10.572465 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m09:08:10.639335 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m09:08:10.816827 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m09:08:10.818022 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/marts/mart_cust_rides_daily.sql
[0m09:08:11.071516 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7fe45d33-ec55-4b8c-b194-9df957d74555', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fec12ff4090>]}
[0m09:08:11.140440 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m09:08:11.145796 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m09:08:11.161044 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7fe45d33-ec55-4b8c-b194-9df957d74555', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fec13136950>]}
[0m09:08:11.162082 [info ] [MainThread]: Found 8 models, 8 sources, 489 macros
[0m09:08:11.163363 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7fe45d33-ec55-4b8c-b194-9df957d74555', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fec12e33f50>]}
[0m09:08:11.165529 [info ] [MainThread]: 
[0m09:08:11.166712 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m09:08:11.167879 [info ] [MainThread]: 
[0m09:08:11.169370 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m09:08:11.171063 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m09:08:11.172167 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:08:11.658581 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_staging)
[0m09:08:11.659186 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_marts'
[0m09:08:11.660458 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_facts'
[0m09:08:11.660961 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m09:08:11.661950 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:08:11.662667 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:08:11.886831 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7fe45d33-ec55-4b8c-b194-9df957d74555', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fec12caffd0>]}
[0m09:08:11.887815 [debug] [MainThread]: Opening a new connection, currently in state init
[0m09:08:11.893538 [debug] [Thread-1 (]: Began running node model.hailing_project.mart_cust_rides_daily
[0m09:08:11.894484 [info ] [Thread-1 (]: 1 of 1 START sql table model rizky_dwh_hailing_marts.mart_cust_rides_daily ..... [RUN]
[0m09:08:11.895589 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_facts, now model.hailing_project.mart_cust_rides_daily)
[0m09:08:11.896508 [debug] [Thread-1 (]: Began compiling node model.hailing_project.mart_cust_rides_daily
[0m09:08:11.903839 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.mart_cust_rides_daily"
[0m09:08:11.911837 [debug] [Thread-1 (]: Began executing node model.hailing_project.mart_cust_rides_daily
[0m09:08:11.951195 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.mart_cust_rides_daily"
[0m09:08:11.956749 [debug] [Thread-1 (]: On model.hailing_project.mart_cust_rides_daily: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.mart_cust_rides_daily"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_marts`.`mart_cust_rides_daily`
      
    partition by timestamp_trunc(ride_date, day)
    

    OPTIONS()
    as (
      


WITH fact_rides AS(

    SELECT * 
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
)

SELECT 

    fact_rides.cust_id,
    fact_rides.cust_name,
    fact_rides.cust_email,
    fact_rides.cust_phone_number,
    DATE(fact_rides.created_at) AS ride_date,
    COUNT(fact_rides.ride_id) AS no_of_rides,
    SUM(TIMESTAMP_DIFF(fact_rides.ride_end_time, fact_rides.ride_start_time, MINUTE)) AS total_ride_duration_min,
    SUM(fact_rides.fare) AS total_fare,
    SUM(fact_rides.distance_km) as total_distance_km,
    SUM(fact_rides.distance_km)-SUM(fact_rides.fare) AS rev_opportunity_loss
    
FROM fact_rides
    );
  
[0m09:08:11.957712 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m09:08:12.315008 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:383369f3-72a8-4635-806e-6f67ca252cc9&page=queryresults
[0m09:08:12.393011 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:383369f3-72a8-4635-806e-6f67ca252cc9&page=queryresults
[0m09:08:12.398374 [debug] [Thread-1 (]: Database Error in model mart_cust_rides_daily (models/marts/mart_cust_rides_daily.sql)
  SELECT list expression references fact_rides.cust_id which is neither grouped nor aggregated at [24:5]
  compiled code at target/run/hailing_project/models/marts/mart_cust_rides_daily.sql
[0m09:08:12.401077 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7fe45d33-ec55-4b8c-b194-9df957d74555', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fec13034950>]}
[0m09:08:12.402528 [error] [Thread-1 (]: 1 of 1 ERROR creating sql table model rizky_dwh_hailing_marts.mart_cust_rides_daily  [[31mERROR[0m in 0.50s]
[0m09:08:12.404107 [debug] [Thread-1 (]: Finished running node model.hailing_project.mart_cust_rides_daily
[0m09:08:12.405426 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.mart_cust_rides_daily' to be skipped because of status 'error'.  Reason: Database Error in model mart_cust_rides_daily (models/marts/mart_cust_rides_daily.sql)
  SELECT list expression references fact_rides.cust_id which is neither grouped nor aggregated at [24:5]
  compiled code at target/run/hailing_project/models/marts/mart_cust_rides_daily.sql.
[0m09:08:12.408104 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m09:08:12.412208 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:08:12.413054 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_staging' was properly closed.
[0m09:08:12.413775 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_marts' was properly closed.
[0m09:08:12.414588 [debug] [MainThread]: Connection 'model.hailing_project.mart_cust_rides_daily' was properly closed.
[0m09:08:12.415766 [info ] [MainThread]: 
[0m09:08:12.417610 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 1.25 seconds (1.25s).
[0m09:08:12.419322 [debug] [MainThread]: Command end result
[0m09:08:12.453452 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m09:08:12.458538 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m09:08:12.466650 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m09:08:12.467583 [info ] [MainThread]: 
[0m09:08:12.468743 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m09:08:12.469976 [info ] [MainThread]: 
[0m09:08:12.471110 [error] [MainThread]:   Database Error in model mart_cust_rides_daily (models/marts/mart_cust_rides_daily.sql)
  SELECT list expression references fact_rides.cust_id which is neither grouped nor aggregated at [24:5]
  compiled code at target/run/hailing_project/models/marts/mart_cust_rides_daily.sql
[0m09:08:12.472205 [info ] [MainThread]: 
[0m09:08:12.473357 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m09:08:12.474986 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 2.572953, "process_in_blocks": "0", "process_kernel_time": 0.194669, "process_mem_max_rss": "217368", "process_out_blocks": "0", "process_user_time": 3.340115}
[0m09:08:12.476259 [debug] [MainThread]: Command `dbt run` failed at 09:08:12.476113 after 2.57 seconds
[0m09:08:12.477535 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fec40ed5dd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fec447f5450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fec447f56d0>]}
[0m09:08:12.478752 [debug] [MainThread]: Flushing usage events
[0m09:08:13.494191 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m09:09:20.319314 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fda5a432710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fda5a432ed0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fda5a432c50>]}


============================== 09:09:20.321853 | 89ab8812-887d-4b04-8d31-9b2260407e34 ==============================
[0m09:09:20.321853 [info ] [MainThread]: Running with dbt=1.9.0
[0m09:09:20.323028 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --select mart_cust_rides_daily', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m09:09:20.937148 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '89ab8812-887d-4b04-8d31-9b2260407e34', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fda31c26dd0>]}
[0m09:09:20.984096 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '89ab8812-887d-4b04-8d31-9b2260407e34', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fda30722550>]}
[0m09:09:20.985664 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m09:09:21.060298 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m09:09:21.256150 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m09:09:21.258001 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/marts/mart_cust_rides_daily.sql
[0m09:09:21.512035 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '89ab8812-887d-4b04-8d31-9b2260407e34', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fda30666e90>]}
[0m09:09:21.575415 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m09:09:21.581600 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m09:09:21.597727 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '89ab8812-887d-4b04-8d31-9b2260407e34', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fda2a93f0d0>]}
[0m09:09:21.598736 [info ] [MainThread]: Found 8 models, 8 sources, 489 macros
[0m09:09:21.599809 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '89ab8812-887d-4b04-8d31-9b2260407e34', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fda30716310>]}
[0m09:09:21.602286 [info ] [MainThread]: 
[0m09:09:21.603400 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m09:09:21.604332 [info ] [MainThread]: 
[0m09:09:21.605536 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m09:09:21.607244 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m09:09:21.608223 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:09:22.181705 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_staging)
[0m09:09:22.182370 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_marts'
[0m09:09:22.185673 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:09:22.183877 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m09:09:22.182892 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_facts'
[0m09:09:22.192715 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:09:22.445721 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '89ab8812-887d-4b04-8d31-9b2260407e34', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fda5a43a950>]}
[0m09:09:22.446944 [debug] [MainThread]: Opening a new connection, currently in state init
[0m09:09:22.452390 [debug] [Thread-1 (]: Began running node model.hailing_project.mart_cust_rides_daily
[0m09:09:22.453703 [info ] [Thread-1 (]: 1 of 1 START sql table model rizky_dwh_hailing_marts.mart_cust_rides_daily ..... [RUN]
[0m09:09:22.455010 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_facts, now model.hailing_project.mart_cust_rides_daily)
[0m09:09:22.456083 [debug] [Thread-1 (]: Began compiling node model.hailing_project.mart_cust_rides_daily
[0m09:09:22.463926 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.mart_cust_rides_daily"
[0m09:09:22.469987 [debug] [Thread-1 (]: Began executing node model.hailing_project.mart_cust_rides_daily
[0m09:09:22.510830 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.mart_cust_rides_daily"
[0m09:09:22.516559 [debug] [Thread-1 (]: On model.hailing_project.mart_cust_rides_daily: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.mart_cust_rides_daily"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_marts`.`mart_cust_rides_daily`
      
    partition by timestamp_trunc(ride_date, day)
    

    OPTIONS()
    as (
      


WITH fact_rides AS(

    SELECT * 
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
)

SELECT 

    fact_rides.cust_id,
    DATE(fact_rides.created_at) AS ride_date,
    fact_rides.cust_name,
    fact_rides.cust_email,
    fact_rides.cust_phone_number,
    COUNT(fact_rides.ride_id) AS no_of_rides,
    SUM(TIMESTAMP_DIFF(fact_rides.ride_end_time, fact_rides.ride_start_time, MINUTE)) AS total_ride_duration_min,
    SUM(fact_rides.fare) AS total_fare,
    SUM(fact_rides.distance_km) as total_distance_km,
    SUM(fact_rides.distance_km)-SUM(fact_rides.fare) AS rev_opportunity_loss

GROUP BY cust_id, ride_date
    
FROM fact_rides
    );
  
[0m09:09:22.517535 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m09:09:22.989282 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:7419061a-b177-4145-9caa-e7a966102a19&page=queryresults
[0m09:09:22.990390 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:7419061a-b177-4145-9caa-e7a966102a19&page=queryresults
[0m09:09:22.994728 [debug] [Thread-1 (]: Database Error in model mart_cust_rides_daily (models/marts/mart_cust_rides_daily.sql)
  Syntax error: Expected ")" but got keyword FROM at [37:1]
  compiled code at target/run/hailing_project/models/marts/mart_cust_rides_daily.sql
[0m09:09:22.996408 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '89ab8812-887d-4b04-8d31-9b2260407e34', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fda30628910>]}
[0m09:09:22.997667 [error] [Thread-1 (]: 1 of 1 ERROR creating sql table model rizky_dwh_hailing_marts.mart_cust_rides_daily  [[31mERROR[0m in 0.54s]
[0m09:09:22.998745 [debug] [Thread-1 (]: Finished running node model.hailing_project.mart_cust_rides_daily
[0m09:09:22.999898 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.mart_cust_rides_daily' to be skipped because of status 'error'.  Reason: Database Error in model mart_cust_rides_daily (models/marts/mart_cust_rides_daily.sql)
  Syntax error: Expected ")" but got keyword FROM at [37:1]
  compiled code at target/run/hailing_project/models/marts/mart_cust_rides_daily.sql.
[0m09:09:23.002575 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m09:09:23.006121 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:09:23.007110 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_staging' was properly closed.
[0m09:09:23.007932 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_marts' was properly closed.
[0m09:09:23.008787 [debug] [MainThread]: Connection 'model.hailing_project.mart_cust_rides_daily' was properly closed.
[0m09:09:23.009524 [info ] [MainThread]: 
[0m09:09:23.010336 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 1.40 seconds (1.40s).
[0m09:09:23.011679 [debug] [MainThread]: Command end result
[0m09:09:23.049425 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m09:09:23.054488 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m09:09:23.062663 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m09:09:23.063380 [info ] [MainThread]: 
[0m09:09:23.064432 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m09:09:23.065461 [info ] [MainThread]: 
[0m09:09:23.066523 [error] [MainThread]:   Database Error in model mart_cust_rides_daily (models/marts/mart_cust_rides_daily.sql)
  Syntax error: Expected ")" but got keyword FROM at [37:1]
  compiled code at target/run/hailing_project/models/marts/mart_cust_rides_daily.sql
[0m09:09:23.067660 [info ] [MainThread]: 
[0m09:09:23.068565 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m09:09:23.070288 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 2.796151, "process_in_blocks": "0", "process_kernel_time": 0.250293, "process_mem_max_rss": "222728", "process_out_blocks": "0", "process_user_time": 3.295526}
[0m09:09:23.071476 [debug] [MainThread]: Command `dbt run` failed at 09:09:23.071309 after 2.80 seconds
[0m09:09:23.072724 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fda5df5d8d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fda5a94c950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fda307cbcd0>]}
[0m09:09:23.073836 [debug] [MainThread]: Flushing usage events
[0m09:09:24.168111 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m09:09:51.769629 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f974961bb50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f974961bc10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f974961bcd0>]}


============================== 09:09:51.772321 | e571e1bb-c1ba-4ef1-8940-d1c280f4f532 ==============================
[0m09:09:51.772321 [info ] [MainThread]: Running with dbt=1.9.0
[0m09:09:51.774744 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt run --select mart_cust_rides_daily', 'send_anonymous_usage_stats': 'True'}
[0m09:09:52.337822 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e571e1bb-c1ba-4ef1-8940-d1c280f4f532', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f971b9f3e90>]}
[0m09:09:52.388015 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e571e1bb-c1ba-4ef1-8940-d1c280f4f532', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f974a35a250>]}
[0m09:09:52.389113 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m09:09:52.463673 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m09:09:52.643930 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m09:09:52.644976 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/marts/mart_cust_rides_daily.sql
[0m09:09:52.893093 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e571e1bb-c1ba-4ef1-8940-d1c280f4f532', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f971b511650>]}
[0m09:09:52.966533 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m09:09:52.972562 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m09:09:52.987428 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e571e1bb-c1ba-4ef1-8940-d1c280f4f532', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9719a8bd50>]}
[0m09:09:52.988383 [info ] [MainThread]: Found 8 models, 8 sources, 489 macros
[0m09:09:52.989596 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e571e1bb-c1ba-4ef1-8940-d1c280f4f532', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f971b511dd0>]}
[0m09:09:52.991998 [info ] [MainThread]: 
[0m09:09:52.993092 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m09:09:52.994042 [info ] [MainThread]: 
[0m09:09:52.995175 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m09:09:52.996857 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m09:09:52.997788 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:09:53.494798 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_staging)
[0m09:09:53.495497 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_marts'
[0m09:09:53.496174 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_facts'
[0m09:09:53.497248 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m09:09:53.498387 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:09:53.499588 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:09:53.742035 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e571e1bb-c1ba-4ef1-8940-d1c280f4f532', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f971b7d9210>]}
[0m09:09:53.743231 [debug] [MainThread]: Opening a new connection, currently in state init
[0m09:09:53.747516 [debug] [Thread-1 (]: Began running node model.hailing_project.mart_cust_rides_daily
[0m09:09:53.748453 [info ] [Thread-1 (]: 1 of 1 START sql table model rizky_dwh_hailing_marts.mart_cust_rides_daily ..... [RUN]
[0m09:09:53.749490 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_facts, now model.hailing_project.mart_cust_rides_daily)
[0m09:09:53.750360 [debug] [Thread-1 (]: Began compiling node model.hailing_project.mart_cust_rides_daily
[0m09:09:53.757449 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.mart_cust_rides_daily"
[0m09:09:53.765073 [debug] [Thread-1 (]: Began executing node model.hailing_project.mart_cust_rides_daily
[0m09:09:53.806669 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.mart_cust_rides_daily"
[0m09:09:53.812394 [debug] [Thread-1 (]: On model.hailing_project.mart_cust_rides_daily: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.mart_cust_rides_daily"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_marts`.`mart_cust_rides_daily`
      
    partition by timestamp_trunc(ride_date, day)
    

    OPTIONS()
    as (
      


WITH fact_rides AS(

    SELECT * 
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
)

SELECT 

    fact_rides.cust_id,
    DATE(fact_rides.created_at) AS ride_date,
    fact_rides.cust_name,
    fact_rides.cust_email,
    fact_rides.cust_phone_number,
    COUNT(fact_rides.ride_id) AS no_of_rides,
    SUM(TIMESTAMP_DIFF(fact_rides.ride_end_time, fact_rides.ride_start_time, MINUTE)) AS total_ride_duration_min,
    SUM(fact_rides.fare) AS total_fare,
    SUM(fact_rides.distance_km) as total_distance_km,
    SUM(fact_rides.distance_km)-SUM(fact_rides.fare) AS rev_opportunity_loss

FROM fact_rides
GROUP BY cust_id, ride_date
    );
  
[0m09:09:53.813411 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m09:09:54.269197 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:ef6dd6d7-685a-4809-831a-164e51d4d0e9&page=queryresults
[0m09:09:54.364902 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:ef6dd6d7-685a-4809-831a-164e51d4d0e9&page=queryresults
[0m09:09:54.370059 [debug] [Thread-1 (]: Database Error in model mart_cust_rides_daily (models/marts/mart_cust_rides_daily.sql)
  SELECT list expression references fact_rides.cust_name which is neither grouped nor aggregated at [26:5]
  compiled code at target/run/hailing_project/models/marts/mart_cust_rides_daily.sql
[0m09:09:54.372460 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e571e1bb-c1ba-4ef1-8940-d1c280f4f532', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f971b726410>]}
[0m09:09:54.373602 [error] [Thread-1 (]: 1 of 1 ERROR creating sql table model rizky_dwh_hailing_marts.mart_cust_rides_daily  [[31mERROR[0m in 0.62s]
[0m09:09:54.374810 [debug] [Thread-1 (]: Finished running node model.hailing_project.mart_cust_rides_daily
[0m09:09:54.376525 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.mart_cust_rides_daily' to be skipped because of status 'error'.  Reason: Database Error in model mart_cust_rides_daily (models/marts/mart_cust_rides_daily.sql)
  SELECT list expression references fact_rides.cust_name which is neither grouped nor aggregated at [26:5]
  compiled code at target/run/hailing_project/models/marts/mart_cust_rides_daily.sql.
[0m09:09:54.379555 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m09:09:54.383202 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:09:54.384386 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_staging' was properly closed.
[0m09:09:54.385357 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_marts' was properly closed.
[0m09:09:54.386173 [debug] [MainThread]: Connection 'model.hailing_project.mart_cust_rides_daily' was properly closed.
[0m09:09:54.387281 [info ] [MainThread]: 
[0m09:09:54.388312 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 1.39 seconds (1.39s).
[0m09:09:54.389744 [debug] [MainThread]: Command end result
[0m09:09:54.426224 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m09:09:54.431500 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m09:09:54.441179 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m09:09:54.442134 [info ] [MainThread]: 
[0m09:09:54.443243 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m09:09:54.444339 [info ] [MainThread]: 
[0m09:09:54.445631 [error] [MainThread]:   Database Error in model mart_cust_rides_daily (models/marts/mart_cust_rides_daily.sql)
  SELECT list expression references fact_rides.cust_name which is neither grouped nor aggregated at [26:5]
  compiled code at target/run/hailing_project/models/marts/mart_cust_rides_daily.sql
[0m09:09:54.446745 [info ] [MainThread]: 
[0m09:09:54.447839 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m09:09:54.450136 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 2.727146, "process_in_blocks": "0", "process_kernel_time": 0.162569, "process_mem_max_rss": "219268", "process_out_blocks": "0", "process_user_time": 3.31235}
[0m09:09:54.451702 [debug] [MainThread]: Command `dbt run` failed at 09:09:54.451479 after 2.73 seconds
[0m09:09:54.452969 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9749420cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9749422710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f974cf11410>]}
[0m09:09:54.454080 [debug] [MainThread]: Flushing usage events
[0m09:09:55.462742 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m09:10:45.456080 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f525fc4ba10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f525fc9fdd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f525fc4b590>]}


============================== 09:10:45.458834 | 1ee397e0-02a8-4557-b834-21136f9ccf2e ==============================
[0m09:10:45.458834 [info ] [MainThread]: Running with dbt=1.9.0
[0m09:10:45.460129 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'invocation_command': 'dbt run --select mart_cust_rides_daily', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m09:10:46.069017 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1ee397e0-02a8-4557-b834-21136f9ccf2e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f52320a6a50>]}
[0m09:10:46.115389 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '1ee397e0-02a8-4557-b834-21136f9ccf2e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5261ef4e10>]}
[0m09:10:46.117087 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m09:10:46.181694 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m09:10:46.372739 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m09:10:46.374000 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/marts/mart_cust_rides_daily.sql
[0m09:10:46.626863 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1ee397e0-02a8-4557-b834-21136f9ccf2e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5231f6ac50>]}
[0m09:10:46.698966 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m09:10:46.705035 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m09:10:46.720308 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1ee397e0-02a8-4557-b834-21136f9ccf2e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f523014f010>]}
[0m09:10:46.721788 [info ] [MainThread]: Found 8 models, 8 sources, 489 macros
[0m09:10:46.723186 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1ee397e0-02a8-4557-b834-21136f9ccf2e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5231f94e10>]}
[0m09:10:46.725328 [info ] [MainThread]: 
[0m09:10:46.726596 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m09:10:46.727629 [info ] [MainThread]: 
[0m09:10:46.729271 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m09:10:46.731319 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m09:10:46.732192 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:10:47.258334 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_facts)
[0m09:10:47.260017 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m09:10:47.259529 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_marts'
[0m09:10:47.258998 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_staging'
[0m09:10:47.264870 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:10:47.290319 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:10:47.542444 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1ee397e0-02a8-4557-b834-21136f9ccf2e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5231dce990>]}
[0m09:10:47.543604 [debug] [MainThread]: Opening a new connection, currently in state init
[0m09:10:47.548827 [debug] [Thread-1 (]: Began running node model.hailing_project.mart_cust_rides_daily
[0m09:10:47.550358 [info ] [Thread-1 (]: 1 of 1 START sql table model rizky_dwh_hailing_marts.mart_cust_rides_daily ..... [RUN]
[0m09:10:47.551691 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_staging, now model.hailing_project.mart_cust_rides_daily)
[0m09:10:47.552889 [debug] [Thread-1 (]: Began compiling node model.hailing_project.mart_cust_rides_daily
[0m09:10:47.564100 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.mart_cust_rides_daily"
[0m09:10:47.569645 [debug] [Thread-1 (]: Began executing node model.hailing_project.mart_cust_rides_daily
[0m09:10:47.614099 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.mart_cust_rides_daily"
[0m09:10:47.620865 [debug] [Thread-1 (]: On model.hailing_project.mart_cust_rides_daily: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.mart_cust_rides_daily"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_marts`.`mart_cust_rides_daily`
      
    partition by timestamp_trunc(ride_date, day)
    

    OPTIONS()
    as (
      


WITH fact_rides AS(

    SELECT * 
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
)

SELECT 

    fact_rides.cust_id,
    DATE(fact_rides.created_at) AS ride_date,
    fact_rides.cust_name,
    fact_rides.cust_email,
    fact_rides.cust_phone_number,
    COUNT(fact_rides.ride_id) AS no_of_rides,
    SUM(TIMESTAMP_DIFF(fact_rides.ride_end_time, fact_rides.ride_start_time, MINUTE)) AS total_ride_duration_min,
    SUM(fact_rides.fare) AS total_fare,
    SUM(fact_rides.distance_km) as total_distance_km,
    SUM(fact_rides.distance_km)-SUM(fact_rides.fare) AS rev_opportunity_loss

FROM fact_rides
GROUP BY cust_name
    );
  
[0m09:10:47.622120 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m09:10:48.111272 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:42dee268-7e21-4074-b817-7ec29cf4ce5c&page=queryresults
[0m09:10:48.201424 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:42dee268-7e21-4074-b817-7ec29cf4ce5c&page=queryresults
[0m09:10:48.206159 [debug] [Thread-1 (]: Database Error in model mart_cust_rides_daily (models/marts/mart_cust_rides_daily.sql)
  SELECT list expression references fact_rides.cust_id which is neither grouped nor aggregated at [24:5]
  compiled code at target/run/hailing_project/models/marts/mart_cust_rides_daily.sql
[0m09:10:48.208594 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1ee397e0-02a8-4557-b834-21136f9ccf2e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5231fd0650>]}
[0m09:10:48.210048 [error] [Thread-1 (]: 1 of 1 ERROR creating sql table model rizky_dwh_hailing_marts.mart_cust_rides_daily  [[31mERROR[0m in 0.66s]
[0m09:10:48.211310 [debug] [Thread-1 (]: Finished running node model.hailing_project.mart_cust_rides_daily
[0m09:10:48.212638 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.mart_cust_rides_daily' to be skipped because of status 'error'.  Reason: Database Error in model mart_cust_rides_daily (models/marts/mart_cust_rides_daily.sql)
  SELECT list expression references fact_rides.cust_id which is neither grouped nor aggregated at [24:5]
  compiled code at target/run/hailing_project/models/marts/mart_cust_rides_daily.sql.
[0m09:10:48.215206 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m09:10:48.218898 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:10:48.220015 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_facts' was properly closed.
[0m09:10:48.221222 [debug] [MainThread]: Connection 'model.hailing_project.mart_cust_rides_daily' was properly closed.
[0m09:10:48.222594 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_marts' was properly closed.
[0m09:10:48.223490 [info ] [MainThread]: 
[0m09:10:48.224430 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 1.49 seconds (1.49s).
[0m09:10:48.225873 [debug] [MainThread]: Command end result
[0m09:10:48.263129 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m09:10:48.267490 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m09:10:48.277829 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m09:10:48.278844 [info ] [MainThread]: 
[0m09:10:48.280028 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m09:10:48.281428 [info ] [MainThread]: 
[0m09:10:48.282917 [error] [MainThread]:   Database Error in model mart_cust_rides_daily (models/marts/mart_cust_rides_daily.sql)
  SELECT list expression references fact_rides.cust_id which is neither grouped nor aggregated at [24:5]
  compiled code at target/run/hailing_project/models/marts/mart_cust_rides_daily.sql
[0m09:10:48.284040 [info ] [MainThread]: 
[0m09:10:48.285170 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m09:10:48.287086 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 2.8854601, "process_in_blocks": "0", "process_kernel_time": 0.199658, "process_mem_max_rss": "219096", "process_out_blocks": "0", "process_user_time": 3.364252}
[0m09:10:48.288494 [debug] [MainThread]: Command `dbt run` failed at 09:10:48.288286 after 2.89 seconds
[0m09:10:48.289729 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f52635fd210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f52635fd090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f52320a6a50>]}
[0m09:10:48.291102 [debug] [MainThread]: Flushing usage events
[0m09:10:49.419766 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m09:11:16.757369 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2c2f6fb810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2c2f753950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2c2fad6210>]}


============================== 09:11:16.759984 | aff6fafd-53c1-4998-ac4c-99a272b0b762 ==============================
[0m09:11:16.759984 [info ] [MainThread]: Running with dbt=1.9.0
[0m09:11:16.761634 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --select mart_cust_rides_daily', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m09:11:17.342170 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'aff6fafd-53c1-4998-ac4c-99a272b0b762', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2c01a9edd0>]}
[0m09:11:17.386783 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'aff6fafd-53c1-4998-ac4c-99a272b0b762', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2c01a93750>]}
[0m09:11:17.388375 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m09:11:17.454493 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m09:11:17.648364 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m09:11:17.649325 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/marts/mart_cust_rides_daily.sql
[0m09:11:17.894591 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'aff6fafd-53c1-4998-ac4c-99a272b0b762', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2c2f72ebd0>]}
[0m09:11:17.969832 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m09:11:17.975160 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m09:11:17.989277 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'aff6fafd-53c1-4998-ac4c-99a272b0b762', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2bdbb3eb10>]}
[0m09:11:17.990361 [info ] [MainThread]: Found 8 models, 8 sources, 489 macros
[0m09:11:17.991784 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'aff6fafd-53c1-4998-ac4c-99a272b0b762', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2c01aa4450>]}
[0m09:11:17.994213 [info ] [MainThread]: 
[0m09:11:17.995284 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m09:11:17.996230 [info ] [MainThread]: 
[0m09:11:17.997456 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m09:11:17.999215 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m09:11:18.000269 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:11:18.490942 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_facts)
[0m09:11:18.491738 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_staging'
[0m09:11:18.492498 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_marts'
[0m09:11:18.493480 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m09:11:18.494390 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:11:18.495224 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:11:18.753926 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'aff6fafd-53c1-4998-ac4c-99a272b0b762', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2c01692d90>]}
[0m09:11:18.755024 [debug] [MainThread]: Opening a new connection, currently in state init
[0m09:11:18.759533 [debug] [Thread-1 (]: Began running node model.hailing_project.mart_cust_rides_daily
[0m09:11:18.760687 [info ] [Thread-1 (]: 1 of 1 START sql table model rizky_dwh_hailing_marts.mart_cust_rides_daily ..... [RUN]
[0m09:11:18.761997 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_staging, now model.hailing_project.mart_cust_rides_daily)
[0m09:11:18.763017 [debug] [Thread-1 (]: Began compiling node model.hailing_project.mart_cust_rides_daily
[0m09:11:18.770342 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.mart_cust_rides_daily"
[0m09:11:18.776199 [debug] [Thread-1 (]: Began executing node model.hailing_project.mart_cust_rides_daily
[0m09:11:18.821053 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.mart_cust_rides_daily"
[0m09:11:18.828877 [debug] [Thread-1 (]: On model.hailing_project.mart_cust_rides_daily: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.mart_cust_rides_daily"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_marts`.`mart_cust_rides_daily`
      
    partition by timestamp_trunc(ride_date, day)
    

    OPTIONS()
    as (
      


WITH fact_rides AS(

    SELECT * 
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
)

SELECT 

    fact_rides.cust_id,
    DATE(fact_rides.created_at) AS ride_date,
    fact_rides.cust_name,
    fact_rides.cust_email,
    fact_rides.cust_phone_number,
    COUNT(fact_rides.ride_id) AS no_of_rides,
    SUM(TIMESTAMP_DIFF(fact_rides.ride_end_time, fact_rides.ride_start_time, MINUTE)) AS total_ride_duration_min,
    SUM(fact_rides.fare) AS total_fare,
    SUM(fact_rides.distance_km) as total_distance_km,
    SUM(fact_rides.distance_km)-SUM(fact_rides.fare) AS rev_opportunity_loss

FROM fact_rides
GROUP BY cust_name, cust_id, ride_date
    );
  
[0m09:11:18.829942 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m09:11:19.248135 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:d120fa2c-e7f7-48b6-807e-8fff47a16357&page=queryresults
[0m09:11:19.302678 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:d120fa2c-e7f7-48b6-807e-8fff47a16357&page=queryresults
[0m09:11:19.307187 [debug] [Thread-1 (]: Database Error in model mart_cust_rides_daily (models/marts/mart_cust_rides_daily.sql)
  SELECT list expression references fact_rides.cust_email which is neither grouped nor aggregated at [27:5]
  compiled code at target/run/hailing_project/models/marts/mart_cust_rides_daily.sql
[0m09:11:19.309497 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'aff6fafd-53c1-4998-ac4c-99a272b0b762', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2c01a86750>]}
[0m09:11:19.310730 [error] [Thread-1 (]: 1 of 1 ERROR creating sql table model rizky_dwh_hailing_marts.mart_cust_rides_daily  [[31mERROR[0m in 0.55s]
[0m09:11:19.312028 [debug] [Thread-1 (]: Finished running node model.hailing_project.mart_cust_rides_daily
[0m09:11:19.313375 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.mart_cust_rides_daily' to be skipped because of status 'error'.  Reason: Database Error in model mart_cust_rides_daily (models/marts/mart_cust_rides_daily.sql)
  SELECT list expression references fact_rides.cust_email which is neither grouped nor aggregated at [27:5]
  compiled code at target/run/hailing_project/models/marts/mart_cust_rides_daily.sql.
[0m09:11:19.316102 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m09:11:19.319617 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:11:19.320552 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_facts' was properly closed.
[0m09:11:19.321379 [debug] [MainThread]: Connection 'model.hailing_project.mart_cust_rides_daily' was properly closed.
[0m09:11:19.322116 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_marts' was properly closed.
[0m09:11:19.323058 [info ] [MainThread]: 
[0m09:11:19.324046 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 1.33 seconds (1.33s).
[0m09:11:19.325547 [debug] [MainThread]: Command end result
[0m09:11:19.362709 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m09:11:19.366565 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m09:11:19.374205 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m09:11:19.375140 [info ] [MainThread]: 
[0m09:11:19.376282 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m09:11:19.377388 [info ] [MainThread]: 
[0m09:11:19.378514 [error] [MainThread]:   Database Error in model mart_cust_rides_daily (models/marts/mart_cust_rides_daily.sql)
  SELECT list expression references fact_rides.cust_email which is neither grouped nor aggregated at [27:5]
  compiled code at target/run/hailing_project/models/marts/mart_cust_rides_daily.sql
[0m09:11:19.379491 [info ] [MainThread]: 
[0m09:11:19.380570 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m09:11:19.382515 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 2.6781523, "process_in_blocks": "0", "process_kernel_time": 0.263397, "process_mem_max_rss": "220012", "process_out_blocks": "0", "process_user_time": 3.24182}
[0m09:11:19.383813 [debug] [MainThread]: Command `dbt run` failed at 09:11:19.383680 after 2.68 seconds
[0m09:11:19.384934 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2c2f756250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2c2f754290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2c330b11d0>]}
[0m09:11:19.386058 [debug] [MainThread]: Flushing usage events
[0m09:11:20.596609 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m09:11:40.310753 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f12e433f410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f12e438fed0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f12e481b950>]}


============================== 09:11:40.313997 | 9919bd51-fe53-4e8b-83e7-c17614e83cf5 ==============================
[0m09:11:40.313997 [info ] [MainThread]: Running with dbt=1.9.0
[0m09:11:40.315756 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'invocation_command': 'dbt run --select mart_cust_rides_daily', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m09:11:40.909780 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '9919bd51-fe53-4e8b-83e7-c17614e83cf5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f12b663cfd0>]}
[0m09:11:40.954525 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '9919bd51-fe53-4e8b-83e7-c17614e83cf5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f12e65c6190>]}
[0m09:11:40.955811 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m09:11:41.019831 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m09:11:41.203707 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m09:11:41.204827 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/marts/mart_cust_rides_daily.sql
[0m09:11:41.450530 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9919bd51-fe53-4e8b-83e7-c17614e83cf5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f12e438c310>]}
[0m09:11:41.520832 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m09:11:41.527554 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m09:11:41.544354 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9919bd51-fe53-4e8b-83e7-c17614e83cf5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f12b617ea50>]}
[0m09:11:41.545528 [info ] [MainThread]: Found 8 models, 8 sources, 489 macros
[0m09:11:41.546750 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9919bd51-fe53-4e8b-83e7-c17614e83cf5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f12b64c0c10>]}
[0m09:11:41.549156 [info ] [MainThread]: 
[0m09:11:41.550352 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m09:11:41.551551 [info ] [MainThread]: 
[0m09:11:41.552864 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m09:11:41.555323 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m09:11:41.556624 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:11:42.176720 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_marts)
[0m09:11:42.177602 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_staging'
[0m09:11:42.178217 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_facts'
[0m09:11:42.178903 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m09:11:42.179717 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:11:42.180636 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:11:42.428090 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9919bd51-fe53-4e8b-83e7-c17614e83cf5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f12b66cbf50>]}
[0m09:11:42.429086 [debug] [MainThread]: Opening a new connection, currently in state init
[0m09:11:42.433316 [debug] [Thread-1 (]: Began running node model.hailing_project.mart_cust_rides_daily
[0m09:11:42.434482 [info ] [Thread-1 (]: 1 of 1 START sql table model rizky_dwh_hailing_marts.mart_cust_rides_daily ..... [RUN]
[0m09:11:42.435696 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_facts, now model.hailing_project.mart_cust_rides_daily)
[0m09:11:42.436712 [debug] [Thread-1 (]: Began compiling node model.hailing_project.mart_cust_rides_daily
[0m09:11:42.447461 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.mart_cust_rides_daily"
[0m09:11:42.457431 [debug] [Thread-1 (]: Began executing node model.hailing_project.mart_cust_rides_daily
[0m09:11:42.504658 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.mart_cust_rides_daily"
[0m09:11:42.510140 [debug] [Thread-1 (]: On model.hailing_project.mart_cust_rides_daily: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.mart_cust_rides_daily"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_marts`.`mart_cust_rides_daily`
      
    partition by timestamp_trunc(ride_date, day)
    

    OPTIONS()
    as (
      


WITH fact_rides AS(

    SELECT * 
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
)

SELECT 

    fact_rides.cust_id,
    DATE(fact_rides.created_at) AS ride_date,
    fact_rides.cust_name,
    fact_rides.cust_email,
    fact_rides.cust_phone_number,
    COUNT(fact_rides.ride_id) AS no_of_rides,
    SUM(TIMESTAMP_DIFF(fact_rides.ride_end_time, fact_rides.ride_start_time, MINUTE)) AS total_ride_duration_min,
    SUM(fact_rides.fare) AS total_fare,
    SUM(fact_rides.distance_km) as total_distance_km,
    SUM(fact_rides.distance_km)-SUM(fact_rides.fare) AS rev_opportunity_loss

FROM fact_rides
GROUP BY cust_name, cust_id, ride_date, cust_email, cust_phone_number
    );
  
[0m09:11:42.511053 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m09:11:42.847165 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:a3549eca-129e-4e3f-9d04-e9693c5a87fa&page=queryresults
[0m09:11:42.937557 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:a3549eca-129e-4e3f-9d04-e9693c5a87fa&page=queryresults
[0m09:11:42.943780 [debug] [Thread-1 (]: Database Error in model mart_cust_rides_daily (models/marts/mart_cust_rides_daily.sql)
  PARTITION BY expression must be DATE(<timestamp_column>), DATE(<datetime_column>), DATETIME_TRUNC(<datetime_column>, DAY/HOUR/MONTH/YEAR), a DATE column, TIMESTAMP_TRUNC(<timestamp_column>, DAY/HOUR/MONTH/YEAR), DATE_TRUNC(<date_column>, MONTH/YEAR), or RANGE_BUCKET(<int64_column>, GENERATE_ARRAY(<int64_value>, <int64_value>[, <int64_value>]))
  compiled code at target/run/hailing_project/models/marts/mart_cust_rides_daily.sql
[0m09:11:42.945962 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9919bd51-fe53-4e8b-83e7-c17614e83cf5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f12b48af150>]}
[0m09:11:42.947004 [error] [Thread-1 (]: 1 of 1 ERROR creating sql table model rizky_dwh_hailing_marts.mart_cust_rides_daily  [[31mERROR[0m in 0.51s]
[0m09:11:42.948148 [debug] [Thread-1 (]: Finished running node model.hailing_project.mart_cust_rides_daily
[0m09:11:42.949543 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.mart_cust_rides_daily' to be skipped because of status 'error'.  Reason: Database Error in model mart_cust_rides_daily (models/marts/mart_cust_rides_daily.sql)
  PARTITION BY expression must be DATE(<timestamp_column>), DATE(<datetime_column>), DATETIME_TRUNC(<datetime_column>, DAY/HOUR/MONTH/YEAR), a DATE column, TIMESTAMP_TRUNC(<timestamp_column>, DAY/HOUR/MONTH/YEAR), DATE_TRUNC(<date_column>, MONTH/YEAR), or RANGE_BUCKET(<int64_column>, GENERATE_ARRAY(<int64_value>, <int64_value>[, <int64_value>]))
  compiled code at target/run/hailing_project/models/marts/mart_cust_rides_daily.sql.
[0m09:11:42.952487 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m09:11:42.955515 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:11:42.956379 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_marts' was properly closed.
[0m09:11:42.957386 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_staging' was properly closed.
[0m09:11:42.958193 [debug] [MainThread]: Connection 'model.hailing_project.mart_cust_rides_daily' was properly closed.
[0m09:11:42.958957 [info ] [MainThread]: 
[0m09:11:42.959833 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 1.41 seconds (1.41s).
[0m09:11:42.961476 [debug] [MainThread]: Command end result
[0m09:11:42.996831 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m09:11:43.001485 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m09:11:43.009604 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m09:11:43.010312 [info ] [MainThread]: 
[0m09:11:43.011302 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m09:11:43.012386 [info ] [MainThread]: 
[0m09:11:43.013521 [error] [MainThread]:   Database Error in model mart_cust_rides_daily (models/marts/mart_cust_rides_daily.sql)
  PARTITION BY expression must be DATE(<timestamp_column>), DATE(<datetime_column>), DATETIME_TRUNC(<datetime_column>, DAY/HOUR/MONTH/YEAR), a DATE column, TIMESTAMP_TRUNC(<timestamp_column>, DAY/HOUR/MONTH/YEAR), DATE_TRUNC(<date_column>, MONTH/YEAR), or RANGE_BUCKET(<int64_column>, GENERATE_ARRAY(<int64_value>, <int64_value>[, <int64_value>]))
  compiled code at target/run/hailing_project/models/marts/mart_cust_rides_daily.sql
[0m09:11:43.014504 [info ] [MainThread]: 
[0m09:11:43.015563 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m09:11:43.017504 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 2.7555344, "process_in_blocks": "0", "process_kernel_time": 0.30006, "process_mem_max_rss": "218140", "process_out_blocks": "0", "process_user_time": 3.190645}
[0m09:11:43.018552 [debug] [MainThread]: Command `dbt run` failed at 09:11:43.018416 after 2.76 seconds
[0m09:11:43.019569 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f12e7e29890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f12e7cb9310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f12e7cb8990>]}
[0m09:11:43.020364 [debug] [MainThread]: Flushing usage events
[0m09:11:44.222908 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m09:15:08.376744 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6437f6b350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6437fc3cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6438362450>]}


============================== 09:15:08.380604 | b75f76f5-8023-47bb-81e6-f2d9afab5b62 ==============================
[0m09:15:08.380604 [info ] [MainThread]: Running with dbt=1.9.0
[0m09:15:08.382243 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt run --select mart_cust_rides_dailty', 'send_anonymous_usage_stats': 'True'}
[0m09:15:08.962890 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b75f76f5-8023-47bb-81e6-f2d9afab5b62', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f640a733950>]}
[0m09:15:09.009357 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b75f76f5-8023-47bb-81e6-f2d9afab5b62', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6438cfa190>]}
[0m09:15:09.011153 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m09:15:09.076677 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m09:15:09.271621 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m09:15:09.272586 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/marts/mart_cust_rides_daily.sql
[0m09:15:09.529616 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b75f76f5-8023-47bb-81e6-f2d9afab5b62', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f640a0cd750>]}
[0m09:15:09.599499 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m09:15:09.605470 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m09:15:09.622876 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b75f76f5-8023-47bb-81e6-f2d9afab5b62', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6408620910>]}
[0m09:15:09.624412 [info ] [MainThread]: Found 8 models, 8 sources, 489 macros
[0m09:15:09.625615 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b75f76f5-8023-47bb-81e6-f2d9afab5b62', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f640a2c5550>]}
[0m09:15:09.627176 [warn ] [MainThread]: The selection criterion 'mart_cust_rides_dailty' does not match any enabled nodes
[0m09:15:09.629391 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m09:15:09.631282 [debug] [MainThread]: Command end result
[0m09:15:09.666689 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m09:15:09.670783 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m09:15:09.676619 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m09:15:09.678383 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 1.3516601, "process_in_blocks": "0", "process_kernel_time": 0.231121, "process_mem_max_rss": "214380", "process_out_blocks": "0", "process_user_time": 3.054819}
[0m09:15:09.679751 [debug] [MainThread]: Command `dbt run` succeeded at 09:15:09.679560 after 1.35 seconds
[0m09:15:09.680747 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f643864df50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6437fc3cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f643b734cd0>]}
[0m09:15:09.681754 [debug] [MainThread]: Flushing usage events
[0m09:15:10.923394 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m09:15:22.945814 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0bee33550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0bf30f950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0bee33a10>]}


============================== 09:15:22.948780 | b51408eb-f3bc-4261-85fb-a3e8316f5fbe ==============================
[0m09:15:22.948780 [info ] [MainThread]: Running with dbt=1.9.0
[0m09:15:22.950437 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'invocation_command': 'dbt run --select mart_cust_rides_daily', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m09:15:23.538622 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b51408eb-f3bc-4261-85fb-a3e8316f5fbe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc094fe3b50>]}
[0m09:15:23.586501 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b51408eb-f3bc-4261-85fb-a3e8316f5fbe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0c1086950>]}
[0m09:15:23.588001 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m09:15:23.651882 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m09:15:23.835621 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m09:15:23.836502 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m09:15:23.866008 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b51408eb-f3bc-4261-85fb-a3e8316f5fbe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc094e84a50>]}
[0m09:15:23.987628 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m09:15:23.993155 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m09:15:24.008665 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b51408eb-f3bc-4261-85fb-a3e8316f5fbe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc094bfdb90>]}
[0m09:15:24.009688 [info ] [MainThread]: Found 8 models, 8 sources, 489 macros
[0m09:15:24.011432 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b51408eb-f3bc-4261-85fb-a3e8316f5fbe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0950ebd90>]}
[0m09:15:24.013905 [info ] [MainThread]: 
[0m09:15:24.015111 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m09:15:24.016133 [info ] [MainThread]: 
[0m09:15:24.017362 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m09:15:24.019457 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m09:15:24.020690 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:15:24.638874 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_facts)
[0m09:15:24.639881 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_marts'
[0m09:15:24.640712 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_staging'
[0m09:15:24.641414 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m09:15:24.642228 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:15:24.643266 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:15:24.881927 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b51408eb-f3bc-4261-85fb-a3e8316f5fbe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc094d39210>]}
[0m09:15:24.882988 [debug] [MainThread]: Opening a new connection, currently in state init
[0m09:15:24.888882 [debug] [Thread-1 (]: Began running node model.hailing_project.mart_cust_rides_daily
[0m09:15:24.889873 [info ] [Thread-1 (]: 1 of 1 START sql table model rizky_dwh_hailing_marts.mart_cust_rides_daily ..... [RUN]
[0m09:15:24.891115 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_staging, now model.hailing_project.mart_cust_rides_daily)
[0m09:15:24.892291 [debug] [Thread-1 (]: Began compiling node model.hailing_project.mart_cust_rides_daily
[0m09:15:24.903242 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.mart_cust_rides_daily"
[0m09:15:24.910348 [debug] [Thread-1 (]: Began executing node model.hailing_project.mart_cust_rides_daily
[0m09:15:24.953019 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.mart_cust_rides_daily"
[0m09:15:24.959105 [debug] [Thread-1 (]: On model.hailing_project.mart_cust_rides_daily: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.mart_cust_rides_daily"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_marts`.`mart_cust_rides_daily`
      
    partition by ride_date
    

    OPTIONS()
    as (
      


WITH fact_rides AS(

    SELECT * 
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
)

SELECT 

    fact_rides.cust_id,
    DATE(fact_rides.created_at) AS ride_date,
    fact_rides.cust_name,
    fact_rides.cust_email,
    fact_rides.cust_phone_number,
    COUNT(fact_rides.ride_id) AS no_of_rides,
    SUM(TIMESTAMP_DIFF(fact_rides.ride_end_time, fact_rides.ride_start_time, MINUTE)) AS total_ride_duration_min,
    SUM(fact_rides.fare) AS total_fare,
    SUM(fact_rides.distance_km) as total_distance_km,
    SUM(fact_rides.distance_km)-SUM(fact_rides.fare) AS rev_opportunity_loss

FROM fact_rides
GROUP BY cust_name, cust_id, ride_date, cust_email, cust_phone_number
    );
  
[0m09:15:24.960125 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m09:15:25.439092 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:a3769b87-0114-4acb-827f-235d0115f1c1&page=queryresults
[0m09:15:27.394152 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b51408eb-f3bc-4261-85fb-a3e8316f5fbe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc08cf70710>]}
[0m09:15:27.395325 [info ] [Thread-1 (]: 1 of 1 OK created sql table model rizky_dwh_hailing_marts.mart_cust_rides_daily  [[32mCREATE TABLE (69.0 rows, 10.2 KiB processed)[0m in 2.50s]
[0m09:15:27.397005 [debug] [Thread-1 (]: Finished running node model.hailing_project.mart_cust_rides_daily
[0m09:15:27.399173 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m09:15:27.402343 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:15:27.403111 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_facts' was properly closed.
[0m09:15:27.403879 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_marts' was properly closed.
[0m09:15:27.404617 [debug] [MainThread]: Connection 'model.hailing_project.mart_cust_rides_daily' was properly closed.
[0m09:15:27.405322 [info ] [MainThread]: 
[0m09:15:27.406250 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 3.39 seconds (3.39s).
[0m09:15:27.408595 [debug] [MainThread]: Command end result
[0m09:15:27.446829 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m09:15:27.454428 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m09:15:27.462457 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m09:15:27.463447 [info ] [MainThread]: 
[0m09:15:27.464707 [info ] [MainThread]: [32mCompleted successfully[0m
[0m09:15:27.465723 [info ] [MainThread]: 
[0m09:15:27.466647 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m09:15:27.468138 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 4.5703964, "process_in_blocks": "0", "process_kernel_time": 0.201071, "process_mem_max_rss": "218516", "process_out_blocks": "0", "process_user_time": 3.237246}
[0m09:15:27.469081 [debug] [MainThread]: Command `dbt run` succeeded at 09:15:27.468974 after 4.57 seconds
[0m09:15:27.470040 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0bee8e2d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0bee8c2d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0c25fcd50>]}
[0m09:15:27.470976 [debug] [MainThread]: Flushing usage events
[0m09:15:28.698497 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m09:29:50.103488 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f83f6d36ad0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f83f6d37810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f83f6d37850>]}


============================== 09:29:50.105978 | 42027b59-01c4-4da6-9c27-8153887c6fff ==============================
[0m09:29:50.105978 [info ] [MainThread]: Running with dbt=1.9.0
[0m09:29:50.108701 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt run --select mart_cust_rides_daily', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m09:29:50.735337 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '42027b59-01c4-4da6-9c27-8153887c6fff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f83ceaa6dd0>]}
[0m09:29:50.779419 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '42027b59-01c4-4da6-9c27-8153887c6fff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f83f8faa590>]}
[0m09:29:50.780706 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m09:29:50.843698 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m09:29:51.029347 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m09:29:51.030687 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/marts/mart_cust_rides_daily.sql
[0m09:29:51.275092 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '42027b59-01c4-4da6-9c27-8153887c6fff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f83cceaf390>]}
[0m09:29:51.344908 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m09:29:51.352037 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m09:29:51.369579 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '42027b59-01c4-4da6-9c27-8153887c6fff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f83c71475d0>]}
[0m09:29:51.370635 [info ] [MainThread]: Found 8 models, 8 sources, 489 macros
[0m09:29:51.371829 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '42027b59-01c4-4da6-9c27-8153887c6fff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f83ccb471d0>]}
[0m09:29:51.374154 [info ] [MainThread]: 
[0m09:29:51.375419 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m09:29:51.376410 [info ] [MainThread]: 
[0m09:29:51.377620 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m09:29:51.379281 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m09:29:51.380473 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:29:52.018529 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_staging)
[0m09:29:52.019246 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_facts'
[0m09:29:52.019855 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_marts'
[0m09:29:52.022032 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m09:29:52.023478 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:29:52.024440 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:29:52.304251 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '42027b59-01c4-4da6-9c27-8153887c6fff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f83cd01b910>]}
[0m09:29:52.306119 [debug] [MainThread]: Opening a new connection, currently in state init
[0m09:29:52.311108 [debug] [Thread-1 (]: Began running node model.hailing_project.mart_cust_rides_daily
[0m09:29:52.312470 [info ] [Thread-1 (]: 1 of 1 START sql table model rizky_dwh_hailing_marts.mart_cust_rides_daily ..... [RUN]
[0m09:29:52.314605 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_marts, now model.hailing_project.mart_cust_rides_daily)
[0m09:29:52.316294 [debug] [Thread-1 (]: Began compiling node model.hailing_project.mart_cust_rides_daily
[0m09:29:52.323710 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.mart_cust_rides_daily"
[0m09:29:52.329995 [debug] [Thread-1 (]: Began executing node model.hailing_project.mart_cust_rides_daily
[0m09:29:52.369097 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.mart_cust_rides_daily"
[0m09:29:52.374843 [debug] [Thread-1 (]: On model.hailing_project.mart_cust_rides_daily: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.mart_cust_rides_daily"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_marts`.`mart_cust_rides_daily`
      
    partition by ride_date
    

    OPTIONS()
    as (
      


WITH fact_rides AS(

    SELECT * 
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
)

SELECT 

    fact_rides.cust_id,
    DATE(fact_rides.created_at) AS ride_date,
    fact_rides.cust_name,
    fact_rides.cust_email,
    fact_rides.cust_phone_number,
    COUNT(fact_rides.ride_id) AS no_of_rides,
    SUM(TIMESTAMP_DIFF(fact_rides.ride_end_time, fact_rides.ride_start_time, MINUTE)) AS total_ride_duration_min,
    SUM(fact_rides.fare) AS total_fare,
    SUM(fact_rides.distance_km) as total_distance_km,
    SUM(fact_rides.distance_km)-SUM(fact_rides.fare) AS rev_opportunity_loss,
    fact_rides.ride_status

FROM fact_rides
GROUP BY cust_name, cust_id, ride_date, cust_email, cust_phone_number
    );
  
[0m09:29:52.375990 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m09:29:52.813927 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:8cf8914c-8627-491d-b3ed-fd47ff7edd56&page=queryresults
[0m09:29:52.946181 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:8cf8914c-8627-491d-b3ed-fd47ff7edd56&page=queryresults
[0m09:29:52.951299 [debug] [Thread-1 (]: Database Error in model mart_cust_rides_daily (models/marts/mart_cust_rides_daily.sql)
  SELECT list expression references fact_rides.ride_status which is neither grouped nor aggregated at [34:5]
  compiled code at target/run/hailing_project/models/marts/mart_cust_rides_daily.sql
[0m09:29:52.953199 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '42027b59-01c4-4da6-9c27-8153887c6fff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f83c71ce790>]}
[0m09:29:52.954363 [error] [Thread-1 (]: 1 of 1 ERROR creating sql table model rizky_dwh_hailing_marts.mart_cust_rides_daily  [[31mERROR[0m in 0.64s]
[0m09:29:52.955389 [debug] [Thread-1 (]: Finished running node model.hailing_project.mart_cust_rides_daily
[0m09:29:52.956438 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.mart_cust_rides_daily' to be skipped because of status 'error'.  Reason: Database Error in model mart_cust_rides_daily (models/marts/mart_cust_rides_daily.sql)
  SELECT list expression references fact_rides.ride_status which is neither grouped nor aggregated at [34:5]
  compiled code at target/run/hailing_project/models/marts/mart_cust_rides_daily.sql.
[0m09:29:52.958817 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m09:29:52.961370 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:29:52.962093 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_staging' was properly closed.
[0m09:29:52.962673 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_facts' was properly closed.
[0m09:29:52.963507 [debug] [MainThread]: Connection 'model.hailing_project.mart_cust_rides_daily' was properly closed.
[0m09:29:52.964496 [info ] [MainThread]: 
[0m09:29:52.965635 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 1.59 seconds (1.59s).
[0m09:29:52.967528 [debug] [MainThread]: Command end result
[0m09:29:53.002490 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m09:29:53.006859 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m09:29:53.014123 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m09:29:53.014852 [info ] [MainThread]: 
[0m09:29:53.015835 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m09:29:53.016750 [info ] [MainThread]: 
[0m09:29:53.017664 [error] [MainThread]:   Database Error in model mart_cust_rides_daily (models/marts/mart_cust_rides_daily.sql)
  SELECT list expression references fact_rides.ride_status which is neither grouped nor aggregated at [34:5]
  compiled code at target/run/hailing_project/models/marts/mart_cust_rides_daily.sql
[0m09:29:53.018637 [info ] [MainThread]: 
[0m09:29:53.019626 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m09:29:53.021842 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 2.9676523, "process_in_blocks": "0", "process_kernel_time": 0.215047, "process_mem_max_rss": "220920", "process_out_blocks": "0", "process_user_time": 3.379318}
[0m09:29:53.023124 [debug] [MainThread]: Command `dbt run` failed at 09:29:53.022968 after 2.97 seconds
[0m09:29:53.024108 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f83fa6b1350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f83fa6b1310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f83cccec3d0>]}
[0m09:29:53.024947 [debug] [MainThread]: Flushing usage events
[0m09:29:54.332375 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m09:30:29.175276 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f98d9feea90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f98da047950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f98da3ea490>]}


============================== 09:30:29.177676 | 26e3e6d9-6fb9-4e47-b0fe-bd6862b8694a ==============================
[0m09:30:29.177676 [info ] [MainThread]: Running with dbt=1.9.0
[0m09:30:29.180515 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt run --select mart_cust_rides_daily', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m09:30:29.749778 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '26e3e6d9-6fb9-4e47-b0fe-bd6862b8694a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f98b037bb50>]}
[0m09:30:29.796823 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '26e3e6d9-6fb9-4e47-b0fe-bd6862b8694a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f98b02d7750>]}
[0m09:30:29.798011 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m09:30:29.864063 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m09:30:30.052349 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m09:30:30.053501 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/marts/mart_cust_rides_daily.sql
[0m09:30:30.299651 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '26e3e6d9-6fb9-4e47-b0fe-bd6862b8694a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f98abe174d0>]}
[0m09:30:30.370090 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m09:30:30.375918 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m09:30:30.390013 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '26e3e6d9-6fb9-4e47-b0fe-bd6862b8694a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f98aa432a50>]}
[0m09:30:30.391218 [info ] [MainThread]: Found 8 models, 8 sources, 489 macros
[0m09:30:30.392480 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '26e3e6d9-6fb9-4e47-b0fe-bd6862b8694a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f98abdc4690>]}
[0m09:30:30.394908 [info ] [MainThread]: 
[0m09:30:30.395903 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m09:30:30.396893 [info ] [MainThread]: 
[0m09:30:30.397960 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m09:30:30.399604 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m09:30:30.400870 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:30:30.953686 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_marts)
[0m09:30:30.954333 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_staging'
[0m09:30:30.954914 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_facts'
[0m09:30:30.955765 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m09:30:30.956568 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:30:30.957484 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:30:31.242567 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '26e3e6d9-6fb9-4e47-b0fe-bd6862b8694a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f98d9ff7190>]}
[0m09:30:31.243719 [debug] [MainThread]: Opening a new connection, currently in state init
[0m09:30:31.248213 [debug] [Thread-1 (]: Began running node model.hailing_project.mart_cust_rides_daily
[0m09:30:31.249504 [info ] [Thread-1 (]: 1 of 1 START sql table model rizky_dwh_hailing_marts.mart_cust_rides_daily ..... [RUN]
[0m09:30:31.252443 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_facts, now model.hailing_project.mart_cust_rides_daily)
[0m09:30:31.253415 [debug] [Thread-1 (]: Began compiling node model.hailing_project.mart_cust_rides_daily
[0m09:30:31.262057 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.mart_cust_rides_daily"
[0m09:30:31.269200 [debug] [Thread-1 (]: Began executing node model.hailing_project.mart_cust_rides_daily
[0m09:30:31.307512 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.mart_cust_rides_daily"
[0m09:30:31.314262 [debug] [Thread-1 (]: On model.hailing_project.mart_cust_rides_daily: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.mart_cust_rides_daily"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_marts`.`mart_cust_rides_daily`
      
    partition by ride_date
    

    OPTIONS()
    as (
      


WITH fact_rides AS(

    SELECT * 
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
)

SELECT 

    fact_rides.cust_id,
    DATE(fact_rides.created_at) AS ride_date,
    fact_rides.cust_name,
    fact_rides.cust_email,
    fact_rides.cust_phone_number,
    COUNT(fact_rides.ride_id) AS no_of_rides,
    SUM(TIMESTAMP_DIFF(fact_rides.ride_end_time, fact_rides.ride_start_time, MINUTE)) AS total_ride_duration_min,
    SUM(fact_rides.fare) AS total_fare,
    SUM(fact_rides.distance_km) as total_distance_km,
    SUM(fact_rides.distance_km)-SUM(fact_rides.fare) AS rev_opportunity_loss,
    fact_rides.ride_status

FROM fact_rides
GROUP BY cust_name, cust_id, ride_date, cust_email, cust_phone_number, ride_status
    );
  
[0m09:30:31.315126 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m09:30:31.697081 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:693dce65-abab-4092-a459-624401e6702c&page=queryresults
[0m09:30:33.568750 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '26e3e6d9-6fb9-4e47-b0fe-bd6862b8694a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f98b04a9190>]}
[0m09:30:33.570192 [info ] [Thread-1 (]: 1 of 1 OK created sql table model rizky_dwh_hailing_marts.mart_cust_rides_daily  [[32mCREATE TABLE (73.0 rows, 11.2 KiB processed)[0m in 2.32s]
[0m09:30:33.571502 [debug] [Thread-1 (]: Finished running node model.hailing_project.mart_cust_rides_daily
[0m09:30:33.573430 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m09:30:33.576185 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:30:33.576952 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_marts' was properly closed.
[0m09:30:33.577602 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_staging' was properly closed.
[0m09:30:33.578205 [debug] [MainThread]: Connection 'model.hailing_project.mart_cust_rides_daily' was properly closed.
[0m09:30:33.578918 [info ] [MainThread]: 
[0m09:30:33.579764 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 3.18 seconds (3.18s).
[0m09:30:33.581435 [debug] [MainThread]: Command end result
[0m09:30:33.615725 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m09:30:33.620441 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m09:30:33.628357 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m09:30:33.629155 [info ] [MainThread]: 
[0m09:30:33.630178 [info ] [MainThread]: [32mCompleted successfully[0m
[0m09:30:33.631133 [info ] [MainThread]: 
[0m09:30:33.632097 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m09:30:33.633585 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 4.508024, "process_in_blocks": "0", "process_kernel_time": 0.268608, "process_mem_max_rss": "222512", "process_out_blocks": "0", "process_user_time": 3.26463}
[0m09:30:33.634454 [debug] [MainThread]: Command `dbt run` succeeded at 09:30:33.634349 after 4.51 seconds
[0m09:30:33.635232 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f98da4a8490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f98da048790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f98dd907e50>]}
[0m09:30:33.636014 [debug] [MainThread]: Flushing usage events
[0m09:30:34.844958 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m09:43:07.493268 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9a22023890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9a21fcaf90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9a21fcb450>]}


============================== 09:43:07.496293 | 2992e264-4f65-4772-8819-ff50c2d7c2db ==============================
[0m09:43:07.496293 [info ] [MainThread]: Running with dbt=1.9.0
[0m09:43:07.497454 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'profiles_dir': '/usr/app/dbt_project', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'invocation_command': 'dbt run --select mart_driver_loyalty_mgmt', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m09:43:08.049370 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '2992e264-4f65-4772-8819-ff50c2d7c2db', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f99f8157cd0>]}
[0m09:43:08.094489 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '2992e264-4f65-4772-8819-ff50c2d7c2db', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f99f97e4f10>]}
[0m09:43:08.095657 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m09:43:08.160132 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m09:43:08.351866 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m09:43:08.352928 [debug] [MainThread]: Partial parsing: added file: hailing_project://models/marts/mart_driver_loyalty_mgmt.sql
[0m09:43:08.604331 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2992e264-4f65-4772-8819-ff50c2d7c2db', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f99f3d78210>]}
[0m09:43:08.670773 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m09:43:08.676582 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m09:43:08.697659 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2992e264-4f65-4772-8819-ff50c2d7c2db', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f99f2403b50>]}
[0m09:43:08.699146 [info ] [MainThread]: Found 9 models, 8 sources, 489 macros
[0m09:43:08.701580 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2992e264-4f65-4772-8819-ff50c2d7c2db', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f99f3df8d50>]}
[0m09:43:08.705334 [info ] [MainThread]: 
[0m09:43:08.707534 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m09:43:08.709885 [info ] [MainThread]: 
[0m09:43:08.712204 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m09:43:08.714317 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m09:43:08.715658 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:43:09.332458 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_marts)
[0m09:43:09.333068 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_staging'
[0m09:43:09.333684 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_facts'
[0m09:43:09.334609 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m09:43:09.335907 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:43:09.336983 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:43:09.620691 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2992e264-4f65-4772-8819-ff50c2d7c2db', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9a22011b90>]}
[0m09:43:09.621744 [debug] [MainThread]: Opening a new connection, currently in state init
[0m09:43:09.626710 [debug] [Thread-1 (]: Began running node model.hailing_project.mart_driver_loyalty_mgmt
[0m09:43:09.627799 [info ] [Thread-1 (]: 1 of 1 START sql incremental model rizky_dwh_hailing_marts.mart_driver_loyalty_mgmt  [RUN]
[0m09:43:09.628822 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_facts, now model.hailing_project.mart_driver_loyalty_mgmt)
[0m09:43:09.629693 [debug] [Thread-1 (]: Began compiling node model.hailing_project.mart_driver_loyalty_mgmt
[0m09:43:09.637992 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.mart_driver_loyalty_mgmt"
[0m09:43:09.644857 [debug] [Thread-1 (]: Began executing node model.hailing_project.mart_driver_loyalty_mgmt
[0m09:43:09.703857 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.mart_driver_loyalty_mgmt"
[0m09:43:09.710231 [debug] [Thread-1 (]: On model.hailing_project.mart_driver_loyalty_mgmt: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.mart_driver_loyalty_mgmt"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_marts`.`mart_driver_loyalty_mgmt`
      
    
    

    OPTIONS()
    as (
      

WITH dim_driver AS(
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
),

fact_rides AS(
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
)

SELECT 
dim_driver.driver_id,
dim_driver.driver_name,
dim_driver.phone_number,
dim_driver.email,
dim_driver.vehicle_type,
COUNT(fact_rides.ride_id) AS no_of_rides,
SUM(TIMESTAMP_DIFF(fact_rides.ride_end_time, fact_rides.ride_start_time, MINUTE)) AS total_ride_duration_min,
SUM(fact_rides.fare) AS total_fare,
SUM(fact_rides.distance_km) as total_distance_km,
SUM(fact_rides.distance_km)-SUM(fact_rides.fare) AS rev_opportunity_loss
SUM(fact_rides.ride_status) AS ride_status

FROM dim_driver
LEFT JOIN fact_rides
ON dim_driver.driver_id = fact_rides.driver_id

GROUP BY driver_id,driver_name,phone_number,email,vehicle_type
    );
  
[0m09:43:09.711343 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m09:43:10.242148 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:dec16880-f405-4f73-92c8-3ca5cd4f32ac&page=queryresults
[0m09:43:10.244112 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:dec16880-f405-4f73-92c8-3ca5cd4f32ac&page=queryresults
[0m09:43:10.248963 [debug] [Thread-1 (]: Database Error in model mart_driver_loyalty_mgmt (models/marts/mart_driver_loyalty_mgmt.sql)
  Syntax error: Expected ")" but got identifier "SUM" at [36:1]
  compiled code at target/run/hailing_project/models/marts/mart_driver_loyalty_mgmt.sql
[0m09:43:10.251287 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2992e264-4f65-4772-8819-ff50c2d7c2db', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f99f24ea510>]}
[0m09:43:10.252807 [error] [Thread-1 (]: 1 of 1 ERROR creating sql incremental model rizky_dwh_hailing_marts.mart_driver_loyalty_mgmt  [[31mERROR[0m in 0.62s]
[0m09:43:10.254686 [debug] [Thread-1 (]: Finished running node model.hailing_project.mart_driver_loyalty_mgmt
[0m09:43:10.257765 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.mart_driver_loyalty_mgmt' to be skipped because of status 'error'.  Reason: Database Error in model mart_driver_loyalty_mgmt (models/marts/mart_driver_loyalty_mgmt.sql)
  Syntax error: Expected ")" but got identifier "SUM" at [36:1]
  compiled code at target/run/hailing_project/models/marts/mart_driver_loyalty_mgmt.sql.
[0m09:43:10.261506 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m09:43:10.264976 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:43:10.265948 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_marts' was properly closed.
[0m09:43:10.266791 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_staging' was properly closed.
[0m09:43:10.267596 [debug] [MainThread]: Connection 'model.hailing_project.mart_driver_loyalty_mgmt' was properly closed.
[0m09:43:10.268328 [info ] [MainThread]: 
[0m09:43:10.269296 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 1.56 seconds (1.56s).
[0m09:43:10.270761 [debug] [MainThread]: Command end result
[0m09:43:10.306996 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m09:43:10.311656 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m09:43:10.320287 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m09:43:10.321340 [info ] [MainThread]: 
[0m09:43:10.322551 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m09:43:10.323748 [info ] [MainThread]: 
[0m09:43:10.325080 [error] [MainThread]:   Database Error in model mart_driver_loyalty_mgmt (models/marts/mart_driver_loyalty_mgmt.sql)
  Syntax error: Expected ")" but got identifier "SUM" at [36:1]
  compiled code at target/run/hailing_project/models/marts/mart_driver_loyalty_mgmt.sql
[0m09:43:10.326264 [info ] [MainThread]: 
[0m09:43:10.327631 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m09:43:10.329804 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 2.887706, "process_in_blocks": "0", "process_kernel_time": 0.242152, "process_mem_max_rss": "219212", "process_out_blocks": "0", "process_user_time": 3.238783}
[0m09:43:10.330983 [debug] [MainThread]: Command `dbt run` failed at 09:43:10.330735 after 2.89 seconds
[0m09:43:10.331990 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9a21e4ba10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9a21e4b790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f99f8127c50>]}
[0m09:43:10.333001 [debug] [MainThread]: Flushing usage events
[0m09:43:11.623730 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m09:43:34.287557 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1ad4ec3b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1ad534b950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1ad4e6fad0>]}


============================== 09:43:34.290183 | 1e472720-eb94-4c6e-94d2-919ebd315f05 ==============================
[0m09:43:34.290183 [info ] [MainThread]: Running with dbt=1.9.0
[0m09:43:34.292860 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt run --select mart_driver_loyalt_mgmt', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m09:43:34.870804 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1e472720-eb94-4c6e-94d2-919ebd315f05', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1aa7175c10>]}
[0m09:43:34.914953 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '1e472720-eb94-4c6e-94d2-919ebd315f05', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1ad70f1890>]}
[0m09:43:34.916144 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m09:43:34.987365 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m09:43:35.154295 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m09:43:35.155487 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/marts/mart_driver_loyalty_mgmt.sql
[0m09:43:35.400569 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1e472720-eb94-4c6e-94d2-919ebd315f05', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1aa6d28910>]}
[0m09:43:35.473461 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m09:43:35.478570 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m09:43:35.493480 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1e472720-eb94-4c6e-94d2-919ebd315f05', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1aa6c90450>]}
[0m09:43:35.494677 [info ] [MainThread]: Found 9 models, 8 sources, 489 macros
[0m09:43:35.496270 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1e472720-eb94-4c6e-94d2-919ebd315f05', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1aa71a69d0>]}
[0m09:43:35.498255 [warn ] [MainThread]: The selection criterion 'mart_driver_loyalt_mgmt' does not match any enabled nodes
[0m09:43:35.500661 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m09:43:35.502302 [debug] [MainThread]: Command end result
[0m09:43:35.534699 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m09:43:35.539081 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m09:43:35.544794 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m09:43:35.546059 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 1.303069, "process_in_blocks": "0", "process_kernel_time": 0.25335, "process_mem_max_rss": "216540", "process_out_blocks": "0", "process_user_time": 3.060472}
[0m09:43:35.547244 [debug] [MainThread]: Command `dbt run` succeeded at 09:43:35.547012 after 1.30 seconds
[0m09:43:35.548042 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1ad4f79e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1ad4ec3a50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1ad874a790>]}
[0m09:43:35.548968 [debug] [MainThread]: Flushing usage events
[0m09:43:36.576000 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m09:43:44.922180 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbe2c8c3090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbe2c913a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbe2c8c39d0>]}


============================== 09:43:44.924697 | bae00e28-b8da-4e57-836b-61b1b0aa881b ==============================
[0m09:43:44.924697 [info ] [MainThread]: Running with dbt=1.9.0
[0m09:43:44.926292 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'invocation_command': 'dbt run --select mart_driver_loyalty_mgmt', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m09:43:45.512185 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'bae00e28-b8da-4e57-836b-61b1b0aa881b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbdfeb27910>]}
[0m09:43:45.559871 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'bae00e28-b8da-4e57-836b-61b1b0aa881b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbe04ee0f10>]}
[0m09:43:45.561197 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m09:43:45.626541 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m09:43:45.809853 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m09:43:45.811679 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m09:43:45.838950 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'bae00e28-b8da-4e57-836b-61b1b0aa881b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbdfe79db90>]}
[0m09:43:45.960628 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m09:43:45.966577 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m09:43:45.982351 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'bae00e28-b8da-4e57-836b-61b1b0aa881b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbdfe851c10>]}
[0m09:43:45.983598 [info ] [MainThread]: Found 9 models, 8 sources, 489 macros
[0m09:43:45.984717 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'bae00e28-b8da-4e57-836b-61b1b0aa881b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbdff030d90>]}
[0m09:43:45.987246 [info ] [MainThread]: 
[0m09:43:45.988293 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m09:43:45.989387 [info ] [MainThread]: 
[0m09:43:45.990832 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m09:43:45.992632 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m09:43:45.993576 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:43:46.574054 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_marts)
[0m09:43:46.574643 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_facts'
[0m09:43:46.575132 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_staging'
[0m09:43:46.575729 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m09:43:46.577573 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:43:46.578842 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:43:46.859651 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'bae00e28-b8da-4e57-836b-61b1b0aa881b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbdfeb78610>]}
[0m09:43:46.861297 [debug] [MainThread]: Opening a new connection, currently in state init
[0m09:43:46.866326 [debug] [Thread-1 (]: Began running node model.hailing_project.mart_driver_loyalty_mgmt
[0m09:43:46.869577 [info ] [Thread-1 (]: 1 of 1 START sql incremental model rizky_dwh_hailing_marts.mart_driver_loyalty_mgmt  [RUN]
[0m09:43:46.871712 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_staging, now model.hailing_project.mart_driver_loyalty_mgmt)
[0m09:43:46.872960 [debug] [Thread-1 (]: Began compiling node model.hailing_project.mart_driver_loyalty_mgmt
[0m09:43:46.881058 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.mart_driver_loyalty_mgmt"
[0m09:43:46.889013 [debug] [Thread-1 (]: Began executing node model.hailing_project.mart_driver_loyalty_mgmt
[0m09:43:46.944970 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.mart_driver_loyalty_mgmt"
[0m09:43:46.951412 [debug] [Thread-1 (]: On model.hailing_project.mart_driver_loyalty_mgmt: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.mart_driver_loyalty_mgmt"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_marts`.`mart_driver_loyalty_mgmt`
      
    
    

    OPTIONS()
    as (
      

WITH dim_driver AS(
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
),

fact_rides AS(
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
)

SELECT 
dim_driver.driver_id,
dim_driver.driver_name,
dim_driver.phone_number,
dim_driver.email,
dim_driver.vehicle_type,
COUNT(fact_rides.ride_id) AS no_of_rides,
SUM(TIMESTAMP_DIFF(fact_rides.ride_end_time, fact_rides.ride_start_time, MINUTE)) AS total_ride_duration_min,
SUM(fact_rides.fare) AS total_fare,
SUM(fact_rides.distance_km) as total_distance_km,
SUM(fact_rides.distance_km)-SUM(fact_rides.fare) AS rev_opportunity_loss,
SUM(fact_rides.ride_status) AS ride_status

FROM dim_driver
LEFT JOIN fact_rides
ON dim_driver.driver_id = fact_rides.driver_id

GROUP BY driver_id,driver_name,phone_number,email,vehicle_type
    );
  
[0m09:43:46.952523 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m09:43:47.412983 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:333f79e0-6045-4f42-8317-824b23f5953b&page=queryresults
[0m09:43:47.498413 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:333f79e0-6045-4f42-8317-824b23f5953b&page=queryresults
[0m09:43:47.502941 [debug] [Thread-1 (]: Database Error in model mart_driver_loyalty_mgmt (models/marts/mart_driver_loyalty_mgmt.sql)
  No matching signature for aggregate function SUM
    Argument types: STRING
    Signature: SUM(INT64)
      Argument 1: Unable to coerce type STRING to expected type INT64
    Signature: SUM(FLOAT64)
      Argument 1: Unable to coerce type STRING to expected type FLOAT64
    Signature: SUM(NUMERIC)
      Argument 1: Unable to coerce type STRING to expected type NUMERIC
    Signature: SUM(BIGNUMERIC)
      Argument 1: Unable to coerce type STRING to expected type BIGNUMERIC
    Signature: SUM(INTERVAL)
      Argument 1: Unable to coerce type STRING to expected type INTERVAL at [36:1]
  compiled code at target/run/hailing_project/models/marts/mart_driver_loyalty_mgmt.sql
[0m09:43:47.505380 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bae00e28-b8da-4e57-836b-61b1b0aa881b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbdfea597d0>]}
[0m09:43:47.506615 [error] [Thread-1 (]: 1 of 1 ERROR creating sql incremental model rizky_dwh_hailing_marts.mart_driver_loyalty_mgmt  [[31mERROR[0m in 0.63s]
[0m09:43:47.508056 [debug] [Thread-1 (]: Finished running node model.hailing_project.mart_driver_loyalty_mgmt
[0m09:43:47.509210 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.mart_driver_loyalty_mgmt' to be skipped because of status 'error'.  Reason: Database Error in model mart_driver_loyalty_mgmt (models/marts/mart_driver_loyalty_mgmt.sql)
  No matching signature for aggregate function SUM
    Argument types: STRING
    Signature: SUM(INT64)
      Argument 1: Unable to coerce type STRING to expected type INT64
    Signature: SUM(FLOAT64)
      Argument 1: Unable to coerce type STRING to expected type FLOAT64
    Signature: SUM(NUMERIC)
      Argument 1: Unable to coerce type STRING to expected type NUMERIC
    Signature: SUM(BIGNUMERIC)
      Argument 1: Unable to coerce type STRING to expected type BIGNUMERIC
    Signature: SUM(INTERVAL)
      Argument 1: Unable to coerce type STRING to expected type INTERVAL at [36:1]
  compiled code at target/run/hailing_project/models/marts/mart_driver_loyalty_mgmt.sql.
[0m09:43:47.512511 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m09:43:47.515689 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:43:47.516657 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_marts' was properly closed.
[0m09:43:47.517520 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_facts' was properly closed.
[0m09:43:47.518170 [debug] [MainThread]: Connection 'model.hailing_project.mart_driver_loyalty_mgmt' was properly closed.
[0m09:43:47.519067 [info ] [MainThread]: 
[0m09:43:47.520317 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 1.53 seconds (1.53s).
[0m09:43:47.521711 [debug] [MainThread]: Command end result
[0m09:43:47.555925 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m09:43:47.559747 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m09:43:47.567431 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m09:43:47.568125 [info ] [MainThread]: 
[0m09:43:47.569069 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m09:43:47.570005 [info ] [MainThread]: 
[0m09:43:47.571024 [error] [MainThread]:   Database Error in model mart_driver_loyalty_mgmt (models/marts/mart_driver_loyalty_mgmt.sql)
  No matching signature for aggregate function SUM
    Argument types: STRING
    Signature: SUM(INT64)
      Argument 1: Unable to coerce type STRING to expected type INT64
    Signature: SUM(FLOAT64)
      Argument 1: Unable to coerce type STRING to expected type FLOAT64
    Signature: SUM(NUMERIC)
      Argument 1: Unable to coerce type STRING to expected type NUMERIC
    Signature: SUM(BIGNUMERIC)
      Argument 1: Unable to coerce type STRING to expected type BIGNUMERIC
    Signature: SUM(INTERVAL)
      Argument 1: Unable to coerce type STRING to expected type INTERVAL at [36:1]
  compiled code at target/run/hailing_project/models/marts/mart_driver_loyalty_mgmt.sql
[0m09:43:47.572048 [info ] [MainThread]: 
[0m09:43:47.573110 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m09:43:47.574780 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 2.6992533, "process_in_blocks": "0", "process_kernel_time": 0.265753, "process_mem_max_rss": "216828", "process_out_blocks": "0", "process_user_time": 3.219703}
[0m09:43:47.576029 [debug] [MainThread]: Command `dbt run` failed at 09:43:47.575846 after 2.70 seconds
[0m09:43:47.577025 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbe2c73ff50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbe2c73fa50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbe2c8c7f90>]}
[0m09:43:47.578092 [debug] [MainThread]: Flushing usage events
[0m09:43:48.772262 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m09:45:35.933672 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f99baf6ad10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f99bb366310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f99baf6b1d0>]}


============================== 09:45:35.937929 | fb1b9ae9-a67c-4724-9b68-50ebdcfe1a75 ==============================
[0m09:45:35.937929 [info ] [MainThread]: Running with dbt=1.9.0
[0m09:45:35.939133 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --select mart_driver_loyalty_mgmt', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m09:45:36.508551 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'fb1b9ae9-a67c-4724-9b68-50ebdcfe1a75', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f99bb686e50>]}
[0m09:45:36.557005 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'fb1b9ae9-a67c-4724-9b68-50ebdcfe1a75', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f999192b750>]}
[0m09:45:36.558226 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m09:45:36.621465 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m09:45:36.816551 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m09:45:36.817756 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/marts/mart_driver_loyalty_mgmt.sql
[0m09:45:37.068263 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'fb1b9ae9-a67c-4724-9b68-50ebdcfe1a75', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f99baf72d10>]}
[0m09:45:37.140448 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m09:45:37.145617 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m09:45:37.161464 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'fb1b9ae9-a67c-4724-9b68-50ebdcfe1a75', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f999007d710>]}
[0m09:45:37.162666 [info ] [MainThread]: Found 9 models, 8 sources, 489 macros
[0m09:45:37.163760 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'fb1b9ae9-a67c-4724-9b68-50ebdcfe1a75', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f99910f28d0>]}
[0m09:45:37.166109 [info ] [MainThread]: 
[0m09:45:37.167417 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m09:45:37.168416 [info ] [MainThread]: 
[0m09:45:37.169638 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m09:45:37.171532 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m09:45:37.172535 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:45:37.742826 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_facts)
[0m09:45:37.743456 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_staging'
[0m09:45:37.744007 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_marts'
[0m09:45:37.744648 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m09:45:37.745566 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:45:37.746372 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:45:38.068320 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'fb1b9ae9-a67c-4724-9b68-50ebdcfe1a75', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9990d5cd90>]}
[0m09:45:38.069231 [debug] [MainThread]: Opening a new connection, currently in state init
[0m09:45:38.074307 [debug] [Thread-1 (]: Began running node model.hailing_project.mart_driver_loyalty_mgmt
[0m09:45:38.075824 [info ] [Thread-1 (]: 1 of 1 START sql incremental model rizky_dwh_hailing_marts.mart_driver_loyalty_mgmt  [RUN]
[0m09:45:38.077197 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_staging, now model.hailing_project.mart_driver_loyalty_mgmt)
[0m09:45:38.078084 [debug] [Thread-1 (]: Began compiling node model.hailing_project.mart_driver_loyalty_mgmt
[0m09:45:38.086324 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.mart_driver_loyalty_mgmt"
[0m09:45:38.092586 [debug] [Thread-1 (]: Began executing node model.hailing_project.mart_driver_loyalty_mgmt
[0m09:45:38.150605 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.mart_driver_loyalty_mgmt"
[0m09:45:38.162578 [debug] [Thread-1 (]: On model.hailing_project.mart_driver_loyalty_mgmt: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.mart_driver_loyalty_mgmt"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_marts`.`mart_driver_loyalty_mgmt`
      
    
    

    OPTIONS()
    as (
      

WITH dim_driver AS(
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
),

fact_rides AS(
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
)

SELECT 
    dim_driver.driver_id,
    dim_driver.driver_name,
    dim_driver.phone_number,
    dim_driver.email,
    dim_driver.vehicle_type,
    COUNT(fact_rides.ride_id) AS no_of_rides,
    
    -- ✅ Ensure ride_end_time and ride_start_time are timestamps
    SUM(TIMESTAMP_DIFF(fact_rides.ride_end_time, fact_rides.ride_start_time, MINUTE)) AS total_ride_duration_min,

    -- ✅ Convert fare and distance_km to FLOAT64 before SUM()
    SUM(CAST(fact_rides.fare AS FLOAT64)) AS total_fare,
    SUM(CAST(fact_rides.distance_km AS FLOAT64)) AS total_distance_km,
    
    -- ✅ Use SUM() on converted FLOAT64 values
    SUM(CAST(fact_rides.distance_km AS FLOAT64)) - SUM(CAST(fact_rides.fare AS FLOAT64)) AS rev_opportunity_loss,

    -- ✅ Convert ride_status to INT64 before SUM()
    SUM(CAST(fact_rides.ride_status AS INT64)) AS total_ride_status

FROM dim_driver
LEFT JOIN fact_rides
ON dim_driver.driver_id = fact_rides.driver_id

GROUP BY dim_driver.driver_id, dim_driver.driver_name, dim_driver.phone_number, dim_driver.email, dim_driver.vehicle_type
    );
  
[0m09:45:38.163665 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m09:45:38.641037 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:004c98a8-bfd5-403e-a3f3-c1d75241bb54&page=queryresults
[0m09:45:38.809428 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:004c98a8-bfd5-403e-a3f3-c1d75241bb54&page=queryresults
[0m09:45:38.817173 [debug] [Thread-1 (]: Database Error in model mart_driver_loyalty_mgmt (models/marts/mart_driver_loyalty_mgmt.sql)
  Bad int64 value: Completed
  compiled code at target/run/hailing_project/models/marts/mart_driver_loyalty_mgmt.sql
[0m09:45:38.819244 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fb1b9ae9-a67c-4724-9b68-50ebdcfe1a75', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9990e12890>]}
[0m09:45:38.820447 [error] [Thread-1 (]: 1 of 1 ERROR creating sql incremental model rizky_dwh_hailing_marts.mart_driver_loyalty_mgmt  [[31mERROR[0m in 0.74s]
[0m09:45:38.821915 [debug] [Thread-1 (]: Finished running node model.hailing_project.mart_driver_loyalty_mgmt
[0m09:45:38.823495 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.mart_driver_loyalty_mgmt' to be skipped because of status 'error'.  Reason: Database Error in model mart_driver_loyalty_mgmt (models/marts/mart_driver_loyalty_mgmt.sql)
  Bad int64 value: Completed
  compiled code at target/run/hailing_project/models/marts/mart_driver_loyalty_mgmt.sql.
[0m09:45:38.826712 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m09:45:38.829701 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:45:38.830469 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_facts' was properly closed.
[0m09:45:38.831582 [debug] [MainThread]: Connection 'model.hailing_project.mart_driver_loyalty_mgmt' was properly closed.
[0m09:45:38.832894 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_marts' was properly closed.
[0m09:45:38.833783 [info ] [MainThread]: 
[0m09:45:38.834711 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 1.66 seconds (1.66s).
[0m09:45:38.836212 [debug] [MainThread]: Command end result
[0m09:45:38.872408 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m09:45:38.876284 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m09:45:38.884119 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m09:45:38.885024 [info ] [MainThread]: 
[0m09:45:38.886188 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m09:45:38.887558 [info ] [MainThread]: 
[0m09:45:38.888693 [error] [MainThread]:   Database Error in model mart_driver_loyalty_mgmt (models/marts/mart_driver_loyalty_mgmt.sql)
  Bad int64 value: Completed
  compiled code at target/run/hailing_project/models/marts/mart_driver_loyalty_mgmt.sql
[0m09:45:38.889591 [info ] [MainThread]: 
[0m09:45:38.890644 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m09:45:38.892479 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 3.0073342, "process_in_blocks": "0", "process_kernel_time": 0.22642, "process_mem_max_rss": "221936", "process_out_blocks": "0", "process_user_time": 3.283097}
[0m09:45:38.893754 [debug] [MainThread]: Command `dbt run` failed at 09:45:38.893539 after 3.01 seconds
[0m09:45:38.895134 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f99bafc6c50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f99bea958d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f99be9211d0>]}
[0m09:45:38.896181 [debug] [MainThread]: Flushing usage events
[0m09:45:40.205675 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m09:46:47.364737 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbd86c17810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbd86c6f610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbd86c6fcd0>]}


============================== 09:46:47.368057 | a9216cd2-2942-4c5a-835f-51a7fafa0d14 ==============================
[0m09:46:47.368057 [info ] [MainThread]: Running with dbt=1.9.0
[0m09:46:47.371650 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --select mart_driver_loyalty_mgmt', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m09:46:47.936989 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a9216cd2-2942-4c5a-835f-51a7fafa0d14', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbd5d550390>]}
[0m09:46:47.980296 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a9216cd2-2942-4c5a-835f-51a7fafa0d14', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbd88ec88d0>]}
[0m09:46:47.981673 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m09:46:48.049575 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m09:46:48.241899 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m09:46:48.243056 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/marts/mart_driver_loyalty_mgmt.sql
[0m09:46:48.489018 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a9216cd2-2942-4c5a-835f-51a7fafa0d14', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbd5cdb9910>]}
[0m09:46:48.562277 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m09:46:48.568039 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m09:46:48.583349 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a9216cd2-2942-4c5a-835f-51a7fafa0d14', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbd5c139b50>]}
[0m09:46:48.584504 [info ] [MainThread]: Found 9 models, 8 sources, 489 macros
[0m09:46:48.585612 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a9216cd2-2942-4c5a-835f-51a7fafa0d14', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbd5ca23650>]}
[0m09:46:48.587631 [info ] [MainThread]: 
[0m09:46:48.588720 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m09:46:48.589720 [info ] [MainThread]: 
[0m09:46:48.590810 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m09:46:48.592316 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m09:46:48.593252 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:46:49.203060 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_staging)
[0m09:46:49.203703 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_facts'
[0m09:46:49.204321 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_marts'
[0m09:46:49.205174 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m09:46:49.205953 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:46:49.206744 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:46:49.515318 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a9216cd2-2942-4c5a-835f-51a7fafa0d14', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbd5ca3ca90>]}
[0m09:46:49.517025 [debug] [MainThread]: Opening a new connection, currently in state init
[0m09:46:49.522059 [debug] [Thread-1 (]: Began running node model.hailing_project.mart_driver_loyalty_mgmt
[0m09:46:49.523586 [info ] [Thread-1 (]: 1 of 1 START sql incremental model rizky_dwh_hailing_marts.mart_driver_loyalty_mgmt  [RUN]
[0m09:46:49.525165 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_marts, now model.hailing_project.mart_driver_loyalty_mgmt)
[0m09:46:49.526707 [debug] [Thread-1 (]: Began compiling node model.hailing_project.mart_driver_loyalty_mgmt
[0m09:46:49.533772 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.mart_driver_loyalty_mgmt"
[0m09:46:49.539605 [debug] [Thread-1 (]: Began executing node model.hailing_project.mart_driver_loyalty_mgmt
[0m09:46:49.595247 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.mart_driver_loyalty_mgmt"
[0m09:46:49.600535 [debug] [Thread-1 (]: On model.hailing_project.mart_driver_loyalty_mgmt: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.mart_driver_loyalty_mgmt"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_marts`.`mart_driver_loyalty_mgmt`
      
    
    

    OPTIONS()
    as (
      

WITH dim_driver AS(
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
),

fact_rides AS(
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
)

SELECT 
    dim_driver.driver_id,
    dim_driver.driver_name,
    dim_driver.phone_number,
    dim_driver.email,
    dim_driver.vehicle_type,
    COUNT(fact_rides.ride_id) AS no_of_rides,
    
    -- ✅ Ensure ride_end_time and ride_start_time are timestamps
    SUM(TIMESTAMP_DIFF(fact_rides.ride_end_time, fact_rides.ride_start_time, MINUTE)) AS total_ride_duration_min,

    -- ✅ Convert fare and distance_km to FLOAT64 before SUM()
    SUM(CAST(fact_rides.fare AS NUMERIC)) AS total_fare,
    SUM(CAST(fact_rides.distance_km AS NUMERIC)) AS total_distance_km,
    
    -- ✅ Use SUM() on converted FLOAT64 values
    SUM(CAST(fact_rides.distance_km AS NUMERIC)) - SUM(CAST(fact_rides.fare AS FLOAT64)) AS rev_opportunity_loss,

    -- ✅ Convert ride_status to INT64 before SUM()
    SUM(CAST(fact_rides.ride_status AS TEXT)) AS total_ride_status

FROM dim_driver
LEFT JOIN fact_rides
ON dim_driver.driver_id = fact_rides.driver_id

GROUP BY dim_driver.driver_id, dim_driver.driver_name, dim_driver.phone_number, dim_driver.email, dim_driver.vehicle_type
    );
  
[0m09:46:49.601581 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m09:46:50.088359 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:7b6fae82-6fc4-4fb2-a1d0-552ecfc09508&page=queryresults
[0m09:46:50.229554 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:7b6fae82-6fc4-4fb2-a1d0-552ecfc09508&page=queryresults
[0m09:46:50.235238 [debug] [Thread-1 (]: Database Error in model mart_driver_loyalty_mgmt (models/marts/mart_driver_loyalty_mgmt.sql)
  Type not found: TEXT at [44:40]
  compiled code at target/run/hailing_project/models/marts/mart_driver_loyalty_mgmt.sql
[0m09:46:50.236940 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a9216cd2-2942-4c5a-835f-51a7fafa0d14', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbd5c1926d0>]}
[0m09:46:50.238077 [error] [Thread-1 (]: 1 of 1 ERROR creating sql incremental model rizky_dwh_hailing_marts.mart_driver_loyalty_mgmt  [[31mERROR[0m in 0.71s]
[0m09:46:50.239684 [debug] [Thread-1 (]: Finished running node model.hailing_project.mart_driver_loyalty_mgmt
[0m09:46:50.243467 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.mart_driver_loyalty_mgmt' to be skipped because of status 'error'.  Reason: Database Error in model mart_driver_loyalty_mgmt (models/marts/mart_driver_loyalty_mgmt.sql)
  Type not found: TEXT at [44:40]
  compiled code at target/run/hailing_project/models/marts/mart_driver_loyalty_mgmt.sql.
[0m09:46:50.247125 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m09:46:50.251125 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:46:50.252004 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_staging' was properly closed.
[0m09:46:50.252779 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_facts' was properly closed.
[0m09:46:50.253563 [debug] [MainThread]: Connection 'model.hailing_project.mart_driver_loyalty_mgmt' was properly closed.
[0m09:46:50.254450 [info ] [MainThread]: 
[0m09:46:50.255346 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 1.66 seconds (1.66s).
[0m09:46:50.256648 [debug] [MainThread]: Command end result
[0m09:46:50.290939 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m09:46:50.295469 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m09:46:50.303698 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m09:46:50.304589 [info ] [MainThread]: 
[0m09:46:50.305624 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m09:46:50.306554 [info ] [MainThread]: 
[0m09:46:50.307587 [error] [MainThread]:   Database Error in model mart_driver_loyalty_mgmt (models/marts/mart_driver_loyalty_mgmt.sql)
  Type not found: TEXT at [44:40]
  compiled code at target/run/hailing_project/models/marts/mart_driver_loyalty_mgmt.sql
[0m09:46:50.308410 [info ] [MainThread]: 
[0m09:46:50.309613 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m09:46:50.311866 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 3.0013442, "process_in_blocks": "0", "process_kernel_time": 0.24415, "process_mem_max_rss": "221852", "process_out_blocks": "0", "process_user_time": 3.306204}
[0m09:46:50.313442 [debug] [MainThread]: Command `dbt run` failed at 09:46:50.313217 after 3.00 seconds
[0m09:46:50.314786 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbd86c93990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbd86c93810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbd86c91190>]}
[0m09:46:50.316467 [debug] [MainThread]: Flushing usage events
[0m09:46:51.418236 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m09:47:11.190851 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe3db0c0f50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe3db0c2e90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe3db0c3550>]}


============================== 09:47:11.193582 | 950212f3-17d5-4c9d-abeb-928f8ffd9cad ==============================
[0m09:47:11.193582 [info ] [MainThread]: Running with dbt=1.9.0
[0m09:47:11.196102 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'version_check': 'True', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt run --select mart_driver_loyalty_mgmt', 'send_anonymous_usage_stats': 'True'}
[0m09:47:11.767496 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '950212f3-17d5-4c9d-abeb-928f8ffd9cad', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe3ada0d610>]}
[0m09:47:11.812052 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '950212f3-17d5-4c9d-abeb-928f8ffd9cad', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe3dd36ea50>]}
[0m09:47:11.813301 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m09:47:11.875676 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m09:47:12.058342 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m09:47:12.059235 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/marts/mart_driver_loyalty_mgmt.sql
[0m09:47:12.300454 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '950212f3-17d5-4c9d-abeb-928f8ffd9cad', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe3ad4646d0>]}
[0m09:47:12.372792 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m09:47:12.378608 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m09:47:12.393662 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '950212f3-17d5-4c9d-abeb-928f8ffd9cad', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe39f545e10>]}
[0m09:47:12.394929 [info ] [MainThread]: Found 9 models, 8 sources, 489 macros
[0m09:47:12.396195 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '950212f3-17d5-4c9d-abeb-928f8ffd9cad', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe3acf1b490>]}
[0m09:47:12.398380 [info ] [MainThread]: 
[0m09:47:12.399363 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m09:47:12.400448 [info ] [MainThread]: 
[0m09:47:12.402175 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m09:47:12.404583 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m09:47:12.405713 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:47:12.952111 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_staging)
[0m09:47:12.952693 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_facts'
[0m09:47:12.955249 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:47:12.953796 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m09:47:12.953177 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_marts'
[0m09:47:12.959008 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:47:13.245265 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '950212f3-17d5-4c9d-abeb-928f8ffd9cad', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe3ae419110>]}
[0m09:47:13.246827 [debug] [MainThread]: Opening a new connection, currently in state init
[0m09:47:13.251965 [debug] [Thread-1 (]: Began running node model.hailing_project.mart_driver_loyalty_mgmt
[0m09:47:13.253283 [info ] [Thread-1 (]: 1 of 1 START sql incremental model rizky_dwh_hailing_marts.mart_driver_loyalty_mgmt  [RUN]
[0m09:47:13.254720 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_staging, now model.hailing_project.mart_driver_loyalty_mgmt)
[0m09:47:13.255826 [debug] [Thread-1 (]: Began compiling node model.hailing_project.mart_driver_loyalty_mgmt
[0m09:47:13.263905 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.mart_driver_loyalty_mgmt"
[0m09:47:13.272716 [debug] [Thread-1 (]: Began executing node model.hailing_project.mart_driver_loyalty_mgmt
[0m09:47:13.336485 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.mart_driver_loyalty_mgmt"
[0m09:47:13.342774 [debug] [Thread-1 (]: On model.hailing_project.mart_driver_loyalty_mgmt: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.mart_driver_loyalty_mgmt"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_marts`.`mart_driver_loyalty_mgmt`
      
    
    

    OPTIONS()
    as (
      

WITH dim_driver AS(
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
),

fact_rides AS(
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
)

SELECT 
    dim_driver.driver_id,
    dim_driver.driver_name,
    dim_driver.phone_number,
    dim_driver.email,
    dim_driver.vehicle_type,
    COUNT(fact_rides.ride_id) AS no_of_rides,
    
    -- ✅ Ensure ride_end_time and ride_start_time are timestamps
    SUM(TIMESTAMP_DIFF(fact_rides.ride_end_time, fact_rides.ride_start_time, MINUTE)) AS total_ride_duration_min,

    -- ✅ Convert fare and distance_km to FLOAT64 before SUM()
    SUM(CAST(fact_rides.fare AS NUMERIC)) AS total_fare,
    SUM(CAST(fact_rides.distance_km AS NUMERIC)) AS total_distance_km,
    
    -- ✅ Use SUM() on converted FLOAT64 values
    SUM(CAST(fact_rides.distance_km AS NUMERIC)) - SUM(CAST(fact_rides.fare AS FLOAT64)) AS rev_opportunity_loss,

    -- ✅ Convert ride_status to INT64 before SUM()
    SUM(CAST(fact_rides.ride_status AS STRING)) AS total_ride_status

FROM dim_driver
LEFT JOIN fact_rides
ON dim_driver.driver_id = fact_rides.driver_id

GROUP BY dim_driver.driver_id, dim_driver.driver_name, dim_driver.phone_number, dim_driver.email, dim_driver.vehicle_type
    );
  
[0m09:47:13.344112 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m09:47:13.738814 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:2cad52a6-50a9-4dc8-89a7-9535405f2bd7&page=queryresults
[0m09:47:13.804753 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:2cad52a6-50a9-4dc8-89a7-9535405f2bd7&page=queryresults
[0m09:47:13.809374 [debug] [Thread-1 (]: Database Error in model mart_driver_loyalty_mgmt (models/marts/mart_driver_loyalty_mgmt.sql)
  No matching signature for aggregate function SUM
    Argument types: STRING
    Signature: SUM(INT64)
      Argument 1: Unable to coerce type STRING to expected type INT64
    Signature: SUM(FLOAT64)
      Argument 1: Unable to coerce type STRING to expected type FLOAT64
    Signature: SUM(NUMERIC)
      Argument 1: Unable to coerce type STRING to expected type NUMERIC
    Signature: SUM(BIGNUMERIC)
      Argument 1: Unable to coerce type STRING to expected type BIGNUMERIC
    Signature: SUM(INTERVAL)
      Argument 1: Unable to coerce type STRING to expected type INTERVAL at [44:5]
  compiled code at target/run/hailing_project/models/marts/mart_driver_loyalty_mgmt.sql
[0m09:47:13.812072 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '950212f3-17d5-4c9d-abeb-928f8ffd9cad', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe3ad45a290>]}
[0m09:47:13.816136 [error] [Thread-1 (]: 1 of 1 ERROR creating sql incremental model rizky_dwh_hailing_marts.mart_driver_loyalty_mgmt  [[31mERROR[0m in 0.56s]
[0m09:47:13.818419 [debug] [Thread-1 (]: Finished running node model.hailing_project.mart_driver_loyalty_mgmt
[0m09:47:13.820672 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.mart_driver_loyalty_mgmt' to be skipped because of status 'error'.  Reason: Database Error in model mart_driver_loyalty_mgmt (models/marts/mart_driver_loyalty_mgmt.sql)
  No matching signature for aggregate function SUM
    Argument types: STRING
    Signature: SUM(INT64)
      Argument 1: Unable to coerce type STRING to expected type INT64
    Signature: SUM(FLOAT64)
      Argument 1: Unable to coerce type STRING to expected type FLOAT64
    Signature: SUM(NUMERIC)
      Argument 1: Unable to coerce type STRING to expected type NUMERIC
    Signature: SUM(BIGNUMERIC)
      Argument 1: Unable to coerce type STRING to expected type BIGNUMERIC
    Signature: SUM(INTERVAL)
      Argument 1: Unable to coerce type STRING to expected type INTERVAL at [44:5]
  compiled code at target/run/hailing_project/models/marts/mart_driver_loyalty_mgmt.sql.
[0m09:47:13.823965 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m09:47:13.827890 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:47:13.828813 [debug] [MainThread]: Connection 'model.hailing_project.mart_driver_loyalty_mgmt' was properly closed.
[0m09:47:13.829556 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_facts' was properly closed.
[0m09:47:13.830220 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_marts' was properly closed.
[0m09:47:13.830925 [info ] [MainThread]: 
[0m09:47:13.832010 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 1.43 seconds (1.43s).
[0m09:47:13.833803 [debug] [MainThread]: Command end result
[0m09:47:13.872129 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m09:47:13.876531 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m09:47:13.884105 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m09:47:13.884761 [info ] [MainThread]: 
[0m09:47:13.885832 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m09:47:13.886740 [info ] [MainThread]: 
[0m09:47:13.887825 [error] [MainThread]:   Database Error in model mart_driver_loyalty_mgmt (models/marts/mart_driver_loyalty_mgmt.sql)
  No matching signature for aggregate function SUM
    Argument types: STRING
    Signature: SUM(INT64)
      Argument 1: Unable to coerce type STRING to expected type INT64
    Signature: SUM(FLOAT64)
      Argument 1: Unable to coerce type STRING to expected type FLOAT64
    Signature: SUM(NUMERIC)
      Argument 1: Unable to coerce type STRING to expected type NUMERIC
    Signature: SUM(BIGNUMERIC)
      Argument 1: Unable to coerce type STRING to expected type BIGNUMERIC
    Signature: SUM(INTERVAL)
      Argument 1: Unable to coerce type STRING to expected type INTERVAL at [44:5]
  compiled code at target/run/hailing_project/models/marts/mart_driver_loyalty_mgmt.sql
[0m09:47:13.888756 [info ] [MainThread]: 
[0m09:47:13.889723 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m09:47:13.891416 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 2.745026, "process_in_blocks": "0", "process_kernel_time": 0.211903, "process_mem_max_rss": "221040", "process_out_blocks": "0", "process_user_time": 3.279466}
[0m09:47:13.892685 [debug] [MainThread]: Command `dbt run` failed at 09:47:13.892532 after 2.75 seconds
[0m09:47:13.893669 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe3db118510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe3db119e90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe3dea751d0>]}
[0m09:47:13.894634 [debug] [MainThread]: Flushing usage events
[0m09:47:14.925275 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m09:49:16.592756 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f812dc2fb50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f812dbdd790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f812dbdf150>]}


============================== 09:49:16.595436 | 1aa844a3-0a2c-4961-bb46-b5bdf24e9fa7 ==============================
[0m09:49:16.595436 [info ] [MainThread]: Running with dbt=1.9.0
[0m09:49:16.596525 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt run --select mart_driver_loyalty_mgmt', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m09:49:17.174678 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1aa844a3-0a2c-4961-bb46-b5bdf24e9fa7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f80ffed8ad0>]}
[0m09:49:17.221599 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '1aa844a3-0a2c-4961-bb46-b5bdf24e9fa7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f80ffd07350>]}
[0m09:49:17.222549 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m09:49:17.285328 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m09:49:17.476536 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m09:49:17.477433 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/marts/mart_driver_loyalty_mgmt.sql
[0m09:49:17.727105 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1aa844a3-0a2c-4961-bb46-b5bdf24e9fa7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f80fffe7610>]}
[0m09:49:17.797378 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m09:49:17.802948 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m09:49:17.819619 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1aa844a3-0a2c-4961-bb46-b5bdf24e9fa7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f80ff9f5090>]}
[0m09:49:17.820942 [info ] [MainThread]: Found 9 models, 8 sources, 489 macros
[0m09:49:17.822349 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1aa844a3-0a2c-4961-bb46-b5bdf24e9fa7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f80ffeaf190>]}
[0m09:49:17.824640 [info ] [MainThread]: 
[0m09:49:17.825723 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m09:49:17.826941 [info ] [MainThread]: 
[0m09:49:17.828567 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m09:49:17.830824 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m09:49:17.831803 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:49:18.418730 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_facts)
[0m09:49:18.419310 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_marts'
[0m09:49:18.419916 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_staging'
[0m09:49:18.420611 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m09:49:18.421410 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:49:18.422257 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:49:18.729817 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1aa844a3-0a2c-4961-bb46-b5bdf24e9fa7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f80ffeafbd0>]}
[0m09:49:18.730939 [debug] [MainThread]: Opening a new connection, currently in state init
[0m09:49:18.735855 [debug] [Thread-1 (]: Began running node model.hailing_project.mart_driver_loyalty_mgmt
[0m09:49:18.736745 [info ] [Thread-1 (]: 1 of 1 START sql incremental model rizky_dwh_hailing_marts.mart_driver_loyalty_mgmt  [RUN]
[0m09:49:18.738141 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_marts, now model.hailing_project.mart_driver_loyalty_mgmt)
[0m09:49:18.739290 [debug] [Thread-1 (]: Began compiling node model.hailing_project.mart_driver_loyalty_mgmt
[0m09:49:18.747327 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.mart_driver_loyalty_mgmt"
[0m09:49:18.754661 [debug] [Thread-1 (]: Began executing node model.hailing_project.mart_driver_loyalty_mgmt
[0m09:49:18.811430 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.mart_driver_loyalty_mgmt"
[0m09:49:18.818165 [debug] [Thread-1 (]: On model.hailing_project.mart_driver_loyalty_mgmt: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.mart_driver_loyalty_mgmt"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_marts`.`mart_driver_loyalty_mgmt`
      
    
    

    OPTIONS()
    as (
      

WITH dim_driver AS(
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
),

fact_rides AS(
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
)

SELECT 
dim_driver.driver_id,
dim_driver.driver_name,
dim_driver.phone_number,
dim_driver.email,
dim_driver.vehicle_type,
COUNT(fact_rides.ride_id) AS no_of_rides,
SUM(TIMESTAMP_DIFF(fact_rides.ride_end_time, fact_rides.ride_start_time, MINUTE)) AS total_ride_duration_min,
SUM(fact_rides.fare) AS total_fare,
SUM(fact_rides.distance_km) as total_distance_km,
SUM(fact_rides.distance_km)-SUM(fact_rides.fare) AS rev_opportunity_loss,
SUM(fact_rides.ride_status) AS ride_status

FROM dim_driver
LEFT JOIN fact_rides
ON dim_driver.driver_id = fact_rides.driver_id

GROUP BY driver_id,driver_name,phone_number,email,vehicle_type
    );
  
[0m09:49:18.819076 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m09:49:19.313737 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:5a4992a2-b12a-4ee6-b537-216fd3443065&page=queryresults
[0m09:49:19.455230 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:5a4992a2-b12a-4ee6-b537-216fd3443065&page=queryresults
[0m09:49:19.460408 [debug] [Thread-1 (]: Database Error in model mart_driver_loyalty_mgmt (models/marts/mart_driver_loyalty_mgmt.sql)
  No matching signature for aggregate function SUM
    Argument types: STRING
    Signature: SUM(INT64)
      Argument 1: Unable to coerce type STRING to expected type INT64
    Signature: SUM(FLOAT64)
      Argument 1: Unable to coerce type STRING to expected type FLOAT64
    Signature: SUM(NUMERIC)
      Argument 1: Unable to coerce type STRING to expected type NUMERIC
    Signature: SUM(BIGNUMERIC)
      Argument 1: Unable to coerce type STRING to expected type BIGNUMERIC
    Signature: SUM(INTERVAL)
      Argument 1: Unable to coerce type STRING to expected type INTERVAL at [36:1]
  compiled code at target/run/hailing_project/models/marts/mart_driver_loyalty_mgmt.sql
[0m09:49:19.462407 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1aa844a3-0a2c-4961-bb46-b5bdf24e9fa7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f80ffd05f90>]}
[0m09:49:19.463510 [error] [Thread-1 (]: 1 of 1 ERROR creating sql incremental model rizky_dwh_hailing_marts.mart_driver_loyalty_mgmt  [[31mERROR[0m in 0.72s]
[0m09:49:19.464645 [debug] [Thread-1 (]: Finished running node model.hailing_project.mart_driver_loyalty_mgmt
[0m09:49:19.466048 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.mart_driver_loyalty_mgmt' to be skipped because of status 'error'.  Reason: Database Error in model mart_driver_loyalty_mgmt (models/marts/mart_driver_loyalty_mgmt.sql)
  No matching signature for aggregate function SUM
    Argument types: STRING
    Signature: SUM(INT64)
      Argument 1: Unable to coerce type STRING to expected type INT64
    Signature: SUM(FLOAT64)
      Argument 1: Unable to coerce type STRING to expected type FLOAT64
    Signature: SUM(NUMERIC)
      Argument 1: Unable to coerce type STRING to expected type NUMERIC
    Signature: SUM(BIGNUMERIC)
      Argument 1: Unable to coerce type STRING to expected type BIGNUMERIC
    Signature: SUM(INTERVAL)
      Argument 1: Unable to coerce type STRING to expected type INTERVAL at [36:1]
  compiled code at target/run/hailing_project/models/marts/mart_driver_loyalty_mgmt.sql.
[0m09:49:19.469115 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m09:49:19.471778 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:49:19.472973 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_facts' was properly closed.
[0m09:49:19.474075 [debug] [MainThread]: Connection 'model.hailing_project.mart_driver_loyalty_mgmt' was properly closed.
[0m09:49:19.475341 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_staging' was properly closed.
[0m09:49:19.476261 [info ] [MainThread]: 
[0m09:49:19.477236 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 1.65 seconds (1.65s).
[0m09:49:19.478844 [debug] [MainThread]: Command end result
[0m09:49:19.515003 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m09:49:19.519121 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m09:49:19.527176 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m09:49:19.528343 [info ] [MainThread]: 
[0m09:49:19.529553 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m09:49:19.530625 [info ] [MainThread]: 
[0m09:49:19.531737 [error] [MainThread]:   Database Error in model mart_driver_loyalty_mgmt (models/marts/mart_driver_loyalty_mgmt.sql)
  No matching signature for aggregate function SUM
    Argument types: STRING
    Signature: SUM(INT64)
      Argument 1: Unable to coerce type STRING to expected type INT64
    Signature: SUM(FLOAT64)
      Argument 1: Unable to coerce type STRING to expected type FLOAT64
    Signature: SUM(NUMERIC)
      Argument 1: Unable to coerce type STRING to expected type NUMERIC
    Signature: SUM(BIGNUMERIC)
      Argument 1: Unable to coerce type STRING to expected type BIGNUMERIC
    Signature: SUM(INTERVAL)
      Argument 1: Unable to coerce type STRING to expected type INTERVAL at [36:1]
  compiled code at target/run/hailing_project/models/marts/mart_driver_loyalty_mgmt.sql
[0m09:49:19.532795 [info ] [MainThread]: 
[0m09:49:19.533809 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m09:49:19.535448 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 2.9978817, "process_in_blocks": "0", "process_kernel_time": 0.221363, "process_mem_max_rss": "218724", "process_out_blocks": "0", "process_user_time": 3.29026}
[0m09:49:19.536791 [debug] [MainThread]: Command `dbt run` failed at 09:49:19.536614 after 3.00 seconds
[0m09:49:19.537717 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f812dc35f50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f812dc34610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f812dbe0310>]}
[0m09:49:19.538763 [debug] [MainThread]: Flushing usage events
[0m09:49:20.580199 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m09:50:34.085016 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb95cae3c90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb95cae2790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb95cae33d0>]}


============================== 09:50:34.088827 | e7758c26-8ce0-4af4-81bd-2e917852aab6 ==============================
[0m09:50:34.088827 [info ] [MainThread]: Running with dbt=1.9.0
[0m09:50:34.090358 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt run --select mart_driver_loyalty_mgmt', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m09:50:34.708551 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e7758c26-8ce0-4af4-81bd-2e917852aab6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb95cae6350>]}
[0m09:50:34.754497 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e7758c26-8ce0-4af4-81bd-2e917852aab6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb92edd7590>]}
[0m09:50:34.756051 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m09:50:34.823812 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m09:50:35.029867 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m09:50:35.031675 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/marts/mart_driver_loyalty_mgmt.sql
[0m09:50:35.313069 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e7758c26-8ce0-4af4-81bd-2e917852aab6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb92e8e13d0>]}
[0m09:50:35.389164 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m09:50:35.395428 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m09:50:35.411566 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e7758c26-8ce0-4af4-81bd-2e917852aab6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb92cfe8f50>]}
[0m09:50:35.413009 [info ] [MainThread]: Found 9 models, 8 sources, 489 macros
[0m09:50:35.414629 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e7758c26-8ce0-4af4-81bd-2e917852aab6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb92ecc2350>]}
[0m09:50:35.417558 [info ] [MainThread]: 
[0m09:50:35.418731 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m09:50:35.419663 [info ] [MainThread]: 
[0m09:50:35.421115 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m09:50:35.423420 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m09:50:35.424730 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:50:35.959527 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_facts)
[0m09:50:35.960380 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_staging'
[0m09:50:35.961125 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_marts'
[0m09:50:35.961777 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m09:50:35.962890 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:50:35.963974 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:50:36.261577 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e7758c26-8ce0-4af4-81bd-2e917852aab6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb92edc2bd0>]}
[0m09:50:36.262759 [debug] [MainThread]: Opening a new connection, currently in state init
[0m09:50:36.267137 [debug] [Thread-1 (]: Began running node model.hailing_project.mart_driver_loyalty_mgmt
[0m09:50:36.268163 [info ] [Thread-1 (]: 1 of 1 START sql incremental model rizky_dwh_hailing_marts.mart_driver_loyalty_mgmt  [RUN]
[0m09:50:36.269284 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_marts, now model.hailing_project.mart_driver_loyalty_mgmt)
[0m09:50:36.270148 [debug] [Thread-1 (]: Began compiling node model.hailing_project.mart_driver_loyalty_mgmt
[0m09:50:36.277758 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.mart_driver_loyalty_mgmt"
[0m09:50:36.284242 [debug] [Thread-1 (]: Began executing node model.hailing_project.mart_driver_loyalty_mgmt
[0m09:50:36.347923 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.mart_driver_loyalty_mgmt"
[0m09:50:36.353869 [debug] [Thread-1 (]: On model.hailing_project.mart_driver_loyalty_mgmt: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.mart_driver_loyalty_mgmt"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_marts`.`mart_driver_loyalty_mgmt`
      
    
    

    OPTIONS()
    as (
      

WITH dim_driver AS(
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
),

fact_rides AS(
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
)

SELECT 
dim_driver.driver_id,
dim_driver.driver_name,
dim_driver.phone_number,
dim_driver.email,
dim_driver.vehicle_type,
COUNT(fact_rides.ride_id) AS no_of_rides,
SUM(TIMESTAMP_DIFF(fact_rides.ride_end_time, fact_rides.ride_start_time, MINUTE)) AS total_ride_duration_min,
SUM(fact_rides.fare) AS total_fare,
SUM(fact_rides.distance_km) as total_distance_km,
SUM(fact_rides.distance_km)-SUM(fact_rides.fare) AS rev_opportunity_loss,
SUM(fact_rides.ride_status) AS ride_status

FROM dim_driver
LEFT JOIN fact_rides
ON dim_driver.driver_id = fact_rides.driver_id

GROUP BY driver_id,driver_name,phone_number,email,vehicle_type,ride_status
    );
  
[0m09:50:36.354912 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m09:50:36.818879 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:9cdd4745-d16e-4d4e-93a7-cc1482baddb4&page=queryresults
[0m09:50:36.956645 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:9cdd4745-d16e-4d4e-93a7-cc1482baddb4&page=queryresults
[0m09:50:36.962363 [debug] [Thread-1 (]: Database Error in model mart_driver_loyalty_mgmt (models/marts/mart_driver_loyalty_mgmt.sql)
  No matching signature for aggregate function SUM
    Argument types: STRING
    Signature: SUM(INT64)
      Argument 1: Unable to coerce type STRING to expected type INT64
    Signature: SUM(FLOAT64)
      Argument 1: Unable to coerce type STRING to expected type FLOAT64
    Signature: SUM(NUMERIC)
      Argument 1: Unable to coerce type STRING to expected type NUMERIC
    Signature: SUM(BIGNUMERIC)
      Argument 1: Unable to coerce type STRING to expected type BIGNUMERIC
    Signature: SUM(INTERVAL)
      Argument 1: Unable to coerce type STRING to expected type INTERVAL at [36:1]
  compiled code at target/run/hailing_project/models/marts/mart_driver_loyalty_mgmt.sql
[0m09:50:36.964553 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e7758c26-8ce0-4af4-81bd-2e917852aab6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb92ec4fe90>]}
[0m09:50:36.965880 [error] [Thread-1 (]: 1 of 1 ERROR creating sql incremental model rizky_dwh_hailing_marts.mart_driver_loyalty_mgmt  [[31mERROR[0m in 0.69s]
[0m09:50:36.967108 [debug] [Thread-1 (]: Finished running node model.hailing_project.mart_driver_loyalty_mgmt
[0m09:50:36.968299 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.mart_driver_loyalty_mgmt' to be skipped because of status 'error'.  Reason: Database Error in model mart_driver_loyalty_mgmt (models/marts/mart_driver_loyalty_mgmt.sql)
  No matching signature for aggregate function SUM
    Argument types: STRING
    Signature: SUM(INT64)
      Argument 1: Unable to coerce type STRING to expected type INT64
    Signature: SUM(FLOAT64)
      Argument 1: Unable to coerce type STRING to expected type FLOAT64
    Signature: SUM(NUMERIC)
      Argument 1: Unable to coerce type STRING to expected type NUMERIC
    Signature: SUM(BIGNUMERIC)
      Argument 1: Unable to coerce type STRING to expected type BIGNUMERIC
    Signature: SUM(INTERVAL)
      Argument 1: Unable to coerce type STRING to expected type INTERVAL at [36:1]
  compiled code at target/run/hailing_project/models/marts/mart_driver_loyalty_mgmt.sql.
[0m09:50:36.970815 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m09:50:36.974055 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:50:36.974984 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_facts' was properly closed.
[0m09:50:36.976014 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_staging' was properly closed.
[0m09:50:36.976899 [debug] [MainThread]: Connection 'model.hailing_project.mart_driver_loyalty_mgmt' was properly closed.
[0m09:50:36.977893 [info ] [MainThread]: 
[0m09:50:36.978892 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 1.56 seconds (1.56s).
[0m09:50:36.980924 [debug] [MainThread]: Command end result
[0m09:50:37.016726 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m09:50:37.021197 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m09:50:37.029519 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m09:50:37.030267 [info ] [MainThread]: 
[0m09:50:37.031403 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m09:50:37.032608 [info ] [MainThread]: 
[0m09:50:37.033733 [error] [MainThread]:   Database Error in model mart_driver_loyalty_mgmt (models/marts/mart_driver_loyalty_mgmt.sql)
  No matching signature for aggregate function SUM
    Argument types: STRING
    Signature: SUM(INT64)
      Argument 1: Unable to coerce type STRING to expected type INT64
    Signature: SUM(FLOAT64)
      Argument 1: Unable to coerce type STRING to expected type FLOAT64
    Signature: SUM(NUMERIC)
      Argument 1: Unable to coerce type STRING to expected type NUMERIC
    Signature: SUM(BIGNUMERIC)
      Argument 1: Unable to coerce type STRING to expected type BIGNUMERIC
    Signature: SUM(INTERVAL)
      Argument 1: Unable to coerce type STRING to expected type INTERVAL at [36:1]
  compiled code at target/run/hailing_project/models/marts/mart_driver_loyalty_mgmt.sql
[0m09:50:37.034924 [info ] [MainThread]: 
[0m09:50:37.035965 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m09:50:37.037719 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 3.0100534, "process_in_blocks": "0", "process_kernel_time": 0.190403, "process_mem_max_rss": "218060", "process_out_blocks": "0", "process_user_time": 3.427254}
[0m09:50:37.038968 [debug] [MainThread]: Command `dbt run` failed at 09:50:37.038814 after 3.01 seconds
[0m09:50:37.040140 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb95cb12950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb95cb12790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb92c6f63d0>]}
[0m09:50:37.041415 [debug] [MainThread]: Flushing usage events
[0m09:50:38.114924 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m09:53:42.917973 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f77ac99ae90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f77ac9f3cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f77ac99ba90>]}


============================== 09:53:42.920398 | e54f65c0-4405-4b7c-bd6e-3a82f5260bc4 ==============================
[0m09:53:42.920398 [info ] [MainThread]: Running with dbt=1.9.0
[0m09:53:42.921908 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt run --select mart_driver_loyalty_mgmt', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m09:53:43.505294 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e54f65c0-4405-4b7c-bd6e-3a82f5260bc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f777ed403d0>]}
[0m09:53:43.547850 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e54f65c0-4405-4b7c-bd6e-3a82f5260bc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f77aec4df90>]}
[0m09:53:43.549133 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m09:53:43.614357 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m09:53:43.810977 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m09:53:43.812259 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/marts/mart_driver_loyalty_mgmt.sql
[0m09:53:44.055558 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e54f65c0-4405-4b7c-bd6e-3a82f5260bc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f777ebf3c50>]}
[0m09:53:44.125342 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m09:53:44.131685 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m09:53:44.146039 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e54f65c0-4405-4b7c-bd6e-3a82f5260bc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f777cec6590>]}
[0m09:53:44.147262 [info ] [MainThread]: Found 9 models, 8 sources, 489 macros
[0m09:53:44.148412 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e54f65c0-4405-4b7c-bd6e-3a82f5260bc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f777ecce5d0>]}
[0m09:53:44.151062 [info ] [MainThread]: 
[0m09:53:44.152278 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m09:53:44.153284 [info ] [MainThread]: 
[0m09:53:44.154587 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m09:53:44.156267 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m09:53:44.157278 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:53:44.675739 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_marts)
[0m09:53:44.676812 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_facts'
[0m09:53:44.677746 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_staging'
[0m09:53:44.678473 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m09:53:44.679617 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:53:44.680783 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:53:44.968261 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e54f65c0-4405-4b7c-bd6e-3a82f5260bc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f778b772ed0>]}
[0m09:53:44.969846 [debug] [MainThread]: Opening a new connection, currently in state init
[0m09:53:44.974924 [debug] [Thread-1 (]: Began running node model.hailing_project.mart_driver_loyalty_mgmt
[0m09:53:44.975811 [info ] [Thread-1 (]: 1 of 1 START sql incremental model rizky_dwh_hailing_marts.mart_driver_loyalty_mgmt  [RUN]
[0m09:53:44.977777 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_staging, now model.hailing_project.mart_driver_loyalty_mgmt)
[0m09:53:44.979264 [debug] [Thread-1 (]: Began compiling node model.hailing_project.mart_driver_loyalty_mgmt
[0m09:53:44.986636 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.mart_driver_loyalty_mgmt"
[0m09:53:44.997542 [debug] [Thread-1 (]: Began executing node model.hailing_project.mart_driver_loyalty_mgmt
[0m09:53:45.054295 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.mart_driver_loyalty_mgmt"
[0m09:53:45.060247 [debug] [Thread-1 (]: On model.hailing_project.mart_driver_loyalty_mgmt: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.mart_driver_loyalty_mgmt"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_marts`.`mart_driver_loyalty_mgmt`
      
    
    

    OPTIONS()
    as (
      

WITH dim_driver AS(
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
),

fact_rides AS(
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
)

SELECT 
dim_driver.driver_id,
dim_driver.driver_name,
dim_driver.phone_number,
dim_driver.email,
dim_driver.vehicle_type,
COUNT(fact_rides.ride_id) AS no_of_rides,
SUM(TIMESTAMP_DIFF(fact_rides.ride_end_time, fact_rides.ride_start_time, MINUTE)) AS total_ride_duration_min,
SUM(fact_rides.fare) AS total_fare,
SUM(fact_rides.distance_km) as total_distance_km,
SUM(fact_rides.distance_km)-SUM(fact_rides.fare) AS rev_opportunity_loss,
fact_rides.ride_status AS ride_status

FROM dim_driver
LEFT JOIN fact_rides
ON dim_driver.driver_id = fact_rides.driver_id

GROUP BY driver_id,driver_name,phone_number,email,vehicle_type,ride_status
    );
  
[0m09:53:45.061244 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m09:53:45.547269 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:89329ebd-71c0-4e46-a159-0e59881b6fe6&page=queryresults
[0m09:53:47.338441 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e54f65c0-4405-4b7c-bd6e-3a82f5260bc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f777ebc4790>]}
[0m09:53:47.339642 [info ] [Thread-1 (]: 1 of 1 OK created sql incremental model rizky_dwh_hailing_marts.mart_driver_loyalty_mgmt  [[32mCREATE TABLE (99.0 rows, 11.9 KiB processed)[0m in 2.36s]
[0m09:53:47.340978 [debug] [Thread-1 (]: Finished running node model.hailing_project.mart_driver_loyalty_mgmt
[0m09:53:47.343276 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m09:53:47.347419 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:53:47.348463 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_marts' was properly closed.
[0m09:53:47.350565 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_facts' was properly closed.
[0m09:53:47.351605 [debug] [MainThread]: Connection 'model.hailing_project.mart_driver_loyalty_mgmt' was properly closed.
[0m09:53:47.352348 [info ] [MainThread]: 
[0m09:53:47.353351 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 3.20 seconds (3.20s).
[0m09:53:47.355049 [debug] [MainThread]: Command end result
[0m09:53:47.389884 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m09:53:47.393838 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m09:53:47.401706 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m09:53:47.402367 [info ] [MainThread]: 
[0m09:53:47.403356 [info ] [MainThread]: [32mCompleted successfully[0m
[0m09:53:47.404360 [info ] [MainThread]: 
[0m09:53:47.405331 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m09:53:47.406833 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 4.538118, "process_in_blocks": "0", "process_kernel_time": 0.215542, "process_mem_max_rss": "221820", "process_out_blocks": "0", "process_user_time": 3.335781}
[0m09:53:47.407808 [debug] [MainThread]: Command `dbt run` succeeded at 09:53:47.407696 after 4.54 seconds
[0m09:53:47.408560 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f77ac9f68d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f77ac9f5d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f77b01f4b90>]}
[0m09:53:47.409341 [debug] [MainThread]: Flushing usage events
[0m09:53:48.486814 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m10:08:48.326714 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdafe8c7b10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdaffc8bbd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdafe8c62d0>]}


============================== 10:08:48.329219 | ff98ba28-b91b-4565-b1c4-78c4d6dfabc3 ==============================
[0m10:08:48.329219 [info ] [MainThread]: Running with dbt=1.9.0
[0m10:08:48.330982 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m10:08:48.906416 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ff98ba28-b91b-4565-b1c4-78c4d6dfabc3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdad51c3f90>]}
[0m10:08:48.950983 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ff98ba28-b91b-4565-b1c4-78c4d6dfabc3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdad4bb4f10>]}
[0m10:08:48.952531 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m10:08:49.017916 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m10:08:49.183630 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m10:08:49.184802 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m10:08:49.212133 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ff98ba28-b91b-4565-b1c4-78c4d6dfabc3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdad6ec2510>]}
[0m10:08:49.329323 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m10:08:49.334732 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m10:08:49.350678 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ff98ba28-b91b-4565-b1c4-78c4d6dfabc3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdad490ee90>]}
[0m10:08:49.351576 [info ] [MainThread]: Found 9 models, 8 sources, 489 macros
[0m10:08:49.352514 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ff98ba28-b91b-4565-b1c4-78c4d6dfabc3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdad475d350>]}
[0m10:08:49.355117 [info ] [MainThread]: 
[0m10:08:49.356255 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m10:08:49.357360 [info ] [MainThread]: 
[0m10:08:49.358685 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m10:08:49.364436 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m10:08:49.365194 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m10:08:49.365737 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m10:08:49.366297 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:08:49.367096 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:08:49.367751 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:08:50.321700 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_staging)
[0m10:08:50.322275 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_marts)
[0m10:08:50.322817 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_facts)
[0m10:08:50.323441 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:08:50.324245 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:08:50.325272 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:08:50.576976 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ff98ba28-b91b-4565-b1c4-78c4d6dfabc3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdad466b490>]}
[0m10:08:50.578045 [debug] [MainThread]: Opening a new connection, currently in state init
[0m10:08:50.582870 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m10:08:50.583248 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m10:08:50.583553 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m10:08:50.583840 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m10:08:50.584349 [info ] [Thread-1 (]: 1 of 9 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [RUN]
[0m10:08:50.585694 [info ] [Thread-2 (]: 2 of 9 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [RUN]
[0m10:08:50.586861 [info ] [Thread-3 (]: 3 of 9 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [RUN]
[0m10:08:50.588140 [info ] [Thread-4 (]: 4 of 9 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [RUN]
[0m10:08:50.589215 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_facts, now model.hailing_project.production_hailing_staging_customer)
[0m10:08:50.590173 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_marts, now model.hailing_project.production_hailing_staging_driver)
[0m10:08:50.590969 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_staging, now model.hailing_project.production_hailing_staging_ride)
[0m10:08:50.591976 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_vehicle'
[0m10:08:50.593009 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m10:08:50.593799 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m10:08:50.594708 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m10:08:50.595625 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m10:08:50.610072 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m10:08:50.613692 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m10:08:50.617973 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m10:08:50.622261 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m10:08:50.629171 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m10:08:50.640744 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m10:08:50.674643 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m10:08:50.676797 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m10:08:50.677229 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m10:08:50.677635 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m10:08:50.682863 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m10:08:50.731737 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m10:08:50.955170 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m10:08:50.956827 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m10:08:50.957963 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m10:08:50.959585 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m10:08:50.965709 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m10:08:50.968941 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m10:08:50.971643 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m10:08:50.974384 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m10:08:51.233883 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:eb012a96-6c62-4946-900f-877645275b52&page=queryresults
[0m10:08:51.238622 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:ab27938d-e998-4047-a414-e0d1c43010e1&page=queryresults
[0m10:08:51.241568 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:597abc4a-7078-45b5-b418-0f1bf7cd65c7&page=queryresults
[0m10:08:51.275754 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:570b5ca2-f3c2-408b-86ea-2fdf3bf5c45b&page=queryresults
[0m10:08:52.793965 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ff98ba28-b91b-4565-b1c4-78c4d6dfabc3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdad44f1990>]}
[0m10:08:52.795408 [info ] [Thread-4 (]: 4 of 9 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.20s]
[0m10:08:52.797194 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m10:08:52.801148 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ff98ba28-b91b-4565-b1c4-78c4d6dfabc3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdad450e410>]}
[0m10:08:52.802251 [info ] [Thread-1 (]: 1 of 9 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.21s]
[0m10:08:52.803493 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m10:08:52.804960 [debug] [Thread-4 (]: Began running node model.hailing_project.dim_customer
[0m10:08:52.806157 [info ] [Thread-4 (]: 5 of 9 START sql incremental model rizky_dwh_hailing_facts.dim_customer ........ [RUN]
[0m10:08:52.807592 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_vehicle, now model.hailing_project.dim_customer)
[0m10:08:52.808643 [debug] [Thread-4 (]: Began compiling node model.hailing_project.dim_customer
[0m10:08:52.813553 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m10:08:52.820058 [debug] [Thread-4 (]: Began executing node model.hailing_project.dim_customer
[0m10:08:52.824494 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m10:08:52.853003 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ff98ba28-b91b-4565-b1c4-78c4d6dfabc3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdad44f1c10>]}
[0m10:08:52.854444 [info ] [Thread-2 (]: 2 of 9 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.26s]
[0m10:08:52.855644 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m10:08:52.856748 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_driver
[0m10:08:52.857645 [info ] [Thread-1 (]: 6 of 9 START sql incremental model rizky_dwh_hailing_facts.dim_driver .......... [RUN]
[0m10:08:52.858589 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_customer, now model.hailing_project.dim_driver)
[0m10:08:52.859556 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_driver
[0m10:08:52.863913 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_driver"
[0m10:08:52.871625 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_driver
[0m10:08:52.875815 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m10:08:53.044290 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m10:08:53.055258 [debug] [Thread-4 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
)

SELECT * FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m10:08:53.087071 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_driver"
[0m10:08:53.094080 [debug] [Thread-1 (]: On model.hailing_project.dim_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver` as DBT_INTERNAL_DEST
        using (


WITH driver AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver` --pakai ref untuk buat dependency

),

vehicle AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle`
)

SELECT
    driver.driver_id,
    vehicle.vehicle_id,
    driver.name as driver_name,
    driver.phone_number as phone_number,
    driver.email as email,
    vehicle.vehicle_type,
    vehicle.brand as vehicle_brand,
    vehicle.year as vehicle_production_year,
    vehicle.license_plate,
    driver.created_at
FROM driver
LEFT JOIN vehicle
on driver.driver_id = vehicle.vehicle_id


    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_name` = DBT_INTERNAL_SOURCE.`driver_name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`vehicle_brand` = DBT_INTERNAL_SOURCE.`vehicle_brand`,`vehicle_production_year` = DBT_INTERNAL_SOURCE.`vehicle_production_year`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `vehicle_id`, `driver_name`, `phone_number`, `email`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)
    values
        (`driver_id`, `vehicle_id`, `driver_name`, `phone_number`, `email`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)


    
[0m10:08:53.295831 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:8c01b04e-bdc3-4199-9b01-fb26aa3df111&page=queryresults
[0m10:08:53.346615 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ff98ba28-b91b-4565-b1c4-78c4d6dfabc3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdad4bc8150>]}
[0m10:08:53.348131 [info ] [Thread-3 (]: 3 of 9 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.76s]
[0m10:08:53.349736 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m10:08:53.362979 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:c75e7e8f-9a6b-454e-b699-87314cad3fdb&page=queryresults
[0m10:08:53.500987 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:c75e7e8f-9a6b-454e-b699-87314cad3fdb&page=queryresults
[0m10:08:53.506803 [debug] [Thread-1 (]: Database Error in model dim_driver (models/facts/dim_driver.sql)
  Column name created_at is ambiguous at [44:11]
  compiled code at target/run/hailing_project/models/facts/dim_driver.sql
[0m10:08:53.508022 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ff98ba28-b91b-4565-b1c4-78c4d6dfabc3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdad4141250>]}
[0m10:08:53.509414 [error] [Thread-1 (]: 6 of 9 ERROR creating sql incremental model rizky_dwh_hailing_facts.dim_driver . [[31mERROR[0m in 0.65s]
[0m10:08:53.510878 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_driver
[0m10:08:53.512128 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.dim_driver' to be skipped because of status 'error'.  Reason: Database Error in model dim_driver (models/facts/dim_driver.sql)
  Column name created_at is ambiguous at [44:11]
  compiled code at target/run/hailing_project/models/facts/dim_driver.sql.
[0m10:08:54.822199 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ff98ba28-b91b-4565-b1c4-78c4d6dfabc3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdad4143990>]}
[0m10:08:54.823807 [info ] [Thread-4 (]: 5 of 9 OK created sql incremental model rizky_dwh_hailing_facts.dim_customer ... [[32mMERGE (0.0 rows, 11.3 KiB processed)[0m in 2.01s]
[0m10:08:54.825167 [debug] [Thread-4 (]: Finished running node model.hailing_project.dim_customer
[0m10:08:54.826934 [debug] [Thread-2 (]: Began running node model.hailing_project.fact_hailing_rides
[0m10:08:54.827936 [info ] [Thread-2 (]: 7 of 9 SKIP relation rizky_dwh_hailing_facts.fact_hailing_rides ................ [[33mSKIP[0m]
[0m10:08:54.829191 [debug] [Thread-2 (]: Finished running node model.hailing_project.fact_hailing_rides
[0m10:08:54.830752 [debug] [Thread-1 (]: Began running node model.hailing_project.mart_cust_rides_daily
[0m10:08:54.831171 [debug] [Thread-4 (]: Began running node model.hailing_project.mart_driver_loyalty_mgmt
[0m10:08:54.831996 [info ] [Thread-1 (]: 8 of 9 SKIP relation rizky_dwh_hailing_marts.mart_cust_rides_daily ............. [[33mSKIP[0m]
[0m10:08:54.833414 [info ] [Thread-4 (]: 9 of 9 SKIP relation rizky_dwh_hailing_marts.mart_driver_loyalty_mgmt .......... [[33mSKIP[0m]
[0m10:08:54.834523 [debug] [Thread-1 (]: Finished running node model.hailing_project.mart_cust_rides_daily
[0m10:08:54.835938 [debug] [Thread-4 (]: Finished running node model.hailing_project.mart_driver_loyalty_mgmt
[0m10:08:54.840065 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m10:08:54.843167 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:08:54.844022 [debug] [MainThread]: Connection 'model.hailing_project.dim_driver' was properly closed.
[0m10:08:54.844977 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m10:08:54.845949 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m10:08:54.846982 [debug] [MainThread]: Connection 'model.hailing_project.dim_customer' was properly closed.
[0m10:08:54.847941 [info ] [MainThread]: 
[0m10:08:54.848876 [info ] [MainThread]: Finished running 8 incremental models, 1 table model in 0 hours 0 minutes and 5.49 seconds (5.49s).
[0m10:08:54.851089 [debug] [MainThread]: Command end result
[0m10:08:54.888414 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m10:08:54.892945 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m10:08:54.902122 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m10:08:54.902919 [info ] [MainThread]: 
[0m10:08:54.904189 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m10:08:54.905301 [info ] [MainThread]: 
[0m10:08:54.906598 [error] [MainThread]:   Database Error in model dim_driver (models/facts/dim_driver.sql)
  Column name created_at is ambiguous at [44:11]
  compiled code at target/run/hailing_project/models/facts/dim_driver.sql
[0m10:08:54.907596 [info ] [MainThread]: 
[0m10:08:54.908671 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=1 SKIP=3 TOTAL=9
[0m10:08:54.910693 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 6.6345463, "process_in_blocks": "0", "process_kernel_time": 0.290097, "process_mem_max_rss": "222868", "process_out_blocks": "0", "process_user_time": 3.481171}
[0m10:08:54.912199 [debug] [MainThread]: Command `dbt run` failed at 10:08:54.912026 after 6.64 seconds
[0m10:08:54.913650 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdacc79a3d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb02211250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb022115d0>]}
[0m10:08:54.915039 [debug] [MainThread]: Flushing usage events
[0m10:08:56.503214 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m10:09:55.717221 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb83fb23d10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb83fb22810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb83fb23450>]}


============================== 10:09:55.719658 | 8c4610c3-49b4-482d-9f50-256fa74d927c ==============================
[0m10:09:55.719658 [info ] [MainThread]: Running with dbt=1.9.0
[0m10:09:55.722454 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'invocation_command': 'dbt run', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m10:09:56.308138 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '8c4610c3-49b4-482d-9f50-256fa74d927c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb811cc6e50>]}
[0m10:09:56.356695 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '8c4610c3-49b4-482d-9f50-256fa74d927c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb841d7d810>]}
[0m10:09:56.358021 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m10:09:56.419321 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m10:09:56.609860 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m10:09:56.610763 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/facts/dim_driver.sql
[0m10:09:56.857328 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8c4610c3-49b4-482d-9f50-256fa74d927c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb811d217d0>]}
[0m10:09:56.922548 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m10:09:56.930530 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m10:09:56.947678 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '8c4610c3-49b4-482d-9f50-256fa74d927c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb811968710>]}
[0m10:09:56.948699 [info ] [MainThread]: Found 9 models, 8 sources, 489 macros
[0m10:09:56.949840 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8c4610c3-49b4-482d-9f50-256fa74d927c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb81194e9d0>]}
[0m10:09:56.952334 [info ] [MainThread]: 
[0m10:09:56.953507 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m10:09:56.954778 [info ] [MainThread]: 
[0m10:09:56.956142 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m10:09:56.960703 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m10:09:56.961389 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m10:09:56.962108 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m10:09:56.962781 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:09:56.963549 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:09:56.964221 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:09:57.863261 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_marts)
[0m10:09:57.863811 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_staging)
[0m10:09:57.864339 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_facts)
[0m10:09:57.865821 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:09:57.867294 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:09:57.868942 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:09:58.113300 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8c4610c3-49b4-482d-9f50-256fa74d927c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8119bad10>]}
[0m10:09:58.114592 [debug] [MainThread]: Opening a new connection, currently in state init
[0m10:09:58.119740 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m10:09:58.120160 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m10:09:58.120662 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m10:09:58.121099 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m10:09:58.121901 [info ] [Thread-1 (]: 1 of 9 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [RUN]
[0m10:09:58.123045 [info ] [Thread-2 (]: 2 of 9 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [RUN]
[0m10:09:58.124133 [info ] [Thread-3 (]: 3 of 9 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [RUN]
[0m10:09:58.125212 [info ] [Thread-4 (]: 4 of 9 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [RUN]
[0m10:09:58.126388 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_facts, now model.hailing_project.production_hailing_staging_customer)
[0m10:09:58.127441 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_marts, now model.hailing_project.production_hailing_staging_driver)
[0m10:09:58.128540 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_staging, now model.hailing_project.production_hailing_staging_ride)
[0m10:09:58.129778 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_vehicle'
[0m10:09:58.130743 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m10:09:58.131872 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m10:09:58.132760 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m10:09:58.134371 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m10:09:58.144537 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m10:09:58.148339 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m10:09:58.152644 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m10:09:58.156544 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m10:09:58.162546 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m10:09:58.163081 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m10:09:58.169129 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m10:09:58.184863 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m10:09:58.208121 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m10:09:58.210969 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m10:09:58.213324 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m10:09:58.217335 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m10:09:58.449269 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m10:09:58.457262 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m10:09:58.473107 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m10:09:58.480276 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m10:09:58.481785 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m10:09:58.489743 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m10:09:58.490318 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m10:09:58.496861 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m10:09:58.722416 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:730b39a8-6823-4c80-922f-3b5fd8ec53ee&page=queryresults
[0m10:09:58.760553 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:4db640aa-42dc-49d5-adae-676614b46544&page=queryresults
[0m10:09:58.761241 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:c6141e72-c668-44f3-886f-a7880dbc6180&page=queryresults
[0m10:09:58.767263 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:7d5b0880-2796-480d-b26a-27ce991ef9a8&page=queryresults
[0m10:10:00.556041 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8c4610c3-49b4-482d-9f50-256fa74d927c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb81038b710>]}
[0m10:10:00.556334 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8c4610c3-49b4-482d-9f50-256fa74d927c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb81185e210>]}
[0m10:10:00.556643 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8c4610c3-49b4-482d-9f50-256fa74d927c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb81038b7d0>]}
[0m10:10:00.557704 [info ] [Thread-4 (]: 4 of 9 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.42s]
[0m10:10:00.559266 [info ] [Thread-3 (]: 3 of 9 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.43s]
[0m10:10:00.561274 [info ] [Thread-1 (]: 1 of 9 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.43s]
[0m10:10:00.562597 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m10:10:00.563496 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m10:10:00.564589 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m10:10:00.566779 [debug] [Thread-4 (]: Began running node model.hailing_project.dim_customer
[0m10:10:00.567887 [info ] [Thread-4 (]: 5 of 9 START sql incremental model rizky_dwh_hailing_facts.dim_customer ........ [RUN]
[0m10:10:00.569021 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_vehicle, now model.hailing_project.dim_customer)
[0m10:10:00.570036 [debug] [Thread-4 (]: Began compiling node model.hailing_project.dim_customer
[0m10:10:00.574459 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m10:10:00.581374 [debug] [Thread-4 (]: Began executing node model.hailing_project.dim_customer
[0m10:10:00.584508 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m10:10:00.701389 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8c4610c3-49b4-482d-9f50-256fa74d927c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8106724d0>]}
[0m10:10:00.702741 [info ] [Thread-2 (]: 2 of 9 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.57s]
[0m10:10:00.704357 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m10:10:00.706272 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_driver
[0m10:10:00.707821 [info ] [Thread-1 (]: 6 of 9 START sql incremental model rizky_dwh_hailing_facts.dim_driver .......... [RUN]
[0m10:10:00.710303 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_customer, now model.hailing_project.dim_driver)
[0m10:10:00.711784 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_driver
[0m10:10:00.716621 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_driver"
[0m10:10:00.725572 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_driver
[0m10:10:00.729967 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m10:10:01.042087 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m10:10:01.047749 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_driver"
[0m10:10:01.049077 [debug] [Thread-4 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
)

SELECT * FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m10:10:01.053632 [debug] [Thread-1 (]: On model.hailing_project.dim_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver` as DBT_INTERNAL_DEST
        using (


WITH driver AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver` --pakai ref untuk buat dependency

),

vehicle AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle`
)

SELECT
    driver.driver_id,
    vehicle.vehicle_id,
    driver.name as driver_name,
    driver.phone_number as phone_number,
    driver.email as email,
    vehicle.vehicle_type,
    vehicle.brand as vehicle_brand,
    vehicle.year as vehicle_production_year,
    vehicle.license_plate,
    driver.created_at
FROM driver
LEFT JOIN vehicle
on driver.driver_id = vehicle.vehicle_id


    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_name` = DBT_INTERNAL_SOURCE.`driver_name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`vehicle_brand` = DBT_INTERNAL_SOURCE.`vehicle_brand`,`vehicle_production_year` = DBT_INTERNAL_SOURCE.`vehicle_production_year`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `vehicle_id`, `driver_name`, `phone_number`, `email`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)
    values
        (`driver_id`, `vehicle_id`, `driver_name`, `phone_number`, `email`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)


    
[0m10:10:01.288075 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:9a6b2608-0f25-4f02-b78e-cf049e964e1b&page=queryresults
[0m10:10:01.313012 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:654bf1fe-7c4b-466d-924f-314dff63cd03&page=queryresults
[0m10:10:01.414925 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:9a6b2608-0f25-4f02-b78e-cf049e964e1b&page=queryresults
[0m10:10:01.421191 [debug] [Thread-1 (]: Database Error in model dim_driver (models/facts/dim_driver.sql)
  Column name created_at is ambiguous at [44:11]
  compiled code at target/run/hailing_project/models/facts/dim_driver.sql
[0m10:10:01.422497 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8c4610c3-49b4-482d-9f50-256fa74d927c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8102b8390>]}
[0m10:10:01.423578 [error] [Thread-1 (]: 6 of 9 ERROR creating sql incremental model rizky_dwh_hailing_facts.dim_driver . [[31mERROR[0m in 0.71s]
[0m10:10:01.424566 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_driver
[0m10:10:01.425686 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.dim_driver' to be skipped because of status 'error'.  Reason: Database Error in model dim_driver (models/facts/dim_driver.sql)
  Column name created_at is ambiguous at [44:11]
  compiled code at target/run/hailing_project/models/facts/dim_driver.sql.
[0m10:10:03.077671 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8c4610c3-49b4-482d-9f50-256fa74d927c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb81068de90>]}
[0m10:10:03.078712 [info ] [Thread-4 (]: 5 of 9 OK created sql incremental model rizky_dwh_hailing_facts.dim_customer ... [[32mMERGE (0.0 rows, 11.3 KiB processed)[0m in 2.51s]
[0m10:10:03.079990 [debug] [Thread-4 (]: Finished running node model.hailing_project.dim_customer
[0m10:10:03.081679 [debug] [Thread-2 (]: Began running node model.hailing_project.fact_hailing_rides
[0m10:10:03.082455 [info ] [Thread-2 (]: 7 of 9 SKIP relation rizky_dwh_hailing_facts.fact_hailing_rides ................ [[33mSKIP[0m]
[0m10:10:03.083600 [debug] [Thread-2 (]: Finished running node model.hailing_project.fact_hailing_rides
[0m10:10:03.085148 [debug] [Thread-1 (]: Began running node model.hailing_project.mart_cust_rides_daily
[0m10:10:03.085763 [debug] [Thread-4 (]: Began running node model.hailing_project.mart_driver_loyalty_mgmt
[0m10:10:03.086406 [info ] [Thread-1 (]: 8 of 9 SKIP relation rizky_dwh_hailing_marts.mart_cust_rides_daily ............. [[33mSKIP[0m]
[0m10:10:03.087483 [info ] [Thread-4 (]: 9 of 9 SKIP relation rizky_dwh_hailing_marts.mart_driver_loyalty_mgmt .......... [[33mSKIP[0m]
[0m10:10:03.089015 [debug] [Thread-1 (]: Finished running node model.hailing_project.mart_cust_rides_daily
[0m10:10:03.090212 [debug] [Thread-4 (]: Finished running node model.hailing_project.mart_driver_loyalty_mgmt
[0m10:10:03.093524 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m10:10:03.097121 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:10:03.097938 [debug] [MainThread]: Connection 'model.hailing_project.dim_driver' was properly closed.
[0m10:10:03.098997 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m10:10:03.100111 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m10:10:03.101370 [debug] [MainThread]: Connection 'model.hailing_project.dim_customer' was properly closed.
[0m10:10:03.102300 [info ] [MainThread]: 
[0m10:10:03.103333 [info ] [MainThread]: Finished running 8 incremental models, 1 table model in 0 hours 0 minutes and 6.15 seconds (6.15s).
[0m10:10:03.105945 [debug] [MainThread]: Command end result
[0m10:10:03.142983 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m10:10:03.150531 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m10:10:03.160699 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m10:10:03.161803 [info ] [MainThread]: 
[0m10:10:03.163326 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m10:10:03.164508 [info ] [MainThread]: 
[0m10:10:03.166166 [error] [MainThread]:   Database Error in model dim_driver (models/facts/dim_driver.sql)
  Column name created_at is ambiguous at [44:11]
  compiled code at target/run/hailing_project/models/facts/dim_driver.sql
[0m10:10:03.167819 [info ] [MainThread]: 
[0m10:10:03.169255 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=1 SKIP=3 TOTAL=9
[0m10:10:03.171619 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 7.5019383, "process_in_blocks": "0", "process_kernel_time": 0.205744, "process_mem_max_rss": "225744", "process_out_blocks": "0", "process_user_time": 3.693119}
[0m10:10:03.173071 [debug] [MainThread]: Command `dbt run` failed at 10:10:03.172931 after 7.50 seconds
[0m10:10:03.174246 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb83f9a3c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb83f9a3c90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb843471350>]}
[0m10:10:03.175866 [debug] [MainThread]: Flushing usage events
[0m10:10:04.745087 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m10:11:14.157113 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fb5382b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fb5383490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fb5382f90>]}


============================== 10:11:14.159481 | c3c950b5-f8cf-480f-b12f-acf986e1cc26 ==============================
[0m10:11:14.159481 [info ] [MainThread]: Running with dbt=1.9.0
[0m10:11:14.161253 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt run', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m10:11:14.729557 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'c3c950b5-f8cf-480f-b12f-acf986e1cc26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4f87b04150>]}
[0m10:11:14.773471 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'c3c950b5-f8cf-480f-b12f-acf986e1cc26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fb7630850>]}
[0m10:11:14.774732 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m10:11:14.841773 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m10:11:15.020759 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m10:11:15.022004 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/facts/dim_driver.sql
[0m10:11:15.309035 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c3c950b5-f8cf-480f-b12f-acf986e1cc26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fb5385910>]}
[0m10:11:15.378833 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m10:11:15.384036 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m10:11:15.398682 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c3c950b5-f8cf-480f-b12f-acf986e1cc26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4f87048a10>]}
[0m10:11:15.399718 [info ] [MainThread]: Found 9 models, 8 sources, 489 macros
[0m10:11:15.401116 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c3c950b5-f8cf-480f-b12f-acf986e1cc26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4f87138410>]}
[0m10:11:15.404191 [info ] [MainThread]: 
[0m10:11:15.405447 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m10:11:15.406396 [info ] [MainThread]: 
[0m10:11:15.407742 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m10:11:15.412851 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m10:11:15.413501 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m10:11:15.414232 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m10:11:15.414763 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:11:15.415500 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:11:15.416219 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:11:17.179264 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_facts)
[0m10:11:17.179850 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_staging)
[0m10:11:17.180413 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_marts)
[0m10:11:17.180966 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:11:17.182186 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:11:17.183066 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:11:17.440374 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c3c950b5-f8cf-480f-b12f-acf986e1cc26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4f8712e490>]}
[0m10:11:17.441853 [debug] [MainThread]: Opening a new connection, currently in state init
[0m10:11:17.447388 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m10:11:17.447798 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m10:11:17.448205 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m10:11:17.448613 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m10:11:17.449574 [info ] [Thread-1 (]: 1 of 9 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [RUN]
[0m10:11:17.451165 [info ] [Thread-2 (]: 2 of 9 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [RUN]
[0m10:11:17.452518 [info ] [Thread-3 (]: 3 of 9 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [RUN]
[0m10:11:17.454001 [info ] [Thread-4 (]: 4 of 9 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [RUN]
[0m10:11:17.455254 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_marts, now model.hailing_project.production_hailing_staging_customer)
[0m10:11:17.456539 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_staging, now model.hailing_project.production_hailing_staging_driver)
[0m10:11:17.457660 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_facts, now model.hailing_project.production_hailing_staging_ride)
[0m10:11:17.458892 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_vehicle'
[0m10:11:17.460034 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m10:11:17.461144 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m10:11:17.462107 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m10:11:17.462980 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m10:11:17.472970 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m10:11:17.477078 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m10:11:17.481791 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m10:11:17.485646 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m10:11:17.492039 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m10:11:17.492720 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m10:11:17.499278 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m10:11:17.499779 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m10:11:17.539528 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m10:11:17.541864 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m10:11:17.544352 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m10:11:17.548439 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m10:11:17.843990 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m10:11:17.845576 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m10:11:17.846923 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m10:11:17.853022 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m10:11:17.855000 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m10:11:17.857258 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m10:11:17.858876 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m10:11:17.867710 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m10:11:18.115653 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:48a9d18c-17ad-422d-a57d-0aa02c30f487&page=queryresults
[0m10:11:18.117183 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:f15e1057-f66d-437b-ab2f-50e2a2374785&page=queryresults
[0m10:11:18.121287 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:f8a97d90-8719-41b6-839c-a39582af7079&page=queryresults
[0m10:11:18.127953 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:a5cd0fa0-79e8-4a02-8521-41c375e89d91&page=queryresults
[0m10:11:19.675837 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c3c950b5-f8cf-480f-b12f-acf986e1cc26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4f871e7f10>]}
[0m10:11:19.676278 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c3c950b5-f8cf-480f-b12f-acf986e1cc26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4f84732650>]}
[0m10:11:19.676724 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c3c950b5-f8cf-480f-b12f-acf986e1cc26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4f87ca0390>]}
[0m10:11:19.678884 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c3c950b5-f8cf-480f-b12f-acf986e1cc26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4f8704ac10>]}
[0m10:11:19.679494 [info ] [Thread-1 (]: 1 of 9 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.22s]
[0m10:11:19.681023 [info ] [Thread-4 (]: 4 of 9 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.22s]
[0m10:11:19.682436 [info ] [Thread-2 (]: 2 of 9 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.22s]
[0m10:11:19.684124 [info ] [Thread-3 (]: 3 of 9 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.22s]
[0m10:11:19.685483 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m10:11:19.686846 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m10:11:19.687917 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m10:11:19.689047 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m10:11:19.690411 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m10:11:19.692134 [debug] [Thread-4 (]: Began running node model.hailing_project.dim_driver
[0m10:11:19.693616 [info ] [Thread-1 (]: 5 of 9 START sql incremental model rizky_dwh_hailing_facts.dim_customer ........ [RUN]
[0m10:11:19.694762 [info ] [Thread-4 (]: 6 of 9 START sql incremental model rizky_dwh_hailing_facts.dim_driver .......... [RUN]
[0m10:11:19.696094 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_customer, now model.hailing_project.dim_customer)
[0m10:11:19.697498 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_vehicle, now model.hailing_project.dim_driver)
[0m10:11:19.698566 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m10:11:19.699390 [debug] [Thread-4 (]: Began compiling node model.hailing_project.dim_driver
[0m10:11:19.704384 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m10:11:19.708544 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.dim_driver"
[0m10:11:19.713775 [debug] [Thread-4 (]: Began executing node model.hailing_project.dim_driver
[0m10:11:19.718215 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m10:11:19.718619 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m10:11:19.724740 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m10:11:19.952868 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.dim_driver"
[0m10:11:19.959845 [debug] [Thread-4 (]: On model.hailing_project.dim_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver` as DBT_INTERNAL_DEST
        using (


WITH driver AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver` --pakai ref untuk buat dependency

),

vehicle AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle`
)

SELECT
    driver.driver_id,
    vehicle.vehicle_id,
    driver.name as driver_name,
    driver.phone_number as phone_number,
    driver.email as email,
    vehicle.vehicle_type,
    vehicle.brand as vehicle_brand,
    vehicle.year as vehicle_production_year,
    vehicle.license_plate,
    driver.created_at
FROM driver
LEFT JOIN vehicle
on driver.driver_id = vehicle.vehicle_id


    WHERE created_at > (
        SELECT MAX(driver.created_at)
        FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_name` = DBT_INTERNAL_SOURCE.`driver_name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`vehicle_brand` = DBT_INTERNAL_SOURCE.`vehicle_brand`,`vehicle_production_year` = DBT_INTERNAL_SOURCE.`vehicle_production_year`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `vehicle_id`, `driver_name`, `phone_number`, `email`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)
    values
        (`driver_id`, `vehicle_id`, `driver_name`, `phone_number`, `email`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)


    
[0m10:11:19.968594 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m10:11:19.974947 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
)

SELECT * FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m10:11:20.227467 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:5621e1d3-1eff-4ccf-9622-0870177ccc4e&page=queryresults
[0m10:11:20.230442 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:bcb77522-0b1f-4955-8304-c9ac4d445d1b&page=queryresults
[0m10:11:20.341972 [error] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:5621e1d3-1eff-4ccf-9622-0870177ccc4e&page=queryresults
[0m10:11:20.347916 [debug] [Thread-4 (]: Database Error in model dim_driver (models/facts/dim_driver.sql)
  Column name created_at is ambiguous at [44:11]
  compiled code at target/run/hailing_project/models/facts/dim_driver.sql
[0m10:11:20.349214 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c3c950b5-f8cf-480f-b12f-acf986e1cc26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4f870e0250>]}
[0m10:11:20.351859 [error] [Thread-4 (]: 6 of 9 ERROR creating sql incremental model rizky_dwh_hailing_facts.dim_driver . [[31mERROR[0m in 0.65s]
[0m10:11:20.353267 [debug] [Thread-4 (]: Finished running node model.hailing_project.dim_driver
[0m10:11:20.354914 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.dim_driver' to be skipped because of status 'error'.  Reason: Database Error in model dim_driver (models/facts/dim_driver.sql)
  Column name created_at is ambiguous at [44:11]
  compiled code at target/run/hailing_project/models/facts/dim_driver.sql.
[0m10:11:21.719699 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c3c950b5-f8cf-480f-b12f-acf986e1cc26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fb53b3110>]}
[0m10:11:21.721338 [info ] [Thread-1 (]: 5 of 9 OK created sql incremental model rizky_dwh_hailing_facts.dim_customer ... [[32mMERGE (0.0 rows, 11.3 KiB processed)[0m in 2.02s]
[0m10:11:21.722662 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m10:11:21.724396 [debug] [Thread-2 (]: Began running node model.hailing_project.fact_hailing_rides
[0m10:11:21.725420 [info ] [Thread-2 (]: 7 of 9 SKIP relation rizky_dwh_hailing_facts.fact_hailing_rides ................ [[33mSKIP[0m]
[0m10:11:21.726571 [debug] [Thread-2 (]: Finished running node model.hailing_project.fact_hailing_rides
[0m10:11:21.728369 [debug] [Thread-4 (]: Began running node model.hailing_project.mart_cust_rides_daily
[0m10:11:21.728778 [debug] [Thread-1 (]: Began running node model.hailing_project.mart_driver_loyalty_mgmt
[0m10:11:21.729741 [info ] [Thread-4 (]: 8 of 9 SKIP relation rizky_dwh_hailing_marts.mart_cust_rides_daily ............. [[33mSKIP[0m]
[0m10:11:21.731305 [info ] [Thread-1 (]: 9 of 9 SKIP relation rizky_dwh_hailing_marts.mart_driver_loyalty_mgmt .......... [[33mSKIP[0m]
[0m10:11:21.732658 [debug] [Thread-4 (]: Finished running node model.hailing_project.mart_cust_rides_daily
[0m10:11:21.734240 [debug] [Thread-1 (]: Finished running node model.hailing_project.mart_driver_loyalty_mgmt
[0m10:11:21.737291 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m10:11:21.740344 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:11:21.741521 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m10:11:21.742510 [debug] [MainThread]: Connection 'model.hailing_project.dim_customer' was properly closed.
[0m10:11:21.743735 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m10:11:21.744687 [debug] [MainThread]: Connection 'model.hailing_project.dim_driver' was properly closed.
[0m10:11:21.746072 [info ] [MainThread]: 
[0m10:11:21.747315 [info ] [MainThread]: Finished running 8 incremental models, 1 table model in 0 hours 0 minutes and 6.34 seconds (6.34s).
[0m10:11:21.749312 [debug] [MainThread]: Command end result
[0m10:11:21.834042 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m10:11:21.854683 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m10:11:21.864008 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m10:11:21.864903 [info ] [MainThread]: 
[0m10:11:21.866070 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m10:11:21.867461 [info ] [MainThread]: 
[0m10:11:21.868608 [error] [MainThread]:   Database Error in model dim_driver (models/facts/dim_driver.sql)
  Column name created_at is ambiguous at [44:11]
  compiled code at target/run/hailing_project/models/facts/dim_driver.sql
[0m10:11:21.869625 [info ] [MainThread]: 
[0m10:11:21.870679 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=1 SKIP=3 TOTAL=9
[0m10:11:21.872523 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 7.763536, "process_in_blocks": "0", "process_kernel_time": 0.259098, "process_mem_max_rss": "225884", "process_out_blocks": "0", "process_user_time": 3.793201}
[0m10:11:21.873933 [debug] [MainThread]: Command `dbt run` failed at 10:11:21.873700 after 7.77 seconds
[0m10:11:21.874991 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fb53b2a50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fb53b2f90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4fb53842d0>]}
[0m10:11:21.876006 [debug] [MainThread]: Flushing usage events
[0m10:11:23.433298 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m10:11:48.679249 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f12342fb810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f123440dc90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1234353d10>]}


============================== 10:11:48.682476 | 02154afb-430e-42c0-ae29-a07343088357 ==============================
[0m10:11:48.682476 [info ] [MainThread]: Running with dbt=1.9.0
[0m10:11:48.685312 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt run', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m10:11:49.269247 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '02154afb-430e-42c0-ae29-a07343088357', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1207fa5e10>]}
[0m10:11:49.314845 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '02154afb-430e-42c0-ae29-a07343088357', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f123657db90>]}
[0m10:11:49.315944 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m10:11:49.385023 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m10:11:49.573181 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m10:11:49.574824 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/facts/dim_driver.sql
[0m10:11:49.825350 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '02154afb-430e-42c0-ae29-a07343088357', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1236585c50>]}
[0m10:11:49.899089 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m10:11:49.905153 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m10:11:49.919938 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '02154afb-430e-42c0-ae29-a07343088357', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1205fa7790>]}
[0m10:11:49.921275 [info ] [MainThread]: Found 9 models, 8 sources, 489 macros
[0m10:11:49.922508 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '02154afb-430e-42c0-ae29-a07343088357', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1206238ad0>]}
[0m10:11:49.925185 [info ] [MainThread]: 
[0m10:11:49.926283 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m10:11:49.927369 [info ] [MainThread]: 
[0m10:11:49.928524 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m10:11:49.933576 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m10:11:49.934366 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m10:11:49.935012 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m10:11:49.935641 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:11:49.936604 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:11:49.937569 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:11:50.748519 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_facts)
[0m10:11:50.749117 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_staging)
[0m10:11:50.751551 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_marts)
[0m10:11:50.752434 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:11:50.753395 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:11:50.754598 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:11:50.995347 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '02154afb-430e-42c0-ae29-a07343088357', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f12065c67d0>]}
[0m10:11:50.997276 [debug] [MainThread]: Opening a new connection, currently in state init
[0m10:11:51.002472 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m10:11:51.002863 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m10:11:51.003249 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m10:11:51.003602 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m10:11:51.004329 [info ] [Thread-1 (]: 1 of 9 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [RUN]
[0m10:11:51.006631 [info ] [Thread-2 (]: 2 of 9 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [RUN]
[0m10:11:51.008425 [info ] [Thread-3 (]: 3 of 9 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [RUN]
[0m10:11:51.010560 [info ] [Thread-4 (]: 4 of 9 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [RUN]
[0m10:11:51.013191 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_staging, now model.hailing_project.production_hailing_staging_customer)
[0m10:11:51.019506 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_marts, now model.hailing_project.production_hailing_staging_driver)
[0m10:11:51.020607 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_facts, now model.hailing_project.production_hailing_staging_ride)
[0m10:11:51.022008 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_vehicle'
[0m10:11:51.023073 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m10:11:51.024601 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m10:11:51.025748 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m10:11:51.026648 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m10:11:51.036208 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m10:11:51.039924 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m10:11:51.044300 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m10:11:51.049174 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m10:11:51.055423 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m10:11:51.056482 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m10:11:51.056931 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m10:11:51.062852 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m10:11:51.099995 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m10:11:51.101940 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m10:11:51.104600 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m10:11:51.108131 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m10:11:51.379326 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m10:11:51.382724 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m10:11:51.384282 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m10:11:51.385501 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m10:11:51.390487 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m10:11:51.391789 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m10:11:51.393429 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m10:11:51.396232 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m10:11:51.606705 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:5f2a8b62-41f4-49b6-bb1b-9c254095e727&page=queryresults
[0m10:11:51.611328 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:411a146a-9774-4a94-a0a2-afa79d0496f2&page=queryresults
[0m10:11:51.621099 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:14443f17-032d-4d69-b7b1-282611843a8b&page=queryresults
[0m10:11:51.636851 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:11ac3150-0ceb-4487-a9fa-dab47488852b&page=queryresults
[0m10:11:53.586942 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '02154afb-430e-42c0-ae29-a07343088357', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f12046b8790>]}
[0m10:11:53.588077 [info ] [Thread-2 (]: 2 of 9 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.57s]
[0m10:11:53.590673 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m10:11:53.690096 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '02154afb-430e-42c0-ae29-a07343088357', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f12046bced0>]}
[0m10:11:53.691845 [info ] [Thread-1 (]: 1 of 9 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.68s]
[0m10:11:53.693129 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m10:11:53.694366 [debug] [Thread-2 (]: Began running node model.hailing_project.dim_customer
[0m10:11:53.695288 [info ] [Thread-2 (]: 5 of 9 START sql incremental model rizky_dwh_hailing_facts.dim_customer ........ [RUN]
[0m10:11:53.696560 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_driver, now model.hailing_project.dim_customer)
[0m10:11:53.697384 [debug] [Thread-2 (]: Began compiling node model.hailing_project.dim_customer
[0m10:11:53.701298 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m10:11:53.709045 [debug] [Thread-2 (]: Began executing node model.hailing_project.dim_customer
[0m10:11:53.713756 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m10:11:53.755710 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '02154afb-430e-42c0-ae29-a07343088357', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f120612e450>]}
[0m10:11:53.756956 [info ] [Thread-3 (]: 3 of 9 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.74s]
[0m10:11:53.758165 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m10:11:53.875349 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '02154afb-430e-42c0-ae29-a07343088357', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1205fa67d0>]}
[0m10:11:53.877449 [info ] [Thread-4 (]: 4 of 9 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.85s]
[0m10:11:53.880509 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m10:11:53.882655 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_driver
[0m10:11:53.883688 [info ] [Thread-1 (]: 6 of 9 START sql incremental model rizky_dwh_hailing_facts.dim_driver .......... [RUN]
[0m10:11:53.885450 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_customer, now model.hailing_project.dim_driver)
[0m10:11:53.886459 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_driver
[0m10:11:53.891310 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_driver"
[0m10:11:53.901509 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_driver
[0m10:11:53.907552 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m10:11:54.080660 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m10:11:54.086833 [debug] [Thread-2 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
)

SELECT * FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m10:11:54.117310 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_driver"
[0m10:11:54.122346 [debug] [Thread-1 (]: On model.hailing_project.dim_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver` as DBT_INTERNAL_DEST
        using (


WITH driver AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver` --pakai ref untuk buat dependency

),

vehicle AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle`
)

SELECT
    driver.driver_id,
    vehicle.vehicle_id,
    driver.name as driver_name,
    driver.phone_number as phone_number,
    driver.email as email,
    vehicle.vehicle_type,
    vehicle.brand as vehicle_brand,
    vehicle.year as vehicle_production_year,
    vehicle.license_plate,
    driver.created_at
FROM driver
LEFT JOIN vehicle
on driver.driver_id = vehicle.vehicle_id


    WHERE driver.created_at > (
        SELECT MAX(driver.created_at)
        FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_name` = DBT_INTERNAL_SOURCE.`driver_name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`vehicle_brand` = DBT_INTERNAL_SOURCE.`vehicle_brand`,`vehicle_production_year` = DBT_INTERNAL_SOURCE.`vehicle_production_year`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `vehicle_id`, `driver_name`, `phone_number`, `email`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)
    values
        (`driver_id`, `vehicle_id`, `driver_name`, `phone_number`, `email`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)


    
[0m10:11:54.355989 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:9b9230bf-957a-4c50-becc-4d0a50434c7b&page=queryresults
[0m10:11:54.365006 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:d79460cd-462f-498d-a53e-9223f5fb31fe&page=queryresults
[0m10:11:55.891407 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '02154afb-430e-42c0-ae29-a07343088357', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f120468ce50>]}
[0m10:11:55.893701 [info ] [Thread-2 (]: 5 of 9 OK created sql incremental model rizky_dwh_hailing_facts.dim_customer ... [[32mMERGE (0.0 rows, 11.3 KiB processed)[0m in 2.19s]
[0m10:11:55.895968 [debug] [Thread-2 (]: Finished running node model.hailing_project.dim_customer
[0m10:11:56.117703 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '02154afb-430e-42c0-ae29-a07343088357', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1206044450>]}
[0m10:11:56.119079 [info ] [Thread-1 (]: 6 of 9 OK created sql incremental model rizky_dwh_hailing_facts.dim_driver ..... [[32mMERGE (0.0 rows, 18.0 KiB processed)[0m in 2.23s]
[0m10:11:56.120407 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_driver
[0m10:11:56.122064 [debug] [Thread-4 (]: Began running node model.hailing_project.fact_hailing_rides
[0m10:11:56.123321 [info ] [Thread-4 (]: 7 of 9 START sql incremental model rizky_dwh_hailing_facts.fact_hailing_rides .. [RUN]
[0m10:11:56.124379 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_vehicle, now model.hailing_project.fact_hailing_rides)
[0m10:11:56.125272 [debug] [Thread-4 (]: Began compiling node model.hailing_project.fact_hailing_rides
[0m10:11:56.130021 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.fact_hailing_rides"
[0m10:11:56.137514 [debug] [Thread-4 (]: Began executing node model.hailing_project.fact_hailing_rides
[0m10:11:56.141104 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m10:11:56.365337 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.fact_hailing_rides"
[0m10:11:56.371568 [debug] [Thread-4 (]: On model.hailing_project.fact_hailing_rides: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.fact_hailing_rides"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides` as DBT_INTERNAL_DEST
        using (

WITH dim_driver AS (

    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
),

dim_customer AS (

    SELECT * 
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer`
),

ride_staging AS (

    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride`
)

SELECT
ride_staging.ride_id,
ride_staging.start_time AS ride_start_time,
ride_staging.end_time AS ride_end_time,
ride_staging.distance_km,
ride_staging.fare,
ride_staging.ride_status,
dim_customer.cust_id,
dim_customer.name AS cust_name,
dim_customer.phone_number AS cust_phone_number,
dim_customer.email AS cust_email,
dim_driver.driver_id,
dim_driver.driver_name,
dim_driver.phone_number AS driver_phone_number,
dim_driver.email AS driver_email,
dim_driver.vehicle_id,
dim_driver.vehicle_type,
dim_driver.vehicle_brand,
dim_driver.vehicle_production_year,
dim_driver.license_plate,
ride_staging.created_at

FROM ride_staging

LEFT JOIN dim_customer
on ride_staging.cust_id = dim_customer.cust_id

LEFT JOIN dim_driver
on ride_staging.driver_id = dim_driver.driver_id


    WHERE ride_staging.created_at > (
        SELECT MAX(ride_staging.created_at)
        FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`ride_start_time` = DBT_INTERNAL_SOURCE.`ride_start_time`,`ride_end_time` = DBT_INTERNAL_SOURCE.`ride_end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`cust_name` = DBT_INTERNAL_SOURCE.`cust_name`,`cust_phone_number` = DBT_INTERNAL_SOURCE.`cust_phone_number`,`cust_email` = DBT_INTERNAL_SOURCE.`cust_email`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`driver_name` = DBT_INTERNAL_SOURCE.`driver_name`,`driver_phone_number` = DBT_INTERNAL_SOURCE.`driver_phone_number`,`driver_email` = DBT_INTERNAL_SOURCE.`driver_email`,`vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`vehicle_brand` = DBT_INTERNAL_SOURCE.`vehicle_brand`,`vehicle_production_year` = DBT_INTERNAL_SOURCE.`vehicle_production_year`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `ride_start_time`, `ride_end_time`, `distance_km`, `fare`, `ride_status`, `cust_id`, `cust_name`, `cust_phone_number`, `cust_email`, `driver_id`, `driver_name`, `driver_phone_number`, `driver_email`, `vehicle_id`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)
    values
        (`ride_id`, `ride_start_time`, `ride_end_time`, `distance_km`, `fare`, `ride_status`, `cust_id`, `cust_name`, `cust_phone_number`, `cust_email`, `driver_id`, `driver_name`, `driver_phone_number`, `driver_email`, `vehicle_id`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)


    
[0m10:11:56.613037 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:d010ad0e-ceee-4eb8-a1bc-92468047af74&page=queryresults
[0m10:11:58.396105 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '02154afb-430e-42c0-ae29-a07343088357', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f12046e2650>]}
[0m10:11:58.397447 [info ] [Thread-4 (]: 7 of 9 OK created sql incremental model rizky_dwh_hailing_facts.fact_hailing_rides  [[32mMERGE (0.0 rows, 40.3 KiB processed)[0m in 2.27s]
[0m10:11:58.398698 [debug] [Thread-4 (]: Finished running node model.hailing_project.fact_hailing_rides
[0m10:11:58.400060 [debug] [Thread-2 (]: Began running node model.hailing_project.mart_cust_rides_daily
[0m10:11:58.400513 [debug] [Thread-1 (]: Began running node model.hailing_project.mart_driver_loyalty_mgmt
[0m10:11:58.401346 [info ] [Thread-2 (]: 8 of 9 START sql table model rizky_dwh_hailing_marts.mart_cust_rides_daily ..... [RUN]
[0m10:11:58.402587 [info ] [Thread-1 (]: 9 of 9 START sql incremental model rizky_dwh_hailing_marts.mart_driver_loyalty_mgmt  [RUN]
[0m10:11:58.403612 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.hailing_project.dim_customer, now model.hailing_project.mart_cust_rides_daily)
[0m10:11:58.405027 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.hailing_project.dim_driver, now model.hailing_project.mart_driver_loyalty_mgmt)
[0m10:11:58.406259 [debug] [Thread-2 (]: Began compiling node model.hailing_project.mart_cust_rides_daily
[0m10:11:58.408211 [debug] [Thread-1 (]: Began compiling node model.hailing_project.mart_driver_loyalty_mgmt
[0m10:11:58.412983 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.mart_cust_rides_daily"
[0m10:11:58.417223 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.mart_driver_loyalty_mgmt"
[0m10:11:58.422625 [debug] [Thread-1 (]: Began executing node model.hailing_project.mart_driver_loyalty_mgmt
[0m10:11:58.423213 [debug] [Thread-2 (]: Began executing node model.hailing_project.mart_cust_rides_daily
[0m10:11:58.426371 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m10:11:58.438745 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m10:11:58.644978 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.mart_driver_loyalty_mgmt"
[0m10:11:58.652222 [debug] [Thread-1 (]: On model.hailing_project.mart_driver_loyalty_mgmt: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.mart_driver_loyalty_mgmt"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_marts`.`mart_driver_loyalty_mgmt` as DBT_INTERNAL_DEST
        using (

WITH dim_driver AS(
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
),

fact_rides AS(
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
)

SELECT 
dim_driver.driver_id,
dim_driver.driver_name,
dim_driver.phone_number,
dim_driver.email,
dim_driver.vehicle_type,
COUNT(fact_rides.ride_id) AS no_of_rides,
SUM(TIMESTAMP_DIFF(fact_rides.ride_end_time, fact_rides.ride_start_time, MINUTE)) AS total_ride_duration_min,
SUM(fact_rides.fare) AS total_fare,
SUM(fact_rides.distance_km) as total_distance_km,
SUM(fact_rides.distance_km)-SUM(fact_rides.fare) AS rev_opportunity_loss,
fact_rides.ride_status AS ride_status

FROM dim_driver
LEFT JOIN fact_rides
ON dim_driver.driver_id = fact_rides.driver_id

GROUP BY driver_id,driver_name,phone_number,email,vehicle_type,ride_status
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`driver_name` = DBT_INTERNAL_SOURCE.`driver_name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`no_of_rides` = DBT_INTERNAL_SOURCE.`no_of_rides`,`total_ride_duration_min` = DBT_INTERNAL_SOURCE.`total_ride_duration_min`,`total_fare` = DBT_INTERNAL_SOURCE.`total_fare`,`total_distance_km` = DBT_INTERNAL_SOURCE.`total_distance_km`,`rev_opportunity_loss` = DBT_INTERNAL_SOURCE.`rev_opportunity_loss`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`
    

    when not matched then insert
        (`driver_id`, `driver_name`, `phone_number`, `email`, `vehicle_type`, `no_of_rides`, `total_ride_duration_min`, `total_fare`, `total_distance_km`, `rev_opportunity_loss`, `ride_status`)
    values
        (`driver_id`, `driver_name`, `phone_number`, `email`, `vehicle_type`, `no_of_rides`, `total_ride_duration_min`, `total_fare`, `total_distance_km`, `rev_opportunity_loss`, `ride_status`)


    
[0m10:11:58.701867 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.mart_cust_rides_daily"
[0m10:11:58.710175 [debug] [Thread-2 (]: On model.hailing_project.mart_cust_rides_daily: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.mart_cust_rides_daily"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_marts`.`mart_cust_rides_daily`
      
    partition by ride_date
    

    OPTIONS()
    as (
      


WITH fact_rides AS(

    SELECT * 
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
)

SELECT 

    fact_rides.cust_id,
    DATE(fact_rides.created_at) AS ride_date,
    fact_rides.cust_name,
    fact_rides.cust_email,
    fact_rides.cust_phone_number,
    COUNT(fact_rides.ride_id) AS no_of_rides,
    SUM(TIMESTAMP_DIFF(fact_rides.ride_end_time, fact_rides.ride_start_time, MINUTE)) AS total_ride_duration_min,
    SUM(fact_rides.fare) AS total_fare,
    SUM(fact_rides.distance_km) as total_distance_km,
    SUM(fact_rides.distance_km)-SUM(fact_rides.fare) AS rev_opportunity_loss,
    fact_rides.ride_status

FROM fact_rides
GROUP BY cust_name, cust_id, ride_date, cust_email, cust_phone_number, ride_status
    );
  
[0m10:11:58.930329 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:5e97c1f4-db0f-4fbb-872d-f4a93cf60adf&page=queryresults
[0m10:11:58.932650 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:46a0f99e-66d6-40f3-8c9b-49331b6d8141&page=queryresults
[0m10:11:59.565639 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:5e97c1f4-db0f-4fbb-872d-f4a93cf60adf&page=queryresults
[0m10:11:59.571139 [debug] [Thread-1 (]: Database Error in model mart_driver_loyalty_mgmt (models/marts/mart_driver_loyalty_mgmt.sql)
  UPDATE/MERGE must match at most one source row for each target row
  compiled code at target/run/hailing_project/models/marts/mart_driver_loyalty_mgmt.sql
[0m10:11:59.572489 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '02154afb-430e-42c0-ae29-a07343088357', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1204167c50>]}
[0m10:11:59.573958 [error] [Thread-1 (]: 9 of 9 ERROR creating sql incremental model rizky_dwh_hailing_marts.mart_driver_loyalty_mgmt  [[31mERROR[0m in 1.17s]
[0m10:11:59.575429 [debug] [Thread-1 (]: Finished running node model.hailing_project.mart_driver_loyalty_mgmt
[0m10:11:59.576734 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.mart_driver_loyalty_mgmt' to be skipped because of status 'error'.  Reason: Database Error in model mart_driver_loyalty_mgmt (models/marts/mart_driver_loyalty_mgmt.sql)
  UPDATE/MERGE must match at most one source row for each target row
  compiled code at target/run/hailing_project/models/marts/mart_driver_loyalty_mgmt.sql.
[0m10:12:00.783561 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '02154afb-430e-42c0-ae29-a07343088357', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f12041971d0>]}
[0m10:12:00.785227 [info ] [Thread-2 (]: 8 of 9 OK created sql table model rizky_dwh_hailing_marts.mart_cust_rides_daily  [[32mCREATE TABLE (73.0 rows, 11.2 KiB processed)[0m in 2.38s]
[0m10:12:00.786712 [debug] [Thread-2 (]: Finished running node model.hailing_project.mart_cust_rides_daily
[0m10:12:00.789212 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m10:12:00.792022 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:12:00.792834 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m10:12:00.793788 [debug] [MainThread]: Connection 'model.hailing_project.mart_driver_loyalty_mgmt' was properly closed.
[0m10:12:00.797981 [debug] [MainThread]: Connection 'model.hailing_project.mart_cust_rides_daily' was properly closed.
[0m10:12:00.801954 [debug] [MainThread]: Connection 'model.hailing_project.fact_hailing_rides' was properly closed.
[0m10:12:00.803967 [info ] [MainThread]: 
[0m10:12:00.806516 [info ] [MainThread]: Finished running 8 incremental models, 1 table model in 0 hours 0 minutes and 10.88 seconds (10.88s).
[0m10:12:00.810079 [debug] [MainThread]: Command end result
[0m10:12:00.851569 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m10:12:00.856331 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m10:12:00.864608 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m10:12:00.865731 [info ] [MainThread]: 
[0m10:12:00.866967 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m10:12:00.868333 [info ] [MainThread]: 
[0m10:12:00.869622 [error] [MainThread]:   Database Error in model mart_driver_loyalty_mgmt (models/marts/mart_driver_loyalty_mgmt.sql)
  UPDATE/MERGE must match at most one source row for each target row
  compiled code at target/run/hailing_project/models/marts/mart_driver_loyalty_mgmt.sql
[0m10:12:00.870708 [info ] [MainThread]: 
[0m10:12:00.871640 [info ] [MainThread]: Done. PASS=8 WARN=0 ERROR=1 SKIP=0 TOTAL=9
[0m10:12:00.873428 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 12.249406, "process_in_blocks": "0", "process_kernel_time": 0.235523, "process_mem_max_rss": "226616", "process_out_blocks": "0", "process_user_time": 3.860535}
[0m10:12:00.874955 [debug] [MainThread]: Command `dbt run` failed at 10:12:00.874718 after 12.25 seconds
[0m10:12:00.876083 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1234355f50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1234354fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f12046b8d50>]}
[0m10:12:00.876937 [debug] [MainThread]: Flushing usage events
[0m10:12:02.392623 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m10:13:35.004406 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff385cd6dd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff38618c4d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff38618c510>]}


============================== 10:13:35.007237 | 2459d857-e2ee-43f3-be98-fabccac9c46a ==============================
[0m10:13:35.007237 [info ] [MainThread]: Running with dbt=1.9.0
[0m10:13:35.008501 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'version_check': 'True', 'warn_error': 'None', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m10:13:35.612610 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '2459d857-e2ee-43f3-be98-fabccac9c46a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff385d53f50>]}
[0m10:13:35.658452 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '2459d857-e2ee-43f3-be98-fabccac9c46a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff387f89d50>]}
[0m10:13:35.659742 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m10:13:35.720218 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m10:13:35.905729 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m10:13:35.907073 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/marts/mart_driver_loyalty_mgmt.sql
[0m10:13:36.154857 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2459d857-e2ee-43f3-be98-fabccac9c46a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff387e42350>]}
[0m10:13:36.224274 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m10:13:36.229314 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m10:13:36.246453 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2459d857-e2ee-43f3-be98-fabccac9c46a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff357ae81d0>]}
[0m10:13:36.247635 [info ] [MainThread]: Found 9 models, 8 sources, 489 macros
[0m10:13:36.249048 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2459d857-e2ee-43f3-be98-fabccac9c46a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff385d1d290>]}
[0m10:13:36.252612 [info ] [MainThread]: 
[0m10:13:36.253839 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m10:13:36.254827 [info ] [MainThread]: 
[0m10:13:36.256188 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m10:13:36.261173 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m10:13:36.261897 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m10:13:36.262536 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m10:13:36.263220 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:13:36.264044 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:13:36.264934 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:13:37.125574 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_staging)
[0m10:13:37.126148 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_marts)
[0m10:13:37.126771 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_facts)
[0m10:13:37.127956 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:13:37.129295 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:13:37.130480 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:13:37.361052 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2459d857-e2ee-43f3-be98-fabccac9c46a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff357e6bd50>]}
[0m10:13:37.362083 [debug] [MainThread]: Opening a new connection, currently in state init
[0m10:13:37.366277 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m10:13:37.366652 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m10:13:37.367031 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m10:13:37.367400 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m10:13:37.367954 [info ] [Thread-1 (]: 1 of 9 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [RUN]
[0m10:13:37.369057 [info ] [Thread-2 (]: 2 of 9 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [RUN]
[0m10:13:37.370360 [info ] [Thread-3 (]: 3 of 9 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [RUN]
[0m10:13:37.371547 [info ] [Thread-4 (]: 4 of 9 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [RUN]
[0m10:13:37.372622 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_facts, now model.hailing_project.production_hailing_staging_customer)
[0m10:13:37.373527 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_staging, now model.hailing_project.production_hailing_staging_driver)
[0m10:13:37.374397 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_marts, now model.hailing_project.production_hailing_staging_ride)
[0m10:13:37.375326 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_vehicle'
[0m10:13:37.376091 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m10:13:37.376857 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m10:13:37.377783 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m10:13:37.378621 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m10:13:37.393722 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m10:13:37.397233 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m10:13:37.401349 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m10:13:37.405409 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m10:13:37.411294 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m10:13:37.411862 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m10:13:37.417801 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m10:13:37.418155 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m10:13:37.458257 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m10:13:37.460224 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m10:13:37.462965 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m10:13:37.465799 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m10:13:37.790676 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m10:13:37.792072 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m10:13:37.793388 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m10:13:37.794451 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m10:13:37.800071 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m10:13:37.800855 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m10:13:37.803408 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m10:13:37.804023 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m10:13:38.037386 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:10aba67b-21af-4a16-80ca-0736c59683c2&page=queryresults
[0m10:13:38.063996 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:30b9e065-eae8-4f4b-ae30-8c2428a4757e&page=queryresults
[0m10:13:38.065467 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:6273f10a-e5c3-4cbb-bbcb-865e2a0f639d&page=queryresults
[0m10:13:38.066960 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:2dafabad-0abd-46ee-9f73-89219b3011be&page=queryresults
[0m10:13:39.600595 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2459d857-e2ee-43f3-be98-fabccac9c46a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff357f982d0>]}
[0m10:13:39.604094 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2459d857-e2ee-43f3-be98-fabccac9c46a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff31673f950>]}
[0m10:13:39.608425 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2459d857-e2ee-43f3-be98-fabccac9c46a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff31671ce90>]}
[0m10:13:39.609006 [info ] [Thread-2 (]: 2 of 9 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.23s]
[0m10:13:39.611115 [info ] [Thread-4 (]: 4 of 9 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.23s]
[0m10:13:39.612555 [info ] [Thread-3 (]: 3 of 9 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.23s]
[0m10:13:39.613810 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m10:13:39.615107 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m10:13:39.616203 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m10:13:39.617964 [debug] [Thread-2 (]: Began running node model.hailing_project.dim_driver
[0m10:13:39.619177 [info ] [Thread-2 (]: 5 of 9 START sql incremental model rizky_dwh_hailing_facts.dim_driver .......... [RUN]
[0m10:13:39.620409 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_driver, now model.hailing_project.dim_driver)
[0m10:13:39.621817 [debug] [Thread-2 (]: Began compiling node model.hailing_project.dim_driver
[0m10:13:39.626235 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.dim_driver"
[0m10:13:39.632807 [debug] [Thread-2 (]: Began executing node model.hailing_project.dim_driver
[0m10:13:39.635892 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m10:13:39.973440 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2459d857-e2ee-43f3-be98-fabccac9c46a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff31676dcd0>]}
[0m10:13:39.974806 [info ] [Thread-1 (]: 1 of 9 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.60s]
[0m10:13:39.976371 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m10:13:39.977845 [debug] [Thread-4 (]: Began running node model.hailing_project.dim_customer
[0m10:13:39.979096 [info ] [Thread-4 (]: 6 of 9 START sql incremental model rizky_dwh_hailing_facts.dim_customer ........ [RUN]
[0m10:13:39.981320 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_vehicle, now model.hailing_project.dim_customer)
[0m10:13:39.982431 [debug] [Thread-4 (]: Began compiling node model.hailing_project.dim_customer
[0m10:13:39.987728 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m10:13:39.996613 [debug] [Thread-4 (]: Began executing node model.hailing_project.dim_customer
[0m10:13:40.000814 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m10:13:40.379709 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.dim_driver"
[0m10:13:40.387333 [debug] [Thread-2 (]: On model.hailing_project.dim_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver` as DBT_INTERNAL_DEST
        using (


WITH driver AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver` --pakai ref untuk buat dependency

),

vehicle AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle`
)

SELECT
    driver.driver_id,
    vehicle.vehicle_id,
    driver.name as driver_name,
    driver.phone_number as phone_number,
    driver.email as email,
    vehicle.vehicle_type,
    vehicle.brand as vehicle_brand,
    vehicle.year as vehicle_production_year,
    vehicle.license_plate,
    driver.created_at
FROM driver
LEFT JOIN vehicle
on driver.driver_id = vehicle.vehicle_id


    WHERE driver.created_at > (
        SELECT MAX(driver.created_at)
        FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_name` = DBT_INTERNAL_SOURCE.`driver_name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`vehicle_brand` = DBT_INTERNAL_SOURCE.`vehicle_brand`,`vehicle_production_year` = DBT_INTERNAL_SOURCE.`vehicle_production_year`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `vehicle_id`, `driver_name`, `phone_number`, `email`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)
    values
        (`driver_id`, `vehicle_id`, `driver_name`, `phone_number`, `email`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)


    
[0m10:13:40.646797 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:0acce3a9-be5e-4c77-8ae1-8f14578be8df&page=queryresults
[0m10:13:40.686947 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m10:13:40.694871 [debug] [Thread-4 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
)

SELECT * FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m10:13:40.931197 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:7d400e53-fff8-4c4c-b7c7-cfc2dffd7dea&page=queryresults
[0m10:13:42.410890 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2459d857-e2ee-43f3-be98-fabccac9c46a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3164b4990>]}
[0m10:13:42.412382 [info ] [Thread-2 (]: 5 of 9 OK created sql incremental model rizky_dwh_hailing_facts.dim_driver ..... [[32mMERGE (0.0 rows, 18.0 KiB processed)[0m in 2.79s]
[0m10:13:42.414869 [debug] [Thread-2 (]: Finished running node model.hailing_project.dim_driver
[0m10:13:42.432550 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2459d857-e2ee-43f3-be98-fabccac9c46a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff316752e50>]}
[0m10:13:42.434347 [info ] [Thread-4 (]: 6 of 9 OK created sql incremental model rizky_dwh_hailing_facts.dim_customer ... [[32mMERGE (0.0 rows, 11.3 KiB processed)[0m in 2.45s]
[0m10:13:42.436068 [debug] [Thread-4 (]: Finished running node model.hailing_project.dim_customer
[0m10:13:42.438159 [debug] [Thread-1 (]: Began running node model.hailing_project.fact_hailing_rides
[0m10:13:42.439604 [info ] [Thread-1 (]: 7 of 9 START sql incremental model rizky_dwh_hailing_facts.fact_hailing_rides .. [RUN]
[0m10:13:42.442300 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_customer, now model.hailing_project.fact_hailing_rides)
[0m10:13:42.443638 [debug] [Thread-1 (]: Began compiling node model.hailing_project.fact_hailing_rides
[0m10:13:42.449896 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.fact_hailing_rides"
[0m10:13:42.458646 [debug] [Thread-1 (]: Began executing node model.hailing_project.fact_hailing_rides
[0m10:13:42.462865 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m10:13:42.675462 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.fact_hailing_rides"
[0m10:13:42.681499 [debug] [Thread-1 (]: On model.hailing_project.fact_hailing_rides: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.fact_hailing_rides"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides` as DBT_INTERNAL_DEST
        using (

WITH dim_driver AS (

    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
),

dim_customer AS (

    SELECT * 
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer`
),

ride_staging AS (

    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride`
)

SELECT
ride_staging.ride_id,
ride_staging.start_time AS ride_start_time,
ride_staging.end_time AS ride_end_time,
ride_staging.distance_km,
ride_staging.fare,
ride_staging.ride_status,
dim_customer.cust_id,
dim_customer.name AS cust_name,
dim_customer.phone_number AS cust_phone_number,
dim_customer.email AS cust_email,
dim_driver.driver_id,
dim_driver.driver_name,
dim_driver.phone_number AS driver_phone_number,
dim_driver.email AS driver_email,
dim_driver.vehicle_id,
dim_driver.vehicle_type,
dim_driver.vehicle_brand,
dim_driver.vehicle_production_year,
dim_driver.license_plate,
ride_staging.created_at

FROM ride_staging

LEFT JOIN dim_customer
on ride_staging.cust_id = dim_customer.cust_id

LEFT JOIN dim_driver
on ride_staging.driver_id = dim_driver.driver_id


    WHERE ride_staging.created_at > (
        SELECT MAX(ride_staging.created_at)
        FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`ride_start_time` = DBT_INTERNAL_SOURCE.`ride_start_time`,`ride_end_time` = DBT_INTERNAL_SOURCE.`ride_end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`cust_name` = DBT_INTERNAL_SOURCE.`cust_name`,`cust_phone_number` = DBT_INTERNAL_SOURCE.`cust_phone_number`,`cust_email` = DBT_INTERNAL_SOURCE.`cust_email`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`driver_name` = DBT_INTERNAL_SOURCE.`driver_name`,`driver_phone_number` = DBT_INTERNAL_SOURCE.`driver_phone_number`,`driver_email` = DBT_INTERNAL_SOURCE.`driver_email`,`vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`vehicle_brand` = DBT_INTERNAL_SOURCE.`vehicle_brand`,`vehicle_production_year` = DBT_INTERNAL_SOURCE.`vehicle_production_year`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `ride_start_time`, `ride_end_time`, `distance_km`, `fare`, `ride_status`, `cust_id`, `cust_name`, `cust_phone_number`, `cust_email`, `driver_id`, `driver_name`, `driver_phone_number`, `driver_email`, `vehicle_id`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)
    values
        (`ride_id`, `ride_start_time`, `ride_end_time`, `distance_km`, `fare`, `ride_status`, `cust_id`, `cust_name`, `cust_phone_number`, `cust_email`, `driver_id`, `driver_name`, `driver_phone_number`, `driver_email`, `vehicle_id`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)


    
[0m10:13:42.966458 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:85378f86-007f-44cd-9fb7-210300df2f46&page=queryresults
[0m10:13:44.817889 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2459d857-e2ee-43f3-be98-fabccac9c46a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff316739d90>]}
[0m10:13:44.819019 [info ] [Thread-1 (]: 7 of 9 OK created sql incremental model rizky_dwh_hailing_facts.fact_hailing_rides  [[32mMERGE (0.0 rows, 40.3 KiB processed)[0m in 2.38s]
[0m10:13:44.821176 [debug] [Thread-1 (]: Finished running node model.hailing_project.fact_hailing_rides
[0m10:13:44.823028 [debug] [Thread-2 (]: Began running node model.hailing_project.mart_cust_rides_daily
[0m10:13:44.823434 [debug] [Thread-4 (]: Began running node model.hailing_project.mart_driver_loyalty_mgmt
[0m10:13:44.824759 [info ] [Thread-2 (]: 8 of 9 START sql table model rizky_dwh_hailing_marts.mart_cust_rides_daily ..... [RUN]
[0m10:13:44.826534 [info ] [Thread-4 (]: 9 of 9 START sql table model rizky_dwh_hailing_marts.mart_driver_loyalty_mgmt .. [RUN]
[0m10:13:44.828048 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.hailing_project.dim_driver, now model.hailing_project.mart_cust_rides_daily)
[0m10:13:44.829599 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.hailing_project.dim_customer, now model.hailing_project.mart_driver_loyalty_mgmt)
[0m10:13:44.830879 [debug] [Thread-2 (]: Began compiling node model.hailing_project.mart_cust_rides_daily
[0m10:13:44.832039 [debug] [Thread-4 (]: Began compiling node model.hailing_project.mart_driver_loyalty_mgmt
[0m10:13:44.836520 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.mart_cust_rides_daily"
[0m10:13:44.840912 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.mart_driver_loyalty_mgmt"
[0m10:13:44.846610 [debug] [Thread-2 (]: Began executing node model.hailing_project.mart_cust_rides_daily
[0m10:13:44.847139 [debug] [Thread-4 (]: Began executing node model.hailing_project.mart_driver_loyalty_mgmt
[0m10:13:44.858057 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m10:13:44.860499 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m10:13:45.112350 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.mart_cust_rides_daily"
[0m10:13:45.114222 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.mart_driver_loyalty_mgmt"
[0m10:13:45.118838 [debug] [Thread-2 (]: On model.hailing_project.mart_cust_rides_daily: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.mart_cust_rides_daily"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_marts`.`mart_cust_rides_daily`
      
    partition by ride_date
    

    OPTIONS()
    as (
      


WITH fact_rides AS(

    SELECT * 
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
)

SELECT 

    fact_rides.cust_id,
    DATE(fact_rides.created_at) AS ride_date,
    fact_rides.cust_name,
    fact_rides.cust_email,
    fact_rides.cust_phone_number,
    COUNT(fact_rides.ride_id) AS no_of_rides,
    SUM(TIMESTAMP_DIFF(fact_rides.ride_end_time, fact_rides.ride_start_time, MINUTE)) AS total_ride_duration_min,
    SUM(fact_rides.fare) AS total_fare,
    SUM(fact_rides.distance_km) as total_distance_km,
    SUM(fact_rides.distance_km)-SUM(fact_rides.fare) AS rev_opportunity_loss,
    fact_rides.ride_status

FROM fact_rides
GROUP BY cust_name, cust_id, ride_date, cust_email, cust_phone_number, ride_status
    );
  
[0m10:13:45.122162 [debug] [Thread-4 (]: On model.hailing_project.mart_driver_loyalty_mgmt: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.mart_driver_loyalty_mgmt"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_marts`.`mart_driver_loyalty_mgmt`
      
    
    

    OPTIONS()
    as (
      

WITH dim_driver AS(
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
),

fact_rides AS(
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
)

SELECT 
dim_driver.driver_id,
dim_driver.driver_name,
dim_driver.phone_number,
dim_driver.email,
dim_driver.vehicle_type,
COUNT(fact_rides.ride_id) AS no_of_rides,
SUM(TIMESTAMP_DIFF(fact_rides.ride_end_time, fact_rides.ride_start_time, MINUTE)) AS total_ride_duration_min,
SUM(fact_rides.fare) AS total_fare,
SUM(fact_rides.distance_km) as total_distance_km,
SUM(fact_rides.distance_km)-SUM(fact_rides.fare) AS rev_opportunity_loss,
fact_rides.ride_status AS ride_status

FROM dim_driver
LEFT JOIN fact_rides
ON dim_driver.driver_id = fact_rides.driver_id

GROUP BY driver_id,driver_name,phone_number,email,vehicle_type,ride_status
    );
  
[0m10:13:45.325022 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:fbdcd79f-3e79-4c0a-9b75-24cdf7d2ccee&page=queryresults
[0m10:13:45.326041 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:d20b1380-979d-4584-82d8-d4404bd96cd4&page=queryresults
[0m10:13:47.058640 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2459d857-e2ee-43f3-be98-fabccac9c46a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff316214e90>]}
[0m10:13:47.059970 [info ] [Thread-2 (]: 8 of 9 OK created sql table model rizky_dwh_hailing_marts.mart_cust_rides_daily  [[32mCREATE TABLE (73.0 rows, 11.2 KiB processed)[0m in 2.23s]
[0m10:13:47.062589 [debug] [Thread-2 (]: Finished running node model.hailing_project.mart_cust_rides_daily
[0m10:13:47.068940 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2459d857-e2ee-43f3-be98-fabccac9c46a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff31631fd50>]}
[0m10:13:47.070446 [info ] [Thread-4 (]: 9 of 9 OK created sql table model rizky_dwh_hailing_marts.mart_driver_loyalty_mgmt  [[32mCREATE TABLE (99.0 rows, 11.9 KiB processed)[0m in 2.24s]
[0m10:13:47.072741 [debug] [Thread-4 (]: Finished running node model.hailing_project.mart_driver_loyalty_mgmt
[0m10:13:47.077401 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m10:13:47.081461 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:13:47.082512 [debug] [MainThread]: Connection 'model.hailing_project.fact_hailing_rides' was properly closed.
[0m10:13:47.083502 [debug] [MainThread]: Connection 'model.hailing_project.mart_cust_rides_daily' was properly closed.
[0m10:13:47.084593 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m10:13:47.085517 [debug] [MainThread]: Connection 'model.hailing_project.mart_driver_loyalty_mgmt' was properly closed.
[0m10:13:47.086527 [info ] [MainThread]: 
[0m10:13:47.087445 [info ] [MainThread]: Finished running 7 incremental models, 2 table models in 0 hours 0 minutes and 10.83 seconds (10.83s).
[0m10:13:47.090974 [debug] [MainThread]: Command end result
[0m10:13:47.128519 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m10:13:47.133356 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m10:13:47.142286 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m10:13:47.143072 [info ] [MainThread]: 
[0m10:13:47.144409 [info ] [MainThread]: [32mCompleted successfully[0m
[0m10:13:47.145430 [info ] [MainThread]: 
[0m10:13:47.146455 [info ] [MainThread]: Done. PASS=9 WARN=0 ERROR=0 SKIP=0 TOTAL=9
[0m10:13:47.148153 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 12.209174, "process_in_blocks": "0", "process_kernel_time": 0.289089, "process_mem_max_rss": "227920", "process_out_blocks": "0", "process_user_time": 3.798043}
[0m10:13:47.149228 [debug] [MainThread]: Command `dbt run` succeeded at 10:13:47.149093 after 12.21 seconds
[0m10:13:47.150049 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff385d08e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3869df410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff389508c10>]}
[0m10:13:47.150957 [debug] [MainThread]: Flushing usage events
[0m10:13:48.454579 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m10:15:18.297156 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8710d5a790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8710d59b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8710d5b310>]}


============================== 10:15:18.300454 | 27dcf974-40b1-4a59-a9cc-62b0a612a7d2 ==============================
[0m10:15:18.300454 [info ] [MainThread]: Running with dbt=1.9.0
[0m10:15:18.303903 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m10:15:18.890994 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '27dcf974-40b1-4a59-a9cc-62b0a612a7d2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f86e30c48d0>]}
[0m10:15:18.934514 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '27dcf974-40b1-4a59-a9cc-62b0a612a7d2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f871300e190>]}
[0m10:15:18.935552 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m10:15:18.999299 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m10:15:19.188906 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
[0m10:15:19.190148 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/marts/mart_driver_loyalty_mgmt.sql
[0m10:15:19.191029 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/marts/mart_cust_rides_daily.sql
[0m10:15:19.444712 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '27dcf974-40b1-4a59-a9cc-62b0a612a7d2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f86e2b67810>]}
[0m10:15:19.522788 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m10:15:19.529596 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m10:15:19.546130 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '27dcf974-40b1-4a59-a9cc-62b0a612a7d2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f86e1285a50>]}
[0m10:15:19.547657 [info ] [MainThread]: Found 9 models, 8 sources, 489 macros
[0m10:15:19.548745 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '27dcf974-40b1-4a59-a9cc-62b0a612a7d2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f86e30db490>]}
[0m10:15:19.552171 [info ] [MainThread]: 
[0m10:15:19.553587 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m10:15:19.555119 [info ] [MainThread]: 
[0m10:15:19.556613 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m10:15:19.561152 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m10:15:19.561852 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m10:15:19.562987 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m10:15:19.563768 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:15:19.564748 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:15:19.565497 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:15:20.702671 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_facts)
[0m10:15:20.703262 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_marts)
[0m10:15:20.703817 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_staging)
[0m10:15:20.704490 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:15:20.705323 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:15:20.706588 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:15:21.148757 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '27dcf974-40b1-4a59-a9cc-62b0a612a7d2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f86e2f933d0>]}
[0m10:15:21.149609 [debug] [MainThread]: Opening a new connection, currently in state init
[0m10:15:21.155327 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m10:15:21.155725 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m10:15:21.156085 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m10:15:21.156444 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m10:15:21.157520 [info ] [Thread-1 (]: 1 of 9 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [RUN]
[0m10:15:21.159614 [info ] [Thread-2 (]: 2 of 9 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [RUN]
[0m10:15:21.161429 [info ] [Thread-3 (]: 3 of 9 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [RUN]
[0m10:15:21.162852 [info ] [Thread-4 (]: 4 of 9 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [RUN]
[0m10:15:21.164076 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_marts, now model.hailing_project.production_hailing_staging_customer)
[0m10:15:21.165107 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_staging, now model.hailing_project.production_hailing_staging_driver)
[0m10:15:21.166443 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_facts, now model.hailing_project.production_hailing_staging_ride)
[0m10:15:21.167687 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_vehicle'
[0m10:15:21.168704 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m10:15:21.169793 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m10:15:21.170984 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m10:15:21.171967 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m10:15:21.185138 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m10:15:21.188557 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m10:15:21.192354 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m10:15:21.196767 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m10:15:21.202467 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m10:15:21.203374 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m10:15:21.209279 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m10:15:21.209586 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m10:15:21.245019 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m10:15:21.248610 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m10:15:21.251593 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m10:15:21.255015 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m10:15:21.552708 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m10:15:21.554086 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m10:15:21.555600 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m10:15:21.556592 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m10:15:21.561480 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m10:15:21.562166 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m10:15:21.564530 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m10:15:21.565028 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m10:15:21.812633 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:99877654-ef83-4e84-993b-70ab9a0a3401&page=queryresults
[0m10:15:21.854145 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:73598fe4-acf2-409a-9347-c73da3ee355f&page=queryresults
[0m10:15:21.867796 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:707ca907-2b9c-4df9-876c-57e7e30edf7a&page=queryresults
[0m10:15:21.872145 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:f93af1d0-737c-462a-9807-f81ea00400a4&page=queryresults
[0m10:15:23.462067 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '27dcf974-40b1-4a59-a9cc-62b0a612a7d2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f86e3092450>]}
[0m10:15:23.463292 [info ] [Thread-4 (]: 4 of 9 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.29s]
[0m10:15:23.465012 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m10:15:24.016367 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '27dcf974-40b1-4a59-a9cc-62b0a612a7d2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f86e12ddd10>]}
[0m10:15:24.019549 [info ] [Thread-3 (]: 3 of 9 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.85s]
[0m10:15:24.022281 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m10:15:24.046926 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '27dcf974-40b1-4a59-a9cc-62b0a612a7d2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f86a95ca910>]}
[0m10:15:24.049090 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '27dcf974-40b1-4a59-a9cc-62b0a612a7d2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f86a95f37d0>]}
[0m10:15:24.049836 [info ] [Thread-1 (]: 1 of 9 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.88s]
[0m10:15:24.051326 [info ] [Thread-2 (]: 2 of 9 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.88s]
[0m10:15:24.053051 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m10:15:24.054391 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m10:15:24.056249 [debug] [Thread-4 (]: Began running node model.hailing_project.dim_customer
[0m10:15:24.057113 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_driver
[0m10:15:24.057668 [info ] [Thread-4 (]: 5 of 9 START sql incremental model rizky_dwh_hailing_facts.dim_customer ........ [RUN]
[0m10:15:24.058750 [info ] [Thread-1 (]: 6 of 9 START sql incremental model rizky_dwh_hailing_facts.dim_driver .......... [RUN]
[0m10:15:24.060183 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_vehicle, now model.hailing_project.dim_customer)
[0m10:15:24.061511 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_customer, now model.hailing_project.dim_driver)
[0m10:15:24.062458 [debug] [Thread-4 (]: Began compiling node model.hailing_project.dim_customer
[0m10:15:24.063208 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_driver
[0m10:15:24.068339 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m10:15:24.072477 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_driver"
[0m10:15:24.077998 [debug] [Thread-4 (]: Began executing node model.hailing_project.dim_customer
[0m10:15:24.078478 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_driver
[0m10:15:24.082226 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m10:15:24.085895 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m10:15:24.318186 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_driver"
[0m10:15:24.319892 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m10:15:24.324412 [debug] [Thread-4 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
)

SELECT * FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m10:15:24.327546 [debug] [Thread-1 (]: On model.hailing_project.dim_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver` as DBT_INTERNAL_DEST
        using (


WITH driver AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver` --pakai ref untuk buat dependency

),

vehicle AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle`
)

SELECT
    driver.driver_id,
    vehicle.vehicle_id,
    driver.name as driver_name,
    driver.phone_number as phone_number,
    driver.email as email,
    vehicle.vehicle_type,
    vehicle.brand as vehicle_brand,
    vehicle.year as vehicle_production_year,
    vehicle.license_plate,
    driver.created_at
FROM driver
LEFT JOIN vehicle
on driver.driver_id = vehicle.vehicle_id


    WHERE driver.created_at > (
        SELECT MAX(driver.created_at)
        FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_name` = DBT_INTERNAL_SOURCE.`driver_name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`vehicle_brand` = DBT_INTERNAL_SOURCE.`vehicle_brand`,`vehicle_production_year` = DBT_INTERNAL_SOURCE.`vehicle_production_year`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `vehicle_id`, `driver_name`, `phone_number`, `email`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)
    values
        (`driver_id`, `vehicle_id`, `driver_name`, `phone_number`, `email`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)


    
[0m10:15:24.569337 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:2829bbde-dd18-4933-a4dd-7c0fc4285380&page=queryresults
[0m10:15:24.570334 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:21e01c9c-ac1b-4665-bc17-17e4a4ff034f&page=queryresults
[0m10:15:26.404183 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '27dcf974-40b1-4a59-a9cc-62b0a612a7d2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f86a940f410>]}
[0m10:15:26.405338 [info ] [Thread-1 (]: 6 of 9 OK created sql incremental model rizky_dwh_hailing_facts.dim_driver ..... [[32mMERGE (0.0 rows, 18.0 KiB processed)[0m in 2.34s]
[0m10:15:26.407623 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_driver
[0m10:15:27.063996 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '27dcf974-40b1-4a59-a9cc-62b0a612a7d2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f86a9553a90>]}
[0m10:15:27.065788 [info ] [Thread-4 (]: 5 of 9 OK created sql incremental model rizky_dwh_hailing_facts.dim_customer ... [[32mMERGE (0.0 rows, 11.3 KiB processed)[0m in 3.00s]
[0m10:15:27.067354 [debug] [Thread-4 (]: Finished running node model.hailing_project.dim_customer
[0m10:15:27.068794 [debug] [Thread-2 (]: Began running node model.hailing_project.fact_hailing_rides
[0m10:15:27.070048 [info ] [Thread-2 (]: 7 of 9 START sql incremental model rizky_dwh_hailing_facts.fact_hailing_rides .. [RUN]
[0m10:15:27.071756 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_driver, now model.hailing_project.fact_hailing_rides)
[0m10:15:27.072594 [debug] [Thread-2 (]: Began compiling node model.hailing_project.fact_hailing_rides
[0m10:15:27.078040 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.fact_hailing_rides"
[0m10:15:27.087106 [debug] [Thread-2 (]: Began executing node model.hailing_project.fact_hailing_rides
[0m10:15:27.090908 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m10:15:27.307179 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.fact_hailing_rides"
[0m10:15:27.313635 [debug] [Thread-2 (]: On model.hailing_project.fact_hailing_rides: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.fact_hailing_rides"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides` as DBT_INTERNAL_DEST
        using (

WITH dim_driver AS (

    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
),

dim_customer AS (

    SELECT * 
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer`
),

ride_staging AS (

    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride`
)

SELECT
ride_staging.ride_id,
ride_staging.start_time AS ride_start_time,
ride_staging.end_time AS ride_end_time,
ride_staging.distance_km,
ride_staging.fare,
ride_staging.ride_status,
dim_customer.cust_id,
dim_customer.name AS cust_name,
dim_customer.phone_number AS cust_phone_number,
dim_customer.email AS cust_email,
dim_driver.driver_id,
dim_driver.driver_name,
dim_driver.phone_number AS driver_phone_number,
dim_driver.email AS driver_email,
dim_driver.vehicle_id,
dim_driver.vehicle_type,
dim_driver.vehicle_brand,
dim_driver.vehicle_production_year,
dim_driver.license_plate,
ride_staging.created_at

FROM ride_staging

LEFT JOIN dim_customer
on ride_staging.cust_id = dim_customer.cust_id

LEFT JOIN dim_driver
on ride_staging.driver_id = dim_driver.driver_id


    WHERE ride_staging.created_at > (
        SELECT MAX(ride_staging.created_at)
        FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`ride_start_time` = DBT_INTERNAL_SOURCE.`ride_start_time`,`ride_end_time` = DBT_INTERNAL_SOURCE.`ride_end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`cust_name` = DBT_INTERNAL_SOURCE.`cust_name`,`cust_phone_number` = DBT_INTERNAL_SOURCE.`cust_phone_number`,`cust_email` = DBT_INTERNAL_SOURCE.`cust_email`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`driver_name` = DBT_INTERNAL_SOURCE.`driver_name`,`driver_phone_number` = DBT_INTERNAL_SOURCE.`driver_phone_number`,`driver_email` = DBT_INTERNAL_SOURCE.`driver_email`,`vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`vehicle_brand` = DBT_INTERNAL_SOURCE.`vehicle_brand`,`vehicle_production_year` = DBT_INTERNAL_SOURCE.`vehicle_production_year`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `ride_start_time`, `ride_end_time`, `distance_km`, `fare`, `ride_status`, `cust_id`, `cust_name`, `cust_phone_number`, `cust_email`, `driver_id`, `driver_name`, `driver_phone_number`, `driver_email`, `vehicle_id`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)
    values
        (`ride_id`, `ride_start_time`, `ride_end_time`, `distance_km`, `fare`, `ride_status`, `cust_id`, `cust_name`, `cust_phone_number`, `cust_email`, `driver_id`, `driver_name`, `driver_phone_number`, `driver_email`, `vehicle_id`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)


    
[0m10:15:27.587596 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:683c3eff-13f8-4464-9ea5-291323deb4b0&page=queryresults
[0m10:15:29.997283 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '27dcf974-40b1-4a59-a9cc-62b0a612a7d2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f86e129b790>]}
[0m10:15:29.998534 [info ] [Thread-2 (]: 7 of 9 OK created sql incremental model rizky_dwh_hailing_facts.fact_hailing_rides  [[32mMERGE (0.0 rows, 40.3 KiB processed)[0m in 2.93s]
[0m10:15:30.001456 [debug] [Thread-2 (]: Finished running node model.hailing_project.fact_hailing_rides
[0m10:15:30.003392 [debug] [Thread-1 (]: Began running node model.hailing_project.mart_cust_rides_daily
[0m10:15:30.003772 [debug] [Thread-4 (]: Began running node model.hailing_project.mart_driver_loyalty_mgmt
[0m10:15:30.005073 [info ] [Thread-1 (]: 8 of 9 START sql incremental model rizky_dwh_hailing_marts.mart_cust_rides_daily  [RUN]
[0m10:15:30.006889 [info ] [Thread-4 (]: 9 of 9 START sql incremental model rizky_dwh_hailing_marts.mart_driver_loyalty_mgmt  [RUN]
[0m10:15:30.008500 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.hailing_project.dim_driver, now model.hailing_project.mart_cust_rides_daily)
[0m10:15:30.009665 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.hailing_project.dim_customer, now model.hailing_project.mart_driver_loyalty_mgmt)
[0m10:15:30.010727 [debug] [Thread-1 (]: Began compiling node model.hailing_project.mart_cust_rides_daily
[0m10:15:30.011992 [debug] [Thread-4 (]: Began compiling node model.hailing_project.mart_driver_loyalty_mgmt
[0m10:15:30.016450 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.mart_cust_rides_daily"
[0m10:15:30.019973 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.mart_driver_loyalty_mgmt"
[0m10:15:30.025116 [debug] [Thread-4 (]: Began executing node model.hailing_project.mart_driver_loyalty_mgmt
[0m10:15:30.033495 [debug] [Thread-1 (]: Began executing node model.hailing_project.mart_cust_rides_daily
[0m10:15:30.052023 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.mart_driver_loyalty_mgmt"
[0m10:15:30.054904 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.mart_cust_rides_daily"
[0m10:15:30.059849 [debug] [Thread-4 (]: On model.hailing_project.mart_driver_loyalty_mgmt: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.mart_driver_loyalty_mgmt"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_marts`.`mart_driver_loyalty_mgmt`
      
    
    

    OPTIONS()
    as (
      

WITH dim_driver AS(
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
),

fact_rides AS(
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
)

SELECT 
dim_driver.driver_id,
dim_driver.driver_name,
dim_driver.phone_number,
dim_driver.email,
dim_driver.vehicle_type,
COUNT(fact_rides.ride_id) AS no_of_rides,
SUM(TIMESTAMP_DIFF(fact_rides.ride_end_time, fact_rides.ride_start_time, MINUTE)) AS total_ride_duration_min,
SUM(fact_rides.fare) AS total_fare,
SUM(fact_rides.distance_km) as total_distance_km,
SUM(fact_rides.distance_km)-SUM(fact_rides.fare) AS rev_opportunity_loss,
FROM dim_driver
LEFT JOIN fact_rides
ON dim_driver.driver_id = fact_rides.driver_id

GROUP BY driver_id,driver_name,phone_number,email,vehicle_type,ride_status
    );
  
[0m10:15:30.061220 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m10:15:30.061696 [debug] [Thread-1 (]: On model.hailing_project.mart_cust_rides_daily: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.mart_cust_rides_daily"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_marts`.`mart_cust_rides_daily`
      
    partition by ride_date
    

    OPTIONS()
    as (
      


WITH fact_rides AS(

    SELECT * 
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
)

SELECT 

    fact_rides.cust_id,
    DATE(fact_rides.created_at) AS ride_date,
    fact_rides.cust_name,
    fact_rides.cust_email,
    fact_rides.cust_phone_number,
    COUNT(fact_rides.ride_id) AS no_of_rides,
    SUM(TIMESTAMP_DIFF(fact_rides.ride_end_time, fact_rides.ride_start_time, MINUTE)) AS total_ride_duration_min,
    SUM(fact_rides.fare) AS total_fare,
    SUM(fact_rides.distance_km) as total_distance_km,
    SUM(fact_rides.distance_km)-SUM(fact_rides.fare) AS rev_opportunity_loss,
    fact_rides.ride_status

FROM fact_rides
GROUP BY cust_name, cust_id, ride_date, cust_email, cust_phone_number, ride_status
    );
  
[0m10:15:30.063034 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m10:15:30.482377 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:4d7f347d-e7f6-4b8f-aeb8-9d3a733fad68&page=queryresults
[0m10:15:30.486372 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:0175749f-6eca-432d-90b8-b9c0c44bffe7&page=queryresults
[0m10:15:32.108098 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '27dcf974-40b1-4a59-a9cc-62b0a612a7d2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f86a95e1f90>]}
[0m10:15:32.109211 [info ] [Thread-4 (]: 9 of 9 OK created sql incremental model rizky_dwh_hailing_marts.mart_driver_loyalty_mgmt  [[32mCREATE TABLE (99.0 rows, 11.9 KiB processed)[0m in 2.10s]
[0m10:15:32.110477 [debug] [Thread-4 (]: Finished running node model.hailing_project.mart_driver_loyalty_mgmt
[0m10:15:32.355504 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '27dcf974-40b1-4a59-a9cc-62b0a612a7d2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f86e1285450>]}
[0m10:15:32.356893 [info ] [Thread-1 (]: 8 of 9 OK created sql incremental model rizky_dwh_hailing_marts.mart_cust_rides_daily  [[32mCREATE TABLE (73.0 rows, 11.2 KiB processed)[0m in 2.35s]
[0m10:15:32.358325 [debug] [Thread-1 (]: Finished running node model.hailing_project.mart_cust_rides_daily
[0m10:15:32.361038 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m10:15:32.364170 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:15:32.365421 [debug] [MainThread]: Connection 'model.hailing_project.fact_hailing_rides' was properly closed.
[0m10:15:32.366422 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m10:15:32.367296 [debug] [MainThread]: Connection 'model.hailing_project.mart_cust_rides_daily' was properly closed.
[0m10:15:32.368459 [debug] [MainThread]: Connection 'model.hailing_project.mart_driver_loyalty_mgmt' was properly closed.
[0m10:15:32.369535 [info ] [MainThread]: 
[0m10:15:32.370456 [info ] [MainThread]: Finished running 9 incremental models in 0 hours 0 minutes and 12.81 seconds (12.81s).
[0m10:15:32.373875 [debug] [MainThread]: Command end result
[0m10:15:32.412371 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m10:15:32.417437 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m10:15:32.425981 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m10:15:32.427070 [info ] [MainThread]: 
[0m10:15:32.428303 [info ] [MainThread]: [32mCompleted successfully[0m
[0m10:15:32.429323 [info ] [MainThread]: 
[0m10:15:32.430406 [info ] [MainThread]: Done. PASS=9 WARN=0 ERROR=0 SKIP=0 TOTAL=9
[0m10:15:32.432331 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 14.185142, "process_in_blocks": "0", "process_kernel_time": 0.282631, "process_mem_max_rss": "225264", "process_out_blocks": "0", "process_user_time": 3.855901}
[0m10:15:32.433668 [debug] [MainThread]: Command `dbt run` succeeded at 10:15:32.433410 after 14.19 seconds
[0m10:15:32.434588 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87145b4b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8714711190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8714711150>]}
[0m10:15:32.435652 [debug] [MainThread]: Flushing usage events
[0m10:15:33.794317 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m10:17:08.199172 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f293b351790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f293c033310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f293b353990>]}


============================== 10:17:08.201776 | b783a007-ad2c-4920-bf6b-a1e05e4ac7c8 ==============================
[0m10:17:08.201776 [info ] [MainThread]: Running with dbt=1.9.0
[0m10:17:08.202975 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m10:17:08.825936 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b783a007-ad2c-4920-bf6b-a1e05e4ac7c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f290d4e74d0>]}
[0m10:17:08.881597 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b783a007-ad2c-4920-bf6b-a1e05e4ac7c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f290f964f10>]}
[0m10:17:08.882820 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m10:17:08.947151 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m10:17:09.142368 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m10:17:09.145084 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m10:17:09.179314 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b783a007-ad2c-4920-bf6b-a1e05e4ac7c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f290d1d6a50>]}
[0m10:17:09.304703 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m10:17:09.311148 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m10:17:09.329514 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b783a007-ad2c-4920-bf6b-a1e05e4ac7c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f290d6ad210>]}
[0m10:17:09.330732 [info ] [MainThread]: Found 9 models, 8 sources, 489 macros
[0m10:17:09.331929 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b783a007-ad2c-4920-bf6b-a1e05e4ac7c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f290d1e2150>]}
[0m10:17:09.334762 [info ] [MainThread]: 
[0m10:17:09.336945 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m10:17:09.338726 [info ] [MainThread]: 
[0m10:17:09.340940 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m10:17:09.346187 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m10:17:09.346968 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m10:17:09.347929 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m10:17:09.348453 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:17:09.349264 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:17:09.350005 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:17:10.432761 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_facts)
[0m10:17:10.433305 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_marts)
[0m10:17:10.433819 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_staging)
[0m10:17:10.434318 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:17:10.435218 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:17:10.436163 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:17:10.712746 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b783a007-ad2c-4920-bf6b-a1e05e4ac7c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f290d20add0>]}
[0m10:17:10.713818 [debug] [MainThread]: Opening a new connection, currently in state init
[0m10:17:10.718596 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m10:17:10.718969 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m10:17:10.719344 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m10:17:10.719709 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m10:17:10.721460 [info ] [Thread-1 (]: 1 of 9 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [RUN]
[0m10:17:10.723567 [info ] [Thread-2 (]: 2 of 9 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [RUN]
[0m10:17:10.725706 [info ] [Thread-3 (]: 3 of 9 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [RUN]
[0m10:17:10.731497 [info ] [Thread-4 (]: 4 of 9 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [RUN]
[0m10:17:10.736470 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_staging, now model.hailing_project.production_hailing_staging_customer)
[0m10:17:10.737815 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_marts, now model.hailing_project.production_hailing_staging_driver)
[0m10:17:10.738967 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_facts, now model.hailing_project.production_hailing_staging_ride)
[0m10:17:10.740153 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_vehicle'
[0m10:17:10.741174 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m10:17:10.742383 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m10:17:10.743421 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m10:17:10.744641 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m10:17:10.759104 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m10:17:10.763149 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m10:17:10.767212 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m10:17:10.770994 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m10:17:10.775906 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m10:17:10.776878 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m10:17:10.782926 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m10:17:10.788815 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m10:17:10.864749 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m10:17:10.867676 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m10:17:10.868991 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m10:17:10.872022 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m10:17:10.877901 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    );
  
[0m10:17:10.878884 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    );
  
[0m10:17:10.879604 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m10:17:10.880095 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    );
  
[0m10:17:10.881261 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m10:17:10.881931 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    );
  
[0m10:17:10.883452 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m10:17:10.907700 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m10:17:11.283824 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:f33804da-be73-46da-a57f-aff3f3633a15&page=queryresults
[0m10:17:11.287117 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:bd72fcba-8f4b-4fbc-871b-cc7ff48b605a&page=queryresults
[0m10:17:11.296518 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:75e0689a-5324-4331-a72c-525553cf24a1&page=queryresults
[0m10:17:11.301789 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:1eda8c33-95c4-4a3c-b71f-e174d2b82bcf&page=queryresults
[0m10:17:13.311967 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b783a007-ad2c-4920-bf6b-a1e05e4ac7c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f290568add0>]}
[0m10:17:13.313334 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b783a007-ad2c-4920-bf6b-a1e05e4ac7c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2905718cd0>]}
[0m10:17:13.330404 [info ] [Thread-4 (]: 4 of 9 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [[32mCREATE TABLE (85.0 rows, 4.7 KiB processed)[0m in 2.57s]
[0m10:17:13.314091 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b783a007-ad2c-4920-bf6b-a1e05e4ac7c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f293b8bc690>]}
[0m10:17:13.328980 [info ] [Thread-3 (]: 3 of 9 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [[32mCREATE TABLE (85.0 rows, 7.6 KiB processed)[0m in 2.57s]
[0m10:17:13.337119 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m10:17:13.335973 [info ] [Thread-2 (]: 2 of 9 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [[32mCREATE TABLE (85.0 rows, 5.8 KiB processed)[0m in 2.57s]
[0m10:17:13.334532 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m10:17:13.313871 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b783a007-ad2c-4920-bf6b-a1e05e4ac7c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f290d7aff90>]}
[0m10:17:13.338727 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m10:17:13.342154 [info ] [Thread-1 (]: 1 of 9 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [[32mCREATE TABLE (85.0 rows, 5.8 KiB processed)[0m in 2.58s]
[0m10:17:13.343296 [debug] [Thread-3 (]: Began running node model.hailing_project.dim_driver
[0m10:17:13.344103 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m10:17:13.344956 [info ] [Thread-3 (]: 5 of 9 START sql incremental model rizky_dwh_hailing_facts.dim_driver .......... [RUN]
[0m10:17:13.349234 [debug] [Thread-2 (]: Began running node model.hailing_project.dim_customer
[0m10:17:13.350024 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_ride, now model.hailing_project.dim_driver)
[0m10:17:13.358212 [info ] [Thread-2 (]: 6 of 9 START sql incremental model rizky_dwh_hailing_facts.dim_customer ........ [RUN]
[0m10:17:13.359048 [debug] [Thread-3 (]: Began compiling node model.hailing_project.dim_driver
[0m10:17:13.366116 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_driver, now model.hailing_project.dim_customer)
[0m10:17:13.372443 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.dim_driver"
[0m10:17:13.373572 [debug] [Thread-2 (]: Began compiling node model.hailing_project.dim_customer
[0m10:17:13.381752 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m10:17:13.389411 [debug] [Thread-3 (]: Began executing node model.hailing_project.dim_driver
[0m10:17:13.394373 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.dim_driver"
[0m10:17:13.394998 [debug] [Thread-2 (]: Began executing node model.hailing_project.dim_customer
[0m10:17:13.405422 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m10:17:13.408335 [debug] [Thread-3 (]: On model.hailing_project.dim_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_driver"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      


WITH driver AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver` --pakai ref untuk buat dependency

),

vehicle AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle`
)

SELECT
    driver.driver_id,
    vehicle.vehicle_id,
    driver.name as driver_name,
    driver.phone_number as phone_number,
    driver.email as email,
    vehicle.vehicle_type,
    vehicle.brand as vehicle_brand,
    vehicle.year as vehicle_production_year,
    vehicle.license_plate,
    driver.created_at
FROM driver
LEFT JOIN vehicle
on driver.driver_id = vehicle.vehicle_id


    );
  
[0m10:17:13.409998 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m10:17:13.410436 [debug] [Thread-2 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
)

SELECT * FROM source

    );
  
[0m10:17:13.420594 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m10:17:13.818201 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:e393ff5b-fda5-486e-8ce9-21434c9b1248&page=queryresults
[0m10:17:13.821473 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:060d028f-f05a-4260-adab-a56610a84153&page=queryresults
[0m10:17:15.368545 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b783a007-ad2c-4920-bf6b-a1e05e4ac7c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f290d64d610>]}
[0m10:17:15.369879 [info ] [Thread-3 (]: 5 of 9 OK created sql incremental model rizky_dwh_hailing_facts.dim_driver ..... [[32mCREATE TABLE (85.0 rows, 9.0 KiB processed)[0m in 2.02s]
[0m10:17:15.371983 [debug] [Thread-3 (]: Finished running node model.hailing_project.dim_driver
[0m10:17:15.634411 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b783a007-ad2c-4920-bf6b-a1e05e4ac7c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f29057232d0>]}
[0m10:17:15.635770 [info ] [Thread-2 (]: 6 of 9 OK created sql incremental model rizky_dwh_hailing_facts.dim_customer ... [[32mCREATE TABLE (85.0 rows, 5.7 KiB processed)[0m in 2.27s]
[0m10:17:15.637163 [debug] [Thread-2 (]: Finished running node model.hailing_project.dim_customer
[0m10:17:15.639327 [debug] [Thread-1 (]: Began running node model.hailing_project.fact_hailing_rides
[0m10:17:15.640407 [info ] [Thread-1 (]: 7 of 9 START sql incremental model rizky_dwh_hailing_facts.fact_hailing_rides .. [RUN]
[0m10:17:15.642056 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_customer, now model.hailing_project.fact_hailing_rides)
[0m10:17:15.643271 [debug] [Thread-1 (]: Began compiling node model.hailing_project.fact_hailing_rides
[0m10:17:15.648358 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.fact_hailing_rides"
[0m10:17:15.654952 [debug] [Thread-1 (]: Began executing node model.hailing_project.fact_hailing_rides
[0m10:17:15.659303 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.fact_hailing_rides"
[0m10:17:15.665489 [debug] [Thread-1 (]: On model.hailing_project.fact_hailing_rides: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.fact_hailing_rides"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH dim_driver AS (

    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
),

dim_customer AS (

    SELECT * 
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer`
),

ride_staging AS (

    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride`
)

SELECT
ride_staging.ride_id,
ride_staging.start_time AS ride_start_time,
ride_staging.end_time AS ride_end_time,
ride_staging.distance_km,
ride_staging.fare,
ride_staging.ride_status,
dim_customer.cust_id,
dim_customer.name AS cust_name,
dim_customer.phone_number AS cust_phone_number,
dim_customer.email AS cust_email,
dim_driver.driver_id,
dim_driver.driver_name,
dim_driver.phone_number AS driver_phone_number,
dim_driver.email AS driver_email,
dim_driver.vehicle_id,
dim_driver.vehicle_type,
dim_driver.vehicle_brand,
dim_driver.vehicle_production_year,
dim_driver.license_plate,
ride_staging.created_at

FROM ride_staging

LEFT JOIN dim_customer
on ride_staging.cust_id = dim_customer.cust_id

LEFT JOIN dim_driver
on ride_staging.driver_id = dim_driver.driver_id


    );
  
[0m10:17:15.667761 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m10:17:16.046173 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:ce6b8eb6-4e8f-4e7e-ab88-0639617c4163&page=queryresults
[0m10:17:17.893292 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b783a007-ad2c-4920-bf6b-a1e05e4ac7c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f290d2d4450>]}
[0m10:17:17.894602 [info ] [Thread-1 (]: 7 of 9 OK created sql incremental model rizky_dwh_hailing_facts.fact_hailing_rides  [[32mCREATE TABLE (85.0 rows, 20.9 KiB processed)[0m in 2.25s]
[0m10:17:17.895903 [debug] [Thread-1 (]: Finished running node model.hailing_project.fact_hailing_rides
[0m10:17:17.897991 [debug] [Thread-3 (]: Began running node model.hailing_project.mart_cust_rides_daily
[0m10:17:17.898535 [debug] [Thread-2 (]: Began running node model.hailing_project.mart_driver_loyalty_mgmt
[0m10:17:17.899510 [info ] [Thread-3 (]: 8 of 9 START sql incremental model rizky_dwh_hailing_marts.mart_cust_rides_daily  [RUN]
[0m10:17:17.900591 [info ] [Thread-2 (]: 9 of 9 START sql incremental model rizky_dwh_hailing_marts.mart_driver_loyalty_mgmt  [RUN]
[0m10:17:17.902102 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.hailing_project.dim_driver, now model.hailing_project.mart_cust_rides_daily)
[0m10:17:17.903597 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.hailing_project.dim_customer, now model.hailing_project.mart_driver_loyalty_mgmt)
[0m10:17:17.905068 [debug] [Thread-3 (]: Began compiling node model.hailing_project.mart_cust_rides_daily
[0m10:17:17.906201 [debug] [Thread-2 (]: Began compiling node model.hailing_project.mart_driver_loyalty_mgmt
[0m10:17:17.911674 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.mart_cust_rides_daily"
[0m10:17:17.916074 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.mart_driver_loyalty_mgmt"
[0m10:17:17.921557 [debug] [Thread-3 (]: Began executing node model.hailing_project.mart_cust_rides_daily
[0m10:17:17.929010 [debug] [Thread-2 (]: Began executing node model.hailing_project.mart_driver_loyalty_mgmt
[0m10:17:17.929630 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.mart_cust_rides_daily"
[0m10:17:17.934324 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.mart_driver_loyalty_mgmt"
[0m10:17:17.940893 [debug] [Thread-3 (]: On model.hailing_project.mart_cust_rides_daily: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.mart_cust_rides_daily"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_marts`.`mart_cust_rides_daily`
      
    partition by ride_date
    

    OPTIONS()
    as (
      


WITH fact_rides AS(

    SELECT * 
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
)

SELECT 

    fact_rides.cust_id,
    DATE(fact_rides.created_at) AS ride_date,
    fact_rides.cust_name,
    fact_rides.cust_email,
    fact_rides.cust_phone_number,
    COUNT(fact_rides.ride_id) AS no_of_rides,
    SUM(TIMESTAMP_DIFF(fact_rides.ride_end_time, fact_rides.ride_start_time, MINUTE)) AS total_ride_duration_min,
    SUM(fact_rides.fare) AS total_fare,
    SUM(fact_rides.distance_km) as total_distance_km,
    SUM(fact_rides.distance_km)-SUM(fact_rides.fare) AS rev_opportunity_loss,
    fact_rides.ride_status

FROM fact_rides
GROUP BY cust_name, cust_id, ride_date, cust_email, cust_phone_number, ride_status
    );
  
[0m10:17:17.941593 [debug] [Thread-2 (]: On model.hailing_project.mart_driver_loyalty_mgmt: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.mart_driver_loyalty_mgmt"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_marts`.`mart_driver_loyalty_mgmt`
      
    
    

    OPTIONS()
    as (
      

WITH dim_driver AS(
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
),

fact_rides AS(
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
)

SELECT 
dim_driver.driver_id,
dim_driver.driver_name,
dim_driver.phone_number,
dim_driver.email,
dim_driver.vehicle_type,
COUNT(fact_rides.ride_id) AS no_of_rides,
SUM(TIMESTAMP_DIFF(fact_rides.ride_end_time, fact_rides.ride_start_time, MINUTE)) AS total_ride_duration_min,
SUM(fact_rides.fare) AS total_fare,
SUM(fact_rides.distance_km) as total_distance_km,
SUM(fact_rides.distance_km)-SUM(fact_rides.fare) AS rev_opportunity_loss,
FROM dim_driver
LEFT JOIN fact_rides
ON dim_driver.driver_id = fact_rides.driver_id

GROUP BY driver_id,driver_name,phone_number,email,vehicle_type,ride_status
    );
  
[0m10:17:17.942369 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m10:17:17.943245 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m10:17:18.338467 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:7bee15d4-f0bf-4741-a95d-d38ff462315f&page=queryresults
[0m10:17:18.357561 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:44a88611-398e-44a6-aa49-bba714c90aab&page=queryresults
[0m10:17:19.881000 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b783a007-ad2c-4920-bf6b-a1e05e4ac7c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f290537f950>]}
[0m10:17:19.882597 [info ] [Thread-2 (]: 9 of 9 OK created sql incremental model rizky_dwh_hailing_marts.mart_driver_loyalty_mgmt  [[32mCREATE TABLE (99.0 rows, 11.9 KiB processed)[0m in 1.98s]
[0m10:17:19.883811 [debug] [Thread-2 (]: Finished running node model.hailing_project.mart_driver_loyalty_mgmt
[0m10:17:20.223410 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b783a007-ad2c-4920-bf6b-a1e05e4ac7c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f290537ef90>]}
[0m10:17:20.224731 [info ] [Thread-3 (]: 8 of 9 OK created sql incremental model rizky_dwh_hailing_marts.mart_cust_rides_daily  [[32mCREATE TABLE (73.0 rows, 11.2 KiB processed)[0m in 2.32s]
[0m10:17:20.226018 [debug] [Thread-3 (]: Finished running node model.hailing_project.mart_cust_rides_daily
[0m10:17:20.228535 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m10:17:20.231608 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:17:20.232734 [debug] [MainThread]: Connection 'model.hailing_project.fact_hailing_rides' was properly closed.
[0m10:17:20.233570 [debug] [MainThread]: Connection 'model.hailing_project.mart_cust_rides_daily' was properly closed.
[0m10:17:20.234294 [debug] [MainThread]: Connection 'model.hailing_project.mart_driver_loyalty_mgmt' was properly closed.
[0m10:17:20.235037 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m10:17:20.235859 [info ] [MainThread]: 
[0m10:17:20.236846 [info ] [MainThread]: Finished running 9 incremental models in 0 hours 0 minutes and 10.90 seconds (10.90s).
[0m10:17:20.239346 [debug] [MainThread]: Command end result
[0m10:17:20.278660 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m10:17:20.283671 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m10:17:20.292762 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m10:17:20.293795 [info ] [MainThread]: 
[0m10:17:20.295393 [info ] [MainThread]: [32mCompleted successfully[0m
[0m10:17:20.296491 [info ] [MainThread]: 
[0m10:17:20.297721 [info ] [MainThread]: Done. PASS=9 WARN=0 ERROR=0 SKIP=0 TOTAL=9
[0m10:17:20.299598 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 12.14954, "process_in_blocks": "0", "process_kernel_time": 0.285858, "process_mem_max_rss": "221080", "process_out_blocks": "0", "process_user_time": 3.716154}
[0m10:17:20.300815 [debug] [MainThread]: Command `dbt run` succeeded at 10:17:20.300687 after 12.15 seconds
[0m10:17:20.301791 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f293b1d3fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f293b1d3c90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f293eb44c90>]}
[0m10:17:20.302614 [debug] [MainThread]: Flushing usage events
[0m10:17:21.878376 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m10:24:56.126097 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb2c51e0c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb2c523b950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb2c51e3150>]}


============================== 10:24:56.128703 | d1d45379-1ce9-4108-82ac-41111caaec43 ==============================
[0m10:24:56.128703 [info ] [MainThread]: Running with dbt=1.9.0
[0m10:24:56.130335 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m10:24:56.689628 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd1d45379-1ce9-4108-82ac-41111caaec43', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb2c525f950>]}
[0m10:24:56.738165 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd1d45379-1ce9-4108-82ac-41111caaec43', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb2c7495f10>]}
[0m10:24:56.739426 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m10:24:56.805416 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m10:24:57.012787 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m10:24:57.013554 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m10:24:57.043988 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd1d45379-1ce9-4108-82ac-41111caaec43', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb29723c990>]}
[0m10:24:57.171319 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m10:24:57.177147 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m10:24:57.192668 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd1d45379-1ce9-4108-82ac-41111caaec43', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb2c600cdd0>]}
[0m10:24:57.193730 [info ] [MainThread]: Found 9 models, 8 sources, 489 macros
[0m10:24:57.195039 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd1d45379-1ce9-4108-82ac-41111caaec43', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb29709d390>]}
[0m10:24:57.197988 [info ] [MainThread]: 
[0m10:24:57.199082 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m10:24:57.200167 [info ] [MainThread]: 
[0m10:24:57.201917 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m10:24:57.207643 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m10:24:57.208294 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m10:24:57.208825 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m10:24:57.209514 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:24:57.210465 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:24:57.211212 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:24:58.190942 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_staging)
[0m10:24:58.191463 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_facts)
[0m10:24:58.192001 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_marts)
[0m10:24:58.192494 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:24:58.193217 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:24:58.194026 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:24:58.488257 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd1d45379-1ce9-4108-82ac-41111caaec43', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb2c5fd3cd0>]}
[0m10:24:58.489829 [debug] [MainThread]: Opening a new connection, currently in state init
[0m10:24:58.494694 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m10:24:58.495130 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m10:24:58.495484 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m10:24:58.495887 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m10:24:58.496731 [info ] [Thread-1 (]: 1 of 9 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [RUN]
[0m10:24:58.498682 [info ] [Thread-2 (]: 2 of 9 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [RUN]
[0m10:24:58.499961 [info ] [Thread-3 (]: 3 of 9 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [RUN]
[0m10:24:58.501515 [info ] [Thread-4 (]: 4 of 9 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [RUN]
[0m10:24:58.502639 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_marts, now model.hailing_project.production_hailing_staging_customer)
[0m10:24:58.503727 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_facts, now model.hailing_project.production_hailing_staging_driver)
[0m10:24:58.504759 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_staging, now model.hailing_project.production_hailing_staging_ride)
[0m10:24:58.505803 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_vehicle'
[0m10:24:58.506594 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m10:24:58.507410 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m10:24:58.508240 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m10:24:58.509081 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m10:24:58.524590 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m10:24:58.528829 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m10:24:58.533077 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m10:24:58.537274 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m10:24:58.543472 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m10:24:58.550361 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m10:24:58.556368 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m10:24:58.574233 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m10:24:58.592342 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m10:24:58.592805 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m10:24:58.595326 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m10:24:58.598106 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m10:24:58.924563 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m10:24:58.926327 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m10:24:58.934685 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m10:24:58.936669 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m10:24:58.939525 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m10:24:58.941621 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m10:24:58.950791 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m10:24:58.953395 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m10:24:59.206594 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:7527f183-0d71-4f69-9aa0-7a9cc53c2ecd&page=queryresults
[0m10:24:59.222451 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:1aa522f5-8348-4c6e-8cc1-3a92cdd22fe1&page=queryresults
[0m10:24:59.225483 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:ec047715-f910-4be8-bcab-37fd0b0049be&page=queryresults
[0m10:24:59.228643 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:199b5d87-09b6-4561-a0ff-ad6bb933205f&page=queryresults
[0m10:25:01.160883 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd1d45379-1ce9-4108-82ac-41111caaec43', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb2943f1bd0>]}
[0m10:25:01.161226 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd1d45379-1ce9-4108-82ac-41111caaec43', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb29442cfd0>]}
[0m10:25:01.161526 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd1d45379-1ce9-4108-82ac-41111caaec43', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb29755d0d0>]}
[0m10:25:01.162345 [info ] [Thread-4 (]: 4 of 9 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [[32mMERGE (10.0 rows, 9.9 KiB processed)[0m in 2.65s]
[0m10:25:01.163618 [info ] [Thread-2 (]: 2 of 9 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [[32mMERGE (10.0 rows, 12.2 KiB processed)[0m in 2.66s]
[0m10:25:01.164850 [info ] [Thread-1 (]: 1 of 9 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [[32mMERGE (10.0 rows, 12.2 KiB processed)[0m in 2.66s]
[0m10:25:01.166190 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m10:25:01.167275 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m10:25:01.168602 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m10:25:01.170592 [debug] [Thread-4 (]: Began running node model.hailing_project.dim_driver
[0m10:25:01.171444 [debug] [Thread-2 (]: Began running node model.hailing_project.dim_customer
[0m10:25:01.172077 [info ] [Thread-4 (]: 5 of 9 START sql incremental model rizky_dwh_hailing_facts.dim_driver .......... [RUN]
[0m10:25:01.173059 [info ] [Thread-2 (]: 6 of 9 START sql incremental model rizky_dwh_hailing_facts.dim_customer ........ [RUN]
[0m10:25:01.174699 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_vehicle, now model.hailing_project.dim_driver)
[0m10:25:01.176731 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_driver, now model.hailing_project.dim_customer)
[0m10:25:01.177957 [debug] [Thread-4 (]: Began compiling node model.hailing_project.dim_driver
[0m10:25:01.179092 [debug] [Thread-2 (]: Began compiling node model.hailing_project.dim_customer
[0m10:25:01.184232 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.dim_driver"
[0m10:25:01.188473 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m10:25:01.194074 [debug] [Thread-4 (]: Began executing node model.hailing_project.dim_driver
[0m10:25:01.197875 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m10:25:01.198267 [debug] [Thread-2 (]: Began executing node model.hailing_project.dim_customer
[0m10:25:01.203022 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m10:25:01.337066 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd1d45379-1ce9-4108-82ac-41111caaec43', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb297569690>]}
[0m10:25:01.338368 [info ] [Thread-3 (]: 3 of 9 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [[32mMERGE (10.0 rows, 16.0 KiB processed)[0m in 2.83s]
[0m10:25:01.339515 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m10:25:01.476771 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.dim_driver"
[0m10:25:01.487151 [debug] [Thread-4 (]: On model.hailing_project.dim_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver` as DBT_INTERNAL_DEST
        using (


WITH driver AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver` --pakai ref untuk buat dependency

),

vehicle AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle`
)

SELECT
    driver.driver_id,
    vehicle.vehicle_id,
    driver.name as driver_name,
    driver.phone_number as phone_number,
    driver.email as email,
    vehicle.vehicle_type,
    vehicle.brand as vehicle_brand,
    vehicle.year as vehicle_production_year,
    vehicle.license_plate,
    driver.created_at
FROM driver
LEFT JOIN vehicle
on driver.driver_id = vehicle.vehicle_id


    WHERE driver.created_at > (
        SELECT MAX(driver.created_at)
        FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_name` = DBT_INTERNAL_SOURCE.`driver_name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`vehicle_brand` = DBT_INTERNAL_SOURCE.`vehicle_brand`,`vehicle_production_year` = DBT_INTERNAL_SOURCE.`vehicle_production_year`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `vehicle_id`, `driver_name`, `phone_number`, `email`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)
    values
        (`driver_id`, `vehicle_id`, `driver_name`, `phone_number`, `email`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)


    
[0m10:25:01.489231 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m10:25:01.497171 [debug] [Thread-2 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
)

SELECT * FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m10:25:01.739607 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:6daf5e9e-54e9-453f-8816-a364d1a613a5&page=queryresults
[0m10:25:01.800212 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:f0db77e5-d881-45bb-bfdd-8e9b7fa074ab&page=queryresults
[0m10:25:03.545816 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd1d45379-1ce9-4108-82ac-41111caaec43', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb294566bd0>]}
[0m10:25:03.547024 [info ] [Thread-4 (]: 5 of 9 OK created sql incremental model rizky_dwh_hailing_facts.dim_driver ..... [[32mMERGE (0.0 rows, 19.1 KiB processed)[0m in 2.37s]
[0m10:25:03.548479 [debug] [Thread-4 (]: Finished running node model.hailing_project.dim_driver
[0m10:25:03.649166 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd1d45379-1ce9-4108-82ac-41111caaec43', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb294298750>]}
[0m10:25:03.650141 [info ] [Thread-2 (]: 6 of 9 OK created sql incremental model rizky_dwh_hailing_facts.dim_customer ... [[32mMERGE (10.0 rows, 12.0 KiB processed)[0m in 2.47s]
[0m10:25:03.651501 [debug] [Thread-2 (]: Finished running node model.hailing_project.dim_customer
[0m10:25:03.652955 [debug] [Thread-1 (]: Began running node model.hailing_project.fact_hailing_rides
[0m10:25:03.653853 [info ] [Thread-1 (]: 7 of 9 START sql incremental model rizky_dwh_hailing_facts.fact_hailing_rides .. [RUN]
[0m10:25:03.654812 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_customer, now model.hailing_project.fact_hailing_rides)
[0m10:25:03.655722 [debug] [Thread-1 (]: Began compiling node model.hailing_project.fact_hailing_rides
[0m10:25:03.660792 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.fact_hailing_rides"
[0m10:25:03.666597 [debug] [Thread-1 (]: Began executing node model.hailing_project.fact_hailing_rides
[0m10:25:03.669701 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m10:25:03.939260 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.fact_hailing_rides"
[0m10:25:03.946631 [debug] [Thread-1 (]: On model.hailing_project.fact_hailing_rides: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.fact_hailing_rides"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides` as DBT_INTERNAL_DEST
        using (

WITH dim_driver AS (

    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
),

dim_customer AS (

    SELECT * 
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer`
),

ride_staging AS (

    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride`
)

SELECT
ride_staging.ride_id,
ride_staging.start_time AS ride_start_time,
ride_staging.end_time AS ride_end_time,
ride_staging.distance_km,
ride_staging.fare,
ride_staging.ride_status,
dim_customer.cust_id,
dim_customer.name AS cust_name,
dim_customer.phone_number AS cust_phone_number,
dim_customer.email AS cust_email,
dim_driver.driver_id,
dim_driver.driver_name,
dim_driver.phone_number AS driver_phone_number,
dim_driver.email AS driver_email,
dim_driver.vehicle_id,
dim_driver.vehicle_type,
dim_driver.vehicle_brand,
dim_driver.vehicle_production_year,
dim_driver.license_plate,
ride_staging.created_at

FROM ride_staging

LEFT JOIN dim_customer
on ride_staging.cust_id = dim_customer.cust_id

LEFT JOIN dim_driver
on ride_staging.driver_id = dim_driver.driver_id


    WHERE ride_staging.created_at > (
        SELECT MAX(ride_staging.created_at)
        FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`ride_start_time` = DBT_INTERNAL_SOURCE.`ride_start_time`,`ride_end_time` = DBT_INTERNAL_SOURCE.`ride_end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`cust_name` = DBT_INTERNAL_SOURCE.`cust_name`,`cust_phone_number` = DBT_INTERNAL_SOURCE.`cust_phone_number`,`cust_email` = DBT_INTERNAL_SOURCE.`cust_email`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`driver_name` = DBT_INTERNAL_SOURCE.`driver_name`,`driver_phone_number` = DBT_INTERNAL_SOURCE.`driver_phone_number`,`driver_email` = DBT_INTERNAL_SOURCE.`driver_email`,`vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`vehicle_brand` = DBT_INTERNAL_SOURCE.`vehicle_brand`,`vehicle_production_year` = DBT_INTERNAL_SOURCE.`vehicle_production_year`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `ride_start_time`, `ride_end_time`, `distance_km`, `fare`, `ride_status`, `cust_id`, `cust_name`, `cust_phone_number`, `cust_email`, `driver_id`, `driver_name`, `driver_phone_number`, `driver_email`, `vehicle_id`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)
    values
        (`ride_id`, `ride_start_time`, `ride_end_time`, `distance_km`, `fare`, `ride_status`, `cust_id`, `cust_name`, `cust_phone_number`, `cust_email`, `driver_id`, `driver_name`, `driver_phone_number`, `driver_email`, `vehicle_id`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)


    
[0m10:25:04.220363 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:8f6e1e69-1cd2-4380-929d-3c969267070a&page=queryresults
[0m10:25:06.095305 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd1d45379-1ce9-4108-82ac-41111caaec43', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb2970529d0>]}
[0m10:25:06.096668 [info ] [Thread-1 (]: 7 of 9 OK created sql incremental model rizky_dwh_hailing_facts.fact_hailing_rides  [[32mMERGE (0.0 rows, 41.8 KiB processed)[0m in 2.44s]
[0m10:25:06.098234 [debug] [Thread-1 (]: Finished running node model.hailing_project.fact_hailing_rides
[0m10:25:06.100144 [debug] [Thread-4 (]: Began running node model.hailing_project.mart_cust_rides_daily
[0m10:25:06.100629 [debug] [Thread-2 (]: Began running node model.hailing_project.mart_driver_loyalty_mgmt
[0m10:25:06.102400 [info ] [Thread-4 (]: 8 of 9 START sql incremental model rizky_dwh_hailing_marts.mart_cust_rides_daily  [RUN]
[0m10:25:06.105309 [info ] [Thread-2 (]: 9 of 9 START sql incremental model rizky_dwh_hailing_marts.mart_driver_loyalty_mgmt  [RUN]
[0m10:25:06.106798 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.hailing_project.dim_driver, now model.hailing_project.mart_cust_rides_daily)
[0m10:25:06.109077 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.hailing_project.dim_customer, now model.hailing_project.mart_driver_loyalty_mgmt)
[0m10:25:06.111760 [debug] [Thread-4 (]: Began compiling node model.hailing_project.mart_cust_rides_daily
[0m10:25:06.113246 [debug] [Thread-2 (]: Began compiling node model.hailing_project.mart_driver_loyalty_mgmt
[0m10:25:06.119386 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.mart_cust_rides_daily"
[0m10:25:06.124506 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.mart_driver_loyalty_mgmt"
[0m10:25:06.133775 [debug] [Thread-4 (]: Began executing node model.hailing_project.mart_cust_rides_daily
[0m10:25:06.134984 [debug] [Thread-2 (]: Began executing node model.hailing_project.mart_driver_loyalty_mgmt
[0m10:25:06.141086 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m10:25:06.144280 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m10:25:06.440365 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.mart_cust_rides_daily"
[0m10:25:06.449883 [debug] [Thread-4 (]: On model.hailing_project.mart_cust_rides_daily: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.mart_cust_rides_daily"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_marts`.`mart_cust_rides_daily` as DBT_INTERNAL_DEST
        using (


WITH fact_rides AS(

    SELECT * 
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
)

SELECT 

    fact_rides.cust_id,
    DATE(fact_rides.created_at) AS ride_date,
    fact_rides.cust_name,
    fact_rides.cust_email,
    fact_rides.cust_phone_number,
    COUNT(fact_rides.ride_id) AS no_of_rides,
    SUM(TIMESTAMP_DIFF(fact_rides.ride_end_time, fact_rides.ride_start_time, MINUTE)) AS total_ride_duration_min,
    SUM(fact_rides.fare) AS total_fare,
    SUM(fact_rides.distance_km) as total_distance_km,
    SUM(fact_rides.distance_km)-SUM(fact_rides.fare) AS rev_opportunity_loss,
    fact_rides.ride_status

FROM fact_rides
GROUP BY cust_name, cust_id, ride_date, cust_email, cust_phone_number, ride_status
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`ride_date` = DBT_INTERNAL_SOURCE.`ride_date`,`cust_name` = DBT_INTERNAL_SOURCE.`cust_name`,`cust_email` = DBT_INTERNAL_SOURCE.`cust_email`,`cust_phone_number` = DBT_INTERNAL_SOURCE.`cust_phone_number`,`no_of_rides` = DBT_INTERNAL_SOURCE.`no_of_rides`,`total_ride_duration_min` = DBT_INTERNAL_SOURCE.`total_ride_duration_min`,`total_fare` = DBT_INTERNAL_SOURCE.`total_fare`,`total_distance_km` = DBT_INTERNAL_SOURCE.`total_distance_km`,`rev_opportunity_loss` = DBT_INTERNAL_SOURCE.`rev_opportunity_loss`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`
    

    when not matched then insert
        (`cust_id`, `ride_date`, `cust_name`, `cust_email`, `cust_phone_number`, `no_of_rides`, `total_ride_duration_min`, `total_fare`, `total_distance_km`, `rev_opportunity_loss`, `ride_status`)
    values
        (`cust_id`, `ride_date`, `cust_name`, `cust_email`, `cust_phone_number`, `no_of_rides`, `total_ride_duration_min`, `total_fare`, `total_distance_km`, `rev_opportunity_loss`, `ride_status`)


    
[0m10:25:06.451984 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.mart_driver_loyalty_mgmt"
[0m10:25:06.463052 [debug] [Thread-2 (]: On model.hailing_project.mart_driver_loyalty_mgmt: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.mart_driver_loyalty_mgmt"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_marts`.`mart_driver_loyalty_mgmt` as DBT_INTERNAL_DEST
        using (

WITH dim_driver AS(
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
),

fact_rides AS(
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
)

SELECT 
dim_driver.driver_id,
dim_driver.driver_name,
dim_driver.phone_number,
dim_driver.email,
dim_driver.vehicle_type,
COUNT(fact_rides.ride_id) AS no_of_rides,
SUM(TIMESTAMP_DIFF(fact_rides.ride_end_time, fact_rides.ride_start_time, MINUTE)) AS total_ride_duration_min,
SUM(fact_rides.fare) AS total_fare,
SUM(fact_rides.distance_km) as total_distance_km,
SUM(fact_rides.distance_km)-SUM(fact_rides.fare) AS rev_opportunity_loss,
FROM dim_driver
LEFT JOIN fact_rides
ON dim_driver.driver_id = fact_rides.driver_id

GROUP BY driver_id,driver_name,phone_number,email,vehicle_type,ride_status
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`driver_name` = DBT_INTERNAL_SOURCE.`driver_name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`no_of_rides` = DBT_INTERNAL_SOURCE.`no_of_rides`,`total_ride_duration_min` = DBT_INTERNAL_SOURCE.`total_ride_duration_min`,`total_fare` = DBT_INTERNAL_SOURCE.`total_fare`,`total_distance_km` = DBT_INTERNAL_SOURCE.`total_distance_km`,`rev_opportunity_loss` = DBT_INTERNAL_SOURCE.`rev_opportunity_loss`
    

    when not matched then insert
        (`driver_id`, `driver_name`, `phone_number`, `email`, `vehicle_type`, `no_of_rides`, `total_ride_duration_min`, `total_fare`, `total_distance_km`, `rev_opportunity_loss`)
    values
        (`driver_id`, `driver_name`, `phone_number`, `email`, `vehicle_type`, `no_of_rides`, `total_ride_duration_min`, `total_fare`, `total_distance_km`, `rev_opportunity_loss`)


    
[0m10:25:06.704492 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:540f3802-0441-4739-b367-f2947d12fe18&page=queryresults
[0m10:25:06.746415 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:9e27fa5e-91fe-4a72-9ef8-1fab21cec5c2&page=queryresults
[0m10:25:07.083438 [error] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:540f3802-0441-4739-b367-f2947d12fe18&page=queryresults
[0m10:25:07.089647 [debug] [Thread-4 (]: Database Error in model mart_cust_rides_daily (models/marts/mart_cust_rides_daily.sql)
  UPDATE/MERGE must match at most one source row for each target row
  compiled code at target/run/hailing_project/models/marts/mart_cust_rides_daily.sql
[0m10:25:07.090900 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd1d45379-1ce9-4108-82ac-41111caaec43', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb2942ae350>]}
[0m10:25:07.092405 [error] [Thread-4 (]: 8 of 9 ERROR creating sql incremental model rizky_dwh_hailing_marts.mart_cust_rides_daily  [[31mERROR[0m in 0.98s]
[0m10:25:07.093658 [debug] [Thread-4 (]: Finished running node model.hailing_project.mart_cust_rides_daily
[0m10:25:07.094947 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.mart_cust_rides_daily' to be skipped because of status 'error'.  Reason: Database Error in model mart_cust_rides_daily (models/marts/mart_cust_rides_daily.sql)
  UPDATE/MERGE must match at most one source row for each target row
  compiled code at target/run/hailing_project/models/marts/mart_cust_rides_daily.sql.
[0m10:25:07.142514 [error] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:9e27fa5e-91fe-4a72-9ef8-1fab21cec5c2&page=queryresults
[0m10:25:07.146910 [debug] [Thread-2 (]: Database Error in model mart_driver_loyalty_mgmt (models/marts/mart_driver_loyalty_mgmt.sql)
  UPDATE/MERGE must match at most one source row for each target row
  compiled code at target/run/hailing_project/models/marts/mart_driver_loyalty_mgmt.sql
[0m10:25:07.148216 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd1d45379-1ce9-4108-82ac-41111caaec43', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb2942f7fd0>]}
[0m10:25:07.149598 [error] [Thread-2 (]: 9 of 9 ERROR creating sql incremental model rizky_dwh_hailing_marts.mart_driver_loyalty_mgmt  [[31mERROR[0m in 1.04s]
[0m10:25:07.150819 [debug] [Thread-2 (]: Finished running node model.hailing_project.mart_driver_loyalty_mgmt
[0m10:25:07.152193 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.mart_driver_loyalty_mgmt' to be skipped because of status 'error'.  Reason: Database Error in model mart_driver_loyalty_mgmt (models/marts/mart_driver_loyalty_mgmt.sql)
  UPDATE/MERGE must match at most one source row for each target row
  compiled code at target/run/hailing_project/models/marts/mart_driver_loyalty_mgmt.sql.
[0m10:25:07.154809 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m10:25:07.158091 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:25:07.159253 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m10:25:07.160195 [debug] [MainThread]: Connection 'model.hailing_project.mart_driver_loyalty_mgmt' was properly closed.
[0m10:25:07.161133 [debug] [MainThread]: Connection 'model.hailing_project.fact_hailing_rides' was properly closed.
[0m10:25:07.162249 [debug] [MainThread]: Connection 'model.hailing_project.mart_cust_rides_daily' was properly closed.
[0m10:25:07.163248 [info ] [MainThread]: 
[0m10:25:07.164112 [info ] [MainThread]: Finished running 9 incremental models in 0 hours 0 minutes and 9.96 seconds (9.96s).
[0m10:25:07.166068 [debug] [MainThread]: Command end result
[0m10:25:07.202082 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m10:25:07.206860 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m10:25:07.216081 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m10:25:07.216824 [info ] [MainThread]: 
[0m10:25:07.217879 [info ] [MainThread]: [31mCompleted with 2 errors, 0 partial successes, and 0 warnings:[0m
[0m10:25:07.218863 [info ] [MainThread]: 
[0m10:25:07.220085 [error] [MainThread]:   Database Error in model mart_cust_rides_daily (models/marts/mart_cust_rides_daily.sql)
  UPDATE/MERGE must match at most one source row for each target row
  compiled code at target/run/hailing_project/models/marts/mart_cust_rides_daily.sql
[0m10:25:07.221392 [info ] [MainThread]: 
[0m10:25:07.222426 [error] [MainThread]:   Database Error in model mart_driver_loyalty_mgmt (models/marts/mart_driver_loyalty_mgmt.sql)
  UPDATE/MERGE must match at most one source row for each target row
  compiled code at target/run/hailing_project/models/marts/mart_driver_loyalty_mgmt.sql
[0m10:25:07.223386 [info ] [MainThread]: 
[0m10:25:07.224752 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=2 SKIP=0 TOTAL=9
[0m10:25:07.226724 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 11.14944, "process_in_blocks": "0", "process_kernel_time": 0.28682, "process_mem_max_rss": "222808", "process_out_blocks": "0", "process_user_time": 3.718417}
[0m10:25:07.228108 [debug] [MainThread]: Command `dbt run` failed at 10:25:07.227978 after 11.15 seconds
[0m10:25:07.229072 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb2c525f990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb2c55de4d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb2c8b99490>]}
[0m10:25:07.230365 [debug] [MainThread]: Flushing usage events
[0m10:25:08.542304 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m10:28:14.383867 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc09e18b350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc09e58a110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc09e18b610>]}


============================== 10:28:14.387514 | 3e793a11-2fba-4a3d-ba32-6fb7278e77bd ==============================
[0m10:28:14.387514 [info ] [MainThread]: Running with dbt=1.9.0
[0m10:28:14.389049 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt run', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m10:28:14.998279 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '3e793a11-2fba-4a3d-ba32-6fb7278e77bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc09e191f90>]}
[0m10:28:15.043758 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '3e793a11-2fba-4a3d-ba32-6fb7278e77bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc09efd45d0>]}
[0m10:28:15.045538 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m10:28:15.112190 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m10:28:15.318030 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
[0m10:28:15.319863 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/marts/mart_driver_loyalty_mgmt.sql
[0m10:28:15.321611 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/marts/mart_cust_rides_daily.sql
[0m10:28:15.589600 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3e793a11-2fba-4a3d-ba32-6fb7278e77bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc06ff8e690>]}
[0m10:28:15.672263 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m10:28:15.678216 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m10:28:15.697721 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3e793a11-2fba-4a3d-ba32-6fb7278e77bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc07416a7d0>]}
[0m10:28:15.698869 [info ] [MainThread]: Found 9 models, 8 sources, 489 macros
[0m10:28:15.699977 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3e793a11-2fba-4a3d-ba32-6fb7278e77bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0743e4b10>]}
[0m10:28:15.702552 [info ] [MainThread]: 
[0m10:28:15.703552 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m10:28:15.704540 [info ] [MainThread]: 
[0m10:28:15.705804 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m10:28:15.710837 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m10:28:15.711508 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m10:28:15.711999 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m10:28:15.712616 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:28:15.713473 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:28:15.714781 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:28:16.991822 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_marts)
[0m10:28:16.992536 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_staging)
[0m10:28:16.993321 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_facts)
[0m10:28:16.994071 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:28:16.995937 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:28:16.997757 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:28:17.311424 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3e793a11-2fba-4a3d-ba32-6fb7278e77bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc074346f90>]}
[0m10:28:17.312799 [debug] [MainThread]: Opening a new connection, currently in state init
[0m10:28:17.317812 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m10:28:17.318285 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m10:28:17.318716 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m10:28:17.319317 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m10:28:17.319937 [info ] [Thread-1 (]: 1 of 9 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [RUN]
[0m10:28:17.321150 [info ] [Thread-2 (]: 2 of 9 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [RUN]
[0m10:28:17.322430 [info ] [Thread-3 (]: 3 of 9 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [RUN]
[0m10:28:17.323648 [info ] [Thread-4 (]: 4 of 9 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [RUN]
[0m10:28:17.324930 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_facts, now model.hailing_project.production_hailing_staging_customer)
[0m10:28:17.326114 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_marts, now model.hailing_project.production_hailing_staging_driver)
[0m10:28:17.327241 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_staging, now model.hailing_project.production_hailing_staging_ride)
[0m10:28:17.328202 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_vehicle'
[0m10:28:17.329114 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m10:28:17.329905 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m10:28:17.330947 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m10:28:17.332608 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m10:28:17.347237 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m10:28:17.351157 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m10:28:17.355445 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m10:28:17.359648 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m10:28:17.365661 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m10:28:17.366140 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m10:28:17.366721 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m10:28:17.372724 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m10:28:17.414609 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m10:28:17.416362 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m10:28:17.419051 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m10:28:17.422372 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m10:28:17.762009 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m10:28:17.766334 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m10:28:17.768655 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m10:28:17.769840 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m10:28:17.775027 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m10:28:17.776112 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m10:28:17.776604 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m10:28:17.777874 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m10:28:18.024720 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:f2105c55-888d-4aaf-9258-63ee7e7fa394&page=queryresults
[0m10:28:18.035082 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:184a3976-3562-4bdc-a9c3-35e8e2bbba4a&page=queryresults
[0m10:28:18.042985 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:6ea7d3e8-ead7-41ba-bf82-5764520e3210&page=queryresults
[0m10:28:18.047609 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:2d281340-5206-4f34-bde0-1e6877778cc5&page=queryresults
[0m10:28:19.613071 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3e793a11-2fba-4a3d-ba32-6fb7278e77bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0743c5510>]}
[0m10:28:19.613618 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3e793a11-2fba-4a3d-ba32-6fb7278e77bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc06c576b10>]}
[0m10:28:19.615924 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3e793a11-2fba-4a3d-ba32-6fb7278e77bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc06c52aa10>]}
[0m10:28:19.616740 [info ] [Thread-3 (]: 3 of 9 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 16.9 KiB processed)[0m in 2.28s]
[0m10:28:19.617868 [info ] [Thread-2 (]: 2 of 9 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 12.8 KiB processed)[0m in 2.29s]
[0m10:28:19.619270 [info ] [Thread-4 (]: 4 of 9 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 10.4 KiB processed)[0m in 2.29s]
[0m10:28:19.620576 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m10:28:19.621740 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m10:28:19.622720 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m10:28:19.625234 [debug] [Thread-3 (]: Began running node model.hailing_project.dim_driver
[0m10:28:19.626182 [info ] [Thread-3 (]: 5 of 9 START sql incremental model rizky_dwh_hailing_facts.dim_driver .......... [RUN]
[0m10:28:19.627427 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_ride, now model.hailing_project.dim_driver)
[0m10:28:19.628536 [debug] [Thread-3 (]: Began compiling node model.hailing_project.dim_driver
[0m10:28:19.634576 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.dim_driver"
[0m10:28:19.640599 [debug] [Thread-3 (]: Began executing node model.hailing_project.dim_driver
[0m10:28:19.643850 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m10:28:19.674211 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3e793a11-2fba-4a3d-ba32-6fb7278e77bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc06c50a350>]}
[0m10:28:19.675416 [info ] [Thread-1 (]: 1 of 9 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 12.9 KiB processed)[0m in 2.35s]
[0m10:28:19.676687 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m10:28:19.677900 [debug] [Thread-4 (]: Began running node model.hailing_project.dim_customer
[0m10:28:19.678834 [info ] [Thread-4 (]: 6 of 9 START sql incremental model rizky_dwh_hailing_facts.dim_customer ........ [RUN]
[0m10:28:19.679903 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_vehicle, now model.hailing_project.dim_customer)
[0m10:28:19.680751 [debug] [Thread-4 (]: Began compiling node model.hailing_project.dim_customer
[0m10:28:19.684766 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m10:28:19.691045 [debug] [Thread-4 (]: Began executing node model.hailing_project.dim_customer
[0m10:28:19.695687 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m10:28:19.927708 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.dim_driver"
[0m10:28:19.934962 [debug] [Thread-3 (]: On model.hailing_project.dim_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver` as DBT_INTERNAL_DEST
        using (


WITH driver AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver` --pakai ref untuk buat dependency

),

vehicle AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle`
)

SELECT
    driver.driver_id,
    vehicle.vehicle_id,
    driver.name as driver_name,
    driver.phone_number as phone_number,
    driver.email as email,
    vehicle.vehicle_type,
    vehicle.brand as vehicle_brand,
    vehicle.year as vehicle_production_year,
    vehicle.license_plate,
    driver.created_at
FROM driver
LEFT JOIN vehicle
on driver.driver_id = vehicle.vehicle_id


    WHERE driver.created_at > (
        SELECT MAX(driver.created_at)
        FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_name` = DBT_INTERNAL_SOURCE.`driver_name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`vehicle_brand` = DBT_INTERNAL_SOURCE.`vehicle_brand`,`vehicle_production_year` = DBT_INTERNAL_SOURCE.`vehicle_production_year`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `vehicle_id`, `driver_name`, `phone_number`, `email`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)
    values
        (`driver_id`, `vehicle_id`, `driver_name`, `phone_number`, `email`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)


    
[0m10:28:19.979973 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m10:28:19.985570 [debug] [Thread-4 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
)

SELECT * FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m10:28:20.195462 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:a4c2a86c-8f23-409a-a7db-261a58cb5464&page=queryresults
[0m10:28:20.246668 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:042c4228-9bcb-4a06-a9a2-bd560f19ff0d&page=queryresults
[0m10:28:21.770216 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3e793a11-2fba-4a3d-ba32-6fb7278e77bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc06c13da10>]}
[0m10:28:21.771717 [info ] [Thread-3 (]: 5 of 9 OK created sql incremental model rizky_dwh_hailing_facts.dim_driver ..... [[32mMERGE (0.0 rows, 19.1 KiB processed)[0m in 2.14s]
[0m10:28:21.773078 [debug] [Thread-3 (]: Finished running node model.hailing_project.dim_driver
[0m10:28:21.823848 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3e793a11-2fba-4a3d-ba32-6fb7278e77bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc06c115b50>]}
[0m10:28:21.825209 [info ] [Thread-4 (]: 6 of 9 OK created sql incremental model rizky_dwh_hailing_facts.dim_customer ... [[32mMERGE (0.0 rows, 12.7 KiB processed)[0m in 2.14s]
[0m10:28:21.826659 [debug] [Thread-4 (]: Finished running node model.hailing_project.dim_customer
[0m10:28:21.828153 [debug] [Thread-1 (]: Began running node model.hailing_project.fact_hailing_rides
[0m10:28:21.829019 [info ] [Thread-1 (]: 7 of 9 START sql incremental model rizky_dwh_hailing_facts.fact_hailing_rides .. [RUN]
[0m10:28:21.830128 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_customer, now model.hailing_project.fact_hailing_rides)
[0m10:28:21.830841 [debug] [Thread-1 (]: Began compiling node model.hailing_project.fact_hailing_rides
[0m10:28:21.835402 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.fact_hailing_rides"
[0m10:28:21.843951 [debug] [Thread-1 (]: Began executing node model.hailing_project.fact_hailing_rides
[0m10:28:21.847592 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m10:28:22.121974 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.fact_hailing_rides"
[0m10:28:22.129017 [debug] [Thread-1 (]: On model.hailing_project.fact_hailing_rides: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.fact_hailing_rides"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides` as DBT_INTERNAL_DEST
        using (

WITH dim_driver AS (

    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
),

dim_customer AS (

    SELECT * 
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer`
),

ride_staging AS (

    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride`
)

SELECT
ride_staging.ride_id,
ride_staging.start_time AS ride_start_time,
ride_staging.end_time AS ride_end_time,
ride_staging.distance_km,
ride_staging.fare,
ride_staging.ride_status,
dim_customer.cust_id,
dim_customer.name AS cust_name,
dim_customer.phone_number AS cust_phone_number,
dim_customer.email AS cust_email,
dim_driver.driver_id,
dim_driver.driver_name,
dim_driver.phone_number AS driver_phone_number,
dim_driver.email AS driver_email,
dim_driver.vehicle_id,
dim_driver.vehicle_type,
dim_driver.vehicle_brand,
dim_driver.vehicle_production_year,
dim_driver.license_plate,
ride_staging.created_at

FROM ride_staging

LEFT JOIN dim_customer
on ride_staging.cust_id = dim_customer.cust_id

LEFT JOIN dim_driver
on ride_staging.driver_id = dim_driver.driver_id


    WHERE ride_staging.created_at > (
        SELECT MAX(ride_staging.created_at)
        FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`ride_start_time` = DBT_INTERNAL_SOURCE.`ride_start_time`,`ride_end_time` = DBT_INTERNAL_SOURCE.`ride_end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`cust_name` = DBT_INTERNAL_SOURCE.`cust_name`,`cust_phone_number` = DBT_INTERNAL_SOURCE.`cust_phone_number`,`cust_email` = DBT_INTERNAL_SOURCE.`cust_email`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`driver_name` = DBT_INTERNAL_SOURCE.`driver_name`,`driver_phone_number` = DBT_INTERNAL_SOURCE.`driver_phone_number`,`driver_email` = DBT_INTERNAL_SOURCE.`driver_email`,`vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`vehicle_brand` = DBT_INTERNAL_SOURCE.`vehicle_brand`,`vehicle_production_year` = DBT_INTERNAL_SOURCE.`vehicle_production_year`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `ride_start_time`, `ride_end_time`, `distance_km`, `fare`, `ride_status`, `cust_id`, `cust_name`, `cust_phone_number`, `cust_email`, `driver_id`, `driver_name`, `driver_phone_number`, `driver_email`, `vehicle_id`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)
    values
        (`ride_id`, `ride_start_time`, `ride_end_time`, `distance_km`, `fare`, `ride_status`, `cust_id`, `cust_name`, `cust_phone_number`, `cust_email`, `driver_id`, `driver_name`, `driver_phone_number`, `driver_email`, `vehicle_id`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)


    
[0m10:28:22.371112 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:c2a23e6f-5a0c-45ea-b777-0bc53002fea3&page=queryresults
[0m10:28:23.916526 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3e793a11-2fba-4a3d-ba32-6fb7278e77bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc06c122c50>]}
[0m10:28:23.919009 [info ] [Thread-1 (]: 7 of 9 OK created sql incremental model rizky_dwh_hailing_facts.fact_hailing_rides  [[32mMERGE (0.0 rows, 41.8 KiB processed)[0m in 2.09s]
[0m10:28:23.920884 [debug] [Thread-1 (]: Finished running node model.hailing_project.fact_hailing_rides
[0m10:28:23.922685 [debug] [Thread-3 (]: Began running node model.hailing_project.mart_cust_rides_daily
[0m10:28:23.923018 [debug] [Thread-4 (]: Began running node model.hailing_project.mart_driver_loyalty_mgmt
[0m10:28:23.923922 [info ] [Thread-3 (]: 8 of 9 START sql incremental model rizky_dwh_hailing_marts.mart_cust_rides_daily  [RUN]
[0m10:28:23.924877 [info ] [Thread-4 (]: 9 of 9 START sql incremental model rizky_dwh_hailing_marts.mart_driver_loyalty_mgmt  [RUN]
[0m10:28:23.926106 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.hailing_project.dim_driver, now model.hailing_project.mart_cust_rides_daily)
[0m10:28:23.927204 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.hailing_project.dim_customer, now model.hailing_project.mart_driver_loyalty_mgmt)
[0m10:28:23.928164 [debug] [Thread-3 (]: Began compiling node model.hailing_project.mart_cust_rides_daily
[0m10:28:23.929431 [debug] [Thread-4 (]: Began compiling node model.hailing_project.mart_driver_loyalty_mgmt
[0m10:28:23.934705 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.mart_cust_rides_daily"
[0m10:28:23.938806 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.mart_driver_loyalty_mgmt"
[0m10:28:23.943625 [debug] [Thread-4 (]: Began executing node model.hailing_project.mart_driver_loyalty_mgmt
[0m10:28:23.947169 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m10:28:23.947594 [debug] [Thread-3 (]: Began executing node model.hailing_project.mart_cust_rides_daily
[0m10:28:23.975101 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.mart_cust_rides_daily"
[0m10:28:24.004289 [debug] [Thread-3 (]: On model.hailing_project.mart_cust_rides_daily: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.mart_cust_rides_daily"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_marts`.`mart_cust_rides_daily`
      
    partition by ride_date
    

    OPTIONS()
    as (
      


WITH fact_rides AS(

    SELECT * 
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
)

SELECT 

    fact_rides.cust_id,
    DATE(fact_rides.created_at) AS ride_date,
    fact_rides.cust_name,
    fact_rides.cust_email,
    fact_rides.cust_phone_number,
    COUNT(fact_rides.ride_id) AS no_of_rides,
    SUM(TIMESTAMP_DIFF(fact_rides.ride_end_time, fact_rides.ride_start_time, MINUTE)) AS total_ride_duration_min,
    SUM(fact_rides.fare) AS total_fare,
    SUM(fact_rides.distance_km) as total_distance_km,
    SUM(fact_rides.distance_km)-SUM(fact_rides.fare) AS rev_opportunity_loss,

FROM fact_rides
GROUP BY cust_name, cust_id, ride_date, cust_email, cust_phone_number
    );
  
[0m10:28:24.005398 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m10:28:24.239038 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.mart_driver_loyalty_mgmt"
[0m10:28:24.248343 [debug] [Thread-4 (]: On model.hailing_project.mart_driver_loyalty_mgmt: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.mart_driver_loyalty_mgmt"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_marts`.`mart_driver_loyalty_mgmt` as DBT_INTERNAL_DEST
        using (

WITH dim_driver AS(
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
),

fact_rides AS(
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
)

SELECT 
dim_driver.driver_id,
dim_driver.driver_name,
dim_driver.phone_number,
dim_driver.email,
dim_driver.vehicle_type,
COUNT(fact_rides.ride_id) AS no_of_rides,
SUM(TIMESTAMP_DIFF(fact_rides.ride_end_time, fact_rides.ride_start_time, MINUTE)) AS total_ride_duration_min,
SUM(fact_rides.fare) AS total_fare,
SUM(fact_rides.distance_km) as total_distance_km,
SUM(fact_rides.distance_km)-SUM(fact_rides.fare) AS rev_opportunity_loss,
FROM dim_driver
LEFT JOIN fact_rides
ON dim_driver.driver_id = fact_rides.driver_id

GROUP BY driver_id,driver_name,phone_number,email,vehicle_type
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`driver_name` = DBT_INTERNAL_SOURCE.`driver_name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`no_of_rides` = DBT_INTERNAL_SOURCE.`no_of_rides`,`total_ride_duration_min` = DBT_INTERNAL_SOURCE.`total_ride_duration_min`,`total_fare` = DBT_INTERNAL_SOURCE.`total_fare`,`total_distance_km` = DBT_INTERNAL_SOURCE.`total_distance_km`,`rev_opportunity_loss` = DBT_INTERNAL_SOURCE.`rev_opportunity_loss`
    

    when not matched then insert
        (`driver_id`, `driver_name`, `phone_number`, `email`, `vehicle_type`, `no_of_rides`, `total_ride_duration_min`, `total_fare`, `total_distance_km`, `rev_opportunity_loss`)
    values
        (`driver_id`, `driver_name`, `phone_number`, `email`, `vehicle_type`, `no_of_rides`, `total_ride_duration_min`, `total_fare`, `total_distance_km`, `rev_opportunity_loss`)


    
[0m10:28:24.395917 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:55770b8b-a8fa-4851-9f8d-e86432e59daa&page=queryresults
[0m10:28:24.508483 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:620e139d-5781-40ed-8e85-c3635d1032b6&page=queryresults
[0m10:28:26.067854 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3e793a11-2fba-4a3d-ba32-6fb7278e77bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc02e71f650>]}
[0m10:28:26.069277 [info ] [Thread-4 (]: 9 of 9 OK created sql incremental model rizky_dwh_hailing_marts.mart_driver_loyalty_mgmt  [[32mMERGE (99.0 rows, 21.7 KiB processed)[0m in 2.14s]
[0m10:28:26.070576 [debug] [Thread-4 (]: Finished running node model.hailing_project.mart_driver_loyalty_mgmt
[0m10:28:26.278099 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3e793a11-2fba-4a3d-ba32-6fb7278e77bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc06c5545d0>]}
[0m10:28:26.279752 [info ] [Thread-3 (]: 8 of 9 OK created sql incremental model rizky_dwh_hailing_marts.mart_cust_rides_daily  [[32mCREATE TABLE (69.0 rows, 10.2 KiB processed)[0m in 2.35s]
[0m10:28:26.281393 [debug] [Thread-3 (]: Finished running node model.hailing_project.mart_cust_rides_daily
[0m10:28:26.283749 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m10:28:26.286780 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:28:26.287570 [debug] [MainThread]: Connection 'model.hailing_project.fact_hailing_rides' was properly closed.
[0m10:28:26.288258 [debug] [MainThread]: Connection 'model.hailing_project.mart_cust_rides_daily' was properly closed.
[0m10:28:26.289004 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m10:28:26.289674 [debug] [MainThread]: Connection 'model.hailing_project.mart_driver_loyalty_mgmt' was properly closed.
[0m10:28:26.290692 [info ] [MainThread]: 
[0m10:28:26.291916 [info ] [MainThread]: Finished running 9 incremental models in 0 hours 0 minutes and 10.58 seconds (10.58s).
[0m10:28:26.294702 [debug] [MainThread]: Command end result
[0m10:28:26.333585 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m10:28:26.337864 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m10:28:26.346933 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m10:28:26.347785 [info ] [MainThread]: 
[0m10:28:26.348946 [info ] [MainThread]: [32mCompleted successfully[0m
[0m10:28:26.350099 [info ] [MainThread]: 
[0m10:28:26.351174 [info ] [MainThread]: Done. PASS=9 WARN=0 ERROR=0 SKIP=0 TOTAL=9
[0m10:28:26.352893 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 12.02175, "process_in_blocks": "0", "process_kernel_time": 0.293287, "process_mem_max_rss": "225644", "process_out_blocks": "0", "process_user_time": 3.944216}
[0m10:28:26.354061 [debug] [MainThread]: Command `dbt run` succeeded at 10:28:26.353900 after 12.02 seconds
[0m10:28:26.354987 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc09e875f50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc09e1e5010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc09e673690>]}
[0m10:28:26.355785 [debug] [MainThread]: Flushing usage events
[0m10:28:27.938811 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m10:52:21.332625 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f67bee33810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f67bee8b950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f67bee8bd90>]}


============================== 10:52:21.335175 | 0a313f4c-f8d0-43cb-aadd-95192ea24c68 ==============================
[0m10:52:21.335175 [info ] [MainThread]: Running with dbt=1.9.0
[0m10:52:21.338583 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt run --select mart_driver_loyalty_mgmt', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m10:52:21.926462 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '0a313f4c-f8d0-43cb-aadd-95192ea24c68', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f67bee27cd0>]}
[0m10:52:21.983706 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '0a313f4c-f8d0-43cb-aadd-95192ea24c68', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f67c10e6110>]}
[0m10:52:21.985211 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m10:52:22.051965 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m10:52:22.232133 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m10:52:22.233270 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/marts/mart_driver_loyalty_mgmt.sql
[0m10:52:22.481067 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0a313f4c-f8d0-43cb-aadd-95192ea24c68', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f679507aa50>]}
[0m10:52:22.556588 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m10:52:22.561977 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m10:52:22.576742 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0a313f4c-f8d0-43cb-aadd-95192ea24c68', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f677f2fdc50>]}
[0m10:52:22.577933 [info ] [MainThread]: Found 9 models, 8 sources, 489 macros
[0m10:52:22.579123 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0a313f4c-f8d0-43cb-aadd-95192ea24c68', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6794c49690>]}
[0m10:52:22.581754 [info ] [MainThread]: 
[0m10:52:22.583058 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m10:52:22.584201 [info ] [MainThread]: 
[0m10:52:22.585504 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m10:52:22.587253 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m10:52:22.588153 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:52:23.270766 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_facts)
[0m10:52:23.271379 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_staging'
[0m10:52:23.272030 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_marts'
[0m10:52:23.273222 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:52:23.274778 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:52:23.275678 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:52:23.594514 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0a313f4c-f8d0-43cb-aadd-95192ea24c68', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6794c26390>]}
[0m10:52:23.595789 [debug] [MainThread]: Opening a new connection, currently in state init
[0m10:52:23.599863 [debug] [Thread-1 (]: Began running node model.hailing_project.mart_driver_loyalty_mgmt
[0m10:52:23.600892 [info ] [Thread-1 (]: 1 of 1 START sql incremental model rizky_dwh_hailing_marts.mart_driver_loyalty_mgmt  [RUN]
[0m10:52:23.601953 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_staging, now model.hailing_project.mart_driver_loyalty_mgmt)
[0m10:52:23.602892 [debug] [Thread-1 (]: Began compiling node model.hailing_project.mart_driver_loyalty_mgmt
[0m10:52:23.610799 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.mart_driver_loyalty_mgmt"
[0m10:52:23.616883 [debug] [Thread-1 (]: Began executing node model.hailing_project.mart_driver_loyalty_mgmt
[0m10:52:23.650995 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m10:52:23.957758 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.mart_driver_loyalty_mgmt"
[0m10:52:23.964032 [debug] [Thread-1 (]: On model.hailing_project.mart_driver_loyalty_mgmt: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.mart_driver_loyalty_mgmt"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_marts`.`mart_driver_loyalty_mgmt` as DBT_INTERNAL_DEST
        using (

WITH driver_data AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
),

ride_data AS (
    SELECT 
        driver_id,
        COUNT(ride_id) AS no_of_rides,
        SUM(TIMESTAMP_DIFF(ride_end_time, ride_start_time, MINUTE)) AS total_ride_duration_min,
        SUM(CAST(fare AS FLOAT64)) AS total_fare,
        SUM(CAST(distance_km AS FLOAT64)) AS total_distance_km,
        SUM(CAST(distance_km AS FLOAT64)) - SUM(CAST(fare AS FLOAT64)) AS rev_opportunity_loss
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
    GROUP BY driver_id
)

SELECT 
    driver_data.driver_id,
    driver_data.driver_name,
    driver_data.phone_number,
    driver_data.email,
    driver_data.vehicle_type,
    
    -- ✅ If there are no rides, return 0
    COALESCE(ride_data.no_of_rides, 0) AS no_of_rides,
    COALESCE(ride_data.total_ride_duration_min, 0) AS total_ride_duration_min,
    COALESCE(ride_data.total_fare, 0) AS total_fare,
    COALESCE(ride_data.total_distance_km, 0) AS total_distance_km,
    COALESCE(ride_data.rev_opportunity_loss, 0) AS rev_opportunity_loss,

    -- ✅ Identify if driver is idle
    CASE 
        WHEN COALESCE(ride_data.no_of_rides, 0) = 0 THEN 'Idle'
        ELSE 'Active'
    END AS driver_status

FROM driver_data
LEFT JOIN ride_data
ON driver_data.driver_id = ride_data.driver_id;
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`driver_name` = DBT_INTERNAL_SOURCE.`driver_name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`no_of_rides` = DBT_INTERNAL_SOURCE.`no_of_rides`,`total_ride_duration_min` = DBT_INTERNAL_SOURCE.`total_ride_duration_min`,`total_fare` = DBT_INTERNAL_SOURCE.`total_fare`,`total_distance_km` = DBT_INTERNAL_SOURCE.`total_distance_km`,`rev_opportunity_loss` = DBT_INTERNAL_SOURCE.`rev_opportunity_loss`
    

    when not matched then insert
        (`driver_id`, `driver_name`, `phone_number`, `email`, `vehicle_type`, `no_of_rides`, `total_ride_duration_min`, `total_fare`, `total_distance_km`, `rev_opportunity_loss`)
    values
        (`driver_id`, `driver_name`, `phone_number`, `email`, `vehicle_type`, `no_of_rides`, `total_ride_duration_min`, `total_fare`, `total_distance_km`, `rev_opportunity_loss`)


    
[0m10:52:24.334922 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:76a5f88d-b43a-400c-b9f6-9f28f4844821&page=queryresults
[0m10:52:24.336093 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:76a5f88d-b43a-400c-b9f6-9f28f4844821&page=queryresults
[0m10:52:24.341779 [debug] [Thread-1 (]: Database Error in model mart_driver_loyalty_mgmt (models/marts/mart_driver_loyalty_mgmt.sql)
  Syntax error: Expected ")" but got ";" at [55:47]
  compiled code at target/run/hailing_project/models/marts/mart_driver_loyalty_mgmt.sql
[0m10:52:24.343854 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0a313f4c-f8d0-43cb-aadd-95192ea24c68', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f677f393ad0>]}
[0m10:52:24.345419 [error] [Thread-1 (]: 1 of 1 ERROR creating sql incremental model rizky_dwh_hailing_marts.mart_driver_loyalty_mgmt  [[31mERROR[0m in 0.74s]
[0m10:52:24.346544 [debug] [Thread-1 (]: Finished running node model.hailing_project.mart_driver_loyalty_mgmt
[0m10:52:24.347552 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.mart_driver_loyalty_mgmt' to be skipped because of status 'error'.  Reason: Database Error in model mart_driver_loyalty_mgmt (models/marts/mart_driver_loyalty_mgmt.sql)
  Syntax error: Expected ")" but got ";" at [55:47]
  compiled code at target/run/hailing_project/models/marts/mart_driver_loyalty_mgmt.sql.
[0m10:52:24.349972 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m10:52:24.352993 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:52:24.353865 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_facts' was properly closed.
[0m10:52:24.354837 [debug] [MainThread]: Connection 'model.hailing_project.mart_driver_loyalty_mgmt' was properly closed.
[0m10:52:24.355782 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_marts' was properly closed.
[0m10:52:24.356630 [info ] [MainThread]: 
[0m10:52:24.357533 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 1.77 seconds (1.77s).
[0m10:52:24.358675 [debug] [MainThread]: Command end result
[0m10:52:24.398826 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m10:52:24.402444 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m10:52:24.411222 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m10:52:24.411920 [info ] [MainThread]: 
[0m10:52:24.412956 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m10:52:24.413920 [info ] [MainThread]: 
[0m10:52:24.414961 [error] [MainThread]:   Database Error in model mart_driver_loyalty_mgmt (models/marts/mart_driver_loyalty_mgmt.sql)
  Syntax error: Expected ")" but got ";" at [55:47]
  compiled code at target/run/hailing_project/models/marts/mart_driver_loyalty_mgmt.sql
[0m10:52:24.415952 [info ] [MainThread]: 
[0m10:52:24.417269 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m10:52:24.419182 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 3.1341865, "process_in_blocks": "0", "process_kernel_time": 0.250885, "process_mem_max_rss": "223344", "process_out_blocks": "0", "process_user_time": 3.2314}
[0m10:52:24.420602 [debug] [MainThread]: Command `dbt run` failed at 10:52:24.420415 after 3.14 seconds
[0m10:52:24.421779 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f67bee8c250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f67bee8ed10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f67951e84d0>]}
[0m10:52:24.422893 [debug] [MainThread]: Flushing usage events
[0m10:52:25.521121 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m10:53:04.803496 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f40bad2a090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f40bad83890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f40bad83f10>]}


============================== 10:53:04.806228 | 264a0e4f-3fd9-4d0e-8c85-361adec1ee80 ==============================
[0m10:53:04.806228 [info ] [MainThread]: Running with dbt=1.9.0
[0m10:53:04.807665 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'invocation_command': 'dbt run --select mart_driver_loyalty_mgmt', 'send_anonymous_usage_stats': 'True'}
[0m10:53:05.441923 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '264a0e4f-3fd9-4d0e-8c85-361adec1ee80', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4090f04490>]}
[0m10:53:05.487021 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '264a0e4f-3fd9-4d0e-8c85-361adec1ee80', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f40bcf9ce50>]}
[0m10:53:05.488521 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m10:53:05.553726 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m10:53:05.746578 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m10:53:05.747845 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/marts/mart_driver_loyalty_mgmt.sql
[0m10:53:06.025482 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '264a0e4f-3fd9-4d0e-8c85-361adec1ee80', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4090af38d0>]}
[0m10:53:06.102429 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m10:53:06.108018 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m10:53:06.124304 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '264a0e4f-3fd9-4d0e-8c85-361adec1ee80', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f407b19dbd0>]}
[0m10:53:06.126001 [info ] [MainThread]: Found 9 models, 8 sources, 489 macros
[0m10:53:06.127768 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '264a0e4f-3fd9-4d0e-8c85-361adec1ee80', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4090af5690>]}
[0m10:53:06.129940 [info ] [MainThread]: 
[0m10:53:06.131246 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m10:53:06.132564 [info ] [MainThread]: 
[0m10:53:06.134013 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m10:53:06.136319 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m10:53:06.137431 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:53:06.787262 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_facts)
[0m10:53:06.787964 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_marts'
[0m10:53:06.788846 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_staging'
[0m10:53:06.789524 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:53:06.790577 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:53:06.791775 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:53:07.112830 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '264a0e4f-3fd9-4d0e-8c85-361adec1ee80', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4090d326d0>]}
[0m10:53:07.113784 [debug] [MainThread]: Opening a new connection, currently in state init
[0m10:53:07.119582 [debug] [Thread-1 (]: Began running node model.hailing_project.mart_driver_loyalty_mgmt
[0m10:53:07.121069 [info ] [Thread-1 (]: 1 of 1 START sql incremental model rizky_dwh_hailing_marts.mart_driver_loyalty_mgmt  [RUN]
[0m10:53:07.122606 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_staging, now model.hailing_project.mart_driver_loyalty_mgmt)
[0m10:53:07.123624 [debug] [Thread-1 (]: Began compiling node model.hailing_project.mart_driver_loyalty_mgmt
[0m10:53:07.133713 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.mart_driver_loyalty_mgmt"
[0m10:53:07.140747 [debug] [Thread-1 (]: Began executing node model.hailing_project.mart_driver_loyalty_mgmt
[0m10:53:07.186852 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m10:53:07.508633 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.mart_driver_loyalty_mgmt"
[0m10:53:07.519657 [debug] [Thread-1 (]: On model.hailing_project.mart_driver_loyalty_mgmt: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.mart_driver_loyalty_mgmt"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_marts`.`mart_driver_loyalty_mgmt` as DBT_INTERNAL_DEST
        using (

WITH driver_data AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
),

ride_data AS (
    SELECT 
        driver_id,
        COUNT(ride_id) AS no_of_rides,
        SUM(TIMESTAMP_DIFF(ride_end_time, ride_start_time, MINUTE)) AS total_ride_duration_min,
        SUM(CAST(fare AS FLOAT64)) AS total_fare,
        SUM(CAST(distance_km AS FLOAT64)) AS total_distance_km,
        SUM(CAST(distance_km AS FLOAT64)) - SUM(CAST(fare AS FLOAT64)) AS rev_opportunity_loss
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
    GROUP BY driver_id
)

SELECT 
    driver_data.driver_id,
    driver_data.driver_name,
    driver_data.phone_number,
    driver_data.email,
    driver_data.vehicle_type,
    
    -- ✅ If there are no rides, return 0
    COALESCE(ride_data.no_of_rides, 0) AS no_of_rides,
    COALESCE(ride_data.total_ride_duration_min, 0) AS total_ride_duration_min,
    COALESCE(ride_data.total_fare, 0) AS total_fare,
    COALESCE(ride_data.total_distance_km, 0) AS total_distance_km,
    COALESCE(ride_data.rev_opportunity_loss, 0) AS rev_opportunity_loss,

    -- ✅ Identify if driver is idle
    CASE 
        WHEN COALESCE(ride_data.no_of_rides, 0) = 0 THEN 'Idle'
        ELSE 'Active'
    END AS driver_status

FROM driver_data
LEFT JOIN ride_data
ON driver_data.driver_id = ride_data.driver_id
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`driver_name` = DBT_INTERNAL_SOURCE.`driver_name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`no_of_rides` = DBT_INTERNAL_SOURCE.`no_of_rides`,`total_ride_duration_min` = DBT_INTERNAL_SOURCE.`total_ride_duration_min`,`total_fare` = DBT_INTERNAL_SOURCE.`total_fare`,`total_distance_km` = DBT_INTERNAL_SOURCE.`total_distance_km`,`rev_opportunity_loss` = DBT_INTERNAL_SOURCE.`rev_opportunity_loss`
    

    when not matched then insert
        (`driver_id`, `driver_name`, `phone_number`, `email`, `vehicle_type`, `no_of_rides`, `total_ride_duration_min`, `total_fare`, `total_distance_km`, `rev_opportunity_loss`)
    values
        (`driver_id`, `driver_name`, `phone_number`, `email`, `vehicle_type`, `no_of_rides`, `total_ride_duration_min`, `total_fare`, `total_distance_km`, `rev_opportunity_loss`)


    
[0m10:53:07.873996 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:4ae64b1e-7951-4271-86ce-66ee770b199f&page=queryresults
[0m10:53:08.071847 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:4ae64b1e-7951-4271-86ce-66ee770b199f&page=queryresults
[0m10:53:08.078443 [debug] [Thread-1 (]: Database Error in model mart_driver_loyalty_mgmt (models/marts/mart_driver_loyalty_mgmt.sql)
  Value of type FLOAT64 cannot be assigned to total_fare, which has type NUMERIC at [63:386]
  compiled code at target/run/hailing_project/models/marts/mart_driver_loyalty_mgmt.sql
[0m10:53:08.082223 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '264a0e4f-3fd9-4d0e-8c85-361adec1ee80', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4090f7ec10>]}
[0m10:53:08.083383 [error] [Thread-1 (]: 1 of 1 ERROR creating sql incremental model rizky_dwh_hailing_marts.mart_driver_loyalty_mgmt  [[31mERROR[0m in 0.96s]
[0m10:53:08.085057 [debug] [Thread-1 (]: Finished running node model.hailing_project.mart_driver_loyalty_mgmt
[0m10:53:08.086729 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.mart_driver_loyalty_mgmt' to be skipped because of status 'error'.  Reason: Database Error in model mart_driver_loyalty_mgmt (models/marts/mart_driver_loyalty_mgmt.sql)
  Value of type FLOAT64 cannot be assigned to total_fare, which has type NUMERIC at [63:386]
  compiled code at target/run/hailing_project/models/marts/mart_driver_loyalty_mgmt.sql.
[0m10:53:08.089895 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m10:53:08.093956 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:53:08.094929 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_facts' was properly closed.
[0m10:53:08.095815 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_marts' was properly closed.
[0m10:53:08.096747 [debug] [MainThread]: Connection 'model.hailing_project.mart_driver_loyalty_mgmt' was properly closed.
[0m10:53:08.097821 [info ] [MainThread]: 
[0m10:53:08.098813 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 1.96 seconds (1.96s).
[0m10:53:08.100324 [debug] [MainThread]: Command end result
[0m10:53:08.136970 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m10:53:08.141355 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m10:53:08.149480 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m10:53:08.150457 [info ] [MainThread]: 
[0m10:53:08.151608 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m10:53:08.152716 [info ] [MainThread]: 
[0m10:53:08.153822 [error] [MainThread]:   Database Error in model mart_driver_loyalty_mgmt (models/marts/mart_driver_loyalty_mgmt.sql)
  Value of type FLOAT64 cannot be assigned to total_fare, which has type NUMERIC at [63:386]
  compiled code at target/run/hailing_project/models/marts/mart_driver_loyalty_mgmt.sql
[0m10:53:08.154863 [info ] [MainThread]: 
[0m10:53:08.156105 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m10:53:08.158139 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 3.407914, "process_in_blocks": "0", "process_kernel_time": 0.227758, "process_mem_max_rss": "221684", "process_out_blocks": "0", "process_user_time": 3.41638}
[0m10:53:08.160338 [debug] [MainThread]: Command `dbt run` failed at 10:53:08.160019 after 3.41 seconds
[0m10:53:08.161578 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f40bad859d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f40bad84dd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4090ea6410>]}
[0m10:53:08.162696 [debug] [MainThread]: Flushing usage events
[0m10:53:09.190525 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m10:54:43.995470 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faf89f1f550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faf89f77cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faf89f1eb10>]}


============================== 10:54:43.998354 | 95206598-b519-484c-b092-5321440ec5c7 ==============================
[0m10:54:43.998354 [info ] [MainThread]: Running with dbt=1.9.0
[0m10:54:44.000057 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --select mart_driver_loyalty_mgmt', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m10:54:44.626979 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '95206598-b519-484c-b092-5321440ec5c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faf6022a2d0>]}
[0m10:54:44.673924 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '95206598-b519-484c-b092-5321440ec5c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faf8c1760d0>]}
[0m10:54:44.675671 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m10:54:44.743885 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m10:54:44.967880 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m10:54:44.969424 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/marts/mart_driver_loyalty_mgmt.sql
[0m10:54:45.247557 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '95206598-b519-484c-b092-5321440ec5c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faf5bd7c7d0>]}
[0m10:54:45.326395 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m10:54:45.332838 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m10:54:45.351413 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '95206598-b519-484c-b092-5321440ec5c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faf5be674d0>]}
[0m10:54:45.353206 [info ] [MainThread]: Found 9 models, 8 sources, 489 macros
[0m10:54:45.354763 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '95206598-b519-484c-b092-5321440ec5c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faf60229410>]}
[0m10:54:45.357172 [info ] [MainThread]: 
[0m10:54:45.358353 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m10:54:45.359623 [info ] [MainThread]: 
[0m10:54:45.361188 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m10:54:45.362965 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m10:54:45.363921 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:54:46.037121 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_facts)
[0m10:54:46.037879 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_marts'
[0m10:54:46.038651 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_staging'
[0m10:54:46.039423 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:54:46.040839 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:54:46.042441 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:54:46.376130 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '95206598-b519-484c-b092-5321440ec5c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faf5be56e90>]}
[0m10:54:46.376994 [debug] [MainThread]: Opening a new connection, currently in state init
[0m10:54:46.382769 [debug] [Thread-1 (]: Began running node model.hailing_project.mart_driver_loyalty_mgmt
[0m10:54:46.383846 [info ] [Thread-1 (]: 1 of 1 START sql incremental model rizky_dwh_hailing_marts.mart_driver_loyalty_mgmt  [RUN]
[0m10:54:46.384976 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_marts, now model.hailing_project.mart_driver_loyalty_mgmt)
[0m10:54:46.385998 [debug] [Thread-1 (]: Began compiling node model.hailing_project.mart_driver_loyalty_mgmt
[0m10:54:46.394370 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.mart_driver_loyalty_mgmt"
[0m10:54:46.400039 [debug] [Thread-1 (]: Began executing node model.hailing_project.mart_driver_loyalty_mgmt
[0m10:54:46.434730 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m10:54:46.760539 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.mart_driver_loyalty_mgmt"
[0m10:54:46.769217 [debug] [Thread-1 (]: On model.hailing_project.mart_driver_loyalty_mgmt: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.mart_driver_loyalty_mgmt"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_marts`.`mart_driver_loyalty_mgmt` as DBT_INTERNAL_DEST
        using (

WITH driver_data AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
),

ride_data AS (
    SELECT 
        driver_id,
        COUNT(ride_id) AS no_of_rides,
        SUM(TIMESTAMP_DIFF(ride_end_time, ride_start_time, MINUTE)) AS total_ride_duration_min,
        
        -- ✅ Cast to NUMERIC to match target table
        SUM(CAST(fare AS NUMERIC)) AS total_fare,
        SUM(CAST(distance_km AS NUMERIC)) AS total_distance_km,
        SUM(CAST(distance_km AS NUMERIC)) - SUM(CAST(fare AS NUMERIC)) AS rev_opportunity_loss
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
    GROUP BY driver_id
)

SELECT 
    driver_data.driver_id,
    driver_data.driver_name,
    driver_data.phone_number,
    driver_data.email,
    driver_data.vehicle_type,
    
    -- ✅ Ensure COALESCE matches NUMERIC type
    COALESCE(ride_data.no_of_rides, 0) AS no_of_rides,
    COALESCE(ride_data.total_ride_duration_min, 0) AS total_ride_duration_min,
    COALESCE(ride_data.total_fare, 0.0) AS total_fare,
    COALESCE(ride_data.total_distance_km, 0.0) AS total_distance_km,
    COALESCE(ride_data.rev_opportunity_loss, 0.0) AS rev_opportunity_loss,

    -- ✅ Identify if driver is idle
    CASE 
        WHEN COALESCE(ride_data.no_of_rides, 0) = 0 THEN 'Idle'
        ELSE 'Active'
    END AS driver_status

FROM driver_data
LEFT JOIN ride_data
ON driver_data.driver_id = ride_data.driver_id;
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`driver_name` = DBT_INTERNAL_SOURCE.`driver_name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`no_of_rides` = DBT_INTERNAL_SOURCE.`no_of_rides`,`total_ride_duration_min` = DBT_INTERNAL_SOURCE.`total_ride_duration_min`,`total_fare` = DBT_INTERNAL_SOURCE.`total_fare`,`total_distance_km` = DBT_INTERNAL_SOURCE.`total_distance_km`,`rev_opportunity_loss` = DBT_INTERNAL_SOURCE.`rev_opportunity_loss`
    

    when not matched then insert
        (`driver_id`, `driver_name`, `phone_number`, `email`, `vehicle_type`, `no_of_rides`, `total_ride_duration_min`, `total_fare`, `total_distance_km`, `rev_opportunity_loss`)
    values
        (`driver_id`, `driver_name`, `phone_number`, `email`, `vehicle_type`, `no_of_rides`, `total_ride_duration_min`, `total_fare`, `total_distance_km`, `rev_opportunity_loss`)


    
[0m10:54:47.159643 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:ea73467b-5b08-4dd6-aa34-aa9256120025&page=queryresults
[0m10:54:47.160934 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:ea73467b-5b08-4dd6-aa34-aa9256120025&page=queryresults
[0m10:54:47.166375 [debug] [Thread-1 (]: Database Error in model mart_driver_loyalty_mgmt (models/marts/mart_driver_loyalty_mgmt.sql)
  Syntax error: Expected ")" but got ";" at [57:47]
  compiled code at target/run/hailing_project/models/marts/mart_driver_loyalty_mgmt.sql
[0m10:54:47.168558 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '95206598-b519-484c-b092-5321440ec5c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faf60124b90>]}
[0m10:54:47.169708 [error] [Thread-1 (]: 1 of 1 ERROR creating sql incremental model rizky_dwh_hailing_marts.mart_driver_loyalty_mgmt  [[31mERROR[0m in 0.78s]
[0m10:54:47.170875 [debug] [Thread-1 (]: Finished running node model.hailing_project.mart_driver_loyalty_mgmt
[0m10:54:47.172450 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.mart_driver_loyalty_mgmt' to be skipped because of status 'error'.  Reason: Database Error in model mart_driver_loyalty_mgmt (models/marts/mart_driver_loyalty_mgmt.sql)
  Syntax error: Expected ")" but got ";" at [57:47]
  compiled code at target/run/hailing_project/models/marts/mart_driver_loyalty_mgmt.sql.
[0m10:54:47.175684 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m10:54:47.179831 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:54:47.180777 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_facts' was properly closed.
[0m10:54:47.181815 [debug] [MainThread]: Connection 'model.hailing_project.mart_driver_loyalty_mgmt' was properly closed.
[0m10:54:47.182891 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_staging' was properly closed.
[0m10:54:47.183754 [info ] [MainThread]: 
[0m10:54:47.184665 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 1.82 seconds (1.82s).
[0m10:54:47.186363 [debug] [MainThread]: Command end result
[0m10:54:47.222843 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m10:54:47.228430 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m10:54:47.236934 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m10:54:47.237737 [info ] [MainThread]: 
[0m10:54:47.238870 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m10:54:47.240009 [info ] [MainThread]: 
[0m10:54:47.241255 [error] [MainThread]:   Database Error in model mart_driver_loyalty_mgmt (models/marts/mart_driver_loyalty_mgmt.sql)
  Syntax error: Expected ")" but got ";" at [57:47]
  compiled code at target/run/hailing_project/models/marts/mart_driver_loyalty_mgmt.sql
[0m10:54:47.242400 [info ] [MainThread]: 
[0m10:54:47.243452 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m10:54:47.245123 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 3.3048568, "process_in_blocks": "0", "process_kernel_time": 0.208271, "process_mem_max_rss": "221464", "process_out_blocks": "0", "process_user_time": 3.560456}
[0m10:54:47.246545 [debug] [MainThread]: Command `dbt run` failed at 10:54:47.246343 after 3.31 seconds
[0m10:54:47.247726 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faf89da1390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faf89da3790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faf8d86d310>]}
[0m10:54:47.248907 [debug] [MainThread]: Flushing usage events
[0m10:54:48.311623 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m10:55:01.224555 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd77a082a50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd77aecddd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd77a0dbad0>]}


============================== 10:55:01.227310 | dbd74de1-5000-4b2e-9aaf-77a7f1d4b99f ==============================
[0m10:55:01.227310 [info ] [MainThread]: Running with dbt=1.9.0
[0m10:55:01.228694 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'version_check': 'True', 'warn_error': 'None', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt run --select mart_driver_loyalty_mgmt', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m10:55:01.834595 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'dbd74de1-5000-4b2e-9aaf-77a7f1d4b99f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd750502e50>]}
[0m10:55:01.884473 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'dbd74de1-5000-4b2e-9aaf-77a7f1d4b99f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd77ae16350>]}
[0m10:55:01.885683 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m10:55:01.956551 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m10:55:02.140602 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m10:55:02.141702 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/marts/mart_driver_loyalty_mgmt.sql
[0m10:55:02.407214 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'dbd74de1-5000-4b2e-9aaf-77a7f1d4b99f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd75024d5d0>]}
[0m10:55:02.488205 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m10:55:02.495426 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m10:55:02.513372 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'dbd74de1-5000-4b2e-9aaf-77a7f1d4b99f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd75001d090>]}
[0m10:55:02.515229 [info ] [MainThread]: Found 9 models, 8 sources, 489 macros
[0m10:55:02.516584 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'dbd74de1-5000-4b2e-9aaf-77a7f1d4b99f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd7502d27d0>]}
[0m10:55:02.519069 [info ] [MainThread]: 
[0m10:55:02.520490 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m10:55:02.521878 [info ] [MainThread]: 
[0m10:55:02.523198 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m10:55:02.524689 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m10:55:02.525681 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:55:03.115597 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_marts)
[0m10:55:03.116619 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_facts'
[0m10:55:03.117323 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_staging'
[0m10:55:03.118272 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:55:03.119533 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:55:03.120556 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:55:03.427899 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'dbd74de1-5000-4b2e-9aaf-77a7f1d4b99f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd74bf02dd0>]}
[0m10:55:03.429207 [debug] [MainThread]: Opening a new connection, currently in state init
[0m10:55:03.434358 [debug] [Thread-1 (]: Began running node model.hailing_project.mart_driver_loyalty_mgmt
[0m10:55:03.435442 [info ] [Thread-1 (]: 1 of 1 START sql incremental model rizky_dwh_hailing_marts.mart_driver_loyalty_mgmt  [RUN]
[0m10:55:03.436893 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_staging, now model.hailing_project.mart_driver_loyalty_mgmt)
[0m10:55:03.438016 [debug] [Thread-1 (]: Began compiling node model.hailing_project.mart_driver_loyalty_mgmt
[0m10:55:03.446379 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.mart_driver_loyalty_mgmt"
[0m10:55:03.453925 [debug] [Thread-1 (]: Began executing node model.hailing_project.mart_driver_loyalty_mgmt
[0m10:55:03.488172 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m10:55:03.788273 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.mart_driver_loyalty_mgmt"
[0m10:55:03.795869 [debug] [Thread-1 (]: On model.hailing_project.mart_driver_loyalty_mgmt: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.mart_driver_loyalty_mgmt"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_marts`.`mart_driver_loyalty_mgmt` as DBT_INTERNAL_DEST
        using (

WITH driver_data AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
),

ride_data AS (
    SELECT 
        driver_id,
        COUNT(ride_id) AS no_of_rides,
        SUM(TIMESTAMP_DIFF(ride_end_time, ride_start_time, MINUTE)) AS total_ride_duration_min,
        
        -- ✅ Cast to NUMERIC to match target table
        SUM(CAST(fare AS NUMERIC)) AS total_fare,
        SUM(CAST(distance_km AS NUMERIC)) AS total_distance_km,
        SUM(CAST(distance_km AS NUMERIC)) - SUM(CAST(fare AS NUMERIC)) AS rev_opportunity_loss
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
    GROUP BY driver_id
)

SELECT 
    driver_data.driver_id,
    driver_data.driver_name,
    driver_data.phone_number,
    driver_data.email,
    driver_data.vehicle_type,
    
    -- ✅ Ensure COALESCE matches NUMERIC type
    COALESCE(ride_data.no_of_rides, 0) AS no_of_rides,
    COALESCE(ride_data.total_ride_duration_min, 0) AS total_ride_duration_min,
    COALESCE(ride_data.total_fare, 0.0) AS total_fare,
    COALESCE(ride_data.total_distance_km, 0.0) AS total_distance_km,
    COALESCE(ride_data.rev_opportunity_loss, 0.0) AS rev_opportunity_loss,

    -- ✅ Identify if driver is idle
    CASE 
        WHEN COALESCE(ride_data.no_of_rides, 0) = 0 THEN 'Idle'
        ELSE 'Active'
    END AS driver_status

FROM driver_data
LEFT JOIN ride_data
ON driver_data.driver_id = ride_data.driver_id
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`driver_name` = DBT_INTERNAL_SOURCE.`driver_name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`no_of_rides` = DBT_INTERNAL_SOURCE.`no_of_rides`,`total_ride_duration_min` = DBT_INTERNAL_SOURCE.`total_ride_duration_min`,`total_fare` = DBT_INTERNAL_SOURCE.`total_fare`,`total_distance_km` = DBT_INTERNAL_SOURCE.`total_distance_km`,`rev_opportunity_loss` = DBT_INTERNAL_SOURCE.`rev_opportunity_loss`
    

    when not matched then insert
        (`driver_id`, `driver_name`, `phone_number`, `email`, `vehicle_type`, `no_of_rides`, `total_ride_duration_min`, `total_fare`, `total_distance_km`, `rev_opportunity_loss`)
    values
        (`driver_id`, `driver_name`, `phone_number`, `email`, `vehicle_type`, `no_of_rides`, `total_ride_duration_min`, `total_fare`, `total_distance_km`, `rev_opportunity_loss`)


    
[0m10:55:04.101286 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:dca570c8-9fcd-4d23-9422-5bf11168065e&page=queryresults
[0m10:55:05.761328 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dbd74de1-5000-4b2e-9aaf-77a7f1d4b99f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd75040ec50>]}
[0m10:55:05.763281 [info ] [Thread-1 (]: 1 of 1 OK created sql incremental model rizky_dwh_hailing_marts.mart_driver_loyalty_mgmt  [[32mMERGE (99.0 rows, 21.7 KiB processed)[0m in 2.32s]
[0m10:55:05.764989 [debug] [Thread-1 (]: Finished running node model.hailing_project.mart_driver_loyalty_mgmt
[0m10:55:05.767756 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m10:55:05.771351 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:55:05.772485 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_marts' was properly closed.
[0m10:55:05.773467 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_facts' was properly closed.
[0m10:55:05.774498 [debug] [MainThread]: Connection 'model.hailing_project.mart_driver_loyalty_mgmt' was properly closed.
[0m10:55:05.775567 [info ] [MainThread]: 
[0m10:55:05.777098 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 3.25 seconds (3.25s).
[0m10:55:05.779613 [debug] [MainThread]: Command end result
[0m10:55:05.824788 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m10:55:05.830894 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m10:55:05.843532 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m10:55:05.845402 [info ] [MainThread]: 
[0m10:55:05.847222 [info ] [MainThread]: [32mCompleted successfully[0m
[0m10:55:05.849074 [info ] [MainThread]: 
[0m10:55:05.850630 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m10:55:05.853441 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 4.688491, "process_in_blocks": "0", "process_kernel_time": 0.169624, "process_mem_max_rss": "224580", "process_out_blocks": "0", "process_user_time": 3.522213}
[0m10:55:05.855568 [debug] [MainThread]: Command `dbt run` succeeded at 10:55:05.855265 after 4.69 seconds
[0m10:55:05.857057 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd77a0dc690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd77a0dc350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd77d878d90>]}
[0m10:55:05.858392 [debug] [MainThread]: Flushing usage events
[0m10:55:06.845633 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m10:55:40.366800 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4722a96d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb472783950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4722aaed0>]}


============================== 10:55:40.369248 | 3d51b99f-7b86-4f8f-bedd-d7d4961e78e0 ==============================
[0m10:55:40.369248 [info ] [MainThread]: Running with dbt=1.9.0
[0m10:55:40.371442 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'profiles_dir': '/usr/app/dbt_project', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'invocation_command': 'dbt run --select mart_driver_loyalty_mgmt', 'send_anonymous_usage_stats': 'True'}
[0m10:55:40.948149 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '3d51b99f-7b86-4f8f-bedd-d7d4961e78e0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb448457ed0>]}
[0m10:55:41.003130 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '3d51b99f-7b86-4f8f-bedd-d7d4961e78e0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb474501dd0>]}
[0m10:55:41.004948 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m10:55:41.069084 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m10:55:41.279470 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m10:55:41.280586 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m10:55:41.311841 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3d51b99f-7b86-4f8f-bedd-d7d4961e78e0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4482d9c90>]}
[0m10:55:41.437549 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m10:55:41.442796 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m10:55:41.458781 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3d51b99f-7b86-4f8f-bedd-d7d4961e78e0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4484483d0>]}
[0m10:55:41.459961 [info ] [MainThread]: Found 9 models, 8 sources, 489 macros
[0m10:55:41.461094 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3d51b99f-7b86-4f8f-bedd-d7d4961e78e0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb448186b90>]}
[0m10:55:41.463688 [info ] [MainThread]: 
[0m10:55:41.464739 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m10:55:41.465708 [info ] [MainThread]: 
[0m10:55:41.466879 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m10:55:41.468848 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m10:55:41.469809 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:55:42.098304 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_facts)
[0m10:55:42.099002 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_staging'
[0m10:55:42.099706 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_marts'
[0m10:55:42.100299 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:55:42.101781 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:55:42.103230 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:55:42.422819 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3d51b99f-7b86-4f8f-bedd-d7d4961e78e0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4484c8310>]}
[0m10:55:42.424082 [debug] [MainThread]: Opening a new connection, currently in state init
[0m10:55:42.429396 [debug] [Thread-1 (]: Began running node model.hailing_project.mart_driver_loyalty_mgmt
[0m10:55:42.430288 [info ] [Thread-1 (]: 1 of 1 START sql incremental model rizky_dwh_hailing_marts.mart_driver_loyalty_mgmt  [RUN]
[0m10:55:42.431364 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_marts, now model.hailing_project.mart_driver_loyalty_mgmt)
[0m10:55:42.432427 [debug] [Thread-1 (]: Began compiling node model.hailing_project.mart_driver_loyalty_mgmt
[0m10:55:42.443028 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.mart_driver_loyalty_mgmt"
[0m10:55:42.450226 [debug] [Thread-1 (]: Began executing node model.hailing_project.mart_driver_loyalty_mgmt
[0m10:55:42.508809 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.mart_driver_loyalty_mgmt"
[0m10:55:42.516330 [debug] [Thread-1 (]: On model.hailing_project.mart_driver_loyalty_mgmt: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.mart_driver_loyalty_mgmt"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_marts`.`mart_driver_loyalty_mgmt`
      
    
    

    OPTIONS()
    as (
      

WITH driver_data AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
),

ride_data AS (
    SELECT 
        driver_id,
        COUNT(ride_id) AS no_of_rides,
        SUM(TIMESTAMP_DIFF(ride_end_time, ride_start_time, MINUTE)) AS total_ride_duration_min,
        
        -- ✅ Cast to NUMERIC to match target table
        SUM(CAST(fare AS NUMERIC)) AS total_fare,
        SUM(CAST(distance_km AS NUMERIC)) AS total_distance_km,
        SUM(CAST(distance_km AS NUMERIC)) - SUM(CAST(fare AS NUMERIC)) AS rev_opportunity_loss
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
    GROUP BY driver_id
)

SELECT 
    driver_data.driver_id,
    driver_data.driver_name,
    driver_data.phone_number,
    driver_data.email,
    driver_data.vehicle_type,
    
    -- ✅ Ensure COALESCE matches NUMERIC type
    COALESCE(ride_data.no_of_rides, 0) AS no_of_rides,
    COALESCE(ride_data.total_ride_duration_min, 0) AS total_ride_duration_min,
    COALESCE(ride_data.total_fare, 0.0) AS total_fare,
    COALESCE(ride_data.total_distance_km, 0.0) AS total_distance_km,
    COALESCE(ride_data.rev_opportunity_loss, 0.0) AS rev_opportunity_loss,

    -- ✅ Identify if driver is idle
    CASE 
        WHEN COALESCE(ride_data.no_of_rides, 0) = 0 THEN 'Idle'
        ELSE 'Active'
    END AS driver_status

FROM driver_data
LEFT JOIN ride_data
ON driver_data.driver_id = ride_data.driver_id
    );
  
[0m10:55:42.517717 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m10:55:42.942880 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:4d46bf0f-d7b1-4b9e-bd18-a8c03f79c2d3&page=queryresults
[0m10:55:44.691438 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3d51b99f-7b86-4f8f-bedd-d7d4961e78e0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4482e4ad0>]}
[0m10:55:44.693625 [info ] [Thread-1 (]: 1 of 1 OK created sql incremental model rizky_dwh_hailing_marts.mart_driver_loyalty_mgmt  [[32mCREATE TABLE (85.0 rows, 11.0 KiB processed)[0m in 2.26s]
[0m10:55:44.695157 [debug] [Thread-1 (]: Finished running node model.hailing_project.mart_driver_loyalty_mgmt
[0m10:55:44.697706 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m10:55:44.701184 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:55:44.702113 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_facts' was properly closed.
[0m10:55:44.703126 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_staging' was properly closed.
[0m10:55:44.704141 [debug] [MainThread]: Connection 'model.hailing_project.mart_driver_loyalty_mgmt' was properly closed.
[0m10:55:44.705287 [info ] [MainThread]: 
[0m10:55:44.706444 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 3.24 seconds (3.24s).
[0m10:55:44.708149 [debug] [MainThread]: Command end result
[0m10:55:44.747378 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m10:55:44.752317 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m10:55:44.763721 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m10:55:44.765071 [info ] [MainThread]: 
[0m10:55:44.766940 [info ] [MainThread]: [32mCompleted successfully[0m
[0m10:55:44.768404 [info ] [MainThread]: 
[0m10:55:44.769824 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m10:55:44.771583 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 4.455336, "process_in_blocks": "0", "process_kernel_time": 0.14983, "process_mem_max_rss": "218704", "process_out_blocks": "0", "process_user_time": 3.386164}
[0m10:55:44.772775 [debug] [MainThread]: Command `dbt run` succeeded at 10:55:44.772605 after 4.46 seconds
[0m10:55:44.774003 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb472108950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb472109410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb475a9cd90>]}
[0m10:55:44.775366 [debug] [MainThread]: Flushing usage events
[0m10:55:46.014172 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:08:49.732110 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f820959b6d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f82096adc90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f82095f3cd0>]}


============================== 11:08:49.735158 | abb6d621-82c6-492b-abd9-e78fb899f1bb ==============================
[0m11:08:49.735158 [info ] [MainThread]: Running with dbt=1.9.0
[0m11:08:49.736703 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt run --select mart_driver_loyalty_mgmt', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m11:08:50.354403 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'abb6d621-82c6-492b-abd9-e78fb899f1bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f81db75fb10>]}
[0m11:08:50.405800 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'abb6d621-82c6-492b-abd9-e78fb899f1bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f820a3323d0>]}
[0m11:08:50.407609 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m11:08:50.476609 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m11:08:50.667099 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m11:08:50.668409 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/marts/mart_driver_loyalty_mgmt.sql
[0m11:08:50.928660 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'abb6d621-82c6-492b-abd9-e78fb899f1bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f81db8ebc90>]}
[0m11:08:51.012780 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m11:08:51.021259 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m11:08:51.039251 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'abb6d621-82c6-492b-abd9-e78fb899f1bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f81db3a4c10>]}
[0m11:08:51.040556 [info ] [MainThread]: Found 9 models, 8 sources, 489 macros
[0m11:08:51.041919 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'abb6d621-82c6-492b-abd9-e78fb899f1bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f81db8caf10>]}
[0m11:08:51.044370 [info ] [MainThread]: 
[0m11:08:51.045668 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m11:08:51.046950 [info ] [MainThread]: 
[0m11:08:51.048771 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m11:08:51.050779 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m11:08:51.052062 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:08:51.666736 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_marts)
[0m11:08:51.667540 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_facts'
[0m11:08:51.668441 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_staging'
[0m11:08:51.669106 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:08:51.670460 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:08:51.672011 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:08:52.003269 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'abb6d621-82c6-492b-abd9-e78fb899f1bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f81db8f7950>]}
[0m11:08:52.004477 [debug] [MainThread]: Opening a new connection, currently in state init
[0m11:08:52.010017 [debug] [Thread-1 (]: Began running node model.hailing_project.mart_driver_loyalty_mgmt
[0m11:08:52.011869 [info ] [Thread-1 (]: 1 of 1 START sql incremental model rizky_dwh_hailing_marts.mart_driver_loyalty_mgmt  [RUN]
[0m11:08:52.013348 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_staging, now model.hailing_project.mart_driver_loyalty_mgmt)
[0m11:08:52.014484 [debug] [Thread-1 (]: Began compiling node model.hailing_project.mart_driver_loyalty_mgmt
[0m11:08:52.022776 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.mart_driver_loyalty_mgmt"
[0m11:08:52.030132 [debug] [Thread-1 (]: Began executing node model.hailing_project.mart_driver_loyalty_mgmt
[0m11:08:52.063534 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:08:52.368964 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.mart_driver_loyalty_mgmt"
[0m11:08:52.377678 [debug] [Thread-1 (]: On model.hailing_project.mart_driver_loyalty_mgmt: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.mart_driver_loyalty_mgmt"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_marts`.`mart_driver_loyalty_mgmt` as DBT_INTERNAL_DEST
        using (

WITH driver_data AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
),

ride_data AS (
    SELECT 
        driver_id AS STRING AS driver_id,  -- ✅ Ensure data type consistency
        COUNT(ride_id) AS no_of_rides,
        SUM(TIMESTAMP_DIFF(ride_end_time, ride_start_time, MINUTE)) AS total_ride_duration_min,
        SUM(CAST(fare AS NUMERIC)) AS total_fare,
        SUM(CAST(distance_km AS NUMERIC)) AS total_distance_km,
        SUM(CAST(distance_km AS NUMERIC)) - SUM(CAST(fare AS NUMERIC)) AS rev_opportunity_loss
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
    GROUP BY driver_id
)

SELECT 
    driver_data.driver_id AS STRING AS driver_id,  -- ✅ Ensure ID consistency
    driver_data.driver_name,
    driver_data.phone_number,
    driver_data.email,
    driver_data.vehicle_type,
    
    -- ✅ Ensure all drivers exist
    COALESCE(ride_data.no_of_rides, 0) AS no_of_rides,
    COALESCE(ride_data.total_ride_duration_min, 0) AS total_ride_duration_min,
    COALESCE(ride_data.total_fare, 0.0) AS total_fare,
    COALESCE(ride_data.total_distance_km, 0.0) AS total_distance_km,
    COALESCE(ride_data.rev_opportunity_loss, 0.0) AS rev_opportunity_loss,

    -- ✅ Identify if driver is idle
    CASE 
        WHEN COALESCE(ride_data.no_of_rides, 0) = 0 THEN 'Idle'
        ELSE 'Active'
    END AS driver_status

FROM driver_data
LEFT JOIN ride_data
ON CAST(driver_data.driver_id AS STRING) = CAST(ride_data.driver_id AS STRING)
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`driver_name` = DBT_INTERNAL_SOURCE.`driver_name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`no_of_rides` = DBT_INTERNAL_SOURCE.`no_of_rides`,`total_ride_duration_min` = DBT_INTERNAL_SOURCE.`total_ride_duration_min`,`total_fare` = DBT_INTERNAL_SOURCE.`total_fare`,`total_distance_km` = DBT_INTERNAL_SOURCE.`total_distance_km`,`rev_opportunity_loss` = DBT_INTERNAL_SOURCE.`rev_opportunity_loss`,`driver_status` = DBT_INTERNAL_SOURCE.`driver_status`
    

    when not matched then insert
        (`driver_id`, `driver_name`, `phone_number`, `email`, `vehicle_type`, `no_of_rides`, `total_ride_duration_min`, `total_fare`, `total_distance_km`, `rev_opportunity_loss`, `driver_status`)
    values
        (`driver_id`, `driver_name`, `phone_number`, `email`, `vehicle_type`, `no_of_rides`, `total_ride_duration_min`, `total_fare`, `total_distance_km`, `rev_opportunity_loss`, `driver_status`)


    
[0m11:08:52.752225 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:7d71d8e5-ffef-49fb-91ff-8f386055738a&page=queryresults
[0m11:08:52.753666 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:7d71d8e5-ffef-49fb-91ff-8f386055738a&page=queryresults
[0m11:08:52.759089 [debug] [Thread-1 (]: Database Error in model mart_driver_loyalty_mgmt (models/marts/mart_driver_loyalty_mgmt.sql)
  Syntax error: Expected ")" but got keyword AS at [23:29]
  compiled code at target/run/hailing_project/models/marts/mart_driver_loyalty_mgmt.sql
[0m11:08:52.762023 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'abb6d621-82c6-492b-abd9-e78fb899f1bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f81db713790>]}
[0m11:08:52.763500 [error] [Thread-1 (]: 1 of 1 ERROR creating sql incremental model rizky_dwh_hailing_marts.mart_driver_loyalty_mgmt  [[31mERROR[0m in 0.75s]
[0m11:08:52.764773 [debug] [Thread-1 (]: Finished running node model.hailing_project.mart_driver_loyalty_mgmt
[0m11:08:52.765798 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.mart_driver_loyalty_mgmt' to be skipped because of status 'error'.  Reason: Database Error in model mart_driver_loyalty_mgmt (models/marts/mart_driver_loyalty_mgmt.sql)
  Syntax error: Expected ")" but got keyword AS at [23:29]
  compiled code at target/run/hailing_project/models/marts/mart_driver_loyalty_mgmt.sql.
[0m11:08:52.768224 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m11:08:52.771505 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:08:52.772403 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_marts' was properly closed.
[0m11:08:52.773200 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_facts' was properly closed.
[0m11:08:52.773812 [debug] [MainThread]: Connection 'model.hailing_project.mart_driver_loyalty_mgmt' was properly closed.
[0m11:08:52.774760 [info ] [MainThread]: 
[0m11:08:52.775828 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 1.73 seconds (1.73s).
[0m11:08:52.777493 [debug] [MainThread]: Command end result
[0m11:08:52.810349 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m11:08:52.815028 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m11:08:52.825110 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m11:08:52.825966 [info ] [MainThread]: 
[0m11:08:52.827157 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m11:08:52.828447 [info ] [MainThread]: 
[0m11:08:52.829712 [error] [MainThread]:   Database Error in model mart_driver_loyalty_mgmt (models/marts/mart_driver_loyalty_mgmt.sql)
  Syntax error: Expected ")" but got keyword AS at [23:29]
  compiled code at target/run/hailing_project/models/marts/mart_driver_loyalty_mgmt.sql
[0m11:08:52.830802 [info ] [MainThread]: 
[0m11:08:52.831923 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m11:08:52.833831 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 3.1624393, "process_in_blocks": "0", "process_kernel_time": 0.25752, "process_mem_max_rss": "219136", "process_out_blocks": "0", "process_user_time": 3.446811}
[0m11:08:52.835048 [debug] [MainThread]: Command `dbt run` failed at 11:08:52.834888 after 3.16 seconds
[0m11:08:52.835980 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f820cf19310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f820cf192d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f820cf19410>]}
[0m11:08:52.837013 [debug] [MainThread]: Flushing usage events
[0m11:08:54.127240 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:10:15.062093 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe07e61b7d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe07e61b350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe07e61b090>]}


============================== 11:10:15.064902 | 9e56e1c2-9d25-4734-b207-0b9d21bc1eb6 ==============================
[0m11:10:15.064902 [info ] [MainThread]: Running with dbt=1.9.0
[0m11:10:15.066208 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt run --select mart_driver_loyalty_mgmt', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m11:10:15.647719 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '9e56e1c2-9d25-4734-b207-0b9d21bc1eb6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe0547c6e50>]}
[0m11:10:15.691423 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '9e56e1c2-9d25-4734-b207-0b9d21bc1eb6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe08086e3d0>]}
[0m11:10:15.692828 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m11:10:15.758014 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m11:10:15.956693 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m11:10:15.957875 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/marts/mart_driver_loyalty_mgmt.sql
[0m11:10:16.220279 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9e56e1c2-9d25-4734-b207-0b9d21bc1eb6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe080906690>]}
[0m11:10:16.296601 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m11:10:16.301999 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m11:10:16.317534 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9e56e1c2-9d25-4734-b207-0b9d21bc1eb6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe054434450>]}
[0m11:10:16.318582 [info ] [MainThread]: Found 9 models, 8 sources, 489 macros
[0m11:10:16.319825 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9e56e1c2-9d25-4734-b207-0b9d21bc1eb6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe05478da90>]}
[0m11:10:16.322336 [info ] [MainThread]: 
[0m11:10:16.323524 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m11:10:16.324678 [info ] [MainThread]: 
[0m11:10:16.326201 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m11:10:16.328222 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m11:10:16.329388 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:10:17.017618 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_marts)
[0m11:10:17.018356 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_facts'
[0m11:10:17.018992 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_staging'
[0m11:10:17.019807 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:10:17.020641 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:10:17.021854 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:10:17.339127 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9e56e1c2-9d25-4734-b207-0b9d21bc1eb6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe054963190>]}
[0m11:10:17.340419 [debug] [MainThread]: Opening a new connection, currently in state init
[0m11:10:17.344773 [debug] [Thread-1 (]: Began running node model.hailing_project.mart_driver_loyalty_mgmt
[0m11:10:17.345784 [info ] [Thread-1 (]: 1 of 1 START sql incremental model rizky_dwh_hailing_marts.mart_driver_loyalty_mgmt  [RUN]
[0m11:10:17.346865 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_staging, now model.hailing_project.mart_driver_loyalty_mgmt)
[0m11:10:17.347740 [debug] [Thread-1 (]: Began compiling node model.hailing_project.mart_driver_loyalty_mgmt
[0m11:10:17.355278 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.mart_driver_loyalty_mgmt"
[0m11:10:17.363427 [debug] [Thread-1 (]: Began executing node model.hailing_project.mart_driver_loyalty_mgmt
[0m11:10:17.398999 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:10:17.704943 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.mart_driver_loyalty_mgmt"
[0m11:10:17.712043 [debug] [Thread-1 (]: On model.hailing_project.mart_driver_loyalty_mgmt: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.mart_driver_loyalty_mgmt"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_marts`.`mart_driver_loyalty_mgmt` as DBT_INTERNAL_DEST
        using (

WITH driver_data AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
),

ride_data AS (
    SELECT 
        CAST(driver_id AS STRING) AS driver_id,  -- ✅ Ensure data type consistency
        COUNT(ride_id) AS no_of_rides,
        SUM(TIMESTAMP_DIFF(ride_end_time, ride_start_time, MINUTE)) AS total_ride_duration_min,
        SUM(CAST(fare AS NUMERIC)) AS total_fare,
        SUM(CAST(distance_km AS NUMERIC)) AS total_distance_km,
        SUM(CAST(distance_km AS NUMERIC)) - SUM(CAST(fare AS NUMERIC)) AS rev_opportunity_loss
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
    GROUP BY driver_id
)

SELECT 
    CAST(driver_data.driver_id AS STRING) AS driver_id,  -- ✅ Ensure ID consistency
    driver_data.driver_name,
    driver_data.phone_number,
    driver_data.email,
    driver_data.vehicle_type,
    
    -- ✅ Ensure all drivers exist
    COALESCE(ride_data.no_of_rides, 0) AS no_of_rides,
    COALESCE(ride_data.total_ride_duration_min, 0) AS total_ride_duration_min,
    COALESCE(ride_data.total_fare, 0.0) AS total_fare,
    COALESCE(ride_data.total_distance_km, 0.0) AS total_distance_km,
    COALESCE(ride_data.rev_opportunity_loss, 0.0) AS rev_opportunity_loss,

    -- ✅ Identify if driver is idle
    CASE 
        WHEN COALESCE(ride_data.no_of_rides, 0) = 0 THEN 'Idle'
        ELSE 'Active'
    END AS driver_status

FROM driver_data
LEFT JOIN ride_data
ON CAST(driver_data.driver_id AS STRING) = CAST(ride_data.driver_id AS STRING);
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`driver_name` = DBT_INTERNAL_SOURCE.`driver_name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`no_of_rides` = DBT_INTERNAL_SOURCE.`no_of_rides`,`total_ride_duration_min` = DBT_INTERNAL_SOURCE.`total_ride_duration_min`,`total_fare` = DBT_INTERNAL_SOURCE.`total_fare`,`total_distance_km` = DBT_INTERNAL_SOURCE.`total_distance_km`,`rev_opportunity_loss` = DBT_INTERNAL_SOURCE.`rev_opportunity_loss`,`driver_status` = DBT_INTERNAL_SOURCE.`driver_status`
    

    when not matched then insert
        (`driver_id`, `driver_name`, `phone_number`, `email`, `vehicle_type`, `no_of_rides`, `total_ride_duration_min`, `total_fare`, `total_distance_km`, `rev_opportunity_loss`, `driver_status`)
    values
        (`driver_id`, `driver_name`, `phone_number`, `email`, `vehicle_type`, `no_of_rides`, `total_ride_duration_min`, `total_fare`, `total_distance_km`, `rev_opportunity_loss`, `driver_status`)


    
[0m11:10:18.091087 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:161f57b7-2070-43da-bc8e-7411205e0307&page=queryresults
[0m11:10:18.092221 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:161f57b7-2070-43da-bc8e-7411205e0307&page=queryresults
[0m11:10:18.098149 [debug] [Thread-1 (]: Database Error in model mart_driver_loyalty_mgmt (models/marts/mart_driver_loyalty_mgmt.sql)
  Syntax error: Expected ")" but got ";" at [55:79]
  compiled code at target/run/hailing_project/models/marts/mart_driver_loyalty_mgmt.sql
[0m11:10:18.100577 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9e56e1c2-9d25-4734-b207-0b9d21bc1eb6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe0545fff90>]}
[0m11:10:18.102167 [error] [Thread-1 (]: 1 of 1 ERROR creating sql incremental model rizky_dwh_hailing_marts.mart_driver_loyalty_mgmt  [[31mERROR[0m in 0.75s]
[0m11:10:18.103958 [debug] [Thread-1 (]: Finished running node model.hailing_project.mart_driver_loyalty_mgmt
[0m11:10:18.105943 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.mart_driver_loyalty_mgmt' to be skipped because of status 'error'.  Reason: Database Error in model mart_driver_loyalty_mgmt (models/marts/mart_driver_loyalty_mgmt.sql)
  Syntax error: Expected ")" but got ";" at [55:79]
  compiled code at target/run/hailing_project/models/marts/mart_driver_loyalty_mgmt.sql.
[0m11:10:18.109722 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m11:10:18.114093 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:10:18.115109 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_marts' was properly closed.
[0m11:10:18.116279 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_facts' was properly closed.
[0m11:10:18.117294 [debug] [MainThread]: Connection 'model.hailing_project.mart_driver_loyalty_mgmt' was properly closed.
[0m11:10:18.118467 [info ] [MainThread]: 
[0m11:10:18.119651 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 1.79 seconds (1.79s).
[0m11:10:18.121480 [debug] [MainThread]: Command end result
[0m11:10:18.157902 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m11:10:18.162401 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m11:10:18.171601 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m11:10:18.173019 [info ] [MainThread]: 
[0m11:10:18.174410 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m11:10:18.175488 [info ] [MainThread]: 
[0m11:10:18.176644 [error] [MainThread]:   Database Error in model mart_driver_loyalty_mgmt (models/marts/mart_driver_loyalty_mgmt.sql)
  Syntax error: Expected ")" but got ";" at [55:79]
  compiled code at target/run/hailing_project/models/marts/mart_driver_loyalty_mgmt.sql
[0m11:10:18.177758 [info ] [MainThread]: 
[0m11:10:18.178904 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m11:10:18.180636 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 3.1729252, "process_in_blocks": "0", "process_kernel_time": 0.176635, "process_mem_max_rss": "221068", "process_out_blocks": "0", "process_user_time": 3.385506}
[0m11:10:18.182041 [debug] [MainThread]: Command `dbt run` failed at 11:10:18.181835 after 3.17 seconds
[0m11:10:18.183212 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe081ecbe90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe07e478a50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe07e47af50>]}
[0m11:10:18.184376 [debug] [MainThread]: Flushing usage events
[0m11:10:19.226025 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:00:51.927044 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd2bfa6cb90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd2bfa6fb90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd2bfa6fa10>]}


============================== 13:00:51.929945 | f489bfb9-d731-4442-9718-cafc22aa242e ==============================
[0m13:00:51.929945 [info ] [MainThread]: Running with dbt=1.9.0
[0m13:00:51.931051 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt clean', 'send_anonymous_usage_stats': 'True'}
[0m13:00:52.020314 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f489bfb9-d731-4442-9718-cafc22aa242e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd2bf933050>]}
[0m13:00:52.102147 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.23137072, "process_in_blocks": "0", "process_kernel_time": 0.147526, "process_mem_max_rss": "90040", "process_out_blocks": "0", "process_user_time": 0.993344}
[0m13:00:52.103329 [debug] [MainThread]: Command `dbt clean` succeeded at 13:00:52.103215 after 0.23 seconds
[0m13:00:52.104219 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd2bfac5d50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd2bfac4710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd2c32c8b90>]}
[0m13:00:52.104952 [debug] [MainThread]: Flushing usage events
[0m13:00:53.188213 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:00:54.430654 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4a3face910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4a3feca4d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4a3faccc50>]}


============================== 13:00:54.433310 | c05d29e3-dc07-4d15-9527-08cfa403d573 ==============================
[0m13:00:54.433310 [info ] [MainThread]: Running with dbt=1.9.0
[0m13:00:54.434420 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt deps', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m13:00:54.526047 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'c05d29e3-dc07-4d15-9527-08cfa403d573', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4a3fa0e790>]}
[0m13:00:54.548435 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m13:00:54.551380 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m13:00:54.553403 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.17969131, "process_in_blocks": "0", "process_kernel_time": 0.090237, "process_mem_max_rss": "90204", "process_out_blocks": "0", "process_user_time": 1.112933}
[0m13:00:54.554547 [debug] [MainThread]: Command `dbt deps` succeeded at 13:00:54.554369 after 0.18 seconds
[0m13:00:54.555333 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4a3fafe390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4a3fafd810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4a43328b90>]}
[0m13:00:54.556237 [debug] [MainThread]: Flushing usage events
[0m13:00:55.574664 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:01:01.613131 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e4fced690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e4fcef850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e4fcef110>]}


============================== 13:01:01.616344 | 9f82ce42-b3cc-46ee-a01c-27708c0ea957 ==============================
[0m13:01:01.616344 [info ] [MainThread]: Running with dbt=1.9.0
[0m13:01:01.617768 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'version_check': 'True', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt run', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m13:01:02.229003 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '9f82ce42-b3cc-46ee-a01c-27708c0ea957', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e220721d0>]}
[0m13:01:02.280665 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '9f82ce42-b3cc-46ee-a01c-27708c0ea957', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e51f74990>]}
[0m13:01:02.281816 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m13:01:02.355994 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m13:01:02.358474 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m13:01:02.359523 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '9f82ce42-b3cc-46ee-a01c-27708c0ea957', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e23918b10>]}
[0m13:01:03.530605 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9f82ce42-b3cc-46ee-a01c-27708c0ea957', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e21ed0ed0>]}
[0m13:01:03.614802 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m13:01:03.620625 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m13:01:03.638073 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9f82ce42-b3cc-46ee-a01c-27708c0ea957', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e200abf10>]}
[0m13:01:03.639526 [info ] [MainThread]: Found 9 models, 8 sources, 489 macros
[0m13:01:03.641097 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9f82ce42-b3cc-46ee-a01c-27708c0ea957', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e21ab64d0>]}
[0m13:01:03.644090 [info ] [MainThread]: 
[0m13:01:03.645429 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m13:01:03.646875 [info ] [MainThread]: 
[0m13:01:03.648922 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m13:01:03.655261 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m13:01:03.655989 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m13:01:03.656656 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m13:01:03.657251 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:01:03.658599 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:01:03.660042 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:01:04.918255 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_marts)
[0m13:01:04.918844 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_staging)
[0m13:01:04.919343 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_facts)
[0m13:01:04.919981 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:01:04.920830 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:01:04.921616 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:01:05.203022 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9f82ce42-b3cc-46ee-a01c-27708c0ea957', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e21ab79d0>]}
[0m13:01:05.204300 [debug] [MainThread]: Opening a new connection, currently in state init
[0m13:01:05.209426 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m13:01:05.209922 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m13:01:05.210459 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m13:01:05.210877 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m13:01:05.211620 [info ] [Thread-1 (]: 1 of 9 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [RUN]
[0m13:01:05.213475 [info ] [Thread-2 (]: 2 of 9 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [RUN]
[0m13:01:05.215237 [info ] [Thread-3 (]: 3 of 9 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [RUN]
[0m13:01:05.216613 [info ] [Thread-4 (]: 4 of 9 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [RUN]
[0m13:01:05.218020 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_staging, now model.hailing_project.production_hailing_staging_customer)
[0m13:01:05.219500 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_marts, now model.hailing_project.production_hailing_staging_driver)
[0m13:01:05.220820 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_facts, now model.hailing_project.production_hailing_staging_ride)
[0m13:01:05.222391 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_vehicle'
[0m13:01:05.223606 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m13:01:05.224494 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m13:01:05.225410 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m13:01:05.226272 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m13:01:05.235282 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m13:01:05.239293 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m13:01:05.243733 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m13:01:05.248207 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m13:01:05.261051 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m13:01:05.267705 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m13:01:05.284275 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m13:01:05.284649 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m13:01:05.361950 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m13:01:05.363552 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m13:01:05.364002 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m13:01:05.367034 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m13:01:05.377782 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    );
  
[0m13:01:05.378968 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:01:05.379434 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    );
  
[0m13:01:05.381225 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    );
  
[0m13:01:05.381769 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m13:01:05.384025 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m13:01:05.384544 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    );
  
[0m13:01:05.434764 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m13:01:05.792699 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:b987fc6b-8b7f-4890-963d-b88749d871a9&page=queryresults
[0m13:01:05.850214 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:b13e08f0-37a0-413d-9537-3802368658e6&page=queryresults
[0m13:01:05.850848 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:bc4928a7-34ef-41a9-ac3a-50deadb79521&page=queryresults
[0m13:01:05.881193 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:f69eb173-0466-4cda-bdc4-2dc333239fbd&page=queryresults
[0m13:01:07.832305 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9f82ce42-b3cc-46ee-a01c-27708c0ea957', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e21c1a810>]}
[0m13:01:07.834128 [info ] [Thread-4 (]: 4 of 9 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [[32mCREATE TABLE (95.0 rows, 5.2 KiB processed)[0m in 2.61s]
[0m13:01:07.835588 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m13:01:07.840713 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9f82ce42-b3cc-46ee-a01c-27708c0ea957', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e2016e910>]}
[0m13:01:07.842286 [info ] [Thread-2 (]: 2 of 9 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [[32mCREATE TABLE (95.0 rows, 6.5 KiB processed)[0m in 2.62s]
[0m13:01:07.843781 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m13:01:07.845108 [debug] [Thread-4 (]: Began running node model.hailing_project.dim_driver
[0m13:01:07.846449 [info ] [Thread-4 (]: 5 of 9 START sql incremental model rizky_dwh_hailing_facts.dim_driver .......... [RUN]
[0m13:01:07.848151 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_vehicle, now model.hailing_project.dim_driver)
[0m13:01:07.849218 [debug] [Thread-4 (]: Began compiling node model.hailing_project.dim_driver
[0m13:01:07.854575 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.dim_driver"
[0m13:01:07.867069 [debug] [Thread-4 (]: Began executing node model.hailing_project.dim_driver
[0m13:01:07.871949 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.dim_driver"
[0m13:01:07.883848 [debug] [Thread-4 (]: On model.hailing_project.dim_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_driver"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      


WITH driver AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver` --pakai ref untuk buat dependency

),

vehicle AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle`
)

SELECT
    driver.driver_id,
    vehicle.vehicle_id,
    driver.name as driver_name,
    driver.phone_number as phone_number,
    driver.email as email,
    vehicle.vehicle_type,
    vehicle.brand as vehicle_brand,
    vehicle.year as vehicle_production_year,
    vehicle.license_plate,
    driver.created_at
FROM driver
LEFT JOIN vehicle
on driver.driver_id = vehicle.vehicle_id


    );
  
[0m13:01:07.885044 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m13:01:08.038434 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9f82ce42-b3cc-46ee-a01c-27708c0ea957', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e004d8bd0>]}
[0m13:01:08.039646 [info ] [Thread-1 (]: 1 of 9 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [[32mCREATE TABLE (95.0 rows, 6.5 KiB processed)[0m in 2.82s]
[0m13:01:08.041630 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m13:01:08.043209 [debug] [Thread-2 (]: Began running node model.hailing_project.dim_customer
[0m13:01:08.044297 [info ] [Thread-2 (]: 6 of 9 START sql incremental model rizky_dwh_hailing_facts.dim_customer ........ [RUN]
[0m13:01:08.045378 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_driver, now model.hailing_project.dim_customer)
[0m13:01:08.046501 [debug] [Thread-2 (]: Began compiling node model.hailing_project.dim_customer
[0m13:01:08.051505 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m13:01:08.057895 [debug] [Thread-2 (]: Began executing node model.hailing_project.dim_customer
[0m13:01:08.063246 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m13:01:08.081869 [debug] [Thread-2 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
)

SELECT * FROM source

    );
  
[0m13:01:08.084568 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m13:01:08.117907 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9f82ce42-b3cc-46ee-a01c-27708c0ea957', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e2016ccd0>]}
[0m13:01:08.119440 [info ] [Thread-3 (]: 3 of 9 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [[32mCREATE TABLE (95.0 rows, 8.4 KiB processed)[0m in 2.90s]
[0m13:01:08.120879 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m13:01:08.333051 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:a5a8e266-1172-4133-8fbb-a473ba4bd365&page=queryresults
[0m13:01:08.480534 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:b96ec04f-7da6-4a69-bf8f-583ec628cd0a&page=queryresults
[0m13:01:10.277550 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9f82ce42-b3cc-46ee-a01c-27708c0ea957', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e006222d0>]}
[0m13:01:10.278707 [info ] [Thread-4 (]: 5 of 9 OK created sql incremental model rizky_dwh_hailing_facts.dim_driver ..... [[32mCREATE TABLE (95.0 rows, 10.1 KiB processed)[0m in 2.43s]
[0m13:01:10.280070 [debug] [Thread-4 (]: Finished running node model.hailing_project.dim_driver
[0m13:01:10.407725 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9f82ce42-b3cc-46ee-a01c-27708c0ea957', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e20112390>]}
[0m13:01:10.408868 [info ] [Thread-2 (]: 6 of 9 OK created sql incremental model rizky_dwh_hailing_facts.dim_customer ... [[32mCREATE TABLE (95.0 rows, 6.3 KiB processed)[0m in 2.36s]
[0m13:01:10.410287 [debug] [Thread-2 (]: Finished running node model.hailing_project.dim_customer
[0m13:01:10.412141 [debug] [Thread-1 (]: Began running node model.hailing_project.fact_hailing_rides
[0m13:01:10.413353 [info ] [Thread-1 (]: 7 of 9 START sql incremental model rizky_dwh_hailing_facts.fact_hailing_rides .. [RUN]
[0m13:01:10.414528 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_customer, now model.hailing_project.fact_hailing_rides)
[0m13:01:10.415378 [debug] [Thread-1 (]: Began compiling node model.hailing_project.fact_hailing_rides
[0m13:01:10.420498 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.fact_hailing_rides"
[0m13:01:10.426278 [debug] [Thread-1 (]: Began executing node model.hailing_project.fact_hailing_rides
[0m13:01:10.432110 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.fact_hailing_rides"
[0m13:01:10.438917 [debug] [Thread-1 (]: On model.hailing_project.fact_hailing_rides: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.fact_hailing_rides"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH dim_driver AS (

    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
),

dim_customer AS (

    SELECT * 
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer`
),

ride_staging AS (

    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride`
)

SELECT
ride_staging.ride_id,
ride_staging.start_time AS ride_start_time,
ride_staging.end_time AS ride_end_time,
ride_staging.distance_km,
ride_staging.fare,
ride_staging.ride_status,
dim_customer.cust_id,
dim_customer.name AS cust_name,
dim_customer.phone_number AS cust_phone_number,
dim_customer.email AS cust_email,
dim_driver.driver_id,
dim_driver.driver_name,
dim_driver.phone_number AS driver_phone_number,
dim_driver.email AS driver_email,
dim_driver.vehicle_id,
dim_driver.vehicle_type,
dim_driver.vehicle_brand,
dim_driver.vehicle_production_year,
dim_driver.license_plate,
ride_staging.created_at

FROM ride_staging

LEFT JOIN dim_customer
on ride_staging.cust_id = dim_customer.cust_id

LEFT JOIN dim_driver
on ride_staging.driver_id = dim_driver.driver_id


    );
  
[0m13:01:10.440395 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:01:10.916345 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:439fb50b-57b9-449e-9698-eaacac41338c&page=queryresults
[0m13:01:12.835118 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9f82ce42-b3cc-46ee-a01c-27708c0ea957', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e00351cd0>]}
[0m13:01:12.836543 [info ] [Thread-1 (]: 7 of 9 OK created sql incremental model rizky_dwh_hailing_facts.fact_hailing_rides  [[32mCREATE TABLE (95.0 rows, 23.4 KiB processed)[0m in 2.42s]
[0m13:01:12.837965 [debug] [Thread-1 (]: Finished running node model.hailing_project.fact_hailing_rides
[0m13:01:12.839855 [debug] [Thread-4 (]: Began running node model.hailing_project.mart_cust_rides_daily
[0m13:01:12.840261 [debug] [Thread-2 (]: Began running node model.hailing_project.mart_driver_loyalty_mgmt
[0m13:01:12.841301 [info ] [Thread-4 (]: 8 of 9 START sql incremental model rizky_dwh_hailing_marts.mart_cust_rides_daily  [RUN]
[0m13:01:12.842539 [info ] [Thread-2 (]: 9 of 9 START sql incremental model rizky_dwh_hailing_marts.mart_driver_loyalty_mgmt  [RUN]
[0m13:01:12.843778 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.hailing_project.dim_driver, now model.hailing_project.mart_cust_rides_daily)
[0m13:01:12.844993 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.hailing_project.dim_customer, now model.hailing_project.mart_driver_loyalty_mgmt)
[0m13:01:12.846320 [debug] [Thread-4 (]: Began compiling node model.hailing_project.mart_cust_rides_daily
[0m13:01:12.847796 [debug] [Thread-2 (]: Began compiling node model.hailing_project.mart_driver_loyalty_mgmt
[0m13:01:12.851817 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.mart_cust_rides_daily"
[0m13:01:12.855829 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.mart_driver_loyalty_mgmt"
[0m13:01:12.864013 [debug] [Thread-4 (]: Began executing node model.hailing_project.mart_cust_rides_daily
[0m13:01:12.869899 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.mart_cust_rides_daily"
[0m13:01:12.870432 [debug] [Thread-2 (]: Began executing node model.hailing_project.mart_driver_loyalty_mgmt
[0m13:01:12.875628 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.mart_driver_loyalty_mgmt"
[0m13:01:12.881236 [debug] [Thread-4 (]: On model.hailing_project.mart_cust_rides_daily: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.mart_cust_rides_daily"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_marts`.`mart_cust_rides_daily`
      
    partition by ride_date
    

    OPTIONS()
    as (
      


WITH fact_rides AS(

    SELECT * 
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
)

SELECT 

    fact_rides.cust_id,
    DATE(fact_rides.created_at) AS ride_date,
    fact_rides.cust_name,
    fact_rides.cust_email,
    fact_rides.cust_phone_number,
    COUNT(fact_rides.ride_id) AS no_of_rides,
    SUM(TIMESTAMP_DIFF(fact_rides.ride_end_time, fact_rides.ride_start_time, MINUTE)) AS total_ride_duration_min,
    SUM(fact_rides.fare) AS total_fare,
    SUM(fact_rides.distance_km) as total_distance_km,
    SUM(fact_rides.distance_km)-SUM(fact_rides.fare) AS rev_opportunity_loss,

FROM fact_rides
GROUP BY cust_name, cust_id, ride_date, cust_email, cust_phone_number
    );
  
[0m13:01:12.882644 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m13:01:12.883273 [debug] [Thread-2 (]: On model.hailing_project.mart_driver_loyalty_mgmt: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.mart_driver_loyalty_mgmt"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_marts`.`mart_driver_loyalty_mgmt`
      
    
    

    OPTIONS()
    as (
      

WITH dim_driver AS(
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
),

fact_rides AS(
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
)

SELECT 
dim_driver.driver_id,
dim_driver.driver_name,
dim_driver.phone_number,
dim_driver.email,
dim_driver.vehicle_type,
COUNT(fact_rides.ride_id) AS no_of_rides,
SUM(TIMESTAMP_DIFF(fact_rides.ride_end_time, fact_rides.ride_start_time, MINUTE)) AS total_ride_duration_min,
SUM(fact_rides.fare) AS total_fare,
SUM(fact_rides.distance_km) as total_distance_km,
SUM(fact_rides.distance_km)-SUM(fact_rides.fare) AS rev_opportunity_loss,
FROM dim_driver
LEFT JOIN fact_rides
ON dim_driver.driver_id = fact_rides.driver_id

GROUP BY driver_id,driver_name,phone_number,email,vehicle_type
    );
  
[0m13:01:12.884797 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m13:01:13.290363 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:a830039b-0c8f-420e-b7fe-8a49b6e1c3b5&page=queryresults
[0m13:01:13.293513 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:2c1cbfd6-560b-48f0-8a6f-4959a2fb8706&page=queryresults
[0m13:01:14.950266 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9f82ce42-b3cc-46ee-a01c-27708c0ea957', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e00351e10>]}
[0m13:01:14.951918 [info ] [Thread-2 (]: 9 of 9 OK created sql incremental model rizky_dwh_hailing_marts.mart_driver_loyalty_mgmt  [[32mCREATE TABLE (95.0 rows, 12.3 KiB processed)[0m in 2.11s]
[0m13:01:14.953441 [debug] [Thread-2 (]: Finished running node model.hailing_project.mart_driver_loyalty_mgmt
[0m13:01:15.247640 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9f82ce42-b3cc-46ee-a01c-27708c0ea957', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e00425f10>]}
[0m13:01:15.248862 [info ] [Thread-4 (]: 8 of 9 OK created sql incremental model rizky_dwh_hailing_marts.mart_cust_rides_daily  [[32mCREATE TABLE (78.0 rows, 11.5 KiB processed)[0m in 2.40s]
[0m13:01:15.250653 [debug] [Thread-4 (]: Finished running node model.hailing_project.mart_cust_rides_daily
[0m13:01:15.253140 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m13:01:15.257479 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:01:15.258398 [debug] [MainThread]: Connection 'model.hailing_project.mart_driver_loyalty_mgmt' was properly closed.
[0m13:01:15.259356 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m13:01:15.260566 [debug] [MainThread]: Connection 'model.hailing_project.fact_hailing_rides' was properly closed.
[0m13:01:15.261884 [debug] [MainThread]: Connection 'model.hailing_project.mart_cust_rides_daily' was properly closed.
[0m13:01:15.262851 [info ] [MainThread]: 
[0m13:01:15.263876 [info ] [MainThread]: Finished running 9 incremental models in 0 hours 0 minutes and 11.61 seconds (11.61s).
[0m13:01:15.266453 [debug] [MainThread]: Command end result
[0m13:01:15.306398 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m13:01:15.310660 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m13:01:15.319316 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m13:01:15.320121 [info ] [MainThread]: 
[0m13:01:15.321210 [info ] [MainThread]: [32mCompleted successfully[0m
[0m13:01:15.322220 [info ] [MainThread]: 
[0m13:01:15.323163 [info ] [MainThread]: Done. PASS=9 WARN=0 ERROR=0 SKIP=0 TOTAL=9
[0m13:01:15.325294 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 13.765531, "process_in_blocks": "0", "process_kernel_time": 0.360296, "process_mem_max_rss": "226096", "process_out_blocks": "0", "process_user_time": 4.593783}
[0m13:01:15.326552 [debug] [MainThread]: Command `dbt run` succeeded at 13:01:15.326417 after 13.77 seconds
[0m13:01:15.327307 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e503d9f50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e500ee5d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e4fd4aa50>]}
[0m13:01:15.328217 [debug] [MainThread]: Flushing usage events
[0m13:01:16.622928 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:01:28.810108 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d4147a150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d4186e110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d4147a8d0>]}


============================== 13:01:28.812954 | f7272399-cf3b-47a9-b880-fd9e69e15c89 ==============================
[0m13:01:28.812954 [info ] [MainThread]: Running with dbt=1.9.0
[0m13:01:28.815106 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m13:01:29.387899 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f7272399-cf3b-47a9-b880-fd9e69e15c89', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d13d6ff10>]}
[0m13:01:29.434024 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f7272399-cf3b-47a9-b880-fd9e69e15c89', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d436d2050>]}
[0m13:01:29.435237 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m13:01:29.506901 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m13:01:29.693964 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m13:01:29.695008 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m13:01:29.721109 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f7272399-cf3b-47a9-b880-fd9e69e15c89', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d13679090>]}
[0m13:01:29.840767 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m13:01:29.847300 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m13:01:29.863015 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f7272399-cf3b-47a9-b880-fd9e69e15c89', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d134285d0>]}
[0m13:01:29.864068 [info ] [MainThread]: Found 9 models, 8 sources, 489 macros
[0m13:01:29.865186 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f7272399-cf3b-47a9-b880-fd9e69e15c89', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d1362fb90>]}
[0m13:01:29.867969 [info ] [MainThread]: 
[0m13:01:29.868990 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m13:01:29.870020 [info ] [MainThread]: 
[0m13:01:29.871470 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m13:01:29.876310 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m13:01:29.877722 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m13:01:29.878381 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m13:01:29.878895 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:01:29.879795 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:01:29.880680 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:01:31.840078 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_marts)
[0m13:01:31.840688 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_facts)
[0m13:01:31.841263 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_staging)
[0m13:01:31.841787 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:01:31.842795 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:01:31.843708 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:01:32.108974 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f7272399-cf3b-47a9-b880-fd9e69e15c89', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d1362f390>]}
[0m13:01:32.110051 [debug] [MainThread]: Opening a new connection, currently in state init
[0m13:01:32.115862 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m13:01:32.116388 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m13:01:32.116826 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m13:01:32.117285 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m13:01:32.117975 [info ] [Thread-1 (]: 1 of 9 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [RUN]
[0m13:01:32.119139 [info ] [Thread-2 (]: 2 of 9 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [RUN]
[0m13:01:32.120521 [info ] [Thread-3 (]: 3 of 9 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [RUN]
[0m13:01:32.121643 [info ] [Thread-4 (]: 4 of 9 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [RUN]
[0m13:01:32.122786 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_facts, now model.hailing_project.production_hailing_staging_customer)
[0m13:01:32.123936 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_staging, now model.hailing_project.production_hailing_staging_driver)
[0m13:01:32.125087 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_marts, now model.hailing_project.production_hailing_staging_ride)
[0m13:01:32.126126 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_vehicle'
[0m13:01:32.127014 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m13:01:32.128082 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m13:01:32.129189 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m13:01:32.130364 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m13:01:32.145241 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m13:01:32.149941 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m13:01:32.154746 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m13:01:32.159093 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m13:01:32.164602 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m13:01:32.165095 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m13:01:32.165532 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m13:01:32.171340 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m13:01:32.216551 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m13:01:32.217501 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m13:01:32.220239 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:01:32.224306 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m13:01:32.531160 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m13:01:32.532063 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m13:01:32.533745 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m13:01:32.535773 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m13:01:32.540155 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m13:01:32.540820 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m13:01:32.541879 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m13:01:32.545554 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m13:01:32.795452 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:76e0d983-8f70-4a99-8e30-3aa5f25eee2c&page=queryresults
[0m13:01:32.798095 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:cd7b6013-f20f-4cce-899c-62be40af1375&page=queryresults
[0m13:01:32.814456 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:9f783fba-ec1b-4b0d-990a-9c91463161cc&page=queryresults
[0m13:01:32.815450 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:88a367ac-6898-4c7e-98f9-bcffaac176ba&page=queryresults
[0m13:01:34.622001 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f7272399-cf3b-47a9-b880-fd9e69e15c89', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d1362ea90>]}
[0m13:01:34.622542 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f7272399-cf3b-47a9-b880-fd9e69e15c89', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d13613b10>]}
[0m13:01:34.623144 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f7272399-cf3b-47a9-b880-fd9e69e15c89', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d1361eed0>]}
[0m13:01:34.624175 [info ] [Thread-1 (]: 1 of 9 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 12.9 KiB processed)[0m in 2.49s]
[0m13:01:34.625533 [info ] [Thread-2 (]: 2 of 9 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 12.8 KiB processed)[0m in 2.50s]
[0m13:01:34.626955 [info ] [Thread-4 (]: 4 of 9 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 10.4 KiB processed)[0m in 2.50s]
[0m13:01:34.628191 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m13:01:34.629558 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m13:01:34.630672 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m13:01:34.632745 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m13:01:34.637674 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f7272399-cf3b-47a9-b880-fd9e69e15c89', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d136d09d0>]}
[0m13:01:34.639037 [debug] [Thread-2 (]: Began running node model.hailing_project.dim_driver
[0m13:01:34.640374 [info ] [Thread-1 (]: 5 of 9 START sql incremental model rizky_dwh_hailing_facts.dim_customer ........ [RUN]
[0m13:01:34.642350 [info ] [Thread-3 (]: 3 of 9 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 16.9 KiB processed)[0m in 2.51s]
[0m13:01:34.643576 [info ] [Thread-2 (]: 6 of 9 START sql incremental model rizky_dwh_hailing_facts.dim_driver .......... [RUN]
[0m13:01:34.644714 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_customer, now model.hailing_project.dim_customer)
[0m13:01:34.645831 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m13:01:34.647415 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_driver, now model.hailing_project.dim_driver)
[0m13:01:34.648962 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m13:01:34.650864 [debug] [Thread-2 (]: Began compiling node model.hailing_project.dim_driver
[0m13:01:34.656355 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m13:01:34.660675 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.dim_driver"
[0m13:01:34.666230 [debug] [Thread-2 (]: Began executing node model.hailing_project.dim_driver
[0m13:01:34.666734 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m13:01:34.670782 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m13:01:34.674073 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:01:34.918341 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.dim_driver"
[0m13:01:34.923946 [debug] [Thread-2 (]: On model.hailing_project.dim_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver` as DBT_INTERNAL_DEST
        using (


WITH driver AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver` --pakai ref untuk buat dependency

),

vehicle AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle`
)

SELECT
    driver.driver_id,
    vehicle.vehicle_id,
    driver.name as driver_name,
    driver.phone_number as phone_number,
    driver.email as email,
    vehicle.vehicle_type,
    vehicle.brand as vehicle_brand,
    vehicle.year as vehicle_production_year,
    vehicle.license_plate,
    driver.created_at
FROM driver
LEFT JOIN vehicle
on driver.driver_id = vehicle.vehicle_id


    WHERE driver.created_at > (
        SELECT MAX(driver.created_at)
        FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_name` = DBT_INTERNAL_SOURCE.`driver_name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`vehicle_brand` = DBT_INTERNAL_SOURCE.`vehicle_brand`,`vehicle_production_year` = DBT_INTERNAL_SOURCE.`vehicle_production_year`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `vehicle_id`, `driver_name`, `phone_number`, `email`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)
    values
        (`driver_id`, `vehicle_id`, `driver_name`, `phone_number`, `email`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)


    
[0m13:01:34.935236 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m13:01:34.941115 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
)

SELECT * FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m13:01:35.198911 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:d5aeabee-9b4c-45e3-b875-67e0af5d666b&page=queryresults
[0m13:01:35.200857 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:3023a9fb-05a1-471b-a480-b75a24b88149&page=queryresults
[0m13:01:36.712651 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f7272399-cf3b-47a9-b880-fd9e69e15c89', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7cfb413890>]}
[0m13:01:36.713942 [info ] [Thread-1 (]: 5 of 9 OK created sql incremental model rizky_dwh_hailing_facts.dim_customer ... [[32mMERGE (0.0 rows, 12.7 KiB processed)[0m in 2.07s]
[0m13:01:36.715271 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m13:01:36.986117 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f7272399-cf3b-47a9-b880-fd9e69e15c89', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7cfb4a8e90>]}
[0m13:01:36.987414 [info ] [Thread-2 (]: 6 of 9 OK created sql incremental model rizky_dwh_hailing_facts.dim_driver ..... [[32mMERGE (0.0 rows, 20.2 KiB processed)[0m in 2.34s]
[0m13:01:36.988714 [debug] [Thread-2 (]: Finished running node model.hailing_project.dim_driver
[0m13:01:36.990420 [debug] [Thread-4 (]: Began running node model.hailing_project.fact_hailing_rides
[0m13:01:36.991479 [info ] [Thread-4 (]: 7 of 9 START sql incremental model rizky_dwh_hailing_facts.fact_hailing_rides .. [RUN]
[0m13:01:36.992652 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_vehicle, now model.hailing_project.fact_hailing_rides)
[0m13:01:36.993584 [debug] [Thread-4 (]: Began compiling node model.hailing_project.fact_hailing_rides
[0m13:01:36.998965 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.fact_hailing_rides"
[0m13:01:37.006080 [debug] [Thread-4 (]: Began executing node model.hailing_project.fact_hailing_rides
[0m13:01:37.010505 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m13:01:37.233280 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.fact_hailing_rides"
[0m13:01:37.240242 [debug] [Thread-4 (]: On model.hailing_project.fact_hailing_rides: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.fact_hailing_rides"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides` as DBT_INTERNAL_DEST
        using (

WITH dim_driver AS (

    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
),

dim_customer AS (

    SELECT * 
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer`
),

ride_staging AS (

    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride`
)

SELECT
ride_staging.ride_id,
ride_staging.start_time AS ride_start_time,
ride_staging.end_time AS ride_end_time,
ride_staging.distance_km,
ride_staging.fare,
ride_staging.ride_status,
dim_customer.cust_id,
dim_customer.name AS cust_name,
dim_customer.phone_number AS cust_phone_number,
dim_customer.email AS cust_email,
dim_driver.driver_id,
dim_driver.driver_name,
dim_driver.phone_number AS driver_phone_number,
dim_driver.email AS driver_email,
dim_driver.vehicle_id,
dim_driver.vehicle_type,
dim_driver.vehicle_brand,
dim_driver.vehicle_production_year,
dim_driver.license_plate,
ride_staging.created_at

FROM ride_staging

LEFT JOIN dim_customer
on ride_staging.cust_id = dim_customer.cust_id

LEFT JOIN dim_driver
on ride_staging.driver_id = dim_driver.driver_id


    WHERE ride_staging.created_at > (
        SELECT MAX(ride_staging.created_at)
        FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`ride_start_time` = DBT_INTERNAL_SOURCE.`ride_start_time`,`ride_end_time` = DBT_INTERNAL_SOURCE.`ride_end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`cust_name` = DBT_INTERNAL_SOURCE.`cust_name`,`cust_phone_number` = DBT_INTERNAL_SOURCE.`cust_phone_number`,`cust_email` = DBT_INTERNAL_SOURCE.`cust_email`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`driver_name` = DBT_INTERNAL_SOURCE.`driver_name`,`driver_phone_number` = DBT_INTERNAL_SOURCE.`driver_phone_number`,`driver_email` = DBT_INTERNAL_SOURCE.`driver_email`,`vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`vehicle_brand` = DBT_INTERNAL_SOURCE.`vehicle_brand`,`vehicle_production_year` = DBT_INTERNAL_SOURCE.`vehicle_production_year`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `ride_start_time`, `ride_end_time`, `distance_km`, `fare`, `ride_status`, `cust_id`, `cust_name`, `cust_phone_number`, `cust_email`, `driver_id`, `driver_name`, `driver_phone_number`, `driver_email`, `vehicle_id`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)
    values
        (`ride_id`, `ride_start_time`, `ride_end_time`, `distance_km`, `fare`, `ride_status`, `cust_id`, `cust_name`, `cust_phone_number`, `cust_email`, `driver_id`, `driver_name`, `driver_phone_number`, `driver_email`, `vehicle_id`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)


    
[0m13:01:37.483048 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:5766284e-67c5-41fd-9be6-8736bb8e5d77&page=queryresults
[0m13:01:39.573719 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f7272399-cf3b-47a9-b880-fd9e69e15c89', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7cfb4ca890>]}
[0m13:01:39.574772 [info ] [Thread-4 (]: 7 of 9 OK created sql incremental model rizky_dwh_hailing_facts.fact_hailing_rides  [[32mMERGE (0.0 rows, 45.2 KiB processed)[0m in 2.58s]
[0m13:01:39.575992 [debug] [Thread-4 (]: Finished running node model.hailing_project.fact_hailing_rides
[0m13:01:39.577421 [debug] [Thread-1 (]: Began running node model.hailing_project.mart_cust_rides_daily
[0m13:01:39.578085 [debug] [Thread-2 (]: Began running node model.hailing_project.mart_driver_loyalty_mgmt
[0m13:01:39.579674 [info ] [Thread-1 (]: 8 of 9 START sql incremental model rizky_dwh_hailing_marts.mart_cust_rides_daily  [RUN]
[0m13:01:39.582008 [info ] [Thread-2 (]: 9 of 9 START sql incremental model rizky_dwh_hailing_marts.mart_driver_loyalty_mgmt  [RUN]
[0m13:01:39.583547 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.hailing_project.dim_customer, now model.hailing_project.mart_cust_rides_daily)
[0m13:01:39.584959 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.hailing_project.dim_driver, now model.hailing_project.mart_driver_loyalty_mgmt)
[0m13:01:39.586192 [debug] [Thread-1 (]: Began compiling node model.hailing_project.mart_cust_rides_daily
[0m13:01:39.587587 [debug] [Thread-2 (]: Began compiling node model.hailing_project.mart_driver_loyalty_mgmt
[0m13:01:39.592854 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.mart_cust_rides_daily"
[0m13:01:39.598150 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.mart_driver_loyalty_mgmt"
[0m13:01:39.603442 [debug] [Thread-2 (]: Began executing node model.hailing_project.mart_driver_loyalty_mgmt
[0m13:01:39.607168 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m13:01:39.607606 [debug] [Thread-1 (]: Began executing node model.hailing_project.mart_cust_rides_daily
[0m13:01:39.611761 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:01:39.859508 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.mart_cust_rides_daily"
[0m13:01:39.861836 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.mart_driver_loyalty_mgmt"
[0m13:01:39.865957 [debug] [Thread-1 (]: On model.hailing_project.mart_cust_rides_daily: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.mart_cust_rides_daily"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_marts`.`mart_cust_rides_daily` as DBT_INTERNAL_DEST
        using (


WITH fact_rides AS(

    SELECT * 
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
)

SELECT 

    fact_rides.cust_id,
    DATE(fact_rides.created_at) AS ride_date,
    fact_rides.cust_name,
    fact_rides.cust_email,
    fact_rides.cust_phone_number,
    COUNT(fact_rides.ride_id) AS no_of_rides,
    SUM(TIMESTAMP_DIFF(fact_rides.ride_end_time, fact_rides.ride_start_time, MINUTE)) AS total_ride_duration_min,
    SUM(fact_rides.fare) AS total_fare,
    SUM(fact_rides.distance_km) as total_distance_km,
    SUM(fact_rides.distance_km)-SUM(fact_rides.fare) AS rev_opportunity_loss,

FROM fact_rides
GROUP BY cust_name, cust_id, ride_date, cust_email, cust_phone_number
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`ride_date` = DBT_INTERNAL_SOURCE.`ride_date`,`cust_name` = DBT_INTERNAL_SOURCE.`cust_name`,`cust_email` = DBT_INTERNAL_SOURCE.`cust_email`,`cust_phone_number` = DBT_INTERNAL_SOURCE.`cust_phone_number`,`no_of_rides` = DBT_INTERNAL_SOURCE.`no_of_rides`,`total_ride_duration_min` = DBT_INTERNAL_SOURCE.`total_ride_duration_min`,`total_fare` = DBT_INTERNAL_SOURCE.`total_fare`,`total_distance_km` = DBT_INTERNAL_SOURCE.`total_distance_km`,`rev_opportunity_loss` = DBT_INTERNAL_SOURCE.`rev_opportunity_loss`
    

    when not matched then insert
        (`cust_id`, `ride_date`, `cust_name`, `cust_email`, `cust_phone_number`, `no_of_rides`, `total_ride_duration_min`, `total_fare`, `total_distance_km`, `rev_opportunity_loss`)
    values
        (`cust_id`, `ride_date`, `cust_name`, `cust_email`, `cust_phone_number`, `no_of_rides`, `total_ride_duration_min`, `total_fare`, `total_distance_km`, `rev_opportunity_loss`)


    
[0m13:01:39.868677 [debug] [Thread-2 (]: On model.hailing_project.mart_driver_loyalty_mgmt: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.mart_driver_loyalty_mgmt"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_marts`.`mart_driver_loyalty_mgmt` as DBT_INTERNAL_DEST
        using (

WITH dim_driver AS(
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
),

fact_rides AS(
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
)

SELECT 
dim_driver.driver_id,
dim_driver.driver_name,
dim_driver.phone_number,
dim_driver.email,
dim_driver.vehicle_type,
COUNT(fact_rides.ride_id) AS no_of_rides,
SUM(TIMESTAMP_DIFF(fact_rides.ride_end_time, fact_rides.ride_start_time, MINUTE)) AS total_ride_duration_min,
SUM(fact_rides.fare) AS total_fare,
SUM(fact_rides.distance_km) as total_distance_km,
SUM(fact_rides.distance_km)-SUM(fact_rides.fare) AS rev_opportunity_loss,
FROM dim_driver
LEFT JOIN fact_rides
ON dim_driver.driver_id = fact_rides.driver_id

GROUP BY driver_id,driver_name,phone_number,email,vehicle_type
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`driver_name` = DBT_INTERNAL_SOURCE.`driver_name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`no_of_rides` = DBT_INTERNAL_SOURCE.`no_of_rides`,`total_ride_duration_min` = DBT_INTERNAL_SOURCE.`total_ride_duration_min`,`total_fare` = DBT_INTERNAL_SOURCE.`total_fare`,`total_distance_km` = DBT_INTERNAL_SOURCE.`total_distance_km`,`rev_opportunity_loss` = DBT_INTERNAL_SOURCE.`rev_opportunity_loss`
    

    when not matched then insert
        (`driver_id`, `driver_name`, `phone_number`, `email`, `vehicle_type`, `no_of_rides`, `total_ride_duration_min`, `total_fare`, `total_distance_km`, `rev_opportunity_loss`)
    values
        (`driver_id`, `driver_name`, `phone_number`, `email`, `vehicle_type`, `no_of_rides`, `total_ride_duration_min`, `total_fare`, `total_distance_km`, `rev_opportunity_loss`)


    
[0m13:01:40.093628 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:9157a93f-54df-4d52-b988-b594d8e6a788&page=queryresults
[0m13:01:40.117126 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:a468a9b8-60c6-4a4c-9d87-74bd4c94b99c&page=queryresults
[0m13:01:40.490577 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:9157a93f-54df-4d52-b988-b594d8e6a788&page=queryresults
[0m13:01:40.500765 [debug] [Thread-1 (]: Database Error in model mart_cust_rides_daily (models/marts/mart_cust_rides_daily.sql)
  UPDATE/MERGE must match at most one source row for each target row
  compiled code at target/run/hailing_project/models/marts/mart_cust_rides_daily.sql
[0m13:01:40.502271 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f7272399-cf3b-47a9-b880-fd9e69e15c89', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7cfb4a8f90>]}
[0m13:01:40.503856 [error] [Thread-1 (]: 8 of 9 ERROR creating sql incremental model rizky_dwh_hailing_marts.mart_cust_rides_daily  [[31mERROR[0m in 0.92s]
[0m13:01:40.505124 [debug] [Thread-1 (]: Finished running node model.hailing_project.mart_cust_rides_daily
[0m13:01:40.506460 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.mart_cust_rides_daily' to be skipped because of status 'error'.  Reason: Database Error in model mart_cust_rides_daily (models/marts/mart_cust_rides_daily.sql)
  UPDATE/MERGE must match at most one source row for each target row
  compiled code at target/run/hailing_project/models/marts/mart_cust_rides_daily.sql.
[0m13:01:41.911341 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f7272399-cf3b-47a9-b880-fd9e69e15c89', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d132d8410>]}
[0m13:01:41.912951 [info ] [Thread-2 (]: 9 of 9 OK created sql incremental model rizky_dwh_hailing_marts.mart_driver_loyalty_mgmt  [[32mMERGE (95.0 rows, 22.1 KiB processed)[0m in 2.33s]
[0m13:01:41.914312 [debug] [Thread-2 (]: Finished running node model.hailing_project.mart_driver_loyalty_mgmt
[0m13:01:41.916503 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m13:01:41.919405 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:01:41.920249 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m13:01:41.921152 [debug] [MainThread]: Connection 'model.hailing_project.mart_cust_rides_daily' was properly closed.
[0m13:01:41.921958 [debug] [MainThread]: Connection 'model.hailing_project.mart_driver_loyalty_mgmt' was properly closed.
[0m13:01:41.922695 [debug] [MainThread]: Connection 'model.hailing_project.fact_hailing_rides' was properly closed.
[0m13:01:41.923507 [info ] [MainThread]: 
[0m13:01:41.924562 [info ] [MainThread]: Finished running 9 incremental models in 0 hours 0 minutes and 12.05 seconds (12.05s).
[0m13:01:41.927333 [debug] [MainThread]: Command end result
[0m13:01:41.970661 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m13:01:41.976022 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m13:01:41.984838 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m13:01:41.985865 [info ] [MainThread]: 
[0m13:01:41.987002 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m13:01:41.988268 [info ] [MainThread]: 
[0m13:01:41.989719 [error] [MainThread]:   Database Error in model mart_cust_rides_daily (models/marts/mart_cust_rides_daily.sql)
  UPDATE/MERGE must match at most one source row for each target row
  compiled code at target/run/hailing_project/models/marts/mart_cust_rides_daily.sql
[0m13:01:41.991465 [info ] [MainThread]: 
[0m13:01:41.992811 [info ] [MainThread]: Done. PASS=8 WARN=0 ERROR=1 SKIP=0 TOTAL=9
[0m13:01:41.994882 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 13.233021, "process_in_blocks": "0", "process_kernel_time": 0.259385, "process_mem_max_rss": "225904", "process_out_blocks": "0", "process_user_time": 3.761088}
[0m13:01:41.996395 [debug] [MainThread]: Command `dbt run` failed at 13:01:41.996189 after 13.23 seconds
[0m13:01:41.997621 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d414d1dd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d414d22d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d44dc5250>]}
[0m13:01:41.998951 [debug] [MainThread]: Flushing usage events
[0m13:01:43.285021 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:07:25.930258 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6bbcbe75d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6bbcbe6950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6bbcbe7610>]}


============================== 13:07:25.933485 | a7a5b536-9021-4ca3-91b3-231a0cfd1b8b ==============================
[0m13:07:25.933485 [info ] [MainThread]: Running with dbt=1.9.0
[0m13:07:25.934991 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt run --select mart_cust_rides_daily', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m13:07:26.564509 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a7a5b536-9021-4ca3-91b3-231a0cfd1b8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6b95812e10>]}
[0m13:07:26.609622 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a7a5b536-9021-4ca3-91b3-231a0cfd1b8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6b8eecef10>]}
[0m13:07:26.611263 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m13:07:26.677274 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m13:07:26.886999 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m13:07:26.888546 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/marts/mart_cust_rides_daily.sql
[0m13:07:27.183281 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a7a5b536-9021-4ca3-91b3-231a0cfd1b8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6b8ed714d0>]}
[0m13:07:27.252055 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m13:07:27.257332 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m13:07:27.273102 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a7a5b536-9021-4ca3-91b3-231a0cfd1b8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6b8d0f1b90>]}
[0m13:07:27.274360 [info ] [MainThread]: Found 9 models, 8 sources, 489 macros
[0m13:07:27.275560 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a7a5b536-9021-4ca3-91b3-231a0cfd1b8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6b8ea8c0d0>]}
[0m13:07:27.277642 [info ] [MainThread]: 
[0m13:07:27.278823 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m13:07:27.280028 [info ] [MainThread]: 
[0m13:07:27.281548 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m13:07:27.283543 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m13:07:27.284612 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:07:27.916998 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_staging)
[0m13:07:27.917542 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_facts'
[0m13:07:27.918204 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_marts'
[0m13:07:27.919044 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:07:27.919912 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:07:27.920684 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:07:28.238533 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a7a5b536-9021-4ca3-91b3-231a0cfd1b8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6b8ea36450>]}
[0m13:07:28.239433 [debug] [MainThread]: Opening a new connection, currently in state init
[0m13:07:28.243496 [debug] [Thread-1 (]: Began running node model.hailing_project.mart_cust_rides_daily
[0m13:07:28.244442 [info ] [Thread-1 (]: 1 of 1 START sql incremental model rizky_dwh_hailing_marts.mart_cust_rides_daily  [RUN]
[0m13:07:28.245510 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_staging, now model.hailing_project.mart_cust_rides_daily)
[0m13:07:28.246690 [debug] [Thread-1 (]: Began compiling node model.hailing_project.mart_cust_rides_daily
[0m13:07:28.254757 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.mart_cust_rides_daily"
[0m13:07:28.261387 [debug] [Thread-1 (]: Began executing node model.hailing_project.mart_cust_rides_daily
[0m13:07:28.301191 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:07:28.614187 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.mart_cust_rides_daily"
[0m13:07:28.624115 [debug] [Thread-1 (]: On model.hailing_project.mart_cust_rides_daily: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.mart_cust_rides_daily"} */
-- back compat for old kwarg name
  
  
        
            
                
                
            
                
                
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_marts`.`mart_cust_rides_daily` as DBT_INTERNAL_DEST
        using (


WITH fact_rides AS(

    SELECT * 
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
)

SELECT 

    fact_rides.cust_id,
    DATE(fact_rides.created_at) AS ride_date,
    fact_rides.cust_name,
    fact_rides.cust_email,
    fact_rides.cust_phone_number,
    COUNT(fact_rides.ride_id) AS no_of_rides,
    SUM(TIMESTAMP_DIFF(fact_rides.ride_end_time, fact_rides.ride_start_time, MINUTE)) AS total_ride_duration_min,
    SUM(fact_rides.fare) AS total_fare,
    SUM(fact_rides.distance_km) as total_distance_km,
    SUM(fact_rides.distance_km)-SUM(fact_rides.fare) AS rev_opportunity_loss,

FROM fact_rides
GROUP BY cust_name, cust_id, ride_date, cust_email, cust_phone_number
        ) as DBT_INTERNAL_SOURCE
        on (
                    DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
                ) and (
                    DBT_INTERNAL_SOURCE.ride_date = DBT_INTERNAL_DEST.ride_date
                )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`ride_date` = DBT_INTERNAL_SOURCE.`ride_date`,`cust_name` = DBT_INTERNAL_SOURCE.`cust_name`,`cust_email` = DBT_INTERNAL_SOURCE.`cust_email`,`cust_phone_number` = DBT_INTERNAL_SOURCE.`cust_phone_number`,`no_of_rides` = DBT_INTERNAL_SOURCE.`no_of_rides`,`total_ride_duration_min` = DBT_INTERNAL_SOURCE.`total_ride_duration_min`,`total_fare` = DBT_INTERNAL_SOURCE.`total_fare`,`total_distance_km` = DBT_INTERNAL_SOURCE.`total_distance_km`,`rev_opportunity_loss` = DBT_INTERNAL_SOURCE.`rev_opportunity_loss`
    

    when not matched then insert
        (`cust_id`, `ride_date`, `cust_name`, `cust_email`, `cust_phone_number`, `no_of_rides`, `total_ride_duration_min`, `total_fare`, `total_distance_km`, `rev_opportunity_loss`)
    values
        (`cust_id`, `ride_date`, `cust_name`, `cust_email`, `cust_phone_number`, `no_of_rides`, `total_ride_duration_min`, `total_fare`, `total_distance_km`, `rev_opportunity_loss`)


    
[0m13:07:29.004765 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:1cb60ac1-3291-47f1-94b9-4fe7f554797a&page=queryresults
[0m13:07:31.071526 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a7a5b536-9021-4ca3-91b3-231a0cfd1b8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6b8ebc8e10>]}
[0m13:07:31.072621 [info ] [Thread-1 (]: 1 of 1 OK created sql incremental model rizky_dwh_hailing_marts.mart_cust_rides_daily  [[32mMERGE (78.0 rows, 21.5 KiB processed)[0m in 2.82s]
[0m13:07:31.074070 [debug] [Thread-1 (]: Finished running node model.hailing_project.mart_cust_rides_daily
[0m13:07:31.076045 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m13:07:31.079570 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:07:31.080876 [debug] [MainThread]: Connection 'model.hailing_project.mart_cust_rides_daily' was properly closed.
[0m13:07:31.081948 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_facts' was properly closed.
[0m13:07:31.083198 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_marts' was properly closed.
[0m13:07:31.084201 [info ] [MainThread]: 
[0m13:07:31.085079 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 3.80 seconds (3.80s).
[0m13:07:31.086324 [debug] [MainThread]: Command end result
[0m13:07:31.119215 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m13:07:31.123157 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m13:07:31.131169 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m13:07:31.131884 [info ] [MainThread]: 
[0m13:07:31.132999 [info ] [MainThread]: [32mCompleted successfully[0m
[0m13:07:31.134056 [info ] [MainThread]: 
[0m13:07:31.135066 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m13:07:31.136485 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 5.262494, "process_in_blocks": "0", "process_kernel_time": 0.189906, "process_mem_max_rss": "221652", "process_out_blocks": "0", "process_user_time": 3.398325}
[0m13:07:31.137457 [debug] [MainThread]: Command `dbt run` succeeded at 13:07:31.137331 after 5.26 seconds
[0m13:07:31.138166 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6bbcc5f910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6bbcfde250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6bc043cc10>]}
[0m13:07:31.138927 [debug] [MainThread]: Flushing usage events
[0m13:07:32.180194 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:11:27.507906 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9b30b4f450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9b30f46110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9b30b4f590>]}


============================== 13:11:27.510877 | 5b9a0c41-7534-45f8-b462-fa7a27d7ed48 ==============================
[0m13:11:27.510877 [info ] [MainThread]: Running with dbt=1.9.0
[0m13:11:27.513050 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'profiles_dir': '/usr/app/dbt_project', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m13:11:28.092428 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5b9a0c41-7534-45f8-b462-fa7a27d7ed48', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9b034abf90>]}
[0m13:11:28.141320 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '5b9a0c41-7534-45f8-b462-fa7a27d7ed48', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9b32da5910>]}
[0m13:11:28.142833 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m13:11:28.215363 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m13:11:28.409724 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m13:11:28.410638 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m13:11:28.439752 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5b9a0c41-7534-45f8-b462-fa7a27d7ed48', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9b02a1e350>]}
[0m13:11:28.566973 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m13:11:28.575196 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m13:11:28.594578 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5b9a0c41-7534-45f8-b462-fa7a27d7ed48', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9b02e10a90>]}
[0m13:11:28.595772 [info ] [MainThread]: Found 9 models, 8 sources, 489 macros
[0m13:11:28.597091 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5b9a0c41-7534-45f8-b462-fa7a27d7ed48', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9b02b92f90>]}
[0m13:11:28.600217 [info ] [MainThread]: 
[0m13:11:28.601321 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m13:11:28.602362 [info ] [MainThread]: 
[0m13:11:28.604016 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m13:11:28.610027 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m13:11:28.610642 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m13:11:28.611232 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m13:11:28.611740 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:11:28.612950 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:11:28.614080 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:11:29.797050 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_staging)
[0m13:11:29.797725 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_facts)
[0m13:11:29.798418 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_marts)
[0m13:11:29.799015 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:11:29.800216 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:11:29.801259 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:11:30.123598 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5b9a0c41-7534-45f8-b462-fa7a27d7ed48', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9b02a51390>]}
[0m13:11:30.125104 [debug] [MainThread]: Opening a new connection, currently in state init
[0m13:11:30.130234 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m13:11:30.130597 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m13:11:30.131017 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m13:11:30.131344 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m13:11:30.131880 [info ] [Thread-1 (]: 1 of 9 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [RUN]
[0m13:11:30.132861 [info ] [Thread-2 (]: 2 of 9 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [RUN]
[0m13:11:30.133890 [info ] [Thread-3 (]: 3 of 9 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [RUN]
[0m13:11:30.135046 [info ] [Thread-4 (]: 4 of 9 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [RUN]
[0m13:11:30.136077 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_marts, now model.hailing_project.production_hailing_staging_customer)
[0m13:11:30.137147 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_facts, now model.hailing_project.production_hailing_staging_driver)
[0m13:11:30.137940 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_staging, now model.hailing_project.production_hailing_staging_ride)
[0m13:11:30.138838 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_vehicle'
[0m13:11:30.139762 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m13:11:30.140687 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m13:11:30.141553 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m13:11:30.142432 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m13:11:30.155297 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m13:11:30.159101 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m13:11:30.163107 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m13:11:30.167095 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m13:11:30.172266 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m13:11:30.173123 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m13:11:30.178927 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m13:11:30.184897 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m13:11:30.280106 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m13:11:30.280612 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m13:11:30.282532 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m13:11:30.285370 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m13:11:30.292858 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    );
  
[0m13:11:30.293424 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    );
  
[0m13:11:30.294511 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m13:11:30.295071 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    );
  
[0m13:11:30.297933 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m13:11:30.296342 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    );
  
[0m13:11:30.295874 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m13:11:30.299916 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:11:30.742743 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:f95752a5-73e0-4f10-af3d-9bf5587c3ea0&page=queryresults
[0m13:11:30.786019 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:76e1adae-9107-4d1a-baa1-39b96c857a30&page=queryresults
[0m13:11:30.799404 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:1559bbf6-3479-461e-92dc-000475c41576&page=queryresults
[0m13:11:30.840719 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:32ff86f6-e22a-4771-9d34-091477a0d5d7&page=queryresults
[0m13:11:32.432355 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5b9a0c41-7534-45f8-b462-fa7a27d7ed48', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9b31912210>]}
[0m13:11:32.432649 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5b9a0c41-7534-45f8-b462-fa7a27d7ed48', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9aeaf37bd0>]}
[0m13:11:32.433755 [info ] [Thread-4 (]: 4 of 9 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [[32mCREATE TABLE (95.0 rows, 5.2 KiB processed)[0m in 2.29s]
[0m13:11:32.435064 [info ] [Thread-3 (]: 3 of 9 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [[32mCREATE TABLE (95.0 rows, 8.4 KiB processed)[0m in 2.29s]
[0m13:11:32.436279 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m13:11:32.437264 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m13:11:32.457817 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5b9a0c41-7534-45f8-b462-fa7a27d7ed48', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9b0290aed0>]}
[0m13:11:32.459022 [info ] [Thread-2 (]: 2 of 9 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [[32mCREATE TABLE (95.0 rows, 6.5 KiB processed)[0m in 2.32s]
[0m13:11:32.460525 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m13:11:32.462768 [debug] [Thread-4 (]: Began running node model.hailing_project.dim_driver
[0m13:11:32.464289 [info ] [Thread-4 (]: 5 of 9 START sql incremental model rizky_dwh_hailing_facts.dim_driver .......... [RUN]
[0m13:11:32.465580 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_vehicle, now model.hailing_project.dim_driver)
[0m13:11:32.466815 [debug] [Thread-4 (]: Began compiling node model.hailing_project.dim_driver
[0m13:11:32.474358 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.dim_driver"
[0m13:11:32.478117 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5b9a0c41-7534-45f8-b462-fa7a27d7ed48', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9aeacf5190>]}
[0m13:11:32.479669 [info ] [Thread-1 (]: 1 of 9 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [[32mCREATE TABLE (95.0 rows, 6.5 KiB processed)[0m in 2.34s]
[0m13:11:32.481194 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m13:11:32.483069 [debug] [Thread-2 (]: Began running node model.hailing_project.dim_customer
[0m13:11:32.484646 [info ] [Thread-2 (]: 6 of 9 START sql incremental model rizky_dwh_hailing_facts.dim_customer ........ [RUN]
[0m13:11:32.486284 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_driver, now model.hailing_project.dim_customer)
[0m13:11:32.486765 [debug] [Thread-4 (]: Began executing node model.hailing_project.dim_driver
[0m13:11:32.487485 [debug] [Thread-2 (]: Began compiling node model.hailing_project.dim_customer
[0m13:11:32.492691 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.dim_driver"
[0m13:11:32.497335 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m13:11:32.505766 [debug] [Thread-4 (]: On model.hailing_project.dim_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_driver"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      


WITH driver AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver` --pakai ref untuk buat dependency

),

vehicle AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle`
)

SELECT
    driver.driver_id,
    vehicle.vehicle_id,
    driver.name as driver_name,
    driver.phone_number as phone_number,
    driver.email as email,
    vehicle.vehicle_type,
    vehicle.brand as vehicle_brand,
    vehicle.year as vehicle_production_year,
    vehicle.license_plate,
    driver.created_at
FROM driver
LEFT JOIN vehicle
on driver.driver_id = vehicle.vehicle_id


    );
  
[0m13:11:32.506308 [debug] [Thread-2 (]: Began executing node model.hailing_project.dim_customer
[0m13:11:32.507056 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m13:11:32.511660 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m13:11:32.539512 [debug] [Thread-2 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
)

SELECT * FROM source

    );
  
[0m13:11:32.541077 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m13:11:32.935485 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:11bfacb2-2ae3-4833-96ea-2322e8e7d6e2&page=queryresults
[0m13:11:32.983829 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:9dda2904-8db4-47c5-bdd2-8c4f5502e961&page=queryresults
[0m13:11:34.534304 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5b9a0c41-7534-45f8-b462-fa7a27d7ed48', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9aeacf3fd0>]}
[0m13:11:34.536229 [info ] [Thread-4 (]: 5 of 9 OK created sql incremental model rizky_dwh_hailing_facts.dim_driver ..... [[32mCREATE TABLE (95.0 rows, 10.1 KiB processed)[0m in 2.07s]
[0m13:11:34.539843 [debug] [Thread-4 (]: Finished running node model.hailing_project.dim_driver
[0m13:11:34.627386 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5b9a0c41-7534-45f8-b462-fa7a27d7ed48', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9b02d6ac10>]}
[0m13:11:34.628673 [info ] [Thread-2 (]: 6 of 9 OK created sql incremental model rizky_dwh_hailing_facts.dim_customer ... [[32mCREATE TABLE (95.0 rows, 6.3 KiB processed)[0m in 2.14s]
[0m13:11:34.629938 [debug] [Thread-2 (]: Finished running node model.hailing_project.dim_customer
[0m13:11:34.631536 [debug] [Thread-1 (]: Began running node model.hailing_project.fact_hailing_rides
[0m13:11:34.632679 [info ] [Thread-1 (]: 7 of 9 START sql incremental model rizky_dwh_hailing_facts.fact_hailing_rides .. [RUN]
[0m13:11:34.634047 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_customer, now model.hailing_project.fact_hailing_rides)
[0m13:11:34.635211 [debug] [Thread-1 (]: Began compiling node model.hailing_project.fact_hailing_rides
[0m13:11:34.640868 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.fact_hailing_rides"
[0m13:11:34.649191 [debug] [Thread-1 (]: Began executing node model.hailing_project.fact_hailing_rides
[0m13:11:34.653887 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.fact_hailing_rides"
[0m13:11:34.661006 [debug] [Thread-1 (]: On model.hailing_project.fact_hailing_rides: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.fact_hailing_rides"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH dim_driver AS (

    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
),

dim_customer AS (

    SELECT * 
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer`
),

ride_staging AS (

    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride`
)

SELECT
ride_staging.ride_id,
ride_staging.start_time AS ride_start_time,
ride_staging.end_time AS ride_end_time,
ride_staging.distance_km,
ride_staging.fare,
ride_staging.ride_status,
dim_customer.cust_id,
dim_customer.name AS cust_name,
dim_customer.phone_number AS cust_phone_number,
dim_customer.email AS cust_email,
dim_driver.driver_id,
dim_driver.driver_name,
dim_driver.phone_number AS driver_phone_number,
dim_driver.email AS driver_email,
dim_driver.vehicle_id,
dim_driver.vehicle_type,
dim_driver.vehicle_brand,
dim_driver.vehicle_production_year,
dim_driver.license_plate,
ride_staging.created_at

FROM ride_staging

LEFT JOIN dim_customer
on ride_staging.cust_id = dim_customer.cust_id

LEFT JOIN dim_driver
on ride_staging.driver_id = dim_driver.driver_id


    );
  
[0m13:11:34.662360 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:11:35.129423 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:e5a8d4c1-7c37-4081-9388-08eb80094fc6&page=queryresults
[0m13:11:36.786369 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5b9a0c41-7534-45f8-b462-fa7a27d7ed48', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9aeab62b10>]}
[0m13:11:36.787681 [info ] [Thread-1 (]: 7 of 9 OK created sql incremental model rizky_dwh_hailing_facts.fact_hailing_rides  [[32mCREATE TABLE (95.0 rows, 23.4 KiB processed)[0m in 2.15s]
[0m13:11:36.789055 [debug] [Thread-1 (]: Finished running node model.hailing_project.fact_hailing_rides
[0m13:11:36.790761 [debug] [Thread-4 (]: Began running node model.hailing_project.mart_cust_rides_daily
[0m13:11:36.791149 [debug] [Thread-2 (]: Began running node model.hailing_project.mart_driver_loyalty_mgmt
[0m13:11:36.791884 [info ] [Thread-4 (]: 8 of 9 START sql incremental model rizky_dwh_hailing_marts.mart_cust_rides_daily  [RUN]
[0m13:11:36.793002 [info ] [Thread-2 (]: 9 of 9 START sql incremental model rizky_dwh_hailing_marts.mart_driver_loyalty_mgmt  [RUN]
[0m13:11:36.794107 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.hailing_project.dim_driver, now model.hailing_project.mart_cust_rides_daily)
[0m13:11:36.795403 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.hailing_project.dim_customer, now model.hailing_project.mart_driver_loyalty_mgmt)
[0m13:11:36.796665 [debug] [Thread-4 (]: Began compiling node model.hailing_project.mart_cust_rides_daily
[0m13:11:36.797849 [debug] [Thread-2 (]: Began compiling node model.hailing_project.mart_driver_loyalty_mgmt
[0m13:11:36.802359 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.mart_cust_rides_daily"
[0m13:11:36.806238 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.mart_driver_loyalty_mgmt"
[0m13:11:36.811308 [debug] [Thread-4 (]: Began executing node model.hailing_project.mart_cust_rides_daily
[0m13:11:36.812028 [debug] [Thread-2 (]: Began executing node model.hailing_project.mart_driver_loyalty_mgmt
[0m13:11:36.816956 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.mart_cust_rides_daily"
[0m13:11:36.820401 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.mart_driver_loyalty_mgmt"
[0m13:11:36.826389 [debug] [Thread-4 (]: On model.hailing_project.mart_cust_rides_daily: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.mart_cust_rides_daily"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_marts`.`mart_cust_rides_daily`
      
    partition by ride_date
    

    OPTIONS()
    as (
      


WITH fact_rides AS(

    SELECT * 
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
)

SELECT 

    fact_rides.cust_id,
    DATE(fact_rides.created_at) AS ride_date,
    fact_rides.cust_name,
    fact_rides.cust_email,
    fact_rides.cust_phone_number,
    COUNT(fact_rides.ride_id) AS no_of_rides,
    SUM(TIMESTAMP_DIFF(fact_rides.ride_end_time, fact_rides.ride_start_time, MINUTE)) AS total_ride_duration_min,
    SUM(fact_rides.fare) AS total_fare,
    SUM(fact_rides.distance_km) as total_distance_km,
    SUM(fact_rides.distance_km)-SUM(fact_rides.fare) AS rev_opportunity_loss,

FROM fact_rides
GROUP BY cust_name, cust_id, ride_date, cust_email, cust_phone_number
    );
  
[0m13:11:36.827613 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m13:11:36.828140 [debug] [Thread-2 (]: On model.hailing_project.mart_driver_loyalty_mgmt: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.mart_driver_loyalty_mgmt"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_marts`.`mart_driver_loyalty_mgmt`
      
    
    

    OPTIONS()
    as (
      

WITH dim_driver AS(
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
),

fact_rides AS(
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
)

SELECT 
dim_driver.driver_id,
dim_driver.driver_name,
dim_driver.phone_number,
dim_driver.email,
dim_driver.vehicle_type,
COUNT(fact_rides.ride_id) AS no_of_rides,
SUM(TIMESTAMP_DIFF(fact_rides.ride_end_time, fact_rides.ride_start_time, MINUTE)) AS total_ride_duration_min,
SUM(fact_rides.fare) AS total_fare,
SUM(fact_rides.distance_km) as total_distance_km,
SUM(fact_rides.distance_km)-SUM(fact_rides.fare) AS rev_opportunity_loss,
FROM dim_driver
LEFT JOIN fact_rides
ON dim_driver.driver_id = fact_rides.driver_id

GROUP BY driver_id,driver_name,phone_number,email,vehicle_type
    );
  
[0m13:11:36.830054 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m13:11:37.305650 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:46c4fb22-71fa-40f0-8480-373687139372&page=queryresults
[0m13:11:37.333947 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:e7910cd6-af15-43df-bb8e-61c73c83fd32&page=queryresults
[0m13:11:38.696104 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5b9a0c41-7534-45f8-b462-fa7a27d7ed48', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9b02a51390>]}
[0m13:11:38.697652 [info ] [Thread-2 (]: 9 of 9 OK created sql incremental model rizky_dwh_hailing_marts.mart_driver_loyalty_mgmt  [[32mCREATE TABLE (95.0 rows, 12.3 KiB processed)[0m in 1.90s]
[0m13:11:38.699199 [debug] [Thread-2 (]: Finished running node model.hailing_project.mart_driver_loyalty_mgmt
[0m13:11:38.905191 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5b9a0c41-7534-45f8-b462-fa7a27d7ed48', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9aeab932d0>]}
[0m13:11:38.906436 [info ] [Thread-4 (]: 8 of 9 OK created sql incremental model rizky_dwh_hailing_marts.mart_cust_rides_daily  [[32mCREATE TABLE (78.0 rows, 11.5 KiB processed)[0m in 2.11s]
[0m13:11:38.908354 [debug] [Thread-4 (]: Finished running node model.hailing_project.mart_cust_rides_daily
[0m13:11:38.911489 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m13:11:38.914310 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:11:38.915162 [debug] [MainThread]: Connection 'model.hailing_project.mart_driver_loyalty_mgmt' was properly closed.
[0m13:11:38.915950 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m13:11:38.916642 [debug] [MainThread]: Connection 'model.hailing_project.fact_hailing_rides' was properly closed.
[0m13:11:38.917219 [debug] [MainThread]: Connection 'model.hailing_project.mart_cust_rides_daily' was properly closed.
[0m13:11:38.917905 [info ] [MainThread]: 
[0m13:11:38.918859 [info ] [MainThread]: Finished running 9 incremental models in 0 hours 0 minutes and 10.31 seconds (10.31s).
[0m13:11:38.921647 [debug] [MainThread]: Command end result
[0m13:11:38.959729 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m13:11:38.964027 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m13:11:38.972716 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m13:11:38.973544 [info ] [MainThread]: 
[0m13:11:38.974840 [info ] [MainThread]: [32mCompleted successfully[0m
[0m13:11:38.975974 [info ] [MainThread]: 
[0m13:11:38.977199 [info ] [MainThread]: Done. PASS=9 WARN=0 ERROR=0 SKIP=0 TOTAL=9
[0m13:11:38.978908 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 11.518645, "process_in_blocks": "0", "process_kernel_time": 0.165722, "process_mem_max_rss": "222848", "process_out_blocks": "0", "process_user_time": 3.792112}
[0m13:11:38.980260 [debug] [MainThread]: Command `dbt run` succeeded at 13:11:38.980074 after 11.52 seconds
[0m13:11:38.981317 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9b30ba9910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9b34611850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9b34318c10>]}
[0m13:11:38.982334 [debug] [MainThread]: Flushing usage events
[0m13:11:40.520848 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:11:45.437453 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4a2ceeb9d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4a2cf43a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4a2d3cf7d0>]}


============================== 13:11:45.440598 | fc867aaa-b7ef-4d03-a6ae-c777cc50c3c7 ==============================
[0m13:11:45.440598 [info ] [MainThread]: Running with dbt=1.9.0
[0m13:11:45.442097 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m13:11:46.028265 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'fc867aaa-b7ef-4d03-a6ae-c777cc50c3c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f49ff0bf9d0>]}
[0m13:11:46.077310 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'fc867aaa-b7ef-4d03-a6ae-c777cc50c3c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4a2f164a50>]}
[0m13:11:46.078669 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m13:11:46.149308 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m13:11:46.351726 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m13:11:46.352746 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m13:11:46.380971 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'fc867aaa-b7ef-4d03-a6ae-c777cc50c3c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f49ff1521d0>]}
[0m13:11:46.509589 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m13:11:46.514628 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m13:11:46.532412 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'fc867aaa-b7ef-4d03-a6ae-c777cc50c3c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4a2f1624d0>]}
[0m13:11:46.533451 [info ] [MainThread]: Found 9 models, 8 sources, 489 macros
[0m13:11:46.534644 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'fc867aaa-b7ef-4d03-a6ae-c777cc50c3c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f49fef07e10>]}
[0m13:11:46.537725 [info ] [MainThread]: 
[0m13:11:46.538879 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m13:11:46.539874 [info ] [MainThread]: 
[0m13:11:46.541284 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m13:11:46.547162 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m13:11:46.547955 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m13:11:46.548805 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m13:11:46.549339 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:11:46.550348 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:11:46.551111 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:11:47.520556 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_facts)
[0m13:11:47.521130 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_marts)
[0m13:11:47.521710 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_staging)
[0m13:11:47.522254 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:11:47.523345 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:11:47.524921 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:11:47.825513 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'fc867aaa-b7ef-4d03-a6ae-c777cc50c3c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f49ff0f15d0>]}
[0m13:11:47.826809 [debug] [MainThread]: Opening a new connection, currently in state init
[0m13:11:47.832294 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m13:11:47.832667 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m13:11:47.833028 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m13:11:47.833369 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m13:11:47.833907 [info ] [Thread-1 (]: 1 of 9 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [RUN]
[0m13:11:47.835415 [info ] [Thread-2 (]: 2 of 9 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [RUN]
[0m13:11:47.837278 [info ] [Thread-3 (]: 3 of 9 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [RUN]
[0m13:11:47.838440 [info ] [Thread-4 (]: 4 of 9 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [RUN]
[0m13:11:47.839869 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_staging, now model.hailing_project.production_hailing_staging_customer)
[0m13:11:47.841232 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_marts, now model.hailing_project.production_hailing_staging_driver)
[0m13:11:47.842402 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_facts, now model.hailing_project.production_hailing_staging_ride)
[0m13:11:47.843708 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_vehicle'
[0m13:11:47.844591 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m13:11:47.845605 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m13:11:47.846545 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m13:11:47.847423 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m13:11:47.861862 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m13:11:47.865817 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m13:11:47.869943 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m13:11:47.874813 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m13:11:47.882093 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m13:11:47.883289 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m13:11:47.883686 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m13:11:47.889579 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m13:11:47.927254 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:11:47.929897 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m13:11:47.932792 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m13:11:47.935915 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m13:11:48.247485 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m13:11:48.248953 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m13:11:48.251539 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m13:11:48.255973 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m13:11:48.256740 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m13:11:48.258988 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m13:11:48.260851 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m13:11:48.269939 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m13:11:48.507048 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:c7242015-25ff-42c1-9b19-9e023862ce20&page=queryresults
[0m13:11:48.534492 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:b1460513-1c65-40a7-82cf-a02327937b5d&page=queryresults
[0m13:11:48.545026 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:23fb485b-03fa-424b-a2b1-49f1bee1aa4d&page=queryresults
[0m13:11:48.564751 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:a23abf45-95ba-4f2b-8fea-bbc12ae4d302&page=queryresults
[0m13:11:50.395314 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fc867aaa-b7ef-4d03-a6ae-c777cc50c3c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4a2cf00910>]}
[0m13:11:50.397195 [info ] [Thread-4 (]: 4 of 9 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 10.4 KiB processed)[0m in 2.55s]
[0m13:11:50.398575 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m13:11:50.925699 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fc867aaa-b7ef-4d03-a6ae-c777cc50c3c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f49fef1b910>]}
[0m13:11:50.926847 [info ] [Thread-1 (]: 1 of 9 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 12.9 KiB processed)[0m in 3.09s]
[0m13:11:50.928276 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m13:11:50.930176 [debug] [Thread-4 (]: Began running node model.hailing_project.dim_customer
[0m13:11:50.931488 [info ] [Thread-4 (]: 5 of 9 START sql incremental model rizky_dwh_hailing_facts.dim_customer ........ [RUN]
[0m13:11:50.933010 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_vehicle, now model.hailing_project.dim_customer)
[0m13:11:50.934664 [debug] [Thread-4 (]: Began compiling node model.hailing_project.dim_customer
[0m13:11:50.940458 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m13:11:50.949364 [debug] [Thread-4 (]: Began executing node model.hailing_project.dim_customer
[0m13:11:50.955072 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m13:11:51.064991 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fc867aaa-b7ef-4d03-a6ae-c777cc50c3c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f49fee91990>]}
[0m13:11:51.066570 [info ] [Thread-3 (]: 3 of 9 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 16.9 KiB processed)[0m in 3.22s]
[0m13:11:51.068524 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m13:11:51.073427 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fc867aaa-b7ef-4d03-a6ae-c777cc50c3c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f49ff09ec90>]}
[0m13:11:51.074842 [info ] [Thread-2 (]: 2 of 9 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 12.8 KiB processed)[0m in 3.23s]
[0m13:11:51.076139 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m13:11:51.077831 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_driver
[0m13:11:51.079005 [info ] [Thread-1 (]: 6 of 9 START sql incremental model rizky_dwh_hailing_facts.dim_driver .......... [RUN]
[0m13:11:51.080413 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_customer, now model.hailing_project.dim_driver)
[0m13:11:51.081904 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_driver
[0m13:11:51.086800 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_driver"
[0m13:11:51.094311 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_driver
[0m13:11:51.098099 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:11:51.254546 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m13:11:51.262726 [debug] [Thread-4 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
)

SELECT * FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m13:11:51.353248 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_driver"
[0m13:11:51.358556 [debug] [Thread-1 (]: On model.hailing_project.dim_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver` as DBT_INTERNAL_DEST
        using (


WITH driver AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver` --pakai ref untuk buat dependency

),

vehicle AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle`
)

SELECT
    driver.driver_id,
    vehicle.vehicle_id,
    driver.name as driver_name,
    driver.phone_number as phone_number,
    driver.email as email,
    vehicle.vehicle_type,
    vehicle.brand as vehicle_brand,
    vehicle.year as vehicle_production_year,
    vehicle.license_plate,
    driver.created_at
FROM driver
LEFT JOIN vehicle
on driver.driver_id = vehicle.vehicle_id


    WHERE driver.created_at > (
        SELECT MAX(driver.created_at)
        FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_name` = DBT_INTERNAL_SOURCE.`driver_name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`vehicle_brand` = DBT_INTERNAL_SOURCE.`vehicle_brand`,`vehicle_production_year` = DBT_INTERNAL_SOURCE.`vehicle_production_year`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `vehicle_id`, `driver_name`, `phone_number`, `email`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)
    values
        (`driver_id`, `vehicle_id`, `driver_name`, `phone_number`, `email`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)


    
[0m13:11:51.524098 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:90166112-3c60-440d-a8fe-955d5e8dc673&page=queryresults
[0m13:11:51.610085 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:8257ddc6-86f7-40a8-a275-76075dbc61f3&page=queryresults
[0m13:11:54.211632 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fc867aaa-b7ef-4d03-a6ae-c777cc50c3c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f49fc0ec410>]}
[0m13:11:54.212661 [info ] [Thread-4 (]: 5 of 9 OK created sql incremental model rizky_dwh_hailing_facts.dim_customer ... [[32mMERGE (0.0 rows, 12.7 KiB processed)[0m in 3.28s]
[0m13:11:54.214208 [debug] [Thread-4 (]: Finished running node model.hailing_project.dim_customer
[0m13:11:54.419736 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fc867aaa-b7ef-4d03-a6ae-c777cc50c3c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f49fc046490>]}
[0m13:11:54.421939 [info ] [Thread-1 (]: 6 of 9 OK created sql incremental model rizky_dwh_hailing_facts.dim_driver ..... [[32mMERGE (0.0 rows, 20.2 KiB processed)[0m in 3.34s]
[0m13:11:54.423991 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_driver
[0m13:11:54.426423 [debug] [Thread-2 (]: Began running node model.hailing_project.fact_hailing_rides
[0m13:11:54.428204 [info ] [Thread-2 (]: 7 of 9 START sql incremental model rizky_dwh_hailing_facts.fact_hailing_rides .. [RUN]
[0m13:11:54.429558 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_driver, now model.hailing_project.fact_hailing_rides)
[0m13:11:54.430925 [debug] [Thread-2 (]: Began compiling node model.hailing_project.fact_hailing_rides
[0m13:11:54.438690 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.fact_hailing_rides"
[0m13:11:54.448095 [debug] [Thread-2 (]: Began executing node model.hailing_project.fact_hailing_rides
[0m13:11:54.452235 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m13:11:54.701531 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.fact_hailing_rides"
[0m13:11:54.707783 [debug] [Thread-2 (]: On model.hailing_project.fact_hailing_rides: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.fact_hailing_rides"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides` as DBT_INTERNAL_DEST
        using (

WITH dim_driver AS (

    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
),

dim_customer AS (

    SELECT * 
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer`
),

ride_staging AS (

    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride`
)

SELECT
ride_staging.ride_id,
ride_staging.start_time AS ride_start_time,
ride_staging.end_time AS ride_end_time,
ride_staging.distance_km,
ride_staging.fare,
ride_staging.ride_status,
dim_customer.cust_id,
dim_customer.name AS cust_name,
dim_customer.phone_number AS cust_phone_number,
dim_customer.email AS cust_email,
dim_driver.driver_id,
dim_driver.driver_name,
dim_driver.phone_number AS driver_phone_number,
dim_driver.email AS driver_email,
dim_driver.vehicle_id,
dim_driver.vehicle_type,
dim_driver.vehicle_brand,
dim_driver.vehicle_production_year,
dim_driver.license_plate,
ride_staging.created_at

FROM ride_staging

LEFT JOIN dim_customer
on ride_staging.cust_id = dim_customer.cust_id

LEFT JOIN dim_driver
on ride_staging.driver_id = dim_driver.driver_id


    WHERE ride_staging.created_at > (
        SELECT MAX(ride_staging.created_at)
        FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`ride_start_time` = DBT_INTERNAL_SOURCE.`ride_start_time`,`ride_end_time` = DBT_INTERNAL_SOURCE.`ride_end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`cust_name` = DBT_INTERNAL_SOURCE.`cust_name`,`cust_phone_number` = DBT_INTERNAL_SOURCE.`cust_phone_number`,`cust_email` = DBT_INTERNAL_SOURCE.`cust_email`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`driver_name` = DBT_INTERNAL_SOURCE.`driver_name`,`driver_phone_number` = DBT_INTERNAL_SOURCE.`driver_phone_number`,`driver_email` = DBT_INTERNAL_SOURCE.`driver_email`,`vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`vehicle_brand` = DBT_INTERNAL_SOURCE.`vehicle_brand`,`vehicle_production_year` = DBT_INTERNAL_SOURCE.`vehicle_production_year`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `ride_start_time`, `ride_end_time`, `distance_km`, `fare`, `ride_status`, `cust_id`, `cust_name`, `cust_phone_number`, `cust_email`, `driver_id`, `driver_name`, `driver_phone_number`, `driver_email`, `vehicle_id`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)
    values
        (`ride_id`, `ride_start_time`, `ride_end_time`, `distance_km`, `fare`, `ride_status`, `cust_id`, `cust_name`, `cust_phone_number`, `cust_email`, `driver_id`, `driver_name`, `driver_phone_number`, `driver_email`, `vehicle_id`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)


    
[0m13:11:54.956852 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:7f636fff-a5f6-420d-be4f-dd27df878774&page=queryresults
[0m13:11:56.770394 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fc867aaa-b7ef-4d03-a6ae-c777cc50c3c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f49fc04a250>]}
[0m13:11:56.771754 [info ] [Thread-2 (]: 7 of 9 OK created sql incremental model rizky_dwh_hailing_facts.fact_hailing_rides  [[32mMERGE (0.0 rows, 45.2 KiB processed)[0m in 2.34s]
[0m13:11:56.773256 [debug] [Thread-2 (]: Finished running node model.hailing_project.fact_hailing_rides
[0m13:11:56.774916 [debug] [Thread-4 (]: Began running node model.hailing_project.mart_cust_rides_daily
[0m13:11:56.775287 [debug] [Thread-1 (]: Began running node model.hailing_project.mart_driver_loyalty_mgmt
[0m13:11:56.776302 [info ] [Thread-4 (]: 8 of 9 START sql incremental model rizky_dwh_hailing_marts.mart_cust_rides_daily  [RUN]
[0m13:11:56.777510 [info ] [Thread-1 (]: 9 of 9 START sql incremental model rizky_dwh_hailing_marts.mart_driver_loyalty_mgmt  [RUN]
[0m13:11:56.779049 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.hailing_project.dim_customer, now model.hailing_project.mart_cust_rides_daily)
[0m13:11:56.780599 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.hailing_project.dim_driver, now model.hailing_project.mart_driver_loyalty_mgmt)
[0m13:11:56.781723 [debug] [Thread-4 (]: Began compiling node model.hailing_project.mart_cust_rides_daily
[0m13:11:56.782941 [debug] [Thread-1 (]: Began compiling node model.hailing_project.mart_driver_loyalty_mgmt
[0m13:11:56.787442 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.mart_cust_rides_daily"
[0m13:11:56.792307 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.mart_driver_loyalty_mgmt"
[0m13:11:56.798744 [debug] [Thread-4 (]: Began executing node model.hailing_project.mart_cust_rides_daily
[0m13:11:56.799292 [debug] [Thread-1 (]: Began executing node model.hailing_project.mart_driver_loyalty_mgmt
[0m13:11:56.802442 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m13:11:56.807301 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:11:57.088133 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.mart_driver_loyalty_mgmt"
[0m13:11:57.092158 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.mart_cust_rides_daily"
[0m13:11:57.097586 [debug] [Thread-1 (]: On model.hailing_project.mart_driver_loyalty_mgmt: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.mart_driver_loyalty_mgmt"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_marts`.`mart_driver_loyalty_mgmt` as DBT_INTERNAL_DEST
        using (

WITH dim_driver AS(
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
),

fact_rides AS(
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
)

SELECT 
dim_driver.driver_id,
dim_driver.driver_name,
dim_driver.phone_number,
dim_driver.email,
dim_driver.vehicle_type,
COUNT(fact_rides.ride_id) AS no_of_rides,
SUM(TIMESTAMP_DIFF(fact_rides.ride_end_time, fact_rides.ride_start_time, MINUTE)) AS total_ride_duration_min,
SUM(fact_rides.fare) AS total_fare,
SUM(fact_rides.distance_km) as total_distance_km,
SUM(fact_rides.distance_km)-SUM(fact_rides.fare) AS rev_opportunity_loss,
FROM dim_driver
LEFT JOIN fact_rides
ON dim_driver.driver_id = fact_rides.driver_id

GROUP BY driver_id,driver_name,phone_number,email,vehicle_type
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`driver_name` = DBT_INTERNAL_SOURCE.`driver_name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`no_of_rides` = DBT_INTERNAL_SOURCE.`no_of_rides`,`total_ride_duration_min` = DBT_INTERNAL_SOURCE.`total_ride_duration_min`,`total_fare` = DBT_INTERNAL_SOURCE.`total_fare`,`total_distance_km` = DBT_INTERNAL_SOURCE.`total_distance_km`,`rev_opportunity_loss` = DBT_INTERNAL_SOURCE.`rev_opportunity_loss`
    

    when not matched then insert
        (`driver_id`, `driver_name`, `phone_number`, `email`, `vehicle_type`, `no_of_rides`, `total_ride_duration_min`, `total_fare`, `total_distance_km`, `rev_opportunity_loss`)
    values
        (`driver_id`, `driver_name`, `phone_number`, `email`, `vehicle_type`, `no_of_rides`, `total_ride_duration_min`, `total_fare`, `total_distance_km`, `rev_opportunity_loss`)


    
[0m13:11:57.100580 [debug] [Thread-4 (]: On model.hailing_project.mart_cust_rides_daily: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.mart_cust_rides_daily"} */
-- back compat for old kwarg name
  
  
        
            
                
                
            
                
                
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_marts`.`mart_cust_rides_daily` as DBT_INTERNAL_DEST
        using (


WITH fact_rides AS(

    SELECT * 
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
)

SELECT 

    fact_rides.cust_id,
    DATE(fact_rides.created_at) AS ride_date,
    fact_rides.cust_name,
    fact_rides.cust_email,
    fact_rides.cust_phone_number,
    COUNT(fact_rides.ride_id) AS no_of_rides,
    SUM(TIMESTAMP_DIFF(fact_rides.ride_end_time, fact_rides.ride_start_time, MINUTE)) AS total_ride_duration_min,
    SUM(fact_rides.fare) AS total_fare,
    SUM(fact_rides.distance_km) as total_distance_km,
    SUM(fact_rides.distance_km)-SUM(fact_rides.fare) AS rev_opportunity_loss,

FROM fact_rides
GROUP BY cust_name, cust_id, ride_date, cust_email, cust_phone_number
        ) as DBT_INTERNAL_SOURCE
        on (
                    DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
                ) and (
                    DBT_INTERNAL_SOURCE.ride_date = DBT_INTERNAL_DEST.ride_date
                )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`ride_date` = DBT_INTERNAL_SOURCE.`ride_date`,`cust_name` = DBT_INTERNAL_SOURCE.`cust_name`,`cust_email` = DBT_INTERNAL_SOURCE.`cust_email`,`cust_phone_number` = DBT_INTERNAL_SOURCE.`cust_phone_number`,`no_of_rides` = DBT_INTERNAL_SOURCE.`no_of_rides`,`total_ride_duration_min` = DBT_INTERNAL_SOURCE.`total_ride_duration_min`,`total_fare` = DBT_INTERNAL_SOURCE.`total_fare`,`total_distance_km` = DBT_INTERNAL_SOURCE.`total_distance_km`,`rev_opportunity_loss` = DBT_INTERNAL_SOURCE.`rev_opportunity_loss`
    

    when not matched then insert
        (`cust_id`, `ride_date`, `cust_name`, `cust_email`, `cust_phone_number`, `no_of_rides`, `total_ride_duration_min`, `total_fare`, `total_distance_km`, `rev_opportunity_loss`)
    values
        (`cust_id`, `ride_date`, `cust_name`, `cust_email`, `cust_phone_number`, `no_of_rides`, `total_ride_duration_min`, `total_fare`, `total_distance_km`, `rev_opportunity_loss`)


    
[0m13:11:57.357486 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:79d661e1-bf2e-42c5-a8b8-33dfe1d989fa&page=queryresults
[0m13:11:57.367258 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:9dcee840-bb49-46e4-b6dc-c337a46d2f5e&page=queryresults
[0m13:11:59.162225 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fc867aaa-b7ef-4d03-a6ae-c777cc50c3c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f49e6f7a790>]}
[0m13:11:59.163374 [info ] [Thread-4 (]: 8 of 9 OK created sql incremental model rizky_dwh_hailing_marts.mart_cust_rides_daily  [[32mMERGE (78.0 rows, 21.5 KiB processed)[0m in 2.38s]
[0m13:11:59.164608 [debug] [Thread-4 (]: Finished running node model.hailing_project.mart_cust_rides_daily
[0m13:11:59.922162 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fc867aaa-b7ef-4d03-a6ae-c777cc50c3c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f49fef27010>]}
[0m13:11:59.923228 [info ] [Thread-1 (]: 9 of 9 OK created sql incremental model rizky_dwh_hailing_marts.mart_driver_loyalty_mgmt  [[32mMERGE (95.0 rows, 22.1 KiB processed)[0m in 3.14s]
[0m13:11:59.924633 [debug] [Thread-1 (]: Finished running node model.hailing_project.mart_driver_loyalty_mgmt
[0m13:11:59.927766 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m13:11:59.930936 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:11:59.931884 [debug] [MainThread]: Connection 'model.hailing_project.mart_driver_loyalty_mgmt' was properly closed.
[0m13:11:59.933127 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m13:11:59.934130 [debug] [MainThread]: Connection 'model.hailing_project.fact_hailing_rides' was properly closed.
[0m13:11:59.935169 [debug] [MainThread]: Connection 'model.hailing_project.mart_cust_rides_daily' was properly closed.
[0m13:11:59.936240 [info ] [MainThread]: 
[0m13:11:59.937201 [info ] [MainThread]: Finished running 9 incremental models in 0 hours 0 minutes and 13.40 seconds (13.40s).
[0m13:11:59.939808 [debug] [MainThread]: Command end result
[0m13:11:59.981927 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m13:11:59.986947 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m13:11:59.999915 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m13:12:00.001142 [info ] [MainThread]: 
[0m13:12:00.002298 [info ] [MainThread]: [32mCompleted successfully[0m
[0m13:12:00.003568 [info ] [MainThread]: 
[0m13:12:00.005104 [info ] [MainThread]: Done. PASS=9 WARN=0 ERROR=0 SKIP=0 TOTAL=9
[0m13:12:00.008118 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 14.623011, "process_in_blocks": "0", "process_kernel_time": 0.258898, "process_mem_max_rss": "222832", "process_out_blocks": "0", "process_user_time": 3.793862}
[0m13:12:00.009797 [debug] [MainThread]: Command `dbt run` succeeded at 13:12:00.009513 after 14.62 seconds
[0m13:12:00.011220 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4a2cf44a10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4a2cf44690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4a30708b90>]}
[0m13:12:00.012304 [debug] [MainThread]: Flushing usage events
[0m13:12:01.301269 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m01:17:37.993299 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1961918a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f196196bad0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f196191ae90>]}


============================== 01:17:37.996465 | 4ce5a941-3984-4b24-ad5c-9fa9bf8f652d ==============================
[0m01:17:37.996465 [info ] [MainThread]: Running with dbt=1.9.0
[0m01:17:37.997714 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt debug', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m01:17:38.016107 [info ] [MainThread]: dbt version: 1.9.0
[0m01:17:38.017472 [info ] [MainThread]: python version: 3.11.2
[0m01:17:38.018798 [info ] [MainThread]: python path: /usr/local/bin/python
[0m01:17:38.020065 [info ] [MainThread]: os info: Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.31
[0m01:17:38.546411 [info ] [MainThread]: Using profiles dir at /usr/app/dbt_project
[0m01:17:38.547547 [info ] [MainThread]: Using profiles.yml file at /usr/app/dbt_project/profiles.yml
[0m01:17:38.548989 [info ] [MainThread]: Using dbt_project.yml file at /usr/app/dbt_project/dbt_project.yml
[0m01:17:38.550210 [info ] [MainThread]: adapter type: bigquery
[0m01:17:38.551429 [info ] [MainThread]: adapter version: 1.9.0
[0m01:17:38.633655 [info ] [MainThread]: Configuration:
[0m01:17:38.635178 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m01:17:38.636440 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m01:17:38.637607 [info ] [MainThread]: Required dependencies:
[0m01:17:38.638848 [debug] [MainThread]: Executing "git --help"
[0m01:17:38.653319 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m01:17:38.654320 [debug] [MainThread]: STDERR: "b''"
[0m01:17:38.655062 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m01:17:38.656092 [info ] [MainThread]: Connection:
[0m01:17:38.657564 [info ] [MainThread]:   method: service-account
[0m01:17:38.658657 [info ] [MainThread]:   database: purwadika
[0m01:17:38.659768 [info ] [MainThread]:   execution_project: purwadika
[0m01:17:38.660817 [info ] [MainThread]:   schema: rizky_dwh_hailing_source
[0m01:17:38.661936 [info ] [MainThread]:   location: None
[0m01:17:38.663459 [info ] [MainThread]:   priority: None
[0m01:17:38.664819 [info ] [MainThread]:   maximum_bytes_billed: None
[0m01:17:38.666263 [info ] [MainThread]:   impersonate_service_account: None
[0m01:17:38.667546 [info ] [MainThread]:   job_retry_deadline_seconds: None
[0m01:17:38.668545 [info ] [MainThread]:   job_retries: 1
[0m01:17:38.669724 [info ] [MainThread]:   job_creation_timeout_seconds: None
[0m01:17:38.670943 [info ] [MainThread]:   job_execution_timeout_seconds: None
[0m01:17:38.672181 [info ] [MainThread]:   timeout_seconds: None
[0m01:17:38.673136 [info ] [MainThread]:   client_id: None
[0m01:17:38.674367 [info ] [MainThread]:   token_uri: None
[0m01:17:38.675418 [info ] [MainThread]:   dataproc_region: None
[0m01:17:38.676464 [info ] [MainThread]:   dataproc_cluster_name: None
[0m01:17:38.677434 [info ] [MainThread]:   gcs_bucket: None
[0m01:17:38.678660 [info ] [MainThread]:   dataproc_batch: None
[0m01:17:38.680086 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m01:17:38.745338 [debug] [MainThread]: Acquiring new bigquery connection 'debug'
[0m01:17:38.746428 [debug] [MainThread]: On debug: select 1 as id
[0m01:17:38.747213 [debug] [MainThread]: Opening a new connection, currently in state init
[0m01:17:39.417877 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:8bc3636e-2062-48e7-816c-c3aca392c429&page=queryresults
[0m01:17:40.177995 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m01:17:40.179433 [info ] [MainThread]: [32mAll checks passed![0m
[0m01:17:40.181920 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": true, "command_wall_clock_time": 2.2582889, "process_in_blocks": "3888", "process_kernel_time": 0.231969, "process_mem_max_rss": "212504", "process_out_blocks": "0", "process_user_time": 2.692858}
[0m01:17:40.183428 [debug] [MainThread]: Command `dbt debug` succeeded at 01:17:40.182995 after 2.26 seconds
[0m01:17:40.184824 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m01:17:40.185851 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1961d1a310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1961d19cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1962603310>]}
[0m01:17:40.186985 [debug] [MainThread]: Flushing usage events
[0m01:17:41.447987 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m01:17:46.256554 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6ed7a7ab90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6ed7e76550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6ed7ad3610>]}


============================== 01:17:46.258950 | d6c9388d-6b72-44d3-a4d3-84385d253f5b ==============================
[0m01:17:46.258950 [info ] [MainThread]: Running with dbt=1.9.0
[0m01:17:46.260195 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'invocation_command': 'dbt run', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m01:17:46.854027 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd6c9388d-6b72-44d3-a4d3-84385d253f5b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6ea9c38650>]}
[0m01:17:46.899967 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd6c9388d-6b72-44d3-a4d3-84385d253f5b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6ea9eff490>]}
[0m01:17:46.901332 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m01:17:46.974790 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m01:17:47.300432 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m01:17:47.301224 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m01:17:47.328917 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd6c9388d-6b72-44d3-a4d3-84385d253f5b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6ed7fdee10>]}
[0m01:17:47.449317 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m01:17:47.455635 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m01:17:47.474277 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd6c9388d-6b72-44d3-a4d3-84385d253f5b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6ea9980d10>]}
[0m01:17:47.475262 [info ] [MainThread]: Found 9 models, 8 sources, 489 macros
[0m01:17:47.476438 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd6c9388d-6b72-44d3-a4d3-84385d253f5b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6eab7fc890>]}
[0m01:17:47.479337 [info ] [MainThread]: 
[0m01:17:47.480481 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m01:17:47.481537 [info ] [MainThread]: 
[0m01:17:47.483013 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m01:17:47.488048 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m01:17:47.488938 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m01:17:47.489771 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m01:17:47.490705 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:17:47.491713 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:17:47.492804 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:17:48.561094 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_facts)
[0m01:17:48.561687 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_staging)
[0m01:17:48.562307 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_marts)
[0m01:17:48.562852 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m01:17:48.563751 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m01:17:48.564646 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m01:17:48.917108 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd6c9388d-6b72-44d3-a4d3-84385d253f5b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6ea9956210>]}
[0m01:17:48.918103 [debug] [MainThread]: Opening a new connection, currently in state init
[0m01:17:48.923364 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m01:17:48.923835 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m01:17:48.924183 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m01:17:48.924563 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m01:17:48.925131 [info ] [Thread-1 (]: 1 of 9 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [RUN]
[0m01:17:48.926199 [info ] [Thread-2 (]: 2 of 9 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [RUN]
[0m01:17:48.927251 [info ] [Thread-3 (]: 3 of 9 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [RUN]
[0m01:17:48.928260 [info ] [Thread-4 (]: 4 of 9 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [RUN]
[0m01:17:48.929297 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_staging, now model.hailing_project.production_hailing_staging_customer)
[0m01:17:48.930228 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_marts, now model.hailing_project.production_hailing_staging_driver)
[0m01:17:48.931017 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_facts, now model.hailing_project.production_hailing_staging_ride)
[0m01:17:48.932206 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_vehicle'
[0m01:17:48.933234 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m01:17:48.934271 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m01:17:48.935208 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m01:17:48.936227 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m01:17:48.951268 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m01:17:48.954661 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m01:17:48.958812 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m01:17:48.962576 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m01:17:48.967122 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m01:17:48.978957 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m01:17:49.010057 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m01:17:49.010435 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m01:17:49.010778 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m01:17:49.013327 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m01:17:49.017497 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m01:17:49.021185 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m01:17:49.377362 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m01:17:49.377824 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m01:17:49.384543 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m01:17:49.387584 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m01:17:49.392566 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m01:17:49.400616 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m01:17:49.414355 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m01:17:49.420557 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m01:17:49.726816 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:37275c94-23b7-476d-809f-ce981178b5a8&page=queryresults
[0m01:17:49.734745 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:b9ffd9e0-bc3d-43d8-9d27-a81ffe460d26&page=queryresults
[0m01:17:50.003966 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:a7a7fc83-4e9b-4714-b60a-c446a79b6a8e&page=queryresults
[0m01:17:50.847467 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:46b47cf0-0143-4628-b6e1-fbf940cdb036&page=queryresults
[0m01:17:51.592304 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd6c9388d-6b72-44d3-a4d3-84385d253f5b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6ea9c84890>]}
[0m01:17:51.593794 [info ] [Thread-3 (]: 3 of 9 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [[32mMERGE (10.0 rows, 17.8 KiB processed)[0m in 2.66s]
[0m01:17:51.595466 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m01:17:51.666608 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd6c9388d-6b72-44d3-a4d3-84385d253f5b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6e99ee23d0>]}
[0m01:17:51.667820 [info ] [Thread-4 (]: 4 of 9 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [[32mMERGE (10.0 rows, 11.0 KiB processed)[0m in 2.73s]
[0m01:17:51.669327 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m01:17:52.672743 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd6c9388d-6b72-44d3-a4d3-84385d253f5b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6ea9c85790>]}
[0m01:17:52.674722 [info ] [Thread-1 (]: 1 of 9 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [[32mMERGE (10.0 rows, 13.5 KiB processed)[0m in 3.74s]
[0m01:17:52.676046 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m01:17:52.677507 [debug] [Thread-3 (]: Began running node model.hailing_project.dim_customer
[0m01:17:52.678521 [info ] [Thread-3 (]: 5 of 9 START sql incremental model rizky_dwh_hailing_facts.dim_customer ........ [RUN]
[0m01:17:52.679868 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_ride, now model.hailing_project.dim_customer)
[0m01:17:52.680885 [debug] [Thread-3 (]: Began compiling node model.hailing_project.dim_customer
[0m01:17:52.686297 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m01:17:52.694178 [debug] [Thread-3 (]: Began executing node model.hailing_project.dim_customer
[0m01:17:52.698694 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m01:17:52.702156 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd6c9388d-6b72-44d3-a4d3-84385d253f5b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6ea9d6fa10>]}
[0m01:17:52.703575 [info ] [Thread-2 (]: 2 of 9 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [[32mMERGE (10.0 rows, 13.5 KiB processed)[0m in 3.77s]
[0m01:17:52.728086 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m01:17:52.730127 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_driver
[0m01:17:52.731553 [info ] [Thread-1 (]: 6 of 9 START sql incremental model rizky_dwh_hailing_facts.dim_driver .......... [RUN]
[0m01:17:52.732859 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_customer, now model.hailing_project.dim_driver)
[0m01:17:52.733934 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_driver
[0m01:17:52.739615 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_driver"
[0m01:17:52.746428 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_driver
[0m01:17:52.750793 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m01:17:53.004620 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m01:17:53.011793 [debug] [Thread-3 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
)

SELECT * FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m01:17:53.017316 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_driver"
[0m01:17:53.024029 [debug] [Thread-1 (]: On model.hailing_project.dim_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver` as DBT_INTERNAL_DEST
        using (


WITH driver AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver` --pakai ref untuk buat dependency

),

vehicle AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle`
)

SELECT
    driver.driver_id,
    vehicle.vehicle_id,
    driver.name as driver_name,
    driver.phone_number as phone_number,
    driver.email as email,
    vehicle.vehicle_type,
    vehicle.brand as vehicle_brand,
    vehicle.year as vehicle_production_year,
    vehicle.license_plate,
    driver.created_at
FROM driver
LEFT JOIN vehicle
on driver.driver_id = vehicle.vehicle_id


    WHERE driver.created_at > (
        SELECT MAX(driver.created_at)
        FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_name` = DBT_INTERNAL_SOURCE.`driver_name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`vehicle_brand` = DBT_INTERNAL_SOURCE.`vehicle_brand`,`vehicle_production_year` = DBT_INTERNAL_SOURCE.`vehicle_production_year`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `vehicle_id`, `driver_name`, `phone_number`, `email`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)
    values
        (`driver_id`, `vehicle_id`, `driver_name`, `phone_number`, `email`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)


    
[0m01:17:53.260845 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:1cf69609-dc2a-493a-8a35-24bc8745d88b&page=queryresults
[0m01:17:54.436334 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:6cfd5200-6308-498f-b55a-ac3f3c279022&page=queryresults
[0m01:17:55.094454 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd6c9388d-6b72-44d3-a4d3-84385d253f5b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6e99b1bdd0>]}
[0m01:17:55.096624 [info ] [Thread-3 (]: 5 of 9 OK created sql incremental model rizky_dwh_hailing_facts.dim_customer ... [[32mMERGE (10.0 rows, 13.4 KiB processed)[0m in 2.41s]
[0m01:17:55.098029 [debug] [Thread-3 (]: Finished running node model.hailing_project.dim_customer
[0m01:17:56.228535 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd6c9388d-6b72-44d3-a4d3-84385d253f5b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6e99b0b250>]}
[0m01:17:56.229808 [info ] [Thread-1 (]: 6 of 9 OK created sql incremental model rizky_dwh_hailing_facts.dim_driver ..... [[32mMERGE (0.0 rows, 21.2 KiB processed)[0m in 3.50s]
[0m01:17:56.231202 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_driver
[0m01:17:56.232961 [debug] [Thread-2 (]: Began running node model.hailing_project.fact_hailing_rides
[0m01:17:56.234105 [info ] [Thread-2 (]: 7 of 9 START sql incremental model rizky_dwh_hailing_facts.fact_hailing_rides .. [RUN]
[0m01:17:56.235340 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_driver, now model.hailing_project.fact_hailing_rides)
[0m01:17:56.236247 [debug] [Thread-2 (]: Began compiling node model.hailing_project.fact_hailing_rides
[0m01:17:56.241592 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.fact_hailing_rides"
[0m01:17:56.249451 [debug] [Thread-2 (]: Began executing node model.hailing_project.fact_hailing_rides
[0m01:17:56.255504 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m01:17:56.522672 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.fact_hailing_rides"
[0m01:17:56.533581 [debug] [Thread-2 (]: On model.hailing_project.fact_hailing_rides: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.fact_hailing_rides"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides` as DBT_INTERNAL_DEST
        using (

WITH dim_driver AS (

    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
),

dim_customer AS (

    SELECT * 
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer`
),

ride_staging AS (

    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride`
)

SELECT
ride_staging.ride_id,
ride_staging.start_time AS ride_start_time,
ride_staging.end_time AS ride_end_time,
ride_staging.distance_km,
ride_staging.fare,
ride_staging.ride_status,
dim_customer.cust_id,
dim_customer.name AS cust_name,
dim_customer.phone_number AS cust_phone_number,
dim_customer.email AS cust_email,
dim_driver.driver_id,
dim_driver.driver_name,
dim_driver.phone_number AS driver_phone_number,
dim_driver.email AS driver_email,
dim_driver.vehicle_id,
dim_driver.vehicle_type,
dim_driver.vehicle_brand,
dim_driver.vehicle_production_year,
dim_driver.license_plate,
ride_staging.created_at

FROM ride_staging

LEFT JOIN dim_customer
on ride_staging.cust_id = dim_customer.cust_id

LEFT JOIN dim_driver
on ride_staging.driver_id = dim_driver.driver_id


    WHERE ride_staging.created_at > (
        SELECT MAX(ride_staging.created_at)
        FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`ride_start_time` = DBT_INTERNAL_SOURCE.`ride_start_time`,`ride_end_time` = DBT_INTERNAL_SOURCE.`ride_end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`cust_name` = DBT_INTERNAL_SOURCE.`cust_name`,`cust_phone_number` = DBT_INTERNAL_SOURCE.`cust_phone_number`,`cust_email` = DBT_INTERNAL_SOURCE.`cust_email`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`driver_name` = DBT_INTERNAL_SOURCE.`driver_name`,`driver_phone_number` = DBT_INTERNAL_SOURCE.`driver_phone_number`,`driver_email` = DBT_INTERNAL_SOURCE.`driver_email`,`vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`vehicle_brand` = DBT_INTERNAL_SOURCE.`vehicle_brand`,`vehicle_production_year` = DBT_INTERNAL_SOURCE.`vehicle_production_year`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `ride_start_time`, `ride_end_time`, `distance_km`, `fare`, `ride_status`, `cust_id`, `cust_name`, `cust_phone_number`, `cust_email`, `driver_id`, `driver_name`, `driver_phone_number`, `driver_email`, `vehicle_id`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)
    values
        (`ride_id`, `ride_start_time`, `ride_end_time`, `distance_km`, `fare`, `ride_status`, `cust_id`, `cust_name`, `cust_phone_number`, `cust_email`, `driver_id`, `driver_name`, `driver_phone_number`, `driver_email`, `vehicle_id`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)


    
[0m01:17:57.026853 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:b8b05f0d-e1be-4a66-9489-4e6bc9e2b131&page=queryresults
[0m01:17:58.830897 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd6c9388d-6b72-44d3-a4d3-84385d253f5b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6ea9dbfc10>]}
[0m01:17:58.832205 [info ] [Thread-2 (]: 7 of 9 OK created sql incremental model rizky_dwh_hailing_facts.fact_hailing_rides  [[32mMERGE (0.0 rows, 46.7 KiB processed)[0m in 2.60s]
[0m01:17:58.833732 [debug] [Thread-2 (]: Finished running node model.hailing_project.fact_hailing_rides
[0m01:17:58.835461 [debug] [Thread-3 (]: Began running node model.hailing_project.mart_cust_rides_daily
[0m01:17:58.835919 [debug] [Thread-1 (]: Began running node model.hailing_project.mart_driver_loyalty_mgmt
[0m01:17:58.836736 [info ] [Thread-3 (]: 8 of 9 START sql incremental model rizky_dwh_hailing_marts.mart_cust_rides_daily  [RUN]
[0m01:17:58.837989 [info ] [Thread-1 (]: 9 of 9 START sql incremental model rizky_dwh_hailing_marts.mart_driver_loyalty_mgmt  [RUN]
[0m01:17:58.839618 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.hailing_project.dim_customer, now model.hailing_project.mart_cust_rides_daily)
[0m01:17:58.841066 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.hailing_project.dim_driver, now model.hailing_project.mart_driver_loyalty_mgmt)
[0m01:17:58.842570 [debug] [Thread-3 (]: Began compiling node model.hailing_project.mart_cust_rides_daily
[0m01:17:58.843734 [debug] [Thread-1 (]: Began compiling node model.hailing_project.mart_driver_loyalty_mgmt
[0m01:17:58.848367 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.mart_cust_rides_daily"
[0m01:17:58.852163 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.mart_driver_loyalty_mgmt"
[0m01:17:58.858515 [debug] [Thread-1 (]: Began executing node model.hailing_project.mart_driver_loyalty_mgmt
[0m01:17:58.859608 [debug] [Thread-3 (]: Began executing node model.hailing_project.mart_cust_rides_daily
[0m01:17:58.864899 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m01:17:58.868784 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m01:17:59.156003 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.mart_driver_loyalty_mgmt"
[0m01:17:59.161002 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.mart_cust_rides_daily"
[0m01:17:59.166713 [debug] [Thread-1 (]: On model.hailing_project.mart_driver_loyalty_mgmt: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.mart_driver_loyalty_mgmt"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_marts`.`mart_driver_loyalty_mgmt` as DBT_INTERNAL_DEST
        using (

WITH dim_driver AS(
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
),

fact_rides AS(
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
)

SELECT 
dim_driver.driver_id,
dim_driver.driver_name,
dim_driver.phone_number,
dim_driver.email,
dim_driver.vehicle_type,
COUNT(fact_rides.ride_id) AS no_of_rides,
SUM(TIMESTAMP_DIFF(fact_rides.ride_end_time, fact_rides.ride_start_time, MINUTE)) AS total_ride_duration_min,
SUM(fact_rides.fare) AS total_fare,
SUM(fact_rides.distance_km) as total_distance_km,
SUM(fact_rides.distance_km)-SUM(fact_rides.fare) AS rev_opportunity_loss,
FROM dim_driver
LEFT JOIN fact_rides
ON dim_driver.driver_id = fact_rides.driver_id

GROUP BY driver_id,driver_name,phone_number,email,vehicle_type
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`driver_name` = DBT_INTERNAL_SOURCE.`driver_name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`no_of_rides` = DBT_INTERNAL_SOURCE.`no_of_rides`,`total_ride_duration_min` = DBT_INTERNAL_SOURCE.`total_ride_duration_min`,`total_fare` = DBT_INTERNAL_SOURCE.`total_fare`,`total_distance_km` = DBT_INTERNAL_SOURCE.`total_distance_km`,`rev_opportunity_loss` = DBT_INTERNAL_SOURCE.`rev_opportunity_loss`
    

    when not matched then insert
        (`driver_id`, `driver_name`, `phone_number`, `email`, `vehicle_type`, `no_of_rides`, `total_ride_duration_min`, `total_fare`, `total_distance_km`, `rev_opportunity_loss`)
    values
        (`driver_id`, `driver_name`, `phone_number`, `email`, `vehicle_type`, `no_of_rides`, `total_ride_duration_min`, `total_fare`, `total_distance_km`, `rev_opportunity_loss`)


    
[0m01:17:59.169374 [debug] [Thread-3 (]: On model.hailing_project.mart_cust_rides_daily: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.mart_cust_rides_daily"} */
-- back compat for old kwarg name
  
  
        
            
                
                
            
                
                
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_marts`.`mart_cust_rides_daily` as DBT_INTERNAL_DEST
        using (


WITH fact_rides AS(

    SELECT * 
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
)

SELECT 

    fact_rides.cust_id,
    DATE(fact_rides.created_at) AS ride_date,
    fact_rides.cust_name,
    fact_rides.cust_email,
    fact_rides.cust_phone_number,
    COUNT(fact_rides.ride_id) AS no_of_rides,
    SUM(TIMESTAMP_DIFF(fact_rides.ride_end_time, fact_rides.ride_start_time, MINUTE)) AS total_ride_duration_min,
    SUM(fact_rides.fare) AS total_fare,
    SUM(fact_rides.distance_km) as total_distance_km,
    SUM(fact_rides.distance_km)-SUM(fact_rides.fare) AS rev_opportunity_loss,

FROM fact_rides
GROUP BY cust_name, cust_id, ride_date, cust_email, cust_phone_number
        ) as DBT_INTERNAL_SOURCE
        on (
                    DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
                ) and (
                    DBT_INTERNAL_SOURCE.ride_date = DBT_INTERNAL_DEST.ride_date
                )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`ride_date` = DBT_INTERNAL_SOURCE.`ride_date`,`cust_name` = DBT_INTERNAL_SOURCE.`cust_name`,`cust_email` = DBT_INTERNAL_SOURCE.`cust_email`,`cust_phone_number` = DBT_INTERNAL_SOURCE.`cust_phone_number`,`no_of_rides` = DBT_INTERNAL_SOURCE.`no_of_rides`,`total_ride_duration_min` = DBT_INTERNAL_SOURCE.`total_ride_duration_min`,`total_fare` = DBT_INTERNAL_SOURCE.`total_fare`,`total_distance_km` = DBT_INTERNAL_SOURCE.`total_distance_km`,`rev_opportunity_loss` = DBT_INTERNAL_SOURCE.`rev_opportunity_loss`
    

    when not matched then insert
        (`cust_id`, `ride_date`, `cust_name`, `cust_email`, `cust_phone_number`, `no_of_rides`, `total_ride_duration_min`, `total_fare`, `total_distance_km`, `rev_opportunity_loss`)
    values
        (`cust_id`, `ride_date`, `cust_name`, `cust_email`, `cust_phone_number`, `no_of_rides`, `total_ride_duration_min`, `total_fare`, `total_distance_km`, `rev_opportunity_loss`)


    
[0m01:17:59.423862 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:6184c014-7deb-417e-bd09-064ff519457e&page=queryresults
[0m01:17:59.432626 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:8f503295-8450-4a35-87a9-8e4b5c0ea861&page=queryresults
[0m01:18:01.553367 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd6c9388d-6b72-44d3-a4d3-84385d253f5b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6e99b53890>]}
[0m01:18:01.554850 [info ] [Thread-1 (]: 9 of 9 OK created sql incremental model rizky_dwh_hailing_marts.mart_driver_loyalty_mgmt  [[32mMERGE (95.0 rows, 22.1 KiB processed)[0m in 2.71s]
[0m01:18:01.556087 [debug] [Thread-1 (]: Finished running node model.hailing_project.mart_driver_loyalty_mgmt
[0m01:18:02.414724 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd6c9388d-6b72-44d3-a4d3-84385d253f5b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6e99b50d90>]}
[0m01:18:02.415812 [info ] [Thread-3 (]: 8 of 9 OK created sql incremental model rizky_dwh_hailing_marts.mart_cust_rides_daily  [[32mMERGE (78.0 rows, 21.5 KiB processed)[0m in 3.58s]
[0m01:18:02.418432 [debug] [Thread-3 (]: Finished running node model.hailing_project.mart_cust_rides_daily
[0m01:18:02.420564 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m01:18:02.423753 [debug] [MainThread]: Connection 'master' was properly closed.
[0m01:18:02.424483 [debug] [MainThread]: Connection 'model.hailing_project.fact_hailing_rides' was properly closed.
[0m01:18:02.425363 [debug] [MainThread]: Connection 'model.hailing_project.mart_driver_loyalty_mgmt' was properly closed.
[0m01:18:02.426142 [debug] [MainThread]: Connection 'model.hailing_project.mart_cust_rides_daily' was properly closed.
[0m01:18:02.426962 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m01:18:02.427958 [info ] [MainThread]: 
[0m01:18:02.429025 [info ] [MainThread]: Finished running 9 incremental models in 0 hours 0 minutes and 14.95 seconds (14.95s).
[0m01:18:02.432668 [debug] [MainThread]: Command end result
[0m01:18:02.470658 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m01:18:02.475317 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m01:18:02.484742 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m01:18:02.485782 [info ] [MainThread]: 
[0m01:18:02.487673 [info ] [MainThread]: [32mCompleted successfully[0m
[0m01:18:02.488930 [info ] [MainThread]: 
[0m01:18:02.490019 [info ] [MainThread]: Done. PASS=9 WARN=0 ERROR=0 SKIP=0 TOTAL=9
[0m01:18:02.492095 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 16.284658, "process_in_blocks": "2752", "process_kernel_time": 0.233049, "process_mem_max_rss": "221232", "process_out_blocks": "0", "process_user_time": 3.769316}
[0m01:18:02.493173 [debug] [MainThread]: Command `dbt run` succeeded at 01:18:02.493054 after 16.29 seconds
[0m01:18:02.494452 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6ed7ad5690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6ed875f410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6eaa236910>]}
[0m01:18:02.495476 [debug] [MainThread]: Flushing usage events
[0m01:18:03.997631 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m01:20:08.695641 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f70d6ea34d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f70d7babcd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f70d6ea3410>]}


============================== 01:20:08.698952 | 238834b7-c6b1-42e4-9d2e-18eaec537702 ==============================
[0m01:20:08.698952 [info ] [MainThread]: Running with dbt=1.9.0
[0m01:20:08.700163 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'invocation_command': 'dbt run --select dim_driver', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m01:20:09.322523 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '238834b7-c6b1-42e4-9d2e-18eaec537702', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f70ad24bf10>]}
[0m01:20:09.366488 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '238834b7-c6b1-42e4-9d2e-18eaec537702', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f70d9150fd0>]}
[0m01:20:09.368337 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m01:20:09.442672 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m01:20:09.643413 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m01:20:09.644528 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m01:20:09.675121 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '238834b7-c6b1-42e4-9d2e-18eaec537702', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f70acd7ad50>]}
[0m01:20:09.799246 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m01:20:09.805674 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m01:20:09.822925 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '238834b7-c6b1-42e4-9d2e-18eaec537702', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f70acd792d0>]}
[0m01:20:09.824250 [info ] [MainThread]: Found 9 models, 8 sources, 489 macros
[0m01:20:09.825517 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '238834b7-c6b1-42e4-9d2e-18eaec537702', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f70d7ccc390>]}
[0m01:20:09.828004 [info ] [MainThread]: 
[0m01:20:09.829336 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m01:20:09.830551 [info ] [MainThread]: 
[0m01:20:09.832208 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m01:20:09.835471 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m01:20:09.837074 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:20:10.456633 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_facts)
[0m01:20:10.457612 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_marts'
[0m01:20:10.458274 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_staging'
[0m01:20:10.458939 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m01:20:10.459898 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:20:10.460936 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:20:10.773780 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '238834b7-c6b1-42e4-9d2e-18eaec537702', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f70af9f6e50>]}
[0m01:20:10.775530 [debug] [MainThread]: Opening a new connection, currently in state init
[0m01:20:10.780854 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_driver
[0m01:20:10.782053 [info ] [Thread-1 (]: 1 of 1 START sql incremental model rizky_dwh_hailing_facts.dim_driver .......... [RUN]
[0m01:20:10.783232 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_marts, now model.hailing_project.dim_driver)
[0m01:20:10.784191 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_driver
[0m01:20:10.802836 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_driver"
[0m01:20:10.809091 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_driver
[0m01:20:10.848691 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m01:20:11.134756 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_driver"
[0m01:20:11.142800 [debug] [Thread-1 (]: On model.hailing_project.dim_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver` as DBT_INTERNAL_DEST
        using (


WITH driver AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver` --pakai ref untuk buat dependency

),

vehicle AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle`
)

SELECT
    driver.driver_id,
    vehicle.vehicle_id,
    driver.name as driver_name,
    driver.phone_number as phone_number,
    driver.email as email,
    vehicle.vehicle_type,
    vehicle.brand as vehicle_brand,
    vehicle.year as vehicle_production_year,
    vehicle.license_plate,
    driver.created_at
FROM driver
LEFT JOIN vehicle
on driver.driver_id = vehicle.vehicle_id


    WHERE driver.created_at > (
        SELECT MAX(driver.created_at)
        FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_name` = DBT_INTERNAL_SOURCE.`driver_name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`vehicle_brand` = DBT_INTERNAL_SOURCE.`vehicle_brand`,`vehicle_production_year` = DBT_INTERNAL_SOURCE.`vehicle_production_year`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `vehicle_id`, `driver_name`, `phone_number`, `email`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)
    values
        (`driver_id`, `vehicle_id`, `driver_name`, `phone_number`, `email`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)


    
[0m01:20:11.678433 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:89a4664f-7a57-485a-ad9f-617b0d95ce98&page=queryresults
[0m01:20:13.506298 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '238834b7-c6b1-42e4-9d2e-18eaec537702', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f70accb1550>]}
[0m01:20:13.507408 [info ] [Thread-1 (]: 1 of 1 OK created sql incremental model rizky_dwh_hailing_facts.dim_driver ..... [[32mMERGE (0.0 rows, 21.2 KiB processed)[0m in 2.72s]
[0m01:20:13.508643 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_driver
[0m01:20:13.510977 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m01:20:13.513488 [debug] [MainThread]: Connection 'master' was properly closed.
[0m01:20:13.514143 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_facts' was properly closed.
[0m01:20:13.514803 [debug] [MainThread]: Connection 'model.hailing_project.dim_driver' was properly closed.
[0m01:20:13.515414 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_staging' was properly closed.
[0m01:20:13.516187 [info ] [MainThread]: 
[0m01:20:13.517542 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 3.68 seconds (3.68s).
[0m01:20:13.519927 [debug] [MainThread]: Command end result
[0m01:20:13.555444 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m01:20:13.560174 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m01:20:13.567686 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m01:20:13.568516 [info ] [MainThread]: 
[0m01:20:13.569506 [info ] [MainThread]: [32mCompleted successfully[0m
[0m01:20:13.570648 [info ] [MainThread]: 
[0m01:20:13.571580 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m01:20:13.572956 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 4.9295325, "process_in_blocks": "0", "process_kernel_time": 0.245755, "process_mem_max_rss": "218864", "process_out_blocks": "0", "process_user_time": 3.224316}
[0m01:20:13.573860 [debug] [MainThread]: Command `dbt run` succeeded at 01:20:13.573735 after 4.93 seconds
[0m01:20:13.574660 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f70d729e750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f70d7bab690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f70d7383b50>]}
[0m01:20:13.575381 [debug] [MainThread]: Flushing usage events
[0m01:20:14.810404 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m01:25:25.301153 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2e5ab2b590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2e5ab2b2d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2e5ab2b9d0>]}


============================== 01:25:25.304773 | 7e0b88a4-e38d-4ca2-b9a9-7b40ec439fe3 ==============================
[0m01:25:25.304773 [info ] [MainThread]: Running with dbt=1.9.0
[0m01:25:25.306100 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt run --select dim_driver', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m01:25:25.901302 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '7e0b88a4-e38d-4ca2-b9a9-7b40ec439fe3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2e30e5b010>]}
[0m01:25:25.947712 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '7e0b88a4-e38d-4ca2-b9a9-7b40ec439fe3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2e5cdb0850>]}
[0m01:25:25.949132 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m01:25:26.017421 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m01:25:26.217446 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m01:25:26.218721 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/facts/dim_driver.sql
[0m01:25:26.478097 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7e0b88a4-e38d-4ca2-b9a9-7b40ec439fe3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2e30c8fa50>]}
[0m01:25:26.562256 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m01:25:26.572153 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m01:25:26.587056 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7e0b88a4-e38d-4ca2-b9a9-7b40ec439fe3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2e30968ad0>]}
[0m01:25:26.588592 [info ] [MainThread]: Found 9 models, 8 sources, 489 macros
[0m01:25:26.589776 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7e0b88a4-e38d-4ca2-b9a9-7b40ec439fe3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2e30eb2190>]}
[0m01:25:26.592486 [info ] [MainThread]: 
[0m01:25:26.593721 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m01:25:26.594743 [info ] [MainThread]: 
[0m01:25:26.596025 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m01:25:26.598775 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m01:25:26.600030 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:25:27.227791 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_staging)
[0m01:25:27.228418 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_marts'
[0m01:25:27.229055 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_facts'
[0m01:25:27.229931 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m01:25:27.230806 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:25:27.231600 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:25:27.561196 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7e0b88a4-e38d-4ca2-b9a9-7b40ec439fe3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2e3092c310>]}
[0m01:25:27.562117 [debug] [MainThread]: Opening a new connection, currently in state init
[0m01:25:27.566817 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_driver
[0m01:25:27.567790 [info ] [Thread-1 (]: 1 of 1 START sql incremental model rizky_dwh_hailing_facts.dim_driver .......... [RUN]
[0m01:25:27.568963 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_facts, now model.hailing_project.dim_driver)
[0m01:25:27.570026 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_driver
[0m01:25:27.582195 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_driver"
[0m01:25:27.588325 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_driver
[0m01:25:27.625138 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m01:25:27.923847 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_driver"
[0m01:25:27.929764 [debug] [Thread-1 (]: On model.hailing_project.dim_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver` as DBT_INTERNAL_DEST
        using (


WITH driver AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver` --pakai ref untuk buat dependency

),

vehicle AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle`
)

SELECT
    driver.driver_id,
    vehicle.vehicle_id,
    driver.name AS driver_name,
    driver.phone_number AS phone_number,
    driver.email AS email,
    vehicle.vehicle_type,
    vehicle.brand AS vehicle_brand,
    vehicle.year AS vehicle_production_year,
    vehicle.license_plate,
    driver.created_at
FROM driver
LEFT JOIN vehicle
on driver.driver_id = vehicle.driver_id


    WHERE driver.created_at > (
        SELECT MAX(driver.created_at)
        FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_name` = DBT_INTERNAL_SOURCE.`driver_name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`vehicle_brand` = DBT_INTERNAL_SOURCE.`vehicle_brand`,`vehicle_production_year` = DBT_INTERNAL_SOURCE.`vehicle_production_year`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `vehicle_id`, `driver_name`, `phone_number`, `email`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)
    values
        (`driver_id`, `vehicle_id`, `driver_name`, `phone_number`, `email`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)


    
[0m01:25:28.285709 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:90b09724-8134-442e-ae02-5440270a8328&page=queryresults
[0m01:25:29.930748 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7e0b88a4-e38d-4ca2-b9a9-7b40ec439fe3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2e30861990>]}
[0m01:25:29.932105 [info ] [Thread-1 (]: 1 of 1 OK created sql incremental model rizky_dwh_hailing_facts.dim_driver ..... [[32mMERGE (0.0 rows, 22.0 KiB processed)[0m in 2.36s]
[0m01:25:29.933458 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_driver
[0m01:25:29.935917 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m01:25:29.939654 [debug] [MainThread]: Connection 'master' was properly closed.
[0m01:25:29.940361 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_staging' was properly closed.
[0m01:25:29.941135 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_marts' was properly closed.
[0m01:25:29.941842 [debug] [MainThread]: Connection 'model.hailing_project.dim_driver' was properly closed.
[0m01:25:29.942837 [info ] [MainThread]: 
[0m01:25:29.943817 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 3.35 seconds (3.35s).
[0m01:25:29.945680 [debug] [MainThread]: Command end result
[0m01:25:29.984375 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m01:25:29.992187 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m01:25:30.000424 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m01:25:30.001203 [info ] [MainThread]: 
[0m01:25:30.002438 [info ] [MainThread]: [32mCompleted successfully[0m
[0m01:25:30.003721 [info ] [MainThread]: 
[0m01:25:30.004704 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m01:25:30.006314 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 4.7571807, "process_in_blocks": "280", "process_kernel_time": 0.209459, "process_mem_max_rss": "221636", "process_out_blocks": "0", "process_user_time": 3.381279}
[0m01:25:30.007293 [debug] [MainThread]: Command `dbt run` succeeded at 01:25:30.007129 after 4.76 seconds
[0m01:25:30.008167 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2e5ab83e10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2e5e324e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2e5e4a8ad0>]}
[0m01:25:30.009053 [debug] [MainThread]: Flushing usage events
[0m01:25:31.057264 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m01:26:56.665674 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0fb36f890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0fb716350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0fb31b910>]}


============================== 01:26:56.668542 | 3e3a83ca-7d9d-4b63-bcab-d329be5954ed ==============================
[0m01:26:56.668542 [info ] [MainThread]: Running with dbt=1.9.0
[0m01:26:56.670862 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'invocation_command': 'dbt run --select dim_driver', 'send_anonymous_usage_stats': 'True'}
[0m01:26:57.271409 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '3e3a83ca-7d9d-4b63-bcab-d329be5954ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0cd6bd290>]}
[0m01:26:57.320978 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '3e3a83ca-7d9d-4b63-bcab-d329be5954ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0cd65dfd0>]}
[0m01:26:57.322533 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m01:26:57.394196 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m01:26:57.591098 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m01:26:57.592028 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/facts/dim_driver.sql
[0m01:26:57.846569 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3e3a83ca-7d9d-4b63-bcab-d329be5954ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0cd324310>]}
[0m01:26:57.922288 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m01:26:57.928218 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m01:26:57.944241 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3e3a83ca-7d9d-4b63-bcab-d329be5954ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0cd165510>]}
[0m01:26:57.945383 [info ] [MainThread]: Found 9 models, 8 sources, 489 macros
[0m01:26:57.946504 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3e3a83ca-7d9d-4b63-bcab-d329be5954ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0cd3e2d10>]}
[0m01:26:57.949488 [info ] [MainThread]: 
[0m01:26:57.950646 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m01:26:57.951569 [info ] [MainThread]: 
[0m01:26:57.952864 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m01:26:57.954639 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m01:26:57.955611 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:26:58.489625 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_staging)
[0m01:26:58.491134 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_facts'
[0m01:26:58.491884 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_marts'
[0m01:26:58.492494 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m01:26:58.493472 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:26:58.494506 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:26:58.812442 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3e3a83ca-7d9d-4b63-bcab-d329be5954ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0cd6c4e90>]}
[0m01:26:58.813745 [debug] [MainThread]: Opening a new connection, currently in state init
[0m01:26:58.819076 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_driver
[0m01:26:58.820165 [info ] [Thread-1 (]: 1 of 1 START sql incremental model rizky_dwh_hailing_facts.dim_driver .......... [RUN]
[0m01:26:58.821325 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_facts, now model.hailing_project.dim_driver)
[0m01:26:58.822451 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_driver
[0m01:26:58.833518 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_driver"
[0m01:26:58.840791 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_driver
[0m01:26:58.878077 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m01:26:59.188067 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_driver"
[0m01:26:59.193917 [debug] [Thread-1 (]: On model.hailing_project.dim_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver` as DBT_INTERNAL_DEST
        using (


WITH driver AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver` --pakai ref untuk buat dependency

),

vehicle AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle`
)

SELECT
    driver.driver_id,
    vehicle.vehicle_id,
    driver.name AS driver_name,
    driver.phone_number AS phone_number,
    driver.email AS email,
    vehicle.vehicle_type,
    vehicle.brand AS vehicle_brand,
    vehicle.year AS vehicle_production_year,
    vehicle.license_plate,
    driver.created_at
FROM driver
LEFT JOIN vehicle
on driver.driver_id = vehicle.driver_id


    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_name` = DBT_INTERNAL_SOURCE.`driver_name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`vehicle_brand` = DBT_INTERNAL_SOURCE.`vehicle_brand`,`vehicle_production_year` = DBT_INTERNAL_SOURCE.`vehicle_production_year`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `vehicle_id`, `driver_name`, `phone_number`, `email`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)
    values
        (`driver_id`, `vehicle_id`, `driver_name`, `phone_number`, `email`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)


    
[0m01:26:59.492157 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:6a54e820-272c-4a03-8684-dbff429f1d00&page=queryresults
[0m01:26:59.660511 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:6a54e820-272c-4a03-8684-dbff429f1d00&page=queryresults
[0m01:26:59.673873 [debug] [Thread-1 (]: Database Error in model dim_driver (models/facts/dim_driver.sql)
  Column name created_at is ambiguous at [44:11]
  compiled code at target/run/hailing_project/models/facts/dim_driver.sql
[0m01:26:59.676683 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3e3a83ca-7d9d-4b63-bcab-d329be5954ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0cd6c47d0>]}
[0m01:26:59.678073 [error] [Thread-1 (]: 1 of 1 ERROR creating sql incremental model rizky_dwh_hailing_facts.dim_driver . [[31mERROR[0m in 0.85s]
[0m01:26:59.679723 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_driver
[0m01:26:59.681382 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.dim_driver' to be skipped because of status 'error'.  Reason: Database Error in model dim_driver (models/facts/dim_driver.sql)
  Column name created_at is ambiguous at [44:11]
  compiled code at target/run/hailing_project/models/facts/dim_driver.sql.
[0m01:26:59.684545 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m01:26:59.688219 [debug] [MainThread]: Connection 'master' was properly closed.
[0m01:26:59.689231 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_staging' was properly closed.
[0m01:26:59.690517 [debug] [MainThread]: Connection 'model.hailing_project.dim_driver' was properly closed.
[0m01:26:59.691871 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_marts' was properly closed.
[0m01:26:59.693364 [info ] [MainThread]: 
[0m01:26:59.694384 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 1.74 seconds (1.74s).
[0m01:26:59.695909 [debug] [MainThread]: Command end result
[0m01:26:59.742455 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m01:26:59.749255 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m01:26:59.759880 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m01:26:59.760851 [info ] [MainThread]: 
[0m01:26:59.762125 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m01:26:59.763300 [info ] [MainThread]: 
[0m01:26:59.764742 [error] [MainThread]:   Database Error in model dim_driver (models/facts/dim_driver.sql)
  Column name created_at is ambiguous at [44:11]
  compiled code at target/run/hailing_project/models/facts/dim_driver.sql
[0m01:26:59.765929 [info ] [MainThread]: 
[0m01:26:59.767558 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m01:26:59.769874 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 3.1630337, "process_in_blocks": "1024", "process_kernel_time": 0.205654, "process_mem_max_rss": "218964", "process_out_blocks": "0", "process_user_time": 3.515713}
[0m01:26:59.771387 [debug] [MainThread]: Command `dbt run` failed at 01:26:59.771214 after 3.16 seconds
[0m01:26:59.773040 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0fb376490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0fecd1350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0fc0d7cd0>]}
[0m01:26:59.775235 [debug] [MainThread]: Flushing usage events
[0m01:27:01.012049 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m01:27:17.129203 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd562808e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd563513a10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd56280b450>]}


============================== 01:27:17.131926 | 082fc049-9acf-44c7-a99e-1c806ba22029 ==============================
[0m01:27:17.131926 [info ] [MainThread]: Running with dbt=1.9.0
[0m01:27:17.133044 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt run --select dim_driver', 'send_anonymous_usage_stats': 'True'}
[0m01:27:17.665266 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '082fc049-9acf-44c7-a99e-1c806ba22029', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd56288ba50>]}
[0m01:27:17.716853 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '082fc049-9acf-44c7-a99e-1c806ba22029', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd564abe6d0>]}
[0m01:27:17.718119 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m01:27:17.785019 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m01:27:17.971206 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m01:27:17.972478 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/facts/dim_driver.sql
[0m01:27:18.241850 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '082fc049-9acf-44c7-a99e-1c806ba22029', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd56284c290>]}
[0m01:27:18.311119 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m01:27:18.316372 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m01:27:18.331920 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '082fc049-9acf-44c7-a99e-1c806ba22029', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd538538390>]}
[0m01:27:18.332976 [info ] [MainThread]: Found 9 models, 8 sources, 489 macros
[0m01:27:18.334152 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '082fc049-9acf-44c7-a99e-1c806ba22029', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd538a54cd0>]}
[0m01:27:18.336536 [info ] [MainThread]: 
[0m01:27:18.337739 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m01:27:18.339004 [info ] [MainThread]: 
[0m01:27:18.340470 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m01:27:18.342910 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m01:27:18.343758 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:27:18.863942 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_marts)
[0m01:27:18.868978 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m01:27:18.865391 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_staging'
[0m01:27:18.864622 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_facts'
[0m01:27:18.871357 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:27:18.873403 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:27:19.169717 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '082fc049-9acf-44c7-a99e-1c806ba22029', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd53853a510>]}
[0m01:27:19.171162 [debug] [MainThread]: Opening a new connection, currently in state init
[0m01:27:19.175893 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_driver
[0m01:27:19.176725 [info ] [Thread-1 (]: 1 of 1 START sql incremental model rizky_dwh_hailing_facts.dim_driver .......... [RUN]
[0m01:27:19.177988 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_facts, now model.hailing_project.dim_driver)
[0m01:27:19.179722 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_driver
[0m01:27:19.191346 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_driver"
[0m01:27:19.198511 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_driver
[0m01:27:19.239464 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m01:27:19.557450 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_driver"
[0m01:27:19.563488 [debug] [Thread-1 (]: On model.hailing_project.dim_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver` as DBT_INTERNAL_DEST
        using (


WITH driver AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver` --pakai ref untuk buat dependency

),

vehicle AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle`
)

SELECT
    driver.driver_id,
    vehicle.vehicle_id,
    driver.name AS driver_name,
    driver.phone_number AS phone_number,
    driver.email AS email,
    vehicle.vehicle_type,
    vehicle.brand AS vehicle_brand,
    vehicle.year AS vehicle_production_year,
    vehicle.license_plate,
    driver.created_at
FROM driver
LEFT JOIN vehicle
on driver.driver_id = vehicle.driver_id


    WHERE driver.created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_name` = DBT_INTERNAL_SOURCE.`driver_name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`vehicle_brand` = DBT_INTERNAL_SOURCE.`vehicle_brand`,`vehicle_production_year` = DBT_INTERNAL_SOURCE.`vehicle_production_year`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `vehicle_id`, `driver_name`, `phone_number`, `email`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)
    values
        (`driver_id`, `vehicle_id`, `driver_name`, `phone_number`, `email`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)


    
[0m01:27:19.827141 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:da16ee19-025f-42e7-9b0d-2ab77dacfbf6&page=queryresults
[0m01:27:21.735214 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '082fc049-9acf-44c7-a99e-1c806ba22029', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd53859a910>]}
[0m01:27:21.736282 [info ] [Thread-1 (]: 1 of 1 OK created sql incremental model rizky_dwh_hailing_facts.dim_driver ..... [[32mMERGE (10.0 rows, 22.0 KiB processed)[0m in 2.56s]
[0m01:27:21.738199 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_driver
[0m01:27:21.740156 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m01:27:21.743441 [debug] [MainThread]: Connection 'master' was properly closed.
[0m01:27:21.744604 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_marts' was properly closed.
[0m01:27:21.747275 [debug] [MainThread]: Connection 'model.hailing_project.dim_driver' was properly closed.
[0m01:27:21.749027 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_staging' was properly closed.
[0m01:27:21.750195 [info ] [MainThread]: 
[0m01:27:21.751445 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 3.41 seconds (3.41s).
[0m01:27:21.753089 [debug] [MainThread]: Command end result
[0m01:27:21.790900 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m01:27:21.795577 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m01:27:21.803815 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m01:27:21.805043 [info ] [MainThread]: 
[0m01:27:21.806307 [info ] [MainThread]: [32mCompleted successfully[0m
[0m01:27:21.807397 [info ] [MainThread]: 
[0m01:27:21.808488 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m01:27:21.810416 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 4.7316384, "process_in_blocks": "0", "process_kernel_time": 0.159238, "process_mem_max_rss": "224092", "process_out_blocks": "0", "process_user_time": 3.38381}
[0m01:27:21.811924 [debug] [MainThread]: Command `dbt run` succeeded at 01:27:21.811795 after 4.73 seconds
[0m01:27:21.812901 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd56288b9d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd56288b550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd56603cc50>]}
[0m01:27:21.813786 [debug] [MainThread]: Flushing usage events
[0m01:27:23.076660 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m01:27:39.206031 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f232b083690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f232b47e4d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f232b083590>]}


============================== 01:27:39.208525 | 9f918045-fc92-4bdb-aa27-7d20d8a7dd72 ==============================
[0m01:27:39.208525 [info ] [MainThread]: Running with dbt=1.9.0
[0m01:27:39.209636 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'invocation_command': 'dbt run', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m01:27:39.802127 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '9f918045-fc92-4bdb-aa27-7d20d8a7dd72', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f232b077f90>]}
[0m01:27:39.844412 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '9f918045-fc92-4bdb-aa27-7d20d8a7dd72', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f232d334890>]}
[0m01:27:39.846189 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m01:27:39.911755 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m01:27:40.100582 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m01:27:40.101255 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m01:27:40.128450 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9f918045-fc92-4bdb-aa27-7d20d8a7dd72', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f22ffbb59d0>]}
[0m01:27:40.259034 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m01:27:40.264364 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m01:27:40.281021 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9f918045-fc92-4bdb-aa27-7d20d8a7dd72', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f22fd227f90>]}
[0m01:27:40.282262 [info ] [MainThread]: Found 9 models, 8 sources, 489 macros
[0m01:27:40.283556 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9f918045-fc92-4bdb-aa27-7d20d8a7dd72', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f22fcf80a90>]}
[0m01:27:40.286400 [info ] [MainThread]: 
[0m01:27:40.287442 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m01:27:40.288336 [info ] [MainThread]: 
[0m01:27:40.289467 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m01:27:40.294265 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m01:27:40.295115 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m01:27:40.295779 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m01:27:40.296255 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:27:40.297171 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:27:40.298219 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:27:41.196516 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_staging)
[0m01:27:41.197127 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_facts)
[0m01:27:41.197680 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_marts)
[0m01:27:41.199256 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m01:27:41.200423 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m01:27:41.201434 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m01:27:41.516438 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9f918045-fc92-4bdb-aa27-7d20d8a7dd72', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f22fd299950>]}
[0m01:27:41.517435 [debug] [MainThread]: Opening a new connection, currently in state init
[0m01:27:41.521249 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m01:27:41.521564 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m01:27:41.521908 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m01:27:41.522206 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m01:27:41.522739 [info ] [Thread-1 (]: 1 of 9 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [RUN]
[0m01:27:41.523814 [info ] [Thread-2 (]: 2 of 9 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [RUN]
[0m01:27:41.524823 [info ] [Thread-3 (]: 3 of 9 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [RUN]
[0m01:27:41.525853 [info ] [Thread-4 (]: 4 of 9 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [RUN]
[0m01:27:41.526887 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_marts, now model.hailing_project.production_hailing_staging_customer)
[0m01:27:41.527731 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_staging, now model.hailing_project.production_hailing_staging_driver)
[0m01:27:41.528608 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_facts, now model.hailing_project.production_hailing_staging_ride)
[0m01:27:41.529456 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_vehicle'
[0m01:27:41.530486 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m01:27:41.531621 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m01:27:41.532921 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m01:27:41.533950 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m01:27:41.548176 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m01:27:41.551540 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m01:27:41.555342 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m01:27:41.559087 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m01:27:41.564772 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m01:27:41.565287 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m01:27:41.571472 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m01:27:41.571976 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m01:27:41.606881 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m01:27:41.608953 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m01:27:41.611231 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m01:27:41.614265 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m01:27:41.944448 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m01:27:41.947867 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m01:27:41.949674 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m01:27:41.950843 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m01:27:41.956604 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m01:27:41.957182 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m01:27:41.958149 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m01:27:41.959930 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m01:27:42.206853 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:6bb3d973-dcf7-48ea-b30e-d4854b2792b8&page=queryresults
[0m01:27:42.447452 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:e4f9d869-5e72-4ac3-8f8d-9d585d161390&page=queryresults
[0m01:27:42.470489 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:38190069-edec-4b63-a938-cf42a1b8b9e0&page=queryresults
[0m01:27:42.500939 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:88b36808-6742-4507-b31a-90927a5eeaae&page=queryresults
[0m01:27:43.865272 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9f918045-fc92-4bdb-aa27-7d20d8a7dd72', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f22fd4173d0>]}
[0m01:27:43.866365 [info ] [Thread-4 (]: 4 of 9 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 11.6 KiB processed)[0m in 2.34s]
[0m01:27:43.867563 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m01:27:43.996209 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9f918045-fc92-4bdb-aa27-7d20d8a7dd72', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f232be58190>]}
[0m01:27:43.997366 [info ] [Thread-1 (]: 1 of 9 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 14.2 KiB processed)[0m in 2.47s]
[0m01:27:43.998989 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m01:27:44.000535 [debug] [Thread-4 (]: Began running node model.hailing_project.dim_customer
[0m01:27:44.001610 [info ] [Thread-4 (]: 5 of 9 START sql incremental model rizky_dwh_hailing_facts.dim_customer ........ [RUN]
[0m01:27:44.003019 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_vehicle, now model.hailing_project.dim_customer)
[0m01:27:44.004110 [debug] [Thread-4 (]: Began compiling node model.hailing_project.dim_customer
[0m01:27:44.010564 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m01:27:44.017367 [debug] [Thread-4 (]: Began executing node model.hailing_project.dim_customer
[0m01:27:44.022862 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m01:27:44.075360 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9f918045-fc92-4bdb-aa27-7d20d8a7dd72', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f22fd232090>]}
[0m01:27:44.076597 [info ] [Thread-3 (]: 3 of 9 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 18.7 KiB processed)[0m in 2.55s]
[0m01:27:44.077738 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m01:27:44.109019 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9f918045-fc92-4bdb-aa27-7d20d8a7dd72', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f22fd3c9cd0>]}
[0m01:27:44.110407 [info ] [Thread-2 (]: 2 of 9 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 14.2 KiB processed)[0m in 2.58s]
[0m01:27:44.111465 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m01:27:44.112877 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_driver
[0m01:27:44.113900 [info ] [Thread-1 (]: 6 of 9 START sql incremental model rizky_dwh_hailing_facts.dim_driver .......... [RUN]
[0m01:27:44.115717 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_customer, now model.hailing_project.dim_driver)
[0m01:27:44.117454 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_driver
[0m01:27:44.122452 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_driver"
[0m01:27:44.128384 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_driver
[0m01:27:44.132190 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m01:27:44.303713 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m01:27:44.310421 [debug] [Thread-4 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
)

SELECT * FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m01:27:44.404225 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_driver"
[0m01:27:44.412454 [debug] [Thread-1 (]: On model.hailing_project.dim_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver` as DBT_INTERNAL_DEST
        using (


WITH driver AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver` --pakai ref untuk buat dependency

),

vehicle AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle`
)

SELECT
    driver.driver_id,
    vehicle.vehicle_id,
    driver.name AS driver_name,
    driver.phone_number AS phone_number,
    driver.email AS email,
    vehicle.vehicle_type,
    vehicle.brand AS vehicle_brand,
    vehicle.year AS vehicle_production_year,
    vehicle.license_plate,
    driver.created_at
FROM driver
LEFT JOIN vehicle
on driver.driver_id = vehicle.driver_id


    WHERE driver.created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_name` = DBT_INTERNAL_SOURCE.`driver_name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`vehicle_brand` = DBT_INTERNAL_SOURCE.`vehicle_brand`,`vehicle_production_year` = DBT_INTERNAL_SOURCE.`vehicle_production_year`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `vehicle_id`, `driver_name`, `phone_number`, `email`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)
    values
        (`driver_id`, `vehicle_id`, `driver_name`, `phone_number`, `email`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)


    
[0m01:27:44.645439 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:95b8ebe6-c099-4e39-8922-aca416f64649&page=queryresults
[0m01:27:44.809094 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:a3e957a2-3167-4da7-af3a-857285bfed65&page=queryresults
[0m01:27:46.421954 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9f918045-fc92-4bdb-aa27-7d20d8a7dd72', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f22fc26fc50>]}
[0m01:27:46.423433 [info ] [Thread-1 (]: 6 of 9 OK created sql incremental model rizky_dwh_hailing_facts.dim_driver ..... [[32mMERGE (0.0 rows, 23.1 KiB processed)[0m in 2.31s]
[0m01:27:46.424856 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_driver
[0m01:27:46.628504 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9f918045-fc92-4bdb-aa27-7d20d8a7dd72', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f22fc24de50>]}
[0m01:27:46.629742 [info ] [Thread-4 (]: 5 of 9 OK created sql incremental model rizky_dwh_hailing_facts.dim_customer ... [[32mMERGE (0.0 rows, 14.0 KiB processed)[0m in 2.63s]
[0m01:27:46.631613 [debug] [Thread-4 (]: Finished running node model.hailing_project.dim_customer
[0m01:27:46.633081 [debug] [Thread-2 (]: Began running node model.hailing_project.fact_hailing_rides
[0m01:27:46.634276 [info ] [Thread-2 (]: 7 of 9 START sql incremental model rizky_dwh_hailing_facts.fact_hailing_rides .. [RUN]
[0m01:27:46.635899 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_driver, now model.hailing_project.fact_hailing_rides)
[0m01:27:46.636950 [debug] [Thread-2 (]: Began compiling node model.hailing_project.fact_hailing_rides
[0m01:27:46.642588 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.fact_hailing_rides"
[0m01:27:46.649759 [debug] [Thread-2 (]: Began executing node model.hailing_project.fact_hailing_rides
[0m01:27:46.653339 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m01:27:46.924475 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.fact_hailing_rides"
[0m01:27:46.932701 [debug] [Thread-2 (]: On model.hailing_project.fact_hailing_rides: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.fact_hailing_rides"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides` as DBT_INTERNAL_DEST
        using (

WITH dim_driver AS (

    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
),

dim_customer AS (

    SELECT * 
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer`
),

ride_staging AS (

    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride`
)

SELECT
ride_staging.ride_id,
ride_staging.start_time AS ride_start_time,
ride_staging.end_time AS ride_end_time,
ride_staging.distance_km,
ride_staging.fare,
ride_staging.ride_status,
dim_customer.cust_id,
dim_customer.name AS cust_name,
dim_customer.phone_number AS cust_phone_number,
dim_customer.email AS cust_email,
dim_driver.driver_id,
dim_driver.driver_name,
dim_driver.phone_number AS driver_phone_number,
dim_driver.email AS driver_email,
dim_driver.vehicle_id,
dim_driver.vehicle_type,
dim_driver.vehicle_brand,
dim_driver.vehicle_production_year,
dim_driver.license_plate,
ride_staging.created_at

FROM ride_staging

LEFT JOIN dim_customer
on ride_staging.cust_id = dim_customer.cust_id

LEFT JOIN dim_driver
on ride_staging.driver_id = dim_driver.driver_id


    WHERE ride_staging.created_at > (
        SELECT MAX(ride_staging.created_at)
        FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`ride_start_time` = DBT_INTERNAL_SOURCE.`ride_start_time`,`ride_end_time` = DBT_INTERNAL_SOURCE.`ride_end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`cust_name` = DBT_INTERNAL_SOURCE.`cust_name`,`cust_phone_number` = DBT_INTERNAL_SOURCE.`cust_phone_number`,`cust_email` = DBT_INTERNAL_SOURCE.`cust_email`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`driver_name` = DBT_INTERNAL_SOURCE.`driver_name`,`driver_phone_number` = DBT_INTERNAL_SOURCE.`driver_phone_number`,`driver_email` = DBT_INTERNAL_SOURCE.`driver_email`,`vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`vehicle_brand` = DBT_INTERNAL_SOURCE.`vehicle_brand`,`vehicle_production_year` = DBT_INTERNAL_SOURCE.`vehicle_production_year`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `ride_start_time`, `ride_end_time`, `distance_km`, `fare`, `ride_status`, `cust_id`, `cust_name`, `cust_phone_number`, `cust_email`, `driver_id`, `driver_name`, `driver_phone_number`, `driver_email`, `vehicle_id`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)
    values
        (`ride_id`, `ride_start_time`, `ride_end_time`, `distance_km`, `fare`, `ride_status`, `cust_id`, `cust_name`, `cust_phone_number`, `cust_email`, `driver_id`, `driver_name`, `driver_phone_number`, `driver_email`, `vehicle_id`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)


    
[0m01:27:47.178398 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:a655a30b-9fd2-4a76-a7ba-363c6a5fd167&page=queryresults
[0m01:27:49.021896 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9f918045-fc92-4bdb-aa27-7d20d8a7dd72', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f22fcee5ad0>]}
[0m01:27:49.023113 [info ] [Thread-2 (]: 7 of 9 OK created sql incremental model rizky_dwh_hailing_facts.fact_hailing_rides  [[32mMERGE (0.0 rows, 47.6 KiB processed)[0m in 2.39s]
[0m01:27:49.025233 [debug] [Thread-2 (]: Finished running node model.hailing_project.fact_hailing_rides
[0m01:27:49.026977 [debug] [Thread-1 (]: Began running node model.hailing_project.mart_cust_rides_daily
[0m01:27:49.027421 [debug] [Thread-4 (]: Began running node model.hailing_project.mart_driver_loyalty_mgmt
[0m01:27:49.028972 [info ] [Thread-1 (]: 8 of 9 START sql incremental model rizky_dwh_hailing_marts.mart_cust_rides_daily  [RUN]
[0m01:27:49.030037 [info ] [Thread-4 (]: 9 of 9 START sql incremental model rizky_dwh_hailing_marts.mart_driver_loyalty_mgmt  [RUN]
[0m01:27:49.031287 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.hailing_project.dim_driver, now model.hailing_project.mart_cust_rides_daily)
[0m01:27:49.032555 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.hailing_project.dim_customer, now model.hailing_project.mart_driver_loyalty_mgmt)
[0m01:27:49.034087 [debug] [Thread-1 (]: Began compiling node model.hailing_project.mart_cust_rides_daily
[0m01:27:49.035930 [debug] [Thread-4 (]: Began compiling node model.hailing_project.mart_driver_loyalty_mgmt
[0m01:27:49.040226 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.mart_cust_rides_daily"
[0m01:27:49.044236 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.mart_driver_loyalty_mgmt"
[0m01:27:49.048981 [debug] [Thread-1 (]: Began executing node model.hailing_project.mart_cust_rides_daily
[0m01:27:49.049794 [debug] [Thread-4 (]: Began executing node model.hailing_project.mart_driver_loyalty_mgmt
[0m01:27:49.053887 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m01:27:49.057276 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m01:27:49.336126 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.mart_driver_loyalty_mgmt"
[0m01:27:49.347423 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.mart_cust_rides_daily"
[0m01:27:49.349262 [debug] [Thread-4 (]: On model.hailing_project.mart_driver_loyalty_mgmt: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.mart_driver_loyalty_mgmt"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_marts`.`mart_driver_loyalty_mgmt` as DBT_INTERNAL_DEST
        using (

WITH dim_driver AS(
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
),

fact_rides AS(
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
)

SELECT 
dim_driver.driver_id,
dim_driver.driver_name,
dim_driver.phone_number,
dim_driver.email,
dim_driver.vehicle_type,
COUNT(fact_rides.ride_id) AS no_of_rides,
SUM(TIMESTAMP_DIFF(fact_rides.ride_end_time, fact_rides.ride_start_time, MINUTE)) AS total_ride_duration_min,
SUM(fact_rides.fare) AS total_fare,
SUM(fact_rides.distance_km) as total_distance_km,
SUM(fact_rides.distance_km)-SUM(fact_rides.fare) AS rev_opportunity_loss,
FROM dim_driver
LEFT JOIN fact_rides
ON dim_driver.driver_id = fact_rides.driver_id

GROUP BY driver_id,driver_name,phone_number,email,vehicle_type
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`driver_name` = DBT_INTERNAL_SOURCE.`driver_name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`no_of_rides` = DBT_INTERNAL_SOURCE.`no_of_rides`,`total_ride_duration_min` = DBT_INTERNAL_SOURCE.`total_ride_duration_min`,`total_fare` = DBT_INTERNAL_SOURCE.`total_fare`,`total_distance_km` = DBT_INTERNAL_SOURCE.`total_distance_km`,`rev_opportunity_loss` = DBT_INTERNAL_SOURCE.`rev_opportunity_loss`
    

    when not matched then insert
        (`driver_id`, `driver_name`, `phone_number`, `email`, `vehicle_type`, `no_of_rides`, `total_ride_duration_min`, `total_fare`, `total_distance_km`, `rev_opportunity_loss`)
    values
        (`driver_id`, `driver_name`, `phone_number`, `email`, `vehicle_type`, `no_of_rides`, `total_ride_duration_min`, `total_fare`, `total_distance_km`, `rev_opportunity_loss`)


    
[0m01:27:49.358158 [debug] [Thread-1 (]: On model.hailing_project.mart_cust_rides_daily: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.mart_cust_rides_daily"} */
-- back compat for old kwarg name
  
  
        
            
                
                
            
                
                
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_marts`.`mart_cust_rides_daily` as DBT_INTERNAL_DEST
        using (


WITH fact_rides AS(

    SELECT * 
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
)

SELECT 

    fact_rides.cust_id,
    DATE(fact_rides.created_at) AS ride_date,
    fact_rides.cust_name,
    fact_rides.cust_email,
    fact_rides.cust_phone_number,
    COUNT(fact_rides.ride_id) AS no_of_rides,
    SUM(TIMESTAMP_DIFF(fact_rides.ride_end_time, fact_rides.ride_start_time, MINUTE)) AS total_ride_duration_min,
    SUM(fact_rides.fare) AS total_fare,
    SUM(fact_rides.distance_km) as total_distance_km,
    SUM(fact_rides.distance_km)-SUM(fact_rides.fare) AS rev_opportunity_loss,

FROM fact_rides
GROUP BY cust_name, cust_id, ride_date, cust_email, cust_phone_number
        ) as DBT_INTERNAL_SOURCE
        on (
                    DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
                ) and (
                    DBT_INTERNAL_SOURCE.ride_date = DBT_INTERNAL_DEST.ride_date
                )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`ride_date` = DBT_INTERNAL_SOURCE.`ride_date`,`cust_name` = DBT_INTERNAL_SOURCE.`cust_name`,`cust_email` = DBT_INTERNAL_SOURCE.`cust_email`,`cust_phone_number` = DBT_INTERNAL_SOURCE.`cust_phone_number`,`no_of_rides` = DBT_INTERNAL_SOURCE.`no_of_rides`,`total_ride_duration_min` = DBT_INTERNAL_SOURCE.`total_ride_duration_min`,`total_fare` = DBT_INTERNAL_SOURCE.`total_fare`,`total_distance_km` = DBT_INTERNAL_SOURCE.`total_distance_km`,`rev_opportunity_loss` = DBT_INTERNAL_SOURCE.`rev_opportunity_loss`
    

    when not matched then insert
        (`cust_id`, `ride_date`, `cust_name`, `cust_email`, `cust_phone_number`, `no_of_rides`, `total_ride_duration_min`, `total_fare`, `total_distance_km`, `rev_opportunity_loss`)
    values
        (`cust_id`, `ride_date`, `cust_name`, `cust_email`, `cust_phone_number`, `no_of_rides`, `total_ride_duration_min`, `total_fare`, `total_distance_km`, `rev_opportunity_loss`)


    
[0m01:27:49.584649 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:47082bb2-f0a3-42dd-b8d9-67d7e550197c&page=queryresults
[0m01:27:49.631297 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:074ac63a-2250-4cda-944f-d7fc1c973776&page=queryresults
[0m01:27:51.115476 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9f918045-fc92-4bdb-aa27-7d20d8a7dd72', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f22fc1323d0>]}
[0m01:27:51.116969 [info ] [Thread-4 (]: 9 of 9 OK created sql incremental model rizky_dwh_hailing_marts.mart_driver_loyalty_mgmt  [[32mMERGE (105.0 rows, 22.8 KiB processed)[0m in 2.08s]
[0m01:27:51.118563 [debug] [Thread-4 (]: Finished running node model.hailing_project.mart_driver_loyalty_mgmt
[0m01:27:51.423882 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9f918045-fc92-4bdb-aa27-7d20d8a7dd72', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f22fc13ac10>]}
[0m01:27:51.425102 [info ] [Thread-1 (]: 8 of 9 OK created sql incremental model rizky_dwh_hailing_marts.mart_cust_rides_daily  [[32mMERGE (78.0 rows, 21.5 KiB processed)[0m in 2.39s]
[0m01:27:51.426268 [debug] [Thread-1 (]: Finished running node model.hailing_project.mart_cust_rides_daily
[0m01:27:51.428652 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m01:27:51.431686 [debug] [MainThread]: Connection 'master' was properly closed.
[0m01:27:51.432642 [debug] [MainThread]: Connection 'model.hailing_project.mart_cust_rides_daily' was properly closed.
[0m01:27:51.433446 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m01:27:51.434295 [debug] [MainThread]: Connection 'model.hailing_project.fact_hailing_rides' was properly closed.
[0m01:27:51.435110 [debug] [MainThread]: Connection 'model.hailing_project.mart_driver_loyalty_mgmt' was properly closed.
[0m01:27:51.436016 [info ] [MainThread]: 
[0m01:27:51.436903 [info ] [MainThread]: Finished running 9 incremental models in 0 hours 0 minutes and 11.15 seconds (11.15s).
[0m01:27:51.439668 [debug] [MainThread]: Command end result
[0m01:27:51.474625 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m01:27:51.479790 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m01:27:51.488073 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m01:27:51.488864 [info ] [MainThread]: 
[0m01:27:51.489967 [info ] [MainThread]: [32mCompleted successfully[0m
[0m01:27:51.491151 [info ] [MainThread]: 
[0m01:27:51.492444 [info ] [MainThread]: Done. PASS=9 WARN=0 ERROR=0 SKIP=0 TOTAL=9
[0m01:27:51.494430 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 12.349874, "process_in_blocks": "0", "process_kernel_time": 0.297998, "process_mem_max_rss": "220924", "process_out_blocks": "0", "process_user_time": 3.709568}
[0m01:27:51.495407 [debug] [MainThread]: Command `dbt run` succeeded at 01:27:51.495297 after 12.35 seconds
[0m01:27:51.496267 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f232c1d91d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f232e8dcc10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f232ea38810>]}
[0m01:27:51.497152 [debug] [MainThread]: Flushing usage events
[0m01:27:52.745673 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m01:37:38.261255 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f90249df2d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9024dd5ed0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9024dd6390>]}


============================== 01:37:38.263794 | 1947fa35-4978-478a-8d17-a9d918254f2a ==============================
[0m01:37:38.263794 [info ] [MainThread]: Running with dbt=1.9.0
[0m01:37:38.265263 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt run --select fact_hailing_rides', 'send_anonymous_usage_stats': 'True'}
[0m01:37:38.855603 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1947fa35-4978-478a-8d17-a9d918254f2a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ff73186d0>]}
[0m01:37:38.899158 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '1947fa35-4978-478a-8d17-a9d918254f2a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ffc74b410>]}
[0m01:37:38.900994 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m01:37:38.970350 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m01:37:39.160624 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m01:37:39.162206 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/facts/fact_hailing_rides.sql
[0m01:37:39.417420 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1947fa35-4978-478a-8d17-a9d918254f2a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ff67f1790>]}
[0m01:37:39.488078 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m01:37:39.494271 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m01:37:39.508972 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1947fa35-4978-478a-8d17-a9d918254f2a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ff6657f50>]}
[0m01:37:39.510135 [info ] [MainThread]: Found 9 models, 8 sources, 489 macros
[0m01:37:39.511701 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1947fa35-4978-478a-8d17-a9d918254f2a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ff69e47d0>]}
[0m01:37:39.514045 [info ] [MainThread]: 
[0m01:37:39.515183 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m01:37:39.516286 [info ] [MainThread]: 
[0m01:37:39.517420 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m01:37:39.518936 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m01:37:39.519906 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:37:40.205503 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_staging)
[0m01:37:40.206140 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_facts'
[0m01:37:40.206761 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_marts'
[0m01:37:40.207433 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m01:37:40.209067 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:37:40.210217 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:37:40.533020 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1947fa35-4978-478a-8d17-a9d918254f2a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ff6673fd0>]}
[0m01:37:40.540805 [debug] [MainThread]: Opening a new connection, currently in state init
[0m01:37:40.547549 [debug] [Thread-1 (]: Began running node model.hailing_project.fact_hailing_rides
[0m01:37:40.548462 [info ] [Thread-1 (]: 1 of 1 START sql incremental model rizky_dwh_hailing_facts.fact_hailing_rides .. [RUN]
[0m01:37:40.549686 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_facts, now model.hailing_project.fact_hailing_rides)
[0m01:37:40.550488 [debug] [Thread-1 (]: Began compiling node model.hailing_project.fact_hailing_rides
[0m01:37:40.560538 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.fact_hailing_rides"
[0m01:37:40.567949 [debug] [Thread-1 (]: Began executing node model.hailing_project.fact_hailing_rides
[0m01:37:40.602725 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m01:37:40.898152 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.fact_hailing_rides"
[0m01:37:40.906830 [debug] [Thread-1 (]: On model.hailing_project.fact_hailing_rides: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.fact_hailing_rides"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides` as DBT_INTERNAL_DEST
        using (

WITH dim_driver AS (

    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
),

dim_customer AS (

    SELECT * 
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer`
),

ride_staging AS (

    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride`
)

SELECT
ride_staging.ride_id,
ride_staging.start_time AS ride_start_time,
ride_staging.end_time AS ride_end_time,
ride_staging.distance_km,
ride_staging.fare,
ride_staging.ride_status,
dim_customer.cust_id,
dim_customer.name AS cust_name,
dim_customer.phone_number AS cust_phone_number,
dim_customer.email AS cust_email,
dim_driver.driver_id,
dim_driver.driver_name,
dim_driver.phone_number AS driver_phone_number,
dim_driver.email AS driver_email,
dim_driver.vehicle_id,
dim_driver.vehicle_type,
dim_driver.vehicle_brand,
dim_driver.vehicle_production_year,
dim_driver.license_plate,
ride_staging.created_at

FROM ride_staging

LEFT JOIN dim_customer
on ride_staging.cust_id = dim_customer.cust_id

LEFT JOIN dim_driver
on ride_staging.driver_id = dim_driver.driver_id


    WHERE ride_staging.created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`ride_start_time` = DBT_INTERNAL_SOURCE.`ride_start_time`,`ride_end_time` = DBT_INTERNAL_SOURCE.`ride_end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`cust_name` = DBT_INTERNAL_SOURCE.`cust_name`,`cust_phone_number` = DBT_INTERNAL_SOURCE.`cust_phone_number`,`cust_email` = DBT_INTERNAL_SOURCE.`cust_email`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`driver_name` = DBT_INTERNAL_SOURCE.`driver_name`,`driver_phone_number` = DBT_INTERNAL_SOURCE.`driver_phone_number`,`driver_email` = DBT_INTERNAL_SOURCE.`driver_email`,`vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`vehicle_brand` = DBT_INTERNAL_SOURCE.`vehicle_brand`,`vehicle_production_year` = DBT_INTERNAL_SOURCE.`vehicle_production_year`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `ride_start_time`, `ride_end_time`, `distance_km`, `fare`, `ride_status`, `cust_id`, `cust_name`, `cust_phone_number`, `cust_email`, `driver_id`, `driver_name`, `driver_phone_number`, `driver_email`, `vehicle_id`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)
    values
        (`ride_id`, `ride_start_time`, `ride_end_time`, `distance_km`, `fare`, `ride_status`, `cust_id`, `cust_name`, `cust_phone_number`, `cust_email`, `driver_id`, `driver_name`, `driver_phone_number`, `driver_email`, `vehicle_id`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)


    
[0m01:37:41.212415 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:cfc5b9df-a425-4b8c-8f05-7d2654081893&page=queryresults
[0m01:37:42.838061 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1947fa35-4978-478a-8d17-a9d918254f2a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ff6877890>]}
[0m01:37:42.839455 [info ] [Thread-1 (]: 1 of 1 OK created sql incremental model rizky_dwh_hailing_facts.fact_hailing_rides  [[32mMERGE (10.0 rows, 47.6 KiB processed)[0m in 2.29s]
[0m01:37:42.840880 [debug] [Thread-1 (]: Finished running node model.hailing_project.fact_hailing_rides
[0m01:37:42.843094 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m01:37:42.845850 [debug] [MainThread]: Connection 'master' was properly closed.
[0m01:37:42.846481 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_staging' was properly closed.
[0m01:37:42.847266 [debug] [MainThread]: Connection 'model.hailing_project.fact_hailing_rides' was properly closed.
[0m01:37:42.847931 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_marts' was properly closed.
[0m01:37:42.848569 [info ] [MainThread]: 
[0m01:37:42.849400 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 3.33 seconds (3.33s).
[0m01:37:42.851053 [debug] [MainThread]: Command end result
[0m01:37:42.887138 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m01:37:42.891405 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m01:37:42.899220 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m01:37:42.900013 [info ] [MainThread]: 
[0m01:37:42.901557 [info ] [MainThread]: [32mCompleted successfully[0m
[0m01:37:42.903116 [info ] [MainThread]: 
[0m01:37:42.904339 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m01:37:42.906212 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 4.698688, "process_in_blocks": "0", "process_kernel_time": 0.266647, "process_mem_max_rss": "222808", "process_out_blocks": "0", "process_user_time": 3.292075}
[0m01:37:42.907645 [debug] [MainThread]: Command `dbt run` succeeded at 01:37:42.907493 after 4.70 seconds
[0m01:37:42.908698 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9024a3ae90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9024a3a2d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f90281a8cd0>]}
[0m01:37:42.909829 [debug] [MainThread]: Flushing usage events
[0m01:37:44.476973 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m01:38:15.033593 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f211f88a990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f211fc862d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f211f88a1d0>]}


============================== 01:38:15.036257 | 60b5fa52-0f32-45f6-90d8-964e966305b3 ==============================
[0m01:38:15.036257 [info ] [MainThread]: Running with dbt=1.9.0
[0m01:38:15.037382 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'version_check': 'True', 'warn_error': 'None', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m01:38:15.639448 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '60b5fa52-0f32-45f6-90d8-964e966305b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f211f90bd10>]}
[0m01:38:15.693548 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '60b5fa52-0f32-45f6-90d8-964e966305b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2121b023d0>]}
[0m01:38:15.695048 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m01:38:15.772380 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m01:38:16.013137 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m01:38:16.014233 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m01:38:16.044407 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '60b5fa52-0f32-45f6-90d8-964e966305b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f20f1b9f950>]}
[0m01:38:16.180440 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m01:38:16.187348 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m01:38:16.208158 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '60b5fa52-0f32-45f6-90d8-964e966305b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f20f1a928d0>]}
[0m01:38:16.209386 [info ] [MainThread]: Found 9 models, 8 sources, 489 macros
[0m01:38:16.210461 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '60b5fa52-0f32-45f6-90d8-964e966305b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f20f18cdf10>]}
[0m01:38:16.214386 [info ] [MainThread]: 
[0m01:38:16.215470 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m01:38:16.216462 [info ] [MainThread]: 
[0m01:38:16.217560 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m01:38:16.222442 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m01:38:16.223048 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m01:38:16.223825 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m01:38:16.224450 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:38:16.225212 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:38:16.226248 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:38:17.148499 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_staging)
[0m01:38:17.149049 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_marts)
[0m01:38:17.149578 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_facts)
[0m01:38:17.150734 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m01:38:17.151600 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m01:38:17.152704 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m01:38:17.448950 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '60b5fa52-0f32-45f6-90d8-964e966305b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f20f18ccb90>]}
[0m01:38:17.450792 [debug] [MainThread]: Opening a new connection, currently in state init
[0m01:38:17.455896 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m01:38:17.456278 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m01:38:17.456708 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m01:38:17.457070 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m01:38:17.458120 [info ] [Thread-1 (]: 1 of 9 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [RUN]
[0m01:38:17.459817 [info ] [Thread-2 (]: 2 of 9 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [RUN]
[0m01:38:17.464605 [info ] [Thread-3 (]: 3 of 9 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [RUN]
[0m01:38:17.466095 [info ] [Thread-4 (]: 4 of 9 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [RUN]
[0m01:38:17.467091 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_marts, now model.hailing_project.production_hailing_staging_customer)
[0m01:38:17.468066 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_facts, now model.hailing_project.production_hailing_staging_driver)
[0m01:38:17.468985 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_staging, now model.hailing_project.production_hailing_staging_ride)
[0m01:38:17.469980 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_vehicle'
[0m01:38:17.470803 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m01:38:17.471685 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m01:38:17.472511 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m01:38:17.473498 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m01:38:17.488500 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m01:38:17.492774 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m01:38:17.496777 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m01:38:17.500645 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m01:38:17.506576 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m01:38:17.507166 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m01:38:17.508081 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m01:38:17.513813 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m01:38:17.550925 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m01:38:17.551362 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m01:38:17.554004 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m01:38:17.556848 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m01:38:17.924284 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m01:38:17.925945 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m01:38:17.927162 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m01:38:17.928493 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m01:38:17.934927 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m01:38:17.936346 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m01:38:17.938837 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m01:38:17.939456 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m01:38:18.218606 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:6104fc4a-55be-439c-80ba-438aa8a5cd94&page=queryresults
[0m01:38:18.221517 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:8256851c-55ba-45c3-9a3b-b53845bcdf7b&page=queryresults
[0m01:38:18.222326 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:48b621c9-6db9-414e-906b-7675e6c46b57&page=queryresults
[0m01:38:18.234756 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:3a4e697a-48c7-4d4d-8b6a-826dba96a6e3&page=queryresults
[0m01:38:19.919266 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '60b5fa52-0f32-45f6-90d8-964e966305b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f20f1884750>]}
[0m01:38:19.920398 [info ] [Thread-1 (]: 1 of 9 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 14.2 KiB processed)[0m in 2.45s]
[0m01:38:19.921807 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m01:38:19.922811 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m01:38:19.923691 [info ] [Thread-1 (]: 5 of 9 START sql incremental model rizky_dwh_hailing_facts.dim_customer ........ [RUN]
[0m01:38:19.924665 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_customer, now model.hailing_project.dim_customer)
[0m01:38:19.925529 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m01:38:19.929436 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m01:38:19.936084 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m01:38:19.939849 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m01:38:20.087142 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '60b5fa52-0f32-45f6-90d8-964e966305b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f20f026b890>]}
[0m01:38:20.088166 [info ] [Thread-4 (]: 4 of 9 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 11.6 KiB processed)[0m in 2.62s]
[0m01:38:20.090521 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '60b5fa52-0f32-45f6-90d8-964e966305b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f20f1ba1050>]}
[0m01:38:20.091184 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m01:38:20.092194 [info ] [Thread-2 (]: 2 of 9 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 14.2 KiB processed)[0m in 2.62s]
[0m01:38:20.093811 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m01:38:20.094748 [debug] [Thread-4 (]: Began running node model.hailing_project.dim_driver
[0m01:38:20.095918 [info ] [Thread-4 (]: 6 of 9 START sql incremental model rizky_dwh_hailing_facts.dim_driver .......... [RUN]
[0m01:38:20.097267 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_vehicle, now model.hailing_project.dim_driver)
[0m01:38:20.098253 [debug] [Thread-4 (]: Began compiling node model.hailing_project.dim_driver
[0m01:38:20.103020 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.dim_driver"
[0m01:38:20.109138 [debug] [Thread-4 (]: Began executing node model.hailing_project.dim_driver
[0m01:38:20.113086 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m01:38:20.115545 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '60b5fa52-0f32-45f6-90d8-964e966305b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f20f183be10>]}
[0m01:38:20.116981 [info ] [Thread-3 (]: 3 of 9 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 18.7 KiB processed)[0m in 2.65s]
[0m01:38:20.119425 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m01:38:20.219105 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m01:38:20.225007 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
)

SELECT * FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m01:38:20.371495 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.dim_driver"
[0m01:38:20.380988 [debug] [Thread-4 (]: On model.hailing_project.dim_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver` as DBT_INTERNAL_DEST
        using (


WITH driver AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver` --pakai ref untuk buat dependency

),

vehicle AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle`
)

SELECT
    driver.driver_id,
    vehicle.vehicle_id,
    driver.name AS driver_name,
    driver.phone_number AS phone_number,
    driver.email AS email,
    vehicle.vehicle_type,
    vehicle.brand AS vehicle_brand,
    vehicle.year AS vehicle_production_year,
    vehicle.license_plate,
    driver.created_at
FROM driver
LEFT JOIN vehicle
on driver.driver_id = vehicle.driver_id


    WHERE driver.created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_name` = DBT_INTERNAL_SOURCE.`driver_name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`vehicle_brand` = DBT_INTERNAL_SOURCE.`vehicle_brand`,`vehicle_production_year` = DBT_INTERNAL_SOURCE.`vehicle_production_year`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `vehicle_id`, `driver_name`, `phone_number`, `email`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)
    values
        (`driver_id`, `vehicle_id`, `driver_name`, `phone_number`, `email`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)


    
[0m01:38:20.491306 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:632c1eb4-9a7a-4ba1-ad5c-8cb7083efcce&page=queryresults
[0m01:38:20.638993 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:15800d7c-0afc-4b6f-85a4-cbf7f3edf592&page=queryresults
[0m01:38:22.209368 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '60b5fa52-0f32-45f6-90d8-964e966305b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f20f01fec90>]}
[0m01:38:22.210782 [info ] [Thread-4 (]: 6 of 9 OK created sql incremental model rizky_dwh_hailing_facts.dim_driver ..... [[32mMERGE (0.0 rows, 23.1 KiB processed)[0m in 2.11s]
[0m01:38:22.212713 [debug] [Thread-4 (]: Finished running node model.hailing_project.dim_driver
[0m01:38:22.308371 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '60b5fa52-0f32-45f6-90d8-964e966305b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f20f027a8d0>]}
[0m01:38:22.310276 [info ] [Thread-1 (]: 5 of 9 OK created sql incremental model rizky_dwh_hailing_facts.dim_customer ... [[32mMERGE (0.0 rows, 14.0 KiB processed)[0m in 2.38s]
[0m01:38:22.312158 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m01:38:22.313823 [debug] [Thread-2 (]: Began running node model.hailing_project.fact_hailing_rides
[0m01:38:22.314706 [info ] [Thread-2 (]: 7 of 9 START sql incremental model rizky_dwh_hailing_facts.fact_hailing_rides .. [RUN]
[0m01:38:22.315670 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_driver, now model.hailing_project.fact_hailing_rides)
[0m01:38:22.316450 [debug] [Thread-2 (]: Began compiling node model.hailing_project.fact_hailing_rides
[0m01:38:22.320695 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.fact_hailing_rides"
[0m01:38:22.329046 [debug] [Thread-2 (]: Began executing node model.hailing_project.fact_hailing_rides
[0m01:38:22.332882 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m01:38:22.602692 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.fact_hailing_rides"
[0m01:38:22.610348 [debug] [Thread-2 (]: On model.hailing_project.fact_hailing_rides: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.fact_hailing_rides"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides` as DBT_INTERNAL_DEST
        using (

WITH dim_driver AS (

    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
),

dim_customer AS (

    SELECT * 
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer`
),

ride_staging AS (

    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride`
)

SELECT
ride_staging.ride_id,
ride_staging.start_time AS ride_start_time,
ride_staging.end_time AS ride_end_time,
ride_staging.distance_km,
ride_staging.fare,
ride_staging.ride_status,
dim_customer.cust_id,
dim_customer.name AS cust_name,
dim_customer.phone_number AS cust_phone_number,
dim_customer.email AS cust_email,
dim_driver.driver_id,
dim_driver.driver_name,
dim_driver.phone_number AS driver_phone_number,
dim_driver.email AS driver_email,
dim_driver.vehicle_id,
dim_driver.vehicle_type,
dim_driver.vehicle_brand,
dim_driver.vehicle_production_year,
dim_driver.license_plate,
ride_staging.created_at

FROM ride_staging

LEFT JOIN dim_customer
on ride_staging.cust_id = dim_customer.cust_id

LEFT JOIN dim_driver
on ride_staging.driver_id = dim_driver.driver_id


    WHERE ride_staging.created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`ride_start_time` = DBT_INTERNAL_SOURCE.`ride_start_time`,`ride_end_time` = DBT_INTERNAL_SOURCE.`ride_end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`cust_name` = DBT_INTERNAL_SOURCE.`cust_name`,`cust_phone_number` = DBT_INTERNAL_SOURCE.`cust_phone_number`,`cust_email` = DBT_INTERNAL_SOURCE.`cust_email`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`driver_name` = DBT_INTERNAL_SOURCE.`driver_name`,`driver_phone_number` = DBT_INTERNAL_SOURCE.`driver_phone_number`,`driver_email` = DBT_INTERNAL_SOURCE.`driver_email`,`vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`vehicle_brand` = DBT_INTERNAL_SOURCE.`vehicle_brand`,`vehicle_production_year` = DBT_INTERNAL_SOURCE.`vehicle_production_year`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `ride_start_time`, `ride_end_time`, `distance_km`, `fare`, `ride_status`, `cust_id`, `cust_name`, `cust_phone_number`, `cust_email`, `driver_id`, `driver_name`, `driver_phone_number`, `driver_email`, `vehicle_id`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)
    values
        (`ride_id`, `ride_start_time`, `ride_end_time`, `distance_km`, `fare`, `ride_status`, `cust_id`, `cust_name`, `cust_phone_number`, `cust_email`, `driver_id`, `driver_name`, `driver_phone_number`, `driver_email`, `vehicle_id`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)


    
[0m01:38:22.857847 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:652a6d0e-095f-4346-89d8-64bef1c11a32&page=queryresults
[0m01:38:24.760044 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '60b5fa52-0f32-45f6-90d8-964e966305b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f20f04f9050>]}
[0m01:38:24.761262 [info ] [Thread-2 (]: 7 of 9 OK created sql incremental model rizky_dwh_hailing_facts.fact_hailing_rides  [[32mMERGE (0.0 rows, 49.9 KiB processed)[0m in 2.44s]
[0m01:38:24.762545 [debug] [Thread-2 (]: Finished running node model.hailing_project.fact_hailing_rides
[0m01:38:24.764219 [debug] [Thread-4 (]: Began running node model.hailing_project.mart_cust_rides_daily
[0m01:38:24.764609 [debug] [Thread-1 (]: Began running node model.hailing_project.mart_driver_loyalty_mgmt
[0m01:38:24.765469 [info ] [Thread-4 (]: 8 of 9 START sql incremental model rizky_dwh_hailing_marts.mart_cust_rides_daily  [RUN]
[0m01:38:24.766604 [info ] [Thread-1 (]: 9 of 9 START sql incremental model rizky_dwh_hailing_marts.mart_driver_loyalty_mgmt  [RUN]
[0m01:38:24.767630 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.hailing_project.dim_driver, now model.hailing_project.mart_cust_rides_daily)
[0m01:38:24.768905 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.hailing_project.dim_customer, now model.hailing_project.mart_driver_loyalty_mgmt)
[0m01:38:24.770155 [debug] [Thread-4 (]: Began compiling node model.hailing_project.mart_cust_rides_daily
[0m01:38:24.771451 [debug] [Thread-1 (]: Began compiling node model.hailing_project.mart_driver_loyalty_mgmt
[0m01:38:24.775796 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.mart_cust_rides_daily"
[0m01:38:24.781233 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.mart_driver_loyalty_mgmt"
[0m01:38:24.785961 [debug] [Thread-1 (]: Began executing node model.hailing_project.mart_driver_loyalty_mgmt
[0m01:38:24.789818 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m01:38:24.790205 [debug] [Thread-4 (]: Began executing node model.hailing_project.mart_cust_rides_daily
[0m01:38:24.793760 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m01:38:25.063207 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.mart_driver_loyalty_mgmt"
[0m01:38:25.069317 [debug] [Thread-1 (]: On model.hailing_project.mart_driver_loyalty_mgmt: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.mart_driver_loyalty_mgmt"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_marts`.`mart_driver_loyalty_mgmt` as DBT_INTERNAL_DEST
        using (

WITH dim_driver AS(
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
),

fact_rides AS(
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
)

SELECT 
dim_driver.driver_id,
dim_driver.driver_name,
dim_driver.phone_number,
dim_driver.email,
dim_driver.vehicle_type,
COUNT(fact_rides.ride_id) AS no_of_rides,
SUM(TIMESTAMP_DIFF(fact_rides.ride_end_time, fact_rides.ride_start_time, MINUTE)) AS total_ride_duration_min,
SUM(fact_rides.fare) AS total_fare,
SUM(fact_rides.distance_km) as total_distance_km,
SUM(fact_rides.distance_km)-SUM(fact_rides.fare) AS rev_opportunity_loss,
FROM dim_driver
LEFT JOIN fact_rides
ON dim_driver.driver_id = fact_rides.driver_id

GROUP BY driver_id,driver_name,phone_number,email,vehicle_type
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`driver_name` = DBT_INTERNAL_SOURCE.`driver_name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`no_of_rides` = DBT_INTERNAL_SOURCE.`no_of_rides`,`total_ride_duration_min` = DBT_INTERNAL_SOURCE.`total_ride_duration_min`,`total_fare` = DBT_INTERNAL_SOURCE.`total_fare`,`total_distance_km` = DBT_INTERNAL_SOURCE.`total_distance_km`,`rev_opportunity_loss` = DBT_INTERNAL_SOURCE.`rev_opportunity_loss`
    

    when not matched then insert
        (`driver_id`, `driver_name`, `phone_number`, `email`, `vehicle_type`, `no_of_rides`, `total_ride_duration_min`, `total_fare`, `total_distance_km`, `rev_opportunity_loss`)
    values
        (`driver_id`, `driver_name`, `phone_number`, `email`, `vehicle_type`, `no_of_rides`, `total_ride_duration_min`, `total_fare`, `total_distance_km`, `rev_opportunity_loss`)


    
[0m01:38:25.102230 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.mart_cust_rides_daily"
[0m01:38:25.107974 [debug] [Thread-4 (]: On model.hailing_project.mart_cust_rides_daily: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.mart_cust_rides_daily"} */
-- back compat for old kwarg name
  
  
        
            
                
                
            
                
                
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_marts`.`mart_cust_rides_daily` as DBT_INTERNAL_DEST
        using (


WITH fact_rides AS(

    SELECT * 
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
)

SELECT 

    fact_rides.cust_id,
    DATE(fact_rides.created_at) AS ride_date,
    fact_rides.cust_name,
    fact_rides.cust_email,
    fact_rides.cust_phone_number,
    COUNT(fact_rides.ride_id) AS no_of_rides,
    SUM(TIMESTAMP_DIFF(fact_rides.ride_end_time, fact_rides.ride_start_time, MINUTE)) AS total_ride_duration_min,
    SUM(fact_rides.fare) AS total_fare,
    SUM(fact_rides.distance_km) as total_distance_km,
    SUM(fact_rides.distance_km)-SUM(fact_rides.fare) AS rev_opportunity_loss,

FROM fact_rides
GROUP BY cust_name, cust_id, ride_date, cust_email, cust_phone_number
        ) as DBT_INTERNAL_SOURCE
        on (
                    DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
                ) and (
                    DBT_INTERNAL_SOURCE.ride_date = DBT_INTERNAL_DEST.ride_date
                )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`ride_date` = DBT_INTERNAL_SOURCE.`ride_date`,`cust_name` = DBT_INTERNAL_SOURCE.`cust_name`,`cust_email` = DBT_INTERNAL_SOURCE.`cust_email`,`cust_phone_number` = DBT_INTERNAL_SOURCE.`cust_phone_number`,`no_of_rides` = DBT_INTERNAL_SOURCE.`no_of_rides`,`total_ride_duration_min` = DBT_INTERNAL_SOURCE.`total_ride_duration_min`,`total_fare` = DBT_INTERNAL_SOURCE.`total_fare`,`total_distance_km` = DBT_INTERNAL_SOURCE.`total_distance_km`,`rev_opportunity_loss` = DBT_INTERNAL_SOURCE.`rev_opportunity_loss`
    

    when not matched then insert
        (`cust_id`, `ride_date`, `cust_name`, `cust_email`, `cust_phone_number`, `no_of_rides`, `total_ride_duration_min`, `total_fare`, `total_distance_km`, `rev_opportunity_loss`)
    values
        (`cust_id`, `ride_date`, `cust_name`, `cust_email`, `cust_phone_number`, `no_of_rides`, `total_ride_duration_min`, `total_fare`, `total_distance_km`, `rev_opportunity_loss`)


    
[0m01:38:25.389215 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:a5a1f13e-b991-4467-a216-9c3231a24660&page=queryresults
[0m01:38:25.422827 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:0b3296eb-ae47-4af6-b1e3-9e45dac5ff21&page=queryresults
[0m01:38:26.968080 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '60b5fa52-0f32-45f6-90d8-964e966305b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f20f015d090>]}
[0m01:38:26.969314 [info ] [Thread-1 (]: 9 of 9 OK created sql incremental model rizky_dwh_hailing_marts.mart_driver_loyalty_mgmt  [[32mMERGE (105.0 rows, 24.2 KiB processed)[0m in 2.20s]
[0m01:38:26.971113 [debug] [Thread-1 (]: Finished running node model.hailing_project.mart_driver_loyalty_mgmt
[0m01:38:27.424941 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '60b5fa52-0f32-45f6-90d8-964e966305b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f20f0217290>]}
[0m01:38:27.426032 [info ] [Thread-4 (]: 8 of 9 OK created sql incremental model rizky_dwh_hailing_marts.mart_cust_rides_daily  [[32mMERGE (87.0 rows, 22.7 KiB processed)[0m in 2.66s]
[0m01:38:27.427332 [debug] [Thread-4 (]: Finished running node model.hailing_project.mart_cust_rides_daily
[0m01:38:27.430696 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m01:38:27.433990 [debug] [MainThread]: Connection 'master' was properly closed.
[0m01:38:27.434693 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m01:38:27.435418 [debug] [MainThread]: Connection 'model.hailing_project.fact_hailing_rides' was properly closed.
[0m01:38:27.436068 [debug] [MainThread]: Connection 'model.hailing_project.mart_driver_loyalty_mgmt' was properly closed.
[0m01:38:27.436688 [debug] [MainThread]: Connection 'model.hailing_project.mart_cust_rides_daily' was properly closed.
[0m01:38:27.437466 [info ] [MainThread]: 
[0m01:38:27.438446 [info ] [MainThread]: Finished running 9 incremental models in 0 hours 0 minutes and 11.22 seconds (11.22s).
[0m01:38:27.441002 [debug] [MainThread]: Command end result
[0m01:38:27.477349 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m01:38:27.481785 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m01:38:27.490031 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m01:38:27.491301 [info ] [MainThread]: 
[0m01:38:27.492516 [info ] [MainThread]: [32mCompleted successfully[0m
[0m01:38:27.493834 [info ] [MainThread]: 
[0m01:38:27.494929 [info ] [MainThread]: Done. PASS=9 WARN=0 ERROR=0 SKIP=0 TOTAL=9
[0m01:38:27.496494 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 12.525592, "process_in_blocks": "0", "process_kernel_time": 0.196466, "process_mem_max_rss": "220880", "process_out_blocks": "0", "process_user_time": 3.742688}
[0m01:38:27.497723 [debug] [MainThread]: Command `dbt run` succeeded at 01:38:27.497561 after 12.53 seconds
[0m01:38:27.498626 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f211f90b7d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f211f90b490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2123080c10>]}
[0m01:38:27.499595 [debug] [MainThread]: Flushing usage events
[0m01:38:28.774994 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m01:41:42.116391 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f97e0aef6d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f97e0aef290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f97e0aef8d0>]}


============================== 01:41:42.120197 | 1b81f9a5-83e7-4c5e-a550-4dd9194ff066 ==============================
[0m01:41:42.120197 [info ] [MainThread]: Running with dbt=1.9.0
[0m01:41:42.121722 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m01:41:42.702172 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1b81f9a5-83e7-4c5e-a550-4dd9194ff066', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f97b86835d0>]}
[0m01:41:42.745826 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '1b81f9a5-83e7-4c5e-a550-4dd9194ff066', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f97e2d64910>]}
[0m01:41:42.747406 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m01:41:42.817821 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m01:41:43.012175 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m01:41:43.013093 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m01:41:43.041317 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1b81f9a5-83e7-4c5e-a550-4dd9194ff066', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f97b2cc00d0>]}
[0m01:41:43.156586 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m01:41:43.162330 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m01:41:43.180207 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1b81f9a5-83e7-4c5e-a550-4dd9194ff066', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f97b28bcc50>]}
[0m01:41:43.181422 [info ] [MainThread]: Found 9 models, 8 sources, 489 macros
[0m01:41:43.182644 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1b81f9a5-83e7-4c5e-a550-4dd9194ff066', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f97b2a20d10>]}
[0m01:41:43.185168 [info ] [MainThread]: 
[0m01:41:43.186150 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m01:41:43.187119 [info ] [MainThread]: 
[0m01:41:43.188457 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m01:41:43.194125 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m01:41:43.194717 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m01:41:43.195257 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m01:41:43.195933 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:41:43.196691 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:41:43.197439 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:41:44.097173 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_marts)
[0m01:41:44.097782 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_staging)
[0m01:41:44.098358 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_facts)
[0m01:41:44.099859 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m01:41:44.100986 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m01:41:44.102361 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m01:41:44.365547 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1b81f9a5-83e7-4c5e-a550-4dd9194ff066', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f97e18b4f50>]}
[0m01:41:44.366943 [debug] [MainThread]: Opening a new connection, currently in state init
[0m01:41:44.372103 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m01:41:44.372522 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m01:41:44.372900 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m01:41:44.373233 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m01:41:44.374233 [info ] [Thread-1 (]: 1 of 9 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [RUN]
[0m01:41:44.376061 [info ] [Thread-2 (]: 2 of 9 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [RUN]
[0m01:41:44.377269 [info ] [Thread-3 (]: 3 of 9 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [RUN]
[0m01:41:44.378430 [info ] [Thread-4 (]: 4 of 9 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [RUN]
[0m01:41:44.379882 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_facts, now model.hailing_project.production_hailing_staging_customer)
[0m01:41:44.381313 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_marts, now model.hailing_project.production_hailing_staging_driver)
[0m01:41:44.382421 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_staging, now model.hailing_project.production_hailing_staging_ride)
[0m01:41:44.383659 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_vehicle'
[0m01:41:44.384844 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m01:41:44.385751 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m01:41:44.386624 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m01:41:44.387552 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m01:41:44.404748 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m01:41:44.410451 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m01:41:44.416491 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m01:41:44.422082 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m01:41:44.428343 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m01:41:44.428854 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m01:41:44.429600 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m01:41:44.435187 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m01:41:44.476495 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m01:41:44.477540 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m01:41:44.480186 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m01:41:44.483537 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m01:41:44.788613 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m01:41:44.790538 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m01:41:44.791721 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m01:41:44.794117 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m01:41:44.799632 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m01:41:44.800166 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m01:41:44.802233 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m01:41:44.803144 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m01:41:45.052775 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:78877f7a-8868-43da-934f-d3c0676a6410&page=queryresults
[0m01:41:45.059419 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:8ae3dc7c-de26-4141-a615-97c7257d77f6&page=queryresults
[0m01:41:45.062811 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:6feda772-c21e-4bfb-89a1-d1169b09fcd5&page=queryresults
[0m01:41:45.082780 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:7228b964-a5df-4066-965f-9019c4277d8c&page=queryresults
[0m01:41:46.785137 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1b81f9a5-83e7-4c5e-a550-4dd9194ff066', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f97b2f71790>]}
[0m01:41:46.786230 [info ] [Thread-2 (]: 2 of 9 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [[32mMERGE (5.0 rows, 14.5 KiB processed)[0m in 2.40s]
[0m01:41:46.787684 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m01:41:46.860648 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1b81f9a5-83e7-4c5e-a550-4dd9194ff066', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f979af0ef90>]}
[0m01:41:46.861741 [info ] [Thread-4 (]: 4 of 9 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [[32mMERGE (5.0 rows, 11.8 KiB processed)[0m in 2.48s]
[0m01:41:46.862935 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m01:41:46.864151 [debug] [Thread-2 (]: Began running node model.hailing_project.dim_driver
[0m01:41:46.865023 [info ] [Thread-2 (]: 5 of 9 START sql incremental model rizky_dwh_hailing_facts.dim_driver .......... [RUN]
[0m01:41:46.866058 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_driver, now model.hailing_project.dim_driver)
[0m01:41:46.866896 [debug] [Thread-2 (]: Began compiling node model.hailing_project.dim_driver
[0m01:41:46.871862 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.dim_driver"
[0m01:41:46.879720 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1b81f9a5-83e7-4c5e-a550-4dd9194ff066', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f97b2ca2c10>]}
[0m01:41:46.882279 [debug] [Thread-2 (]: Began executing node model.hailing_project.dim_driver
[0m01:41:46.881812 [info ] [Thread-1 (]: 1 of 9 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [[32mMERGE (5.0 rows, 14.6 KiB processed)[0m in 2.50s]
[0m01:41:46.885992 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m01:41:46.887110 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m01:41:46.889542 [debug] [Thread-4 (]: Began running node model.hailing_project.dim_customer
[0m01:41:46.913197 [info ] [Thread-4 (]: 6 of 9 START sql incremental model rizky_dwh_hailing_facts.dim_customer ........ [RUN]
[0m01:41:46.915751 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_vehicle, now model.hailing_project.dim_customer)
[0m01:41:46.916974 [debug] [Thread-4 (]: Began compiling node model.hailing_project.dim_customer
[0m01:41:46.921672 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m01:41:46.927766 [debug] [Thread-4 (]: Began executing node model.hailing_project.dim_customer
[0m01:41:46.931601 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m01:41:47.150932 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.dim_driver"
[0m01:41:47.159156 [debug] [Thread-2 (]: On model.hailing_project.dim_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver` as DBT_INTERNAL_DEST
        using (


WITH driver AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver` --pakai ref untuk buat dependency

),

vehicle AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle`
)

SELECT
    driver.driver_id,
    vehicle.vehicle_id,
    driver.name AS driver_name,
    driver.phone_number AS phone_number,
    driver.email AS email,
    vehicle.vehicle_type,
    vehicle.brand AS vehicle_brand,
    vehicle.year AS vehicle_production_year,
    vehicle.license_plate,
    driver.created_at
FROM driver
LEFT JOIN vehicle
on driver.driver_id = vehicle.driver_id


    WHERE driver.created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_name` = DBT_INTERNAL_SOURCE.`driver_name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`vehicle_brand` = DBT_INTERNAL_SOURCE.`vehicle_brand`,`vehicle_production_year` = DBT_INTERNAL_SOURCE.`vehicle_production_year`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `vehicle_id`, `driver_name`, `phone_number`, `email`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)
    values
        (`driver_id`, `vehicle_id`, `driver_name`, `phone_number`, `email`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)


    
[0m01:41:47.170676 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m01:41:47.176698 [debug] [Thread-4 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
)

SELECT * FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m01:41:47.400295 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:39e2ba6a-44c8-4183-8556-62b7de1cb4b4&page=queryresults
[0m01:41:47.453340 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:39fc35a1-0e8a-4e83-9865-f53f523a4b58&page=queryresults
[0m01:41:47.731240 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1b81f9a5-83e7-4c5e-a550-4dd9194ff066', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f97b28ac050>]}
[0m01:41:47.733264 [info ] [Thread-3 (]: 3 of 9 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [[32mMERGE (5.0 rows, 19.1 KiB processed)[0m in 3.35s]
[0m01:41:47.735020 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m01:41:49.199797 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1b81f9a5-83e7-4c5e-a550-4dd9194ff066', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f97b2c85a50>]}
[0m01:41:49.202085 [info ] [Thread-2 (]: 5 of 9 OK created sql incremental model rizky_dwh_hailing_facts.dim_driver ..... [[32mMERGE (5.0 rows, 23.7 KiB processed)[0m in 2.33s]
[0m01:41:49.204365 [debug] [Thread-2 (]: Finished running node model.hailing_project.dim_driver
[0m01:41:49.275475 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1b81f9a5-83e7-4c5e-a550-4dd9194ff066', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f979ab46450>]}
[0m01:41:49.276746 [info ] [Thread-4 (]: 6 of 9 OK created sql incremental model rizky_dwh_hailing_facts.dim_customer ... [[32mMERGE (5.0 rows, 14.4 KiB processed)[0m in 2.36s]
[0m01:41:49.278392 [debug] [Thread-4 (]: Finished running node model.hailing_project.dim_customer
[0m01:41:49.279907 [debug] [Thread-1 (]: Began running node model.hailing_project.fact_hailing_rides
[0m01:41:49.280914 [info ] [Thread-1 (]: 7 of 9 START sql incremental model rizky_dwh_hailing_facts.fact_hailing_rides .. [RUN]
[0m01:41:49.281995 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_customer, now model.hailing_project.fact_hailing_rides)
[0m01:41:49.282902 [debug] [Thread-1 (]: Began compiling node model.hailing_project.fact_hailing_rides
[0m01:41:49.288274 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.fact_hailing_rides"
[0m01:41:49.296823 [debug] [Thread-1 (]: Began executing node model.hailing_project.fact_hailing_rides
[0m01:41:49.301097 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m01:41:49.718100 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.fact_hailing_rides"
[0m01:41:49.726276 [debug] [Thread-1 (]: On model.hailing_project.fact_hailing_rides: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.fact_hailing_rides"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides` as DBT_INTERNAL_DEST
        using (

WITH dim_driver AS (

    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
),

dim_customer AS (

    SELECT * 
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer`
),

ride_staging AS (

    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride`
)

SELECT
ride_staging.ride_id,
ride_staging.start_time AS ride_start_time,
ride_staging.end_time AS ride_end_time,
ride_staging.distance_km,
ride_staging.fare,
ride_staging.ride_status,
dim_customer.cust_id,
dim_customer.name AS cust_name,
dim_customer.phone_number AS cust_phone_number,
dim_customer.email AS cust_email,
dim_driver.driver_id,
dim_driver.driver_name,
dim_driver.phone_number AS driver_phone_number,
dim_driver.email AS driver_email,
dim_driver.vehicle_id,
dim_driver.vehicle_type,
dim_driver.vehicle_brand,
dim_driver.vehicle_production_year,
dim_driver.license_plate,
ride_staging.created_at

FROM ride_staging

LEFT JOIN dim_customer
on ride_staging.cust_id = dim_customer.cust_id

LEFT JOIN dim_driver
on ride_staging.driver_id = dim_driver.driver_id


    WHERE ride_staging.created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`ride_start_time` = DBT_INTERNAL_SOURCE.`ride_start_time`,`ride_end_time` = DBT_INTERNAL_SOURCE.`ride_end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`cust_name` = DBT_INTERNAL_SOURCE.`cust_name`,`cust_phone_number` = DBT_INTERNAL_SOURCE.`cust_phone_number`,`cust_email` = DBT_INTERNAL_SOURCE.`cust_email`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`driver_name` = DBT_INTERNAL_SOURCE.`driver_name`,`driver_phone_number` = DBT_INTERNAL_SOURCE.`driver_phone_number`,`driver_email` = DBT_INTERNAL_SOURCE.`driver_email`,`vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`vehicle_brand` = DBT_INTERNAL_SOURCE.`vehicle_brand`,`vehicle_production_year` = DBT_INTERNAL_SOURCE.`vehicle_production_year`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `ride_start_time`, `ride_end_time`, `distance_km`, `fare`, `ride_status`, `cust_id`, `cust_name`, `cust_phone_number`, `cust_email`, `driver_id`, `driver_name`, `driver_phone_number`, `driver_email`, `vehicle_id`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)
    values
        (`ride_id`, `ride_start_time`, `ride_end_time`, `distance_km`, `fare`, `ride_status`, `cust_id`, `cust_name`, `cust_phone_number`, `cust_email`, `driver_id`, `driver_name`, `driver_phone_number`, `driver_email`, `vehicle_id`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)


    
[0m01:41:49.950971 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:bbb49de0-c323-4487-b912-8c6a81db1732&page=queryresults
[0m01:41:51.740659 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1b81f9a5-83e7-4c5e-a550-4dd9194ff066', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f979ab9da10>]}
[0m01:41:51.742108 [info ] [Thread-1 (]: 7 of 9 OK created sql incremental model rizky_dwh_hailing_facts.fact_hailing_rides  [[32mMERGE (5.0 rows, 51.2 KiB processed)[0m in 2.46s]
[0m01:41:51.743607 [debug] [Thread-1 (]: Finished running node model.hailing_project.fact_hailing_rides
[0m01:41:51.745366 [debug] [Thread-2 (]: Began running node model.hailing_project.mart_cust_rides_daily
[0m01:41:51.745815 [debug] [Thread-4 (]: Began running node model.hailing_project.mart_driver_loyalty_mgmt
[0m01:41:51.746520 [info ] [Thread-2 (]: 8 of 9 START sql incremental model rizky_dwh_hailing_marts.mart_cust_rides_daily  [RUN]
[0m01:41:51.747946 [info ] [Thread-4 (]: 9 of 9 START sql incremental model rizky_dwh_hailing_marts.mart_driver_loyalty_mgmt  [RUN]
[0m01:41:51.749068 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.hailing_project.dim_driver, now model.hailing_project.mart_cust_rides_daily)
[0m01:41:51.750542 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.hailing_project.dim_customer, now model.hailing_project.mart_driver_loyalty_mgmt)
[0m01:41:51.751947 [debug] [Thread-2 (]: Began compiling node model.hailing_project.mart_cust_rides_daily
[0m01:41:51.753034 [debug] [Thread-4 (]: Began compiling node model.hailing_project.mart_driver_loyalty_mgmt
[0m01:41:51.757655 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.mart_cust_rides_daily"
[0m01:41:51.762861 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.mart_driver_loyalty_mgmt"
[0m01:41:51.767310 [debug] [Thread-2 (]: Began executing node model.hailing_project.mart_cust_rides_daily
[0m01:41:51.772521 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m01:41:51.772931 [debug] [Thread-4 (]: Began executing node model.hailing_project.mart_driver_loyalty_mgmt
[0m01:41:51.776260 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m01:41:52.029223 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.mart_driver_loyalty_mgmt"
[0m01:41:52.031079 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.mart_cust_rides_daily"
[0m01:41:52.035374 [debug] [Thread-4 (]: On model.hailing_project.mart_driver_loyalty_mgmt: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.mart_driver_loyalty_mgmt"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_marts`.`mart_driver_loyalty_mgmt` as DBT_INTERNAL_DEST
        using (

WITH dim_driver AS(
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
),

fact_rides AS(
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
)

SELECT 
dim_driver.driver_id,
dim_driver.driver_name,
dim_driver.phone_number,
dim_driver.email,
dim_driver.vehicle_type,
COUNT(fact_rides.ride_id) AS no_of_rides,
SUM(TIMESTAMP_DIFF(fact_rides.ride_end_time, fact_rides.ride_start_time, MINUTE)) AS total_ride_duration_min,
SUM(fact_rides.fare) AS total_fare,
SUM(fact_rides.distance_km) as total_distance_km,
SUM(fact_rides.distance_km)-SUM(fact_rides.fare) AS rev_opportunity_loss,
FROM dim_driver
LEFT JOIN fact_rides
ON dim_driver.driver_id = fact_rides.driver_id

GROUP BY driver_id,driver_name,phone_number,email,vehicle_type
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`driver_name` = DBT_INTERNAL_SOURCE.`driver_name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`no_of_rides` = DBT_INTERNAL_SOURCE.`no_of_rides`,`total_ride_duration_min` = DBT_INTERNAL_SOURCE.`total_ride_duration_min`,`total_fare` = DBT_INTERNAL_SOURCE.`total_fare`,`total_distance_km` = DBT_INTERNAL_SOURCE.`total_distance_km`,`rev_opportunity_loss` = DBT_INTERNAL_SOURCE.`rev_opportunity_loss`
    

    when not matched then insert
        (`driver_id`, `driver_name`, `phone_number`, `email`, `vehicle_type`, `no_of_rides`, `total_ride_duration_min`, `total_fare`, `total_distance_km`, `rev_opportunity_loss`)
    values
        (`driver_id`, `driver_name`, `phone_number`, `email`, `vehicle_type`, `no_of_rides`, `total_ride_duration_min`, `total_fare`, `total_distance_km`, `rev_opportunity_loss`)


    
[0m01:41:52.036058 [debug] [Thread-2 (]: On model.hailing_project.mart_cust_rides_daily: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.mart_cust_rides_daily"} */
-- back compat for old kwarg name
  
  
        
            
                
                
            
                
                
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_marts`.`mart_cust_rides_daily` as DBT_INTERNAL_DEST
        using (


WITH fact_rides AS(

    SELECT * 
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
)

SELECT 

    fact_rides.cust_id,
    DATE(fact_rides.created_at) AS ride_date,
    fact_rides.cust_name,
    fact_rides.cust_email,
    fact_rides.cust_phone_number,
    COUNT(fact_rides.ride_id) AS no_of_rides,
    SUM(TIMESTAMP_DIFF(fact_rides.ride_end_time, fact_rides.ride_start_time, MINUTE)) AS total_ride_duration_min,
    SUM(fact_rides.fare) AS total_fare,
    SUM(fact_rides.distance_km) as total_distance_km,
    SUM(fact_rides.distance_km)-SUM(fact_rides.fare) AS rev_opportunity_loss,

FROM fact_rides
GROUP BY cust_name, cust_id, ride_date, cust_email, cust_phone_number
        ) as DBT_INTERNAL_SOURCE
        on (
                    DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
                ) and (
                    DBT_INTERNAL_SOURCE.ride_date = DBT_INTERNAL_DEST.ride_date
                )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`ride_date` = DBT_INTERNAL_SOURCE.`ride_date`,`cust_name` = DBT_INTERNAL_SOURCE.`cust_name`,`cust_email` = DBT_INTERNAL_SOURCE.`cust_email`,`cust_phone_number` = DBT_INTERNAL_SOURCE.`cust_phone_number`,`no_of_rides` = DBT_INTERNAL_SOURCE.`no_of_rides`,`total_ride_duration_min` = DBT_INTERNAL_SOURCE.`total_ride_duration_min`,`total_fare` = DBT_INTERNAL_SOURCE.`total_fare`,`total_distance_km` = DBT_INTERNAL_SOURCE.`total_distance_km`,`rev_opportunity_loss` = DBT_INTERNAL_SOURCE.`rev_opportunity_loss`
    

    when not matched then insert
        (`cust_id`, `ride_date`, `cust_name`, `cust_email`, `cust_phone_number`, `no_of_rides`, `total_ride_duration_min`, `total_fare`, `total_distance_km`, `rev_opportunity_loss`)
    values
        (`cust_id`, `ride_date`, `cust_name`, `cust_email`, `cust_phone_number`, `no_of_rides`, `total_ride_duration_min`, `total_fare`, `total_distance_km`, `rev_opportunity_loss`)


    
[0m01:41:52.267586 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:e426a95e-f7c0-452b-8799-afd3f1b3f163&page=queryresults
[0m01:41:52.274799 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:85d0380a-24b3-4cb0-b7f6-7e4baa554c4a&page=queryresults
[0m01:41:53.834057 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1b81f9a5-83e7-4c5e-a550-4dd9194ff066', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f979ab9a350>]}
[0m01:41:53.835429 [info ] [Thread-4 (]: 9 of 9 OK created sql incremental model rizky_dwh_hailing_marts.mart_driver_loyalty_mgmt  [[32mMERGE (110.0 rows, 25.0 KiB processed)[0m in 2.08s]
[0m01:41:53.836958 [debug] [Thread-4 (]: Finished running node model.hailing_project.mart_driver_loyalty_mgmt
[0m01:41:54.354823 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1b81f9a5-83e7-4c5e-a550-4dd9194ff066', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f979ab99990>]}
[0m01:41:54.356224 [info ] [Thread-2 (]: 8 of 9 OK created sql incremental model rizky_dwh_hailing_marts.mart_cust_rides_daily  [[32mMERGE (91.0 rows, 24.5 KiB processed)[0m in 2.61s]
[0m01:41:54.357720 [debug] [Thread-2 (]: Finished running node model.hailing_project.mart_cust_rides_daily
[0m01:41:54.359928 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m01:41:54.363042 [debug] [MainThread]: Connection 'master' was properly closed.
[0m01:41:54.363925 [debug] [MainThread]: Connection 'model.hailing_project.fact_hailing_rides' was properly closed.
[0m01:41:54.364810 [debug] [MainThread]: Connection 'model.hailing_project.mart_cust_rides_daily' was properly closed.
[0m01:41:54.365584 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m01:41:54.366591 [debug] [MainThread]: Connection 'model.hailing_project.mart_driver_loyalty_mgmt' was properly closed.
[0m01:41:54.367713 [info ] [MainThread]: 
[0m01:41:54.368608 [info ] [MainThread]: Finished running 9 incremental models in 0 hours 0 minutes and 11.18 seconds (11.18s).
[0m01:41:54.370938 [debug] [MainThread]: Command end result
[0m01:41:54.411948 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m01:41:54.418287 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m01:41:54.431369 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m01:41:54.432414 [info ] [MainThread]: 
[0m01:41:54.433628 [info ] [MainThread]: [32mCompleted successfully[0m
[0m01:41:54.434864 [info ] [MainThread]: 
[0m01:41:54.435890 [info ] [MainThread]: Done. PASS=9 WARN=0 ERROR=0 SKIP=0 TOTAL=9
[0m01:41:54.437468 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 12.374568, "process_in_blocks": "0", "process_kernel_time": 0.235307, "process_mem_max_rss": "222120", "process_out_blocks": "0", "process_user_time": 3.68308}
[0m01:41:54.438664 [debug] [MainThread]: Command `dbt run` succeeded at 01:41:54.438510 after 12.38 seconds
[0m01:41:54.439606 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f97e1004b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f97e42e4c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f97e4468a10>]}
[0m01:41:54.440570 [debug] [MainThread]: Flushing usage events
[0m01:41:55.757882 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m08:41:05.486144 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f998b126cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f998b177e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f998be07410>]}


============================== 08:41:05.488732 | f4d2b075-5ba1-42b9-828f-6b7c18ee8d80 ==============================
[0m08:41:05.488732 [info ] [MainThread]: Running with dbt=1.9.0
[0m08:41:05.490701 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/usr/app/dbt/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt debug', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m08:41:05.504234 [info ] [MainThread]: dbt version: 1.9.0
[0m08:41:05.507568 [info ] [MainThread]: python version: 3.11.2
[0m08:41:05.508708 [info ] [MainThread]: python path: /usr/local/bin/python
[0m08:41:05.510129 [info ] [MainThread]: os info: Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.31
[0m08:41:06.008381 [info ] [MainThread]: Using profiles dir at /usr/app/dbt
[0m08:41:06.009664 [info ] [MainThread]: Using profiles.yml file at /usr/app/dbt/profiles.yml
[0m08:41:06.010772 [info ] [MainThread]: Using dbt_project.yml file at /usr/app/dbt/dbt_project.yml
[0m08:41:06.011729 [info ] [MainThread]: adapter type: bigquery
[0m08:41:06.012621 [info ] [MainThread]: adapter version: 1.9.0
[0m08:41:06.091242 [info ] [MainThread]: Configuration:
[0m08:41:06.092322 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m08:41:06.093322 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m08:41:06.094656 [info ] [MainThread]: Required dependencies:
[0m08:41:06.095689 [debug] [MainThread]: Executing "git --help"
[0m08:41:06.098625 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m08:41:06.099564 [debug] [MainThread]: STDERR: "b''"
[0m08:41:06.100435 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m08:41:06.101552 [info ] [MainThread]: Connection:
[0m08:41:06.102548 [info ] [MainThread]:   method: service-account
[0m08:41:06.103976 [info ] [MainThread]:   database: purwadika
[0m08:41:06.105067 [info ] [MainThread]:   execution_project: purwadika
[0m08:41:06.106033 [info ] [MainThread]:   schema: rizky_dwh_hailing_source
[0m08:41:06.106969 [info ] [MainThread]:   location: None
[0m08:41:06.107936 [info ] [MainThread]:   priority: None
[0m08:41:06.109041 [info ] [MainThread]:   maximum_bytes_billed: None
[0m08:41:06.110429 [info ] [MainThread]:   impersonate_service_account: None
[0m08:41:06.111940 [info ] [MainThread]:   job_retry_deadline_seconds: None
[0m08:41:06.113361 [info ] [MainThread]:   job_retries: 1
[0m08:41:06.114620 [info ] [MainThread]:   job_creation_timeout_seconds: None
[0m08:41:06.115654 [info ] [MainThread]:   job_execution_timeout_seconds: None
[0m08:41:06.116746 [info ] [MainThread]:   timeout_seconds: None
[0m08:41:06.118565 [info ] [MainThread]:   client_id: None
[0m08:41:06.120014 [info ] [MainThread]:   token_uri: None
[0m08:41:06.121386 [info ] [MainThread]:   dataproc_region: None
[0m08:41:06.122469 [info ] [MainThread]:   dataproc_cluster_name: None
[0m08:41:06.123430 [info ] [MainThread]:   gcs_bucket: None
[0m08:41:06.124791 [info ] [MainThread]:   dataproc_batch: None
[0m08:41:06.126311 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m08:41:06.199911 [debug] [MainThread]: Acquiring new bigquery connection 'debug'
[0m08:41:06.201181 [debug] [MainThread]: On debug: select 1 as id
[0m08:41:06.202289 [debug] [MainThread]: Opening a new connection, currently in state init
[0m08:41:06.203696 [debug] [MainThread]: BigQuery adapter: Got an error when attempting to create a bigquery " "client: '[Errno 2] No such file or directory: '/root/.dbt/credentials.json''
[0m08:41:06.204461 [debug] [MainThread]: BigQuery adapter: Unhandled error while running:
select 1 as id
[0m08:41:06.205176 [debug] [MainThread]: BigQuery adapter: Database Error
  [Errno 2] No such file or directory: '/root/.dbt/credentials.json'
[0m08:41:06.205830 [info ] [MainThread]:   Connection test: [[31mERROR[0m]

[0m08:41:06.206630 [info ] [MainThread]: [31m1 check failed:[0m
[0m08:41:06.207664 [info ] [MainThread]: dbt was unable to connect to the specified database.
The database returned the following error:

  >'NoneType' object has no attribute 'close'

Check your database credentials and try again. For more information, visit:
https://docs.getdbt.com/docs/configure-your-profile


[0m08:41:06.209416 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": false, "command_wall_clock_time": 0.7710412, "process_in_blocks": "344", "process_kernel_time": 0.140794, "process_mem_max_rss": "207460", "process_out_blocks": "24", "process_user_time": 2.705268}
[0m08:41:06.210613 [debug] [MainThread]: Command `dbt debug` failed at 08:41:06.210506 after 0.77 seconds
[0m08:41:06.211590 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f998b177e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f998b17e710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f998ea75150>]}
[0m08:41:06.212263 [debug] [MainThread]: Flushing usage events
[0m08:41:07.615743 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m08:43:24.838731 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f10f6d63e10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f10f79fb410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f10f7228a90>]}


============================== 08:43:24.842045 | 8d5385b4-aba1-4242-966a-dd4e7baacfce ==============================
[0m08:43:24.842045 [info ] [MainThread]: Running with dbt=1.9.0
[0m08:43:24.843293 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/usr/app/dbt/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt debug', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m08:43:24.850110 [info ] [MainThread]: dbt version: 1.9.0
[0m08:43:24.851537 [info ] [MainThread]: python version: 3.11.2
[0m08:43:24.853109 [info ] [MainThread]: python path: /usr/local/bin/python
[0m08:43:24.854601 [info ] [MainThread]: os info: Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.31
[0m08:43:25.365722 [info ] [MainThread]: Using profiles dir at /usr/app/dbt
[0m08:43:25.367039 [info ] [MainThread]: Using profiles.yml file at /usr/app/dbt/profiles.yml
[0m08:43:25.368176 [info ] [MainThread]: Using dbt_project.yml file at /usr/app/dbt/dbt_project.yml
[0m08:43:25.369548 [info ] [MainThread]: adapter type: bigquery
[0m08:43:25.370563 [info ] [MainThread]: adapter version: 1.9.0
[0m08:43:25.452296 [info ] [MainThread]: Configuration:
[0m08:43:25.453708 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m08:43:25.454762 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m08:43:25.456252 [info ] [MainThread]: Required dependencies:
[0m08:43:25.457750 [debug] [MainThread]: Executing "git --help"
[0m08:43:25.460042 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m08:43:25.461174 [debug] [MainThread]: STDERR: "b''"
[0m08:43:25.462178 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m08:43:25.463208 [info ] [MainThread]: Connection:
[0m08:43:25.464634 [info ] [MainThread]:   method: service-account
[0m08:43:25.465924 [info ] [MainThread]:   database: purwadika
[0m08:43:25.466990 [info ] [MainThread]:   execution_project: purwadika
[0m08:43:25.467897 [info ] [MainThread]:   schema: rizky_dwh_hailing_source
[0m08:43:25.469472 [info ] [MainThread]:   location: None
[0m08:43:25.470706 [info ] [MainThread]:   priority: None
[0m08:43:25.471890 [info ] [MainThread]:   maximum_bytes_billed: None
[0m08:43:25.472955 [info ] [MainThread]:   impersonate_service_account: None
[0m08:43:25.474019 [info ] [MainThread]:   job_retry_deadline_seconds: None
[0m08:43:25.475435 [info ] [MainThread]:   job_retries: 1
[0m08:43:25.476670 [info ] [MainThread]:   job_creation_timeout_seconds: None
[0m08:43:25.478217 [info ] [MainThread]:   job_execution_timeout_seconds: None
[0m08:43:25.479352 [info ] [MainThread]:   timeout_seconds: None
[0m08:43:25.480322 [info ] [MainThread]:   client_id: None
[0m08:43:25.481471 [info ] [MainThread]:   token_uri: None
[0m08:43:25.482819 [info ] [MainThread]:   dataproc_region: None
[0m08:43:25.484093 [info ] [MainThread]:   dataproc_cluster_name: None
[0m08:43:25.485265 [info ] [MainThread]:   gcs_bucket: None
[0m08:43:25.486432 [info ] [MainThread]:   dataproc_batch: None
[0m08:43:25.487443 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m08:43:25.548259 [debug] [MainThread]: Acquiring new bigquery connection 'debug'
[0m08:43:25.549336 [debug] [MainThread]: On debug: select 1 as id
[0m08:43:25.550223 [debug] [MainThread]: Opening a new connection, currently in state init
[0m08:43:26.206474 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:89c3a74e-aaba-470b-ad3b-a8507b2f874b&page=queryresults
[0m08:43:26.986698 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m08:43:26.988184 [info ] [MainThread]: [32mAll checks passed![0m
[0m08:43:26.990675 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": true, "command_wall_clock_time": 2.2057903, "process_in_blocks": "1176", "process_kernel_time": 0.160165, "process_mem_max_rss": "212224", "process_out_blocks": "0", "process_user_time": 2.712806}
[0m08:43:26.992245 [debug] [MainThread]: Command `dbt debug` succeeded at 08:43:26.992085 after 2.21 seconds
[0m08:43:26.993503 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m08:43:26.994456 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f10f7111f90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f10ce996bd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f10cce46d50>]}
[0m08:43:26.995267 [debug] [MainThread]: Flushing usage events
[0m08:43:28.077534 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m08:43:45.703538 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4a0b372990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4a0b373850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4a0b373610>]}


============================== 08:43:45.707112 | 77e41b03-1d24-4e7c-ab17-61ea395bcf0e ==============================
[0m08:43:45.707112 [info ] [MainThread]: Running with dbt=1.9.0
[0m08:43:45.708911 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt/logs', 'profiles_dir': '/usr/app/dbt', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m08:43:46.302410 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '77e41b03-1d24-4e7c-ab17-61ea395bcf0e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f49dd582ed0>]}
[0m08:43:46.349046 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '77e41b03-1d24-4e7c-ab17-61ea395bcf0e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4a0d5ea390>]}
[0m08:43:46.350705 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m08:43:46.420884 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m08:43:46.636644 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m08:43:46.637581 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m08:43:46.668068 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '77e41b03-1d24-4e7c-ab17-61ea395bcf0e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f49dd247090>]}
[0m08:43:46.792805 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt/target/manifest.json
[0m08:43:46.799883 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt/target/semantic_manifest.json
[0m08:43:46.823741 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '77e41b03-1d24-4e7c-ab17-61ea395bcf0e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f49dd17a490>]}
[0m08:43:46.825180 [info ] [MainThread]: Found 9 models, 8 sources, 489 macros
[0m08:43:46.826255 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '77e41b03-1d24-4e7c-ab17-61ea395bcf0e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4a0d5e6550>]}
[0m08:43:46.829112 [info ] [MainThread]: 
[0m08:43:46.830336 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m08:43:46.831676 [info ] [MainThread]: 
[0m08:43:46.833276 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m08:43:46.838571 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m08:43:46.839390 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m08:43:46.840777 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m08:43:46.841666 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:43:46.842599 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:43:46.843347 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:43:47.759279 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_staging)
[0m08:43:47.759849 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_facts)
[0m08:43:47.760359 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_marts)
[0m08:43:47.761042 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:43:47.762945 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:43:47.763840 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:43:48.044740 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '77e41b03-1d24-4e7c-ab17-61ea395bcf0e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f49df0e6b10>]}
[0m08:43:48.046015 [debug] [MainThread]: Opening a new connection, currently in state init
[0m08:43:48.050664 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m08:43:48.051006 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m08:43:48.051382 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m08:43:48.051769 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m08:43:48.052284 [info ] [Thread-1 (]: 1 of 9 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [RUN]
[0m08:43:48.053344 [info ] [Thread-2 (]: 2 of 9 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [RUN]
[0m08:43:48.054743 [info ] [Thread-3 (]: 3 of 9 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [RUN]
[0m08:43:48.055986 [info ] [Thread-4 (]: 4 of 9 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [RUN]
[0m08:43:48.057046 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_staging, now model.hailing_project.production_hailing_staging_customer)
[0m08:43:48.057873 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_facts, now model.hailing_project.production_hailing_staging_driver)
[0m08:43:48.058721 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_marts, now model.hailing_project.production_hailing_staging_ride)
[0m08:43:48.059522 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_vehicle'
[0m08:43:48.060403 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m08:43:48.061427 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m08:43:48.062190 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m08:43:48.062920 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m08:43:48.078516 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m08:43:48.082405 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m08:43:48.086797 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m08:43:48.090887 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m08:43:48.096756 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m08:43:48.097997 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m08:43:48.098509 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m08:43:48.104286 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m08:43:48.150245 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m08:43:48.152617 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m08:43:48.155396 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m08:43:48.158726 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m08:43:48.459642 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m08:43:48.464334 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m08:43:48.467990 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m08:43:48.469292 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m08:43:48.477404 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m08:43:48.480166 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m08:43:48.481587 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m08:43:48.482395 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m08:43:48.742825 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:42a0205b-3ddc-478e-8e31-9aaf572df288&page=queryresults
[0m08:43:48.754715 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:68fb4e05-675c-4275-a3c3-08ac4e09a8e4&page=queryresults
[0m08:43:48.778054 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:d76aa11f-17a9-4b8a-bd13-ef630a7c25ce&page=queryresults
[0m08:43:48.822674 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:6a1872fb-b5be-4387-990e-0fcef2df7462&page=queryresults
[0m08:43:50.634880 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '77e41b03-1d24-4e7c-ab17-61ea395bcf0e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f49dd179310>]}
[0m08:43:50.635265 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '77e41b03-1d24-4e7c-ab17-61ea395bcf0e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f49d5588a90>]}
[0m08:43:50.635693 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '77e41b03-1d24-4e7c-ab17-61ea395bcf0e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f49dd6aca90>]}
[0m08:43:50.636782 [info ] [Thread-2 (]: 2 of 9 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [[32mMERGE (6.0 rows, 15.2 KiB processed)[0m in 2.57s]
[0m08:43:50.638414 [info ] [Thread-1 (]: 1 of 9 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [[32mMERGE (6.0 rows, 15.3 KiB processed)[0m in 2.58s]
[0m08:43:50.639890 [info ] [Thread-4 (]: 4 of 9 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [[32mMERGE (6.0 rows, 12.5 KiB processed)[0m in 2.57s]
[0m08:43:50.641395 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m08:43:50.642625 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m08:43:50.643694 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m08:43:50.646449 [debug] [Thread-2 (]: Began running node model.hailing_project.dim_customer
[0m08:43:50.647349 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_driver
[0m08:43:50.648176 [info ] [Thread-2 (]: 5 of 9 START sql incremental model rizky_dwh_hailing_facts.dim_customer ........ [RUN]
[0m08:43:50.649661 [info ] [Thread-1 (]: 6 of 9 START sql incremental model rizky_dwh_hailing_facts.dim_driver .......... [RUN]
[0m08:43:50.651307 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_driver, now model.hailing_project.dim_customer)
[0m08:43:50.652491 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_customer, now model.hailing_project.dim_driver)
[0m08:43:50.653673 [debug] [Thread-2 (]: Began compiling node model.hailing_project.dim_customer
[0m08:43:50.654638 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_driver
[0m08:43:50.659772 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m08:43:50.664115 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_driver"
[0m08:43:50.670103 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_driver
[0m08:43:50.674992 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m08:43:50.675542 [debug] [Thread-2 (]: Began executing node model.hailing_project.dim_customer
[0m08:43:50.680444 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m08:43:50.835423 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '77e41b03-1d24-4e7c-ab17-61ea395bcf0e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f49dd1f3750>]}
[0m08:43:50.836675 [info ] [Thread-3 (]: 3 of 9 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [[32mMERGE (6.0 rows, 20.1 KiB processed)[0m in 2.78s]
[0m08:43:50.837874 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m08:43:50.894931 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_driver"
[0m08:43:50.902172 [debug] [Thread-1 (]: On model.hailing_project.dim_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver` as DBT_INTERNAL_DEST
        using (


WITH driver AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver` --pakai ref untuk buat dependency

),

vehicle AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle`
)

SELECT
    driver.driver_id,
    vehicle.vehicle_id,
    driver.name AS driver_name,
    driver.phone_number AS phone_number,
    driver.email AS email,
    vehicle.vehicle_type,
    vehicle.brand AS vehicle_brand,
    vehicle.year AS vehicle_production_year,
    vehicle.license_plate,
    driver.created_at
FROM driver
LEFT JOIN vehicle
on driver.driver_id = vehicle.driver_id


    WHERE driver.created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_name` = DBT_INTERNAL_SOURCE.`driver_name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`vehicle_brand` = DBT_INTERNAL_SOURCE.`vehicle_brand`,`vehicle_production_year` = DBT_INTERNAL_SOURCE.`vehicle_production_year`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `vehicle_id`, `driver_name`, `phone_number`, `email`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)
    values
        (`driver_id`, `vehicle_id`, `driver_name`, `phone_number`, `email`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)


    
[0m08:43:50.919647 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m08:43:50.925974 [debug] [Thread-2 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
)

SELECT * FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m08:43:51.153595 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:6f2731e2-45c6-4888-b1d7-546c3bb826b3&page=queryresults
[0m08:43:51.165465 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:4b531670-8c25-4a74-9b10-71f27ec105aa&page=queryresults
[0m08:43:52.948989 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '77e41b03-1d24-4e7c-ab17-61ea395bcf0e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f49dd678d50>]}
[0m08:43:52.950489 [info ] [Thread-1 (]: 6 of 9 OK created sql incremental model rizky_dwh_hailing_facts.dim_driver ..... [[32mMERGE (6.0 rows, 24.9 KiB processed)[0m in 2.30s]
[0m08:43:52.952035 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_driver
[0m08:43:52.957970 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '77e41b03-1d24-4e7c-ab17-61ea395bcf0e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f49d5427650>]}
[0m08:43:52.959657 [info ] [Thread-2 (]: 5 of 9 OK created sql incremental model rizky_dwh_hailing_facts.dim_customer ... [[32mMERGE (6.0 rows, 15.1 KiB processed)[0m in 2.31s]
[0m08:43:52.961160 [debug] [Thread-2 (]: Finished running node model.hailing_project.dim_customer
[0m08:43:52.963705 [debug] [Thread-4 (]: Began running node model.hailing_project.fact_hailing_rides
[0m08:43:52.965517 [info ] [Thread-4 (]: 7 of 9 START sql incremental model rizky_dwh_hailing_facts.fact_hailing_rides .. [RUN]
[0m08:43:52.967136 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_vehicle, now model.hailing_project.fact_hailing_rides)
[0m08:43:52.968342 [debug] [Thread-4 (]: Began compiling node model.hailing_project.fact_hailing_rides
[0m08:43:52.974187 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.fact_hailing_rides"
[0m08:43:52.981945 [debug] [Thread-4 (]: Began executing node model.hailing_project.fact_hailing_rides
[0m08:43:52.986811 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m08:43:53.182872 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.fact_hailing_rides"
[0m08:43:53.192408 [debug] [Thread-4 (]: On model.hailing_project.fact_hailing_rides: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.fact_hailing_rides"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides` as DBT_INTERNAL_DEST
        using (

WITH dim_driver AS (

    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
),

dim_customer AS (

    SELECT * 
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer`
),

ride_staging AS (

    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride`
)

SELECT
ride_staging.ride_id,
ride_staging.start_time AS ride_start_time,
ride_staging.end_time AS ride_end_time,
ride_staging.distance_km,
ride_staging.fare,
ride_staging.ride_status,
dim_customer.cust_id,
dim_customer.name AS cust_name,
dim_customer.phone_number AS cust_phone_number,
dim_customer.email AS cust_email,
dim_driver.driver_id,
dim_driver.driver_name,
dim_driver.phone_number AS driver_phone_number,
dim_driver.email AS driver_email,
dim_driver.vehicle_id,
dim_driver.vehicle_type,
dim_driver.vehicle_brand,
dim_driver.vehicle_production_year,
dim_driver.license_plate,
ride_staging.created_at

FROM ride_staging

LEFT JOIN dim_customer
on ride_staging.cust_id = dim_customer.cust_id

LEFT JOIN dim_driver
on ride_staging.driver_id = dim_driver.driver_id


    WHERE ride_staging.created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`ride_start_time` = DBT_INTERNAL_SOURCE.`ride_start_time`,`ride_end_time` = DBT_INTERNAL_SOURCE.`ride_end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`cust_name` = DBT_INTERNAL_SOURCE.`cust_name`,`cust_phone_number` = DBT_INTERNAL_SOURCE.`cust_phone_number`,`cust_email` = DBT_INTERNAL_SOURCE.`cust_email`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`driver_name` = DBT_INTERNAL_SOURCE.`driver_name`,`driver_phone_number` = DBT_INTERNAL_SOURCE.`driver_phone_number`,`driver_email` = DBT_INTERNAL_SOURCE.`driver_email`,`vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`vehicle_brand` = DBT_INTERNAL_SOURCE.`vehicle_brand`,`vehicle_production_year` = DBT_INTERNAL_SOURCE.`vehicle_production_year`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `ride_start_time`, `ride_end_time`, `distance_km`, `fare`, `ride_status`, `cust_id`, `cust_name`, `cust_phone_number`, `cust_email`, `driver_id`, `driver_name`, `driver_phone_number`, `driver_email`, `vehicle_id`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)
    values
        (`ride_id`, `ride_start_time`, `ride_end_time`, `distance_km`, `fare`, `ride_status`, `cust_id`, `cust_name`, `cust_phone_number`, `cust_email`, `driver_id`, `driver_name`, `driver_phone_number`, `driver_email`, `vehicle_id`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)


    
[0m08:43:53.472096 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:f5a237fe-a65f-4b45-b9c6-5ae78bc2ec85&page=queryresults
[0m08:43:55.285980 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '77e41b03-1d24-4e7c-ab17-61ea395bcf0e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f49d5362f10>]}
[0m08:43:55.287390 [info ] [Thread-4 (]: 7 of 9 OK created sql incremental model rizky_dwh_hailing_facts.fact_hailing_rides  [[32mMERGE (6.0 rows, 53.8 KiB processed)[0m in 2.32s]
[0m08:43:55.290436 [debug] [Thread-4 (]: Finished running node model.hailing_project.fact_hailing_rides
[0m08:43:55.292584 [debug] [Thread-1 (]: Began running node model.hailing_project.mart_cust_rides_daily
[0m08:43:55.293044 [debug] [Thread-2 (]: Began running node model.hailing_project.mart_driver_loyalty_mgmt
[0m08:43:55.294269 [info ] [Thread-1 (]: 8 of 9 START sql incremental model rizky_dwh_hailing_marts.mart_cust_rides_daily  [RUN]
[0m08:43:55.295843 [info ] [Thread-2 (]: 9 of 9 START sql incremental model rizky_dwh_hailing_marts.mart_driver_loyalty_mgmt  [RUN]
[0m08:43:55.297399 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.hailing_project.dim_driver, now model.hailing_project.mart_cust_rides_daily)
[0m08:43:55.298927 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.hailing_project.dim_customer, now model.hailing_project.mart_driver_loyalty_mgmt)
[0m08:43:55.300325 [debug] [Thread-1 (]: Began compiling node model.hailing_project.mart_cust_rides_daily
[0m08:43:55.301863 [debug] [Thread-2 (]: Began compiling node model.hailing_project.mart_driver_loyalty_mgmt
[0m08:43:55.307171 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.mart_cust_rides_daily"
[0m08:43:55.312785 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.mart_driver_loyalty_mgmt"
[0m08:43:55.318042 [debug] [Thread-1 (]: Began executing node model.hailing_project.mart_cust_rides_daily
[0m08:43:55.322581 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m08:43:55.323237 [debug] [Thread-2 (]: Began executing node model.hailing_project.mart_driver_loyalty_mgmt
[0m08:43:55.328332 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m08:43:55.539762 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.mart_cust_rides_daily"
[0m08:43:55.546037 [debug] [Thread-1 (]: On model.hailing_project.mart_cust_rides_daily: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.mart_cust_rides_daily"} */
-- back compat for old kwarg name
  
  
        
            
                
                
            
                
                
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_marts`.`mart_cust_rides_daily` as DBT_INTERNAL_DEST
        using (


WITH fact_rides AS(

    SELECT * 
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
)

SELECT 

    fact_rides.cust_id,
    DATE(fact_rides.created_at) AS ride_date,
    fact_rides.cust_name,
    fact_rides.cust_email,
    fact_rides.cust_phone_number,
    COUNT(fact_rides.ride_id) AS no_of_rides,
    SUM(TIMESTAMP_DIFF(fact_rides.ride_end_time, fact_rides.ride_start_time, MINUTE)) AS total_ride_duration_min,
    SUM(fact_rides.fare) AS total_fare,
    SUM(fact_rides.distance_km) as total_distance_km,
    SUM(fact_rides.distance_km)-SUM(fact_rides.fare) AS rev_opportunity_loss,

FROM fact_rides
GROUP BY cust_name, cust_id, ride_date, cust_email, cust_phone_number
        ) as DBT_INTERNAL_SOURCE
        on (
                    DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
                ) and (
                    DBT_INTERNAL_SOURCE.ride_date = DBT_INTERNAL_DEST.ride_date
                )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`ride_date` = DBT_INTERNAL_SOURCE.`ride_date`,`cust_name` = DBT_INTERNAL_SOURCE.`cust_name`,`cust_email` = DBT_INTERNAL_SOURCE.`cust_email`,`cust_phone_number` = DBT_INTERNAL_SOURCE.`cust_phone_number`,`no_of_rides` = DBT_INTERNAL_SOURCE.`no_of_rides`,`total_ride_duration_min` = DBT_INTERNAL_SOURCE.`total_ride_duration_min`,`total_fare` = DBT_INTERNAL_SOURCE.`total_fare`,`total_distance_km` = DBT_INTERNAL_SOURCE.`total_distance_km`,`rev_opportunity_loss` = DBT_INTERNAL_SOURCE.`rev_opportunity_loss`
    

    when not matched then insert
        (`cust_id`, `ride_date`, `cust_name`, `cust_email`, `cust_phone_number`, `no_of_rides`, `total_ride_duration_min`, `total_fare`, `total_distance_km`, `rev_opportunity_loss`)
    values
        (`cust_id`, `ride_date`, `cust_name`, `cust_email`, `cust_phone_number`, `no_of_rides`, `total_ride_duration_min`, `total_fare`, `total_distance_km`, `rev_opportunity_loss`)


    
[0m08:43:55.555681 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.mart_driver_loyalty_mgmt"
[0m08:43:55.561241 [debug] [Thread-2 (]: On model.hailing_project.mart_driver_loyalty_mgmt: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.mart_driver_loyalty_mgmt"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_marts`.`mart_driver_loyalty_mgmt` as DBT_INTERNAL_DEST
        using (

WITH dim_driver AS(
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
),

fact_rides AS(
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
)

SELECT 
dim_driver.driver_id,
dim_driver.driver_name,
dim_driver.phone_number,
dim_driver.email,
dim_driver.vehicle_type,
COUNT(fact_rides.ride_id) AS no_of_rides,
SUM(TIMESTAMP_DIFF(fact_rides.ride_end_time, fact_rides.ride_start_time, MINUTE)) AS total_ride_duration_min,
SUM(fact_rides.fare) AS total_fare,
SUM(fact_rides.distance_km) as total_distance_km,
SUM(fact_rides.distance_km)-SUM(fact_rides.fare) AS rev_opportunity_loss,
FROM dim_driver
LEFT JOIN fact_rides
ON dim_driver.driver_id = fact_rides.driver_id

GROUP BY driver_id,driver_name,phone_number,email,vehicle_type
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`driver_name` = DBT_INTERNAL_SOURCE.`driver_name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`no_of_rides` = DBT_INTERNAL_SOURCE.`no_of_rides`,`total_ride_duration_min` = DBT_INTERNAL_SOURCE.`total_ride_duration_min`,`total_fare` = DBT_INTERNAL_SOURCE.`total_fare`,`total_distance_km` = DBT_INTERNAL_SOURCE.`total_distance_km`,`rev_opportunity_loss` = DBT_INTERNAL_SOURCE.`rev_opportunity_loss`
    

    when not matched then insert
        (`driver_id`, `driver_name`, `phone_number`, `email`, `vehicle_type`, `no_of_rides`, `total_ride_duration_min`, `total_fare`, `total_distance_km`, `rev_opportunity_loss`)
    values
        (`driver_id`, `driver_name`, `phone_number`, `email`, `vehicle_type`, `no_of_rides`, `total_ride_duration_min`, `total_fare`, `total_distance_km`, `rev_opportunity_loss`)


    
[0m08:43:55.833103 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:2911efca-df8c-4a28-8804-d5bea6134c6d&page=queryresults
[0m08:43:55.871708 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:bd94ac0d-a580-49a9-9ea5-494433b8e80a&page=queryresults
[0m08:43:57.363217 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '77e41b03-1d24-4e7c-ab17-61ea395bcf0e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f49d5438450>]}
[0m08:43:57.364538 [info ] [Thread-2 (]: 9 of 9 OK created sql incremental model rizky_dwh_hailing_marts.mart_driver_loyalty_mgmt  [[32mMERGE (116.0 rows, 26.1 KiB processed)[0m in 2.06s]
[0m08:43:57.366496 [debug] [Thread-2 (]: Finished running node model.hailing_project.mart_driver_loyalty_mgmt
[0m08:43:57.922000 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '77e41b03-1d24-4e7c-ab17-61ea395bcf0e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f49d5371110>]}
[0m08:43:57.923430 [info ] [Thread-1 (]: 8 of 9 OK created sql incremental model rizky_dwh_hailing_marts.mart_cust_rides_daily  [[32mMERGE (97.0 rows, 25.7 KiB processed)[0m in 2.62s]
[0m08:43:57.924724 [debug] [Thread-1 (]: Finished running node model.hailing_project.mart_cust_rides_daily
[0m08:43:57.927210 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m08:43:57.930181 [debug] [MainThread]: Connection 'master' was properly closed.
[0m08:43:57.931027 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m08:43:57.931870 [debug] [MainThread]: Connection 'model.hailing_project.mart_cust_rides_daily' was properly closed.
[0m08:43:57.932715 [debug] [MainThread]: Connection 'model.hailing_project.mart_driver_loyalty_mgmt' was properly closed.
[0m08:43:57.933600 [debug] [MainThread]: Connection 'model.hailing_project.fact_hailing_rides' was properly closed.
[0m08:43:57.934630 [info ] [MainThread]: 
[0m08:43:57.935802 [info ] [MainThread]: Finished running 9 incremental models in 0 hours 0 minutes and 11.10 seconds (11.10s).
[0m08:43:57.938840 [debug] [MainThread]: Command end result
[0m08:43:57.982843 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt/target/manifest.json
[0m08:43:57.988682 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt/target/semantic_manifest.json
[0m08:43:57.997616 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt/target/run_results.json
[0m08:43:57.998458 [info ] [MainThread]: 
[0m08:43:57.999573 [info ] [MainThread]: [32mCompleted successfully[0m
[0m08:43:58.000954 [info ] [MainThread]: 
[0m08:43:58.002091 [info ] [MainThread]: Done. PASS=9 WARN=0 ERROR=0 SKIP=0 TOTAL=9
[0m08:43:58.003817 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 12.357013, "process_in_blocks": "176", "process_kernel_time": 0.272045, "process_mem_max_rss": "222504", "process_out_blocks": "120", "process_user_time": 3.808632}
[0m08:43:58.004988 [debug] [MainThread]: Command `dbt run` succeeded at 08:43:58.004831 after 12.36 seconds
[0m08:43:58.005876 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4a0b3c9290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4a0b3c9150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4a0b76a150>]}
[0m08:43:58.006668 [debug] [MainThread]: Flushing usage events
[0m08:43:59.473767 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m08:50:04.152897 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdd50a7b590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdd51757410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdd50a7a890>]}


============================== 08:50:04.155494 | ed715c3f-f515-4b13-bcff-e62884be174f ==============================
[0m08:50:04.155494 [info ] [MainThread]: Running with dbt=1.9.0
[0m08:50:04.156860 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt/logs', 'profiles_dir': '/usr/app/dbt', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt debug', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m08:50:04.165212 [info ] [MainThread]: dbt version: 1.9.0
[0m08:50:04.166404 [info ] [MainThread]: python version: 3.11.2
[0m08:50:04.167939 [info ] [MainThread]: python path: /usr/local/bin/python
[0m08:50:04.169134 [info ] [MainThread]: os info: Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.31
[0m08:50:04.686511 [info ] [MainThread]: Using profiles dir at /usr/app/dbt
[0m08:50:04.687728 [info ] [MainThread]: Using profiles.yml file at /usr/app/dbt/profiles.yml
[0m08:50:04.688776 [info ] [MainThread]: Using dbt_project.yml file at /usr/app/dbt/dbt_project.yml
[0m08:50:04.689876 [info ] [MainThread]: adapter type: bigquery
[0m08:50:04.690924 [info ] [MainThread]: adapter version: 1.9.0
[0m08:50:04.779233 [info ] [MainThread]: Configuration:
[0m08:50:04.780660 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m08:50:04.781751 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m08:50:04.782952 [info ] [MainThread]: Required dependencies:
[0m08:50:04.783959 [debug] [MainThread]: Executing "git --help"
[0m08:50:04.786197 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m08:50:04.786943 [debug] [MainThread]: STDERR: "b''"
[0m08:50:04.787627 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m08:50:04.788365 [info ] [MainThread]: Connection:
[0m08:50:04.789505 [info ] [MainThread]:   method: service-account
[0m08:50:04.790628 [info ] [MainThread]:   database: purwadika
[0m08:50:04.791512 [info ] [MainThread]:   execution_project: purwadika
[0m08:50:04.792421 [info ] [MainThread]:   schema: rizky_dwh_hailing_source
[0m08:50:04.793360 [info ] [MainThread]:   location: None
[0m08:50:04.794278 [info ] [MainThread]:   priority: None
[0m08:50:04.795447 [info ] [MainThread]:   maximum_bytes_billed: None
[0m08:50:04.796548 [info ] [MainThread]:   impersonate_service_account: None
[0m08:50:04.797700 [info ] [MainThread]:   job_retry_deadline_seconds: None
[0m08:50:04.798763 [info ] [MainThread]:   job_retries: 1
[0m08:50:04.799752 [info ] [MainThread]:   job_creation_timeout_seconds: None
[0m08:50:04.800744 [info ] [MainThread]:   job_execution_timeout_seconds: None
[0m08:50:04.801988 [info ] [MainThread]:   timeout_seconds: None
[0m08:50:04.803092 [info ] [MainThread]:   client_id: None
[0m08:50:04.804187 [info ] [MainThread]:   token_uri: None
[0m08:50:04.805599 [info ] [MainThread]:   dataproc_region: None
[0m08:50:04.806609 [info ] [MainThread]:   dataproc_cluster_name: None
[0m08:50:04.807815 [info ] [MainThread]:   gcs_bucket: None
[0m08:50:04.808779 [info ] [MainThread]:   dataproc_batch: None
[0m08:50:04.809893 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m08:50:04.871003 [debug] [MainThread]: Acquiring new bigquery connection 'debug'
[0m08:50:04.872009 [debug] [MainThread]: On debug: select 1 as id
[0m08:50:04.873100 [debug] [MainThread]: Opening a new connection, currently in state init
[0m08:50:05.527333 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:a4b685b1-efe2-4377-b87b-c6aa61f685e7&page=queryresults
[0m08:50:06.264125 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m08:50:06.265310 [info ] [MainThread]: [32mAll checks passed![0m
[0m08:50:06.267327 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": true, "command_wall_clock_time": 2.166643, "process_in_blocks": "0", "process_kernel_time": 0.237848, "process_mem_max_rss": "212388", "process_out_blocks": "0", "process_user_time": 2.715435}
[0m08:50:06.268935 [debug] [MainThread]: Command `dbt debug` succeeded at 08:50:06.268755 after 2.17 seconds
[0m08:50:06.269962 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m08:50:06.270858 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdd50acd550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdd232443d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdd22bc6f10>]}
[0m08:50:06.271816 [debug] [MainThread]: Flushing usage events
[0m08:50:07.412495 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m08:51:23.181220 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2f2b0623d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2f2b0bbf90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2f2b0bbad0>]}


============================== 08:51:23.183952 | cd32ee69-4641-48b0-acde-4076fe66e6e5 ==============================
[0m08:51:23.183952 [info ] [MainThread]: Running with dbt=1.9.0
[0m08:51:23.185608 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt', 'log_path': '/usr/app/dbt/logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --project-dir /usr/app/dbt --profiles-dir /usr/app/dbt --select staging', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m08:51:23.786212 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'cd32ee69-4641-48b0-acde-4076fe66e6e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2f01284f10>]}
[0m08:51:23.840082 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'cd32ee69-4641-48b0-acde-4076fe66e6e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2f2d2da750>]}
[0m08:51:23.842027 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m08:51:23.917376 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m08:51:24.146882 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m08:51:24.147898 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m08:51:24.180411 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'cd32ee69-4641-48b0-acde-4076fe66e6e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2f014bda10>]}
[0m08:51:24.327260 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt/target/manifest.json
[0m08:51:24.334173 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt/target/semantic_manifest.json
[0m08:51:24.356237 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'cd32ee69-4641-48b0-acde-4076fe66e6e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2f01211a10>]}
[0m08:51:24.357345 [info ] [MainThread]: Found 9 models, 8 sources, 489 macros
[0m08:51:24.359227 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'cd32ee69-4641-48b0-acde-4076fe66e6e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2f00e3abd0>]}
[0m08:51:24.362100 [info ] [MainThread]: 
[0m08:51:24.363311 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m08:51:24.364428 [info ] [MainThread]: 
[0m08:51:24.366406 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m08:51:24.371699 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m08:51:24.373092 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:51:24.960181 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_staging)
[0m08:51:24.961532 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_facts'
[0m08:51:24.963349 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_marts'
[0m08:51:24.963901 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:51:24.964921 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:51:24.965980 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:51:25.270867 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'cd32ee69-4641-48b0-acde-4076fe66e6e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2f00f0b310>]}
[0m08:51:25.272331 [debug] [MainThread]: Opening a new connection, currently in state init
[0m08:51:25.278793 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m08:51:25.279262 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m08:51:25.279613 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m08:51:25.279975 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m08:51:25.280612 [info ] [Thread-1 (]: 1 of 4 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [RUN]
[0m08:51:25.281745 [info ] [Thread-2 (]: 2 of 4 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [RUN]
[0m08:51:25.283285 [info ] [Thread-3 (]: 3 of 4 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [RUN]
[0m08:51:25.284549 [info ] [Thread-4 (]: 4 of 4 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [RUN]
[0m08:51:25.285581 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_facts, now model.hailing_project.production_hailing_staging_customer)
[0m08:51:25.286570 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_marts, now model.hailing_project.production_hailing_staging_driver)
[0m08:51:25.287411 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_staging, now model.hailing_project.production_hailing_staging_ride)
[0m08:51:25.288323 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_vehicle'
[0m08:51:25.289907 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m08:51:25.290738 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m08:51:25.291550 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m08:51:25.292348 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m08:51:25.308575 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m08:51:25.312703 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m08:51:25.317817 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m08:51:25.322587 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m08:51:25.329694 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m08:51:25.330327 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m08:51:25.342058 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m08:51:25.352441 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m08:51:25.372082 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m08:51:25.376343 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m08:51:25.380298 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m08:51:25.383737 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m08:51:25.906926 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m08:51:25.908696 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m08:51:25.912306 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m08:51:25.912980 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m08:51:25.920512 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m08:51:25.921512 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m08:51:25.922621 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m08:51:25.924512 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m08:51:26.262051 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:8144673a-5a04-4462-9927-3cfd80bcb775&page=queryresults
[0m08:51:26.266056 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:bb82c11b-025e-4ad8-84a2-b6ada8ca013d&page=queryresults
[0m08:51:26.269811 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:2e3a80ad-5a6c-4e03-93b9-8725cf64c0bf&page=queryresults
[0m08:51:26.282854 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:e4a635b3-538c-48c7-a59c-1be8c1b13a55&page=queryresults
[0m08:51:27.816248 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cd32ee69-4641-48b0-acde-4076fe66e6e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2f01362ed0>]}
[0m08:51:27.817301 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cd32ee69-4641-48b0-acde-4076fe66e6e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2f013b1710>]}
[0m08:51:27.819015 [info ] [Thread-1 (]: 1 of 4 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 15.7 KiB processed)[0m in 2.53s]
[0m08:51:27.822048 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cd32ee69-4641-48b0-acde-4076fe66e6e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2f01293dd0>]}
[0m08:51:27.822582 [info ] [Thread-3 (]: 3 of 4 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 20.6 KiB processed)[0m in 2.53s]
[0m08:51:27.823686 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m08:51:27.825268 [info ] [Thread-2 (]: 2 of 4 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 15.6 KiB processed)[0m in 2.54s]
[0m08:51:27.826521 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m08:51:27.828265 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m08:51:28.107129 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cd32ee69-4641-48b0-acde-4076fe66e6e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2f2b7b6d90>]}
[0m08:51:28.108952 [info ] [Thread-4 (]: 4 of 4 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 12.8 KiB processed)[0m in 2.82s]
[0m08:51:28.110858 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m08:51:28.113467 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m08:51:28.117274 [debug] [MainThread]: Connection 'master' was properly closed.
[0m08:51:28.118120 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m08:51:28.119022 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m08:51:28.119717 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m08:51:28.120469 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m08:51:28.121338 [info ] [MainThread]: 
[0m08:51:28.122601 [info ] [MainThread]: Finished running 4 incremental models in 0 hours 0 minutes and 3.76 seconds (3.76s).
[0m08:51:28.124657 [debug] [MainThread]: Command end result
[0m08:51:28.159236 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt/target/manifest.json
[0m08:51:28.163220 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt/target/semantic_manifest.json
[0m08:51:28.172251 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt/target/run_results.json
[0m08:51:28.173074 [info ] [MainThread]: 
[0m08:51:28.174348 [info ] [MainThread]: [32mCompleted successfully[0m
[0m08:51:28.175321 [info ] [MainThread]: 
[0m08:51:28.176327 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m08:51:28.178661 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 5.048306, "process_in_blocks": "0", "process_kernel_time": 0.170851, "process_mem_max_rss": "222904", "process_out_blocks": "0", "process_user_time": 3.607975}
[0m08:51:28.179876 [debug] [MainThread]: Command `dbt run` succeeded at 08:51:28.179760 after 5.05 seconds
[0m08:51:28.180726 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2f2e9e1910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2f2e9e0c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2f2e9e0c50>]}
[0m08:51:28.181661 [debug] [MainThread]: Flushing usage events
[0m08:51:29.448001 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m08:51:51.406765 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1117e4b690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1118b2fa10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1117e9fcd0>]}


============================== 08:51:51.411079 | d982c404-c6d8-4d97-94a2-bba8bcba9f62 ==============================
[0m08:51:51.411079 [info ] [MainThread]: Running with dbt=1.9.0
[0m08:51:51.412559 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/usr/app/dbt/logs', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run --project-dir /usr/app/dbt --profiles-dir /usr/app/dbt --select staging', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m08:51:52.170039 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd982c404-c6d8-4d97-94a2-bba8bcba9f62', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f10f0d66110>]}
[0m08:51:52.218969 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd982c404-c6d8-4d97-94a2-bba8bcba9f62', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f111a0bcfd0>]}
[0m08:51:52.220721 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m08:51:52.294758 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m08:51:52.524199 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m08:51:52.525351 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m08:51:52.556562 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd982c404-c6d8-4d97-94a2-bba8bcba9f62', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f10e9e7ca90>]}
[0m08:51:52.690709 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt/target/manifest.json
[0m08:51:52.697222 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt/target/semantic_manifest.json
[0m08:51:52.715372 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd982c404-c6d8-4d97-94a2-bba8bcba9f62', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f10e9fd9c90>]}
[0m08:51:52.716920 [info ] [MainThread]: Found 9 models, 8 sources, 489 macros
[0m08:51:52.718016 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd982c404-c6d8-4d97-94a2-bba8bcba9f62', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f10e9ecc850>]}
[0m08:51:52.720550 [info ] [MainThread]: 
[0m08:51:52.722323 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m08:51:52.723433 [info ] [MainThread]: 
[0m08:51:52.724639 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m08:51:52.729678 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m08:51:52.730580 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:51:53.261153 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_facts)
[0m08:51:53.261770 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_marts'
[0m08:51:53.262404 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_staging'
[0m08:51:53.262920 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:51:53.264119 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:51:53.265154 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:51:53.540273 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd982c404-c6d8-4d97-94a2-bba8bcba9f62', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f10ea020b10>]}
[0m08:51:53.541825 [debug] [MainThread]: Opening a new connection, currently in state init
[0m08:51:53.546769 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m08:51:53.547172 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m08:51:53.547573 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m08:51:53.548875 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m08:51:53.549500 [info ] [Thread-1 (]: 1 of 4 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [RUN]
[0m08:51:53.550574 [info ] [Thread-2 (]: 2 of 4 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [RUN]
[0m08:51:53.551634 [info ] [Thread-3 (]: 3 of 4 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [RUN]
[0m08:51:53.552828 [info ] [Thread-4 (]: 4 of 4 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [RUN]
[0m08:51:53.553908 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_facts, now model.hailing_project.production_hailing_staging_customer)
[0m08:51:53.555357 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_staging, now model.hailing_project.production_hailing_staging_driver)
[0m08:51:53.556917 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_marts, now model.hailing_project.production_hailing_staging_ride)
[0m08:51:53.557943 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_vehicle'
[0m08:51:53.559064 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m08:51:53.559986 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m08:51:53.560919 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m08:51:53.562126 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m08:51:53.578774 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m08:51:53.582451 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m08:51:53.586878 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m08:51:53.591132 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m08:51:53.598022 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m08:51:53.598594 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m08:51:53.604788 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m08:51:53.605345 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m08:51:53.651556 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m08:51:53.652150 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m08:51:53.655910 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m08:51:53.659555 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m08:51:53.931154 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m08:51:53.939451 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m08:51:53.949933 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m08:51:53.956339 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m08:51:53.974205 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m08:51:53.975717 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m08:51:53.980921 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m08:51:53.981512 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m08:51:54.162202 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:eefbc706-8357-48a6-ba40-a2eea46720c5&page=queryresults
[0m08:51:54.194517 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:cba02c61-ab97-4753-91fa-7fa1c67265d1&page=queryresults
[0m08:51:54.231880 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:1e6190f4-3828-42b7-8d91-238ff9ab660b&page=queryresults
[0m08:51:54.263308 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:04042756-7d8b-4bda-9acb-707d6b7481e0&page=queryresults
[0m08:51:55.838947 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd982c404-c6d8-4d97-94a2-bba8bcba9f62', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f10e9cb1fd0>]}
[0m08:51:55.840655 [info ] [Thread-4 (]: 4 of 4 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 12.8 KiB processed)[0m in 2.28s]
[0m08:51:55.842348 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m08:51:55.969437 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd982c404-c6d8-4d97-94a2-bba8bcba9f62', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f10e9fd68d0>]}
[0m08:51:55.970454 [info ] [Thread-2 (]: 2 of 4 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 15.6 KiB processed)[0m in 2.41s]
[0m08:51:55.971659 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m08:51:55.988848 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd982c404-c6d8-4d97-94a2-bba8bcba9f62', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f10e9fd20d0>]}
[0m08:51:55.989850 [info ] [Thread-1 (]: 1 of 4 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 15.7 KiB processed)[0m in 2.43s]
[0m08:51:55.991037 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m08:51:56.001047 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd982c404-c6d8-4d97-94a2-bba8bcba9f62', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f10e9c3db50>]}
[0m08:51:56.002523 [info ] [Thread-3 (]: 3 of 4 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 20.6 KiB processed)[0m in 2.44s]
[0m08:51:56.005230 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m08:51:56.008558 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m08:51:56.012569 [debug] [MainThread]: Connection 'master' was properly closed.
[0m08:51:56.014004 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m08:51:56.015098 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m08:51:56.017931 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m08:51:56.018949 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m08:51:56.020132 [info ] [MainThread]: 
[0m08:51:56.021332 [info ] [MainThread]: Finished running 4 incremental models in 0 hours 0 minutes and 3.30 seconds (3.30s).
[0m08:51:56.023419 [debug] [MainThread]: Command end result
[0m08:51:56.058457 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt/target/manifest.json
[0m08:51:56.062872 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt/target/semantic_manifest.json
[0m08:51:56.071819 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt/target/run_results.json
[0m08:51:56.072642 [info ] [MainThread]: 
[0m08:51:56.073707 [info ] [MainThread]: [32mCompleted successfully[0m
[0m08:51:56.074758 [info ] [MainThread]: 
[0m08:51:56.076523 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m08:51:56.078511 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 4.7453065, "process_in_blocks": "0", "process_kernel_time": 0.276664, "process_mem_max_rss": "223844", "process_out_blocks": "0", "process_user_time": 3.537349}
[0m08:51:56.079671 [debug] [MainThread]: Command `dbt run` succeeded at 08:51:56.079523 after 4.75 seconds
[0m08:51:56.080603 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1117f46a10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1117f47550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f111b734c90>]}
[0m08:51:56.081503 [debug] [MainThread]: Flushing usage events
[0m08:51:57.050685 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m08:53:58.542907 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fef49abb7d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fef4a79f8d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fef49b13fd0>]}


============================== 08:53:58.546630 | d3dc19b6-b72f-42e6-bd62-684130fe7b5e ==============================
[0m08:53:58.546630 [info ] [MainThread]: Running with dbt=1.9.0
[0m08:53:58.547795 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': '/usr/app/dbt', 'log_path': '/usr/app/dbt/logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt run --project-dir /usr/app/dbt --profiles-dir /usr/app/dbt --select staging', 'send_anonymous_usage_stats': 'True'}
[0m08:53:59.178878 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd3dc19b6-b72f-42e6-bd62-684130fe7b5e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fef1bc18750>]}
[0m08:53:59.228617 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd3dc19b6-b72f-42e6-bd62-684130fe7b5e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fef4bd2e5d0>]}
[0m08:53:59.229919 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m08:53:59.300530 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m08:53:59.507187 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m08:53:59.508045 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m08:53:59.539515 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd3dc19b6-b72f-42e6-bd62-684130fe7b5e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fef1bafb410>]}
[0m08:53:59.689001 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt/target/manifest.json
[0m08:53:59.694772 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt/target/semantic_manifest.json
[0m08:53:59.710987 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd3dc19b6-b72f-42e6-bd62-684130fe7b5e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fef1bd30490>]}
[0m08:53:59.712221 [info ] [MainThread]: Found 9 models, 8 sources, 489 macros
[0m08:53:59.713286 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd3dc19b6-b72f-42e6-bd62-684130fe7b5e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fef20c00e50>]}
[0m08:53:59.715655 [info ] [MainThread]: 
[0m08:53:59.716960 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m08:53:59.718334 [info ] [MainThread]: 
[0m08:53:59.719659 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m08:53:59.723821 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m08:53:59.724863 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:54:00.310456 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_marts)
[0m08:54:00.311120 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_facts'
[0m08:54:00.311690 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_staging'
[0m08:54:00.312198 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:54:00.313057 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:54:00.313841 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:54:00.616441 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd3dc19b6-b72f-42e6-bd62-684130fe7b5e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fef1bef4990>]}
[0m08:54:00.617324 [debug] [MainThread]: Opening a new connection, currently in state init
[0m08:54:00.622366 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m08:54:00.622750 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m08:54:00.623084 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m08:54:00.623393 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m08:54:00.623923 [info ] [Thread-1 (]: 1 of 4 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [RUN]
[0m08:54:00.624941 [info ] [Thread-2 (]: 2 of 4 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [RUN]
[0m08:54:00.625835 [info ] [Thread-3 (]: 3 of 4 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [RUN]
[0m08:54:00.626852 [info ] [Thread-4 (]: 4 of 4 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [RUN]
[0m08:54:00.628182 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_facts, now model.hailing_project.production_hailing_staging_customer)
[0m08:54:00.629209 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_staging, now model.hailing_project.production_hailing_staging_driver)
[0m08:54:00.630196 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_marts, now model.hailing_project.production_hailing_staging_ride)
[0m08:54:00.631240 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_vehicle'
[0m08:54:00.632217 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m08:54:00.633046 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m08:54:00.633974 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m08:54:00.635061 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m08:54:00.649806 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m08:54:00.653646 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m08:54:00.657918 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m08:54:00.662826 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m08:54:00.669144 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m08:54:00.669820 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m08:54:00.670208 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m08:54:00.681658 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m08:54:00.723629 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m08:54:00.724710 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m08:54:00.727427 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m08:54:00.730729 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m08:54:01.047040 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m08:54:01.049230 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m08:54:01.055811 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m08:54:01.056674 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m08:54:01.079375 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m08:54:01.086522 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m08:54:01.230757 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m08:54:01.237743 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m08:54:01.327351 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:0433ae0b-3679-4b30-9afe-684db1aa7160&page=queryresults
[0m08:54:01.342769 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:0813bd97-2f46-4aa3-b539-788925ca4edc&page=queryresults
[0m08:54:01.343941 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:18b3202d-2838-4890-9400-6baeb066368c&page=queryresults
[0m08:54:01.526888 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:3313d7e7-4794-468c-81d4-bb223dd3ec5c&page=queryresults
[0m08:54:03.103098 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd3dc19b6-b72f-42e6-bd62-684130fe7b5e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fef1bda2c10>]}
[0m08:54:03.105356 [info ] [Thread-2 (]: 2 of 4 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 15.6 KiB processed)[0m in 2.47s]
[0m08:54:03.107131 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m08:54:03.164608 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd3dc19b6-b72f-42e6-bd62-684130fe7b5e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fef18744a90>]}
[0m08:54:03.165921 [info ] [Thread-1 (]: 1 of 4 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 15.7 KiB processed)[0m in 2.54s]
[0m08:54:03.167574 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m08:54:03.434949 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd3dc19b6-b72f-42e6-bd62-684130fe7b5e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fef1ba71b10>]}
[0m08:54:03.436067 [info ] [Thread-3 (]: 3 of 4 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 20.6 KiB processed)[0m in 2.80s]
[0m08:54:03.437461 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m08:54:03.445690 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd3dc19b6-b72f-42e6-bd62-684130fe7b5e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fef1bdcff90>]}
[0m08:54:03.447113 [info ] [Thread-4 (]: 4 of 4 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 12.8 KiB processed)[0m in 2.81s]
[0m08:54:03.448393 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m08:54:03.450498 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m08:54:03.454185 [debug] [MainThread]: Connection 'master' was properly closed.
[0m08:54:03.454901 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m08:54:03.455657 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m08:54:03.456324 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m08:54:03.457077 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m08:54:03.457862 [info ] [MainThread]: 
[0m08:54:03.458942 [info ] [MainThread]: Finished running 4 incremental models in 0 hours 0 minutes and 3.74 seconds (3.74s).
[0m08:54:03.461243 [debug] [MainThread]: Command end result
[0m08:54:03.497315 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt/target/manifest.json
[0m08:54:03.501814 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt/target/semantic_manifest.json
[0m08:54:03.510855 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt/target/run_results.json
[0m08:54:03.511699 [info ] [MainThread]: 
[0m08:54:03.512831 [info ] [MainThread]: [32mCompleted successfully[0m
[0m08:54:03.513789 [info ] [MainThread]: 
[0m08:54:03.515044 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m08:54:03.517078 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 5.030856, "process_in_blocks": "0", "process_kernel_time": 0.209748, "process_mem_max_rss": "221660", "process_out_blocks": "0", "process_user_time": 3.595692}
[0m08:54:03.518038 [debug] [MainThread]: Command `dbt run` succeeded at 08:54:03.517918 after 5.03 seconds
[0m08:54:03.518896 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fef49b0c0d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fef18326710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fef49b0d490>]}
[0m08:54:03.519823 [debug] [MainThread]: Flushing usage events
[0m08:54:04.616254 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m08:54:07.246079 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f16a278fb50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f16a2737ed0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f16a2736910>]}


============================== 08:54:07.248921 | d727a23e-1728-480d-8afd-ee550c01508f ==============================
[0m08:54:07.248921 [info ] [MainThread]: Running with dbt=1.9.0
[0m08:54:07.250188 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': '/usr/app/dbt', 'log_path': '/usr/app/dbt/logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'invocation_command': 'dbt run --project-dir /usr/app/dbt --profiles-dir /usr/app/dbt --select facts', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m08:54:07.890580 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd727a23e-1728-480d-8afd-ee550c01508f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1678953950>]}
[0m08:54:07.937346 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd727a23e-1728-480d-8afd-ee550c01508f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f16a49a9bd0>]}
[0m08:54:07.938728 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m08:54:08.004865 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m08:54:08.215420 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m08:54:08.216315 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m08:54:08.246521 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd727a23e-1728-480d-8afd-ee550c01508f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1678784cd0>]}
[0m08:54:08.371824 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt/target/manifest.json
[0m08:54:08.378897 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt/target/semantic_manifest.json
[0m08:54:08.395399 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd727a23e-1728-480d-8afd-ee550c01508f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f16784ff1d0>]}
[0m08:54:08.396341 [info ] [MainThread]: Found 9 models, 8 sources, 489 macros
[0m08:54:08.397698 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd727a23e-1728-480d-8afd-ee550c01508f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1678969ad0>]}
[0m08:54:08.400466 [info ] [MainThread]: 
[0m08:54:08.401498 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m08:54:08.402625 [info ] [MainThread]: 
[0m08:54:08.403915 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m08:54:08.408940 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m08:54:08.409968 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:54:08.971840 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_staging)
[0m08:54:08.972518 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_marts'
[0m08:54:08.973079 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_facts'
[0m08:54:08.973497 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:54:08.974509 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:54:08.975457 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:54:09.240180 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd727a23e-1728-480d-8afd-ee550c01508f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1678997850>]}
[0m08:54:09.241413 [debug] [MainThread]: Opening a new connection, currently in state init
[0m08:54:09.246624 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m08:54:09.247087 [debug] [Thread-2 (]: Began running node model.hailing_project.dim_driver
[0m08:54:09.248090 [info ] [Thread-1 (]: 1 of 3 START sql incremental model rizky_dwh_hailing_facts.dim_customer ........ [RUN]
[0m08:54:09.249324 [info ] [Thread-2 (]: 2 of 3 START sql incremental model rizky_dwh_hailing_facts.dim_driver .......... [RUN]
[0m08:54:09.250669 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_facts, now model.hailing_project.dim_customer)
[0m08:54:09.252089 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_staging, now model.hailing_project.dim_driver)
[0m08:54:09.253421 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m08:54:09.254538 [debug] [Thread-2 (]: Began compiling node model.hailing_project.dim_driver
[0m08:54:09.272774 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m08:54:09.277864 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.dim_driver"
[0m08:54:09.283868 [debug] [Thread-2 (]: Began executing node model.hailing_project.dim_driver
[0m08:54:09.284451 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m08:54:09.335968 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m08:54:09.338839 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m08:54:09.627674 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m08:54:09.631947 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
)

SELECT * FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m08:54:09.640414 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.dim_driver"
[0m08:54:09.645824 [debug] [Thread-2 (]: On model.hailing_project.dim_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver` as DBT_INTERNAL_DEST
        using (


WITH driver AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver` --pakai ref untuk buat dependency

),

vehicle AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle`
)

SELECT
    driver.driver_id,
    vehicle.vehicle_id,
    driver.name AS driver_name,
    driver.phone_number AS phone_number,
    driver.email AS email,
    vehicle.vehicle_type,
    vehicle.brand AS vehicle_brand,
    vehicle.year AS vehicle_production_year,
    vehicle.license_plate,
    driver.created_at
FROM driver
LEFT JOIN vehicle
on driver.driver_id = vehicle.driver_id


    WHERE driver.created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_name` = DBT_INTERNAL_SOURCE.`driver_name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`vehicle_brand` = DBT_INTERNAL_SOURCE.`vehicle_brand`,`vehicle_production_year` = DBT_INTERNAL_SOURCE.`vehicle_production_year`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `vehicle_id`, `driver_name`, `phone_number`, `email`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)
    values
        (`driver_id`, `vehicle_id`, `driver_name`, `phone_number`, `email`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)


    
[0m08:54:09.887375 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:a581d630-53e4-466d-b2b9-63e2a448cce8&page=queryresults
[0m08:54:09.938532 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:d0fd01f4-15c9-4e66-96d3-d8c738af6f9b&page=queryresults
[0m08:54:11.729681 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd727a23e-1728-480d-8afd-ee550c01508f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f16788f2090>]}
[0m08:54:11.730783 [info ] [Thread-1 (]: 1 of 3 OK created sql incremental model rizky_dwh_hailing_facts.dim_customer ... [[32mMERGE (0.0 rows, 15.5 KiB processed)[0m in 2.48s]
[0m08:54:11.732190 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m08:54:12.037826 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd727a23e-1728-480d-8afd-ee550c01508f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f16a2ca0110>]}
[0m08:54:12.039101 [info ] [Thread-2 (]: 2 of 3 OK created sql incremental model rizky_dwh_hailing_facts.dim_driver ..... [[32mMERGE (0.0 rows, 25.5 KiB processed)[0m in 2.79s]
[0m08:54:12.040283 [debug] [Thread-2 (]: Finished running node model.hailing_project.dim_driver
[0m08:54:12.041956 [debug] [Thread-4 (]: Began running node model.hailing_project.fact_hailing_rides
[0m08:54:12.042864 [info ] [Thread-4 (]: 3 of 3 START sql incremental model rizky_dwh_hailing_facts.fact_hailing_rides .. [RUN]
[0m08:54:12.044139 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.fact_hailing_rides'
[0m08:54:12.045081 [debug] [Thread-4 (]: Began compiling node model.hailing_project.fact_hailing_rides
[0m08:54:12.050003 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.fact_hailing_rides"
[0m08:54:12.056035 [debug] [Thread-4 (]: Began executing node model.hailing_project.fact_hailing_rides
[0m08:54:12.060496 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m08:54:12.306836 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.fact_hailing_rides"
[0m08:54:12.313947 [debug] [Thread-4 (]: On model.hailing_project.fact_hailing_rides: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.fact_hailing_rides"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides` as DBT_INTERNAL_DEST
        using (

WITH dim_driver AS (

    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
),

dim_customer AS (

    SELECT * 
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer`
),

ride_staging AS (

    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride`
)

SELECT
ride_staging.ride_id,
ride_staging.start_time AS ride_start_time,
ride_staging.end_time AS ride_end_time,
ride_staging.distance_km,
ride_staging.fare,
ride_staging.ride_status,
dim_customer.cust_id,
dim_customer.name AS cust_name,
dim_customer.phone_number AS cust_phone_number,
dim_customer.email AS cust_email,
dim_driver.driver_id,
dim_driver.driver_name,
dim_driver.phone_number AS driver_phone_number,
dim_driver.email AS driver_email,
dim_driver.vehicle_id,
dim_driver.vehicle_type,
dim_driver.vehicle_brand,
dim_driver.vehicle_production_year,
dim_driver.license_plate,
ride_staging.created_at

FROM ride_staging

LEFT JOIN dim_customer
on ride_staging.cust_id = dim_customer.cust_id

LEFT JOIN dim_driver
on ride_staging.driver_id = dim_driver.driver_id


    WHERE ride_staging.created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`ride_start_time` = DBT_INTERNAL_SOURCE.`ride_start_time`,`ride_end_time` = DBT_INTERNAL_SOURCE.`ride_end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`cust_name` = DBT_INTERNAL_SOURCE.`cust_name`,`cust_phone_number` = DBT_INTERNAL_SOURCE.`cust_phone_number`,`cust_email` = DBT_INTERNAL_SOURCE.`cust_email`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`driver_name` = DBT_INTERNAL_SOURCE.`driver_name`,`driver_phone_number` = DBT_INTERNAL_SOURCE.`driver_phone_number`,`driver_email` = DBT_INTERNAL_SOURCE.`driver_email`,`vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`vehicle_brand` = DBT_INTERNAL_SOURCE.`vehicle_brand`,`vehicle_production_year` = DBT_INTERNAL_SOURCE.`vehicle_production_year`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `ride_start_time`, `ride_end_time`, `distance_km`, `fare`, `ride_status`, `cust_id`, `cust_name`, `cust_phone_number`, `cust_email`, `driver_id`, `driver_name`, `driver_phone_number`, `driver_email`, `vehicle_id`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)
    values
        (`ride_id`, `ride_start_time`, `ride_end_time`, `distance_km`, `fare`, `ride_status`, `cust_id`, `cust_name`, `cust_phone_number`, `cust_email`, `driver_id`, `driver_name`, `driver_phone_number`, `driver_email`, `vehicle_id`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)


    
[0m08:54:12.588621 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:f9260bd0-7b4b-4511-bb0d-2f1ab6d15418&page=queryresults
[0m08:54:14.968060 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd727a23e-1728-480d-8afd-ee550c01508f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f16780f2b50>]}
[0m08:54:14.969228 [info ] [Thread-4 (]: 3 of 3 OK created sql incremental model rizky_dwh_hailing_facts.fact_hailing_rides  [[32mMERGE (0.0 rows, 55.2 KiB processed)[0m in 2.92s]
[0m08:54:14.970593 [debug] [Thread-4 (]: Finished running node model.hailing_project.fact_hailing_rides
[0m08:54:14.972881 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m08:54:14.976285 [debug] [MainThread]: Connection 'master' was properly closed.
[0m08:54:14.977047 [debug] [MainThread]: Connection 'model.hailing_project.dim_driver' was properly closed.
[0m08:54:14.977911 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_marts' was properly closed.
[0m08:54:14.978727 [debug] [MainThread]: Connection 'model.hailing_project.dim_customer' was properly closed.
[0m08:54:14.979385 [debug] [MainThread]: Connection 'model.hailing_project.fact_hailing_rides' was properly closed.
[0m08:54:14.980216 [info ] [MainThread]: 
[0m08:54:14.980907 [info ] [MainThread]: Finished running 3 incremental models in 0 hours 0 minutes and 6.58 seconds (6.58s).
[0m08:54:14.982596 [debug] [MainThread]: Command end result
[0m08:54:15.015644 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt/target/manifest.json
[0m08:54:15.019748 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt/target/semantic_manifest.json
[0m08:54:15.027957 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt/target/run_results.json
[0m08:54:15.028880 [info ] [MainThread]: 
[0m08:54:15.029868 [info ] [MainThread]: [32mCompleted successfully[0m
[0m08:54:15.030992 [info ] [MainThread]: 
[0m08:54:15.031932 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
[0m08:54:15.033448 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 7.8415203, "process_in_blocks": "0", "process_kernel_time": 0.172034, "process_mem_max_rss": "220792", "process_out_blocks": "0", "process_user_time": 3.460926}
[0m08:54:15.034442 [debug] [MainThread]: Command `dbt run` succeeded at 08:54:15.034316 after 7.84 seconds
[0m08:54:15.035630 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f16a2841d50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f16a276ab50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f16780df0d0>]}
[0m08:54:15.036374 [debug] [MainThread]: Flushing usage events
[0m08:54:16.013642 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m08:56:35.365149 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f672f897610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f672f8eff10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f672f8efd10>]}


============================== 08:56:35.368325 | 10e61d19-2db3-439d-ab0d-a54b9522f181 ==============================
[0m08:56:35.368325 [info ] [MainThread]: Running with dbt=1.9.0
[0m08:56:35.369598 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/usr/app/dbt/logs', 'version_check': 'True', 'profiles_dir': '/usr/app/dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt run --project-dir /usr/app/dbt --profiles-dir /usr/app/dbt --select staging', 'send_anonymous_usage_stats': 'True'}
[0m08:56:36.013440 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '10e61d19-2db3-439d-ab0d-a54b9522f181', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f67031ca590>]}
[0m08:56:36.060914 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '10e61d19-2db3-439d-ab0d-a54b9522f181', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6731b0a8d0>]}
[0m08:56:36.062767 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m08:56:36.134971 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m08:56:36.352158 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m08:56:36.353440 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m08:56:36.384225 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '10e61d19-2db3-439d-ab0d-a54b9522f181', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f67018c8e10>]}
[0m08:56:36.516395 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt/target/manifest.json
[0m08:56:36.522900 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt/target/semantic_manifest.json
[0m08:56:36.540897 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '10e61d19-2db3-439d-ab0d-a54b9522f181', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6701ada610>]}
[0m08:56:36.542592 [info ] [MainThread]: Found 9 models, 8 sources, 489 macros
[0m08:56:36.543668 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '10e61d19-2db3-439d-ab0d-a54b9522f181', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f670163f4d0>]}
[0m08:56:36.546181 [info ] [MainThread]: 
[0m08:56:36.547347 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m08:56:36.549149 [info ] [MainThread]: 
[0m08:56:36.550446 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m08:56:36.556033 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m08:56:36.556907 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:56:38.225654 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_marts)
[0m08:56:38.226281 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_staging'
[0m08:56:38.227184 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_facts'
[0m08:56:38.227830 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:56:38.228985 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:56:38.229845 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:56:38.542140 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '10e61d19-2db3-439d-ab0d-a54b9522f181', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6701926b10>]}
[0m08:56:38.543260 [debug] [MainThread]: Opening a new connection, currently in state init
[0m08:56:38.548005 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m08:56:38.548442 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m08:56:38.548856 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m08:56:38.549387 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m08:56:38.549992 [info ] [Thread-1 (]: 1 of 4 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [RUN]
[0m08:56:38.551232 [info ] [Thread-2 (]: 2 of 4 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [RUN]
[0m08:56:38.552204 [info ] [Thread-3 (]: 3 of 4 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [RUN]
[0m08:56:38.553223 [info ] [Thread-4 (]: 4 of 4 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [RUN]
[0m08:56:38.554693 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_facts, now model.hailing_project.production_hailing_staging_customer)
[0m08:56:38.556091 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_marts, now model.hailing_project.production_hailing_staging_driver)
[0m08:56:38.556983 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_staging, now model.hailing_project.production_hailing_staging_ride)
[0m08:56:38.558115 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_vehicle'
[0m08:56:38.559133 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m08:56:38.560097 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m08:56:38.560952 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m08:56:38.562345 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m08:56:38.578291 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m08:56:38.581887 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m08:56:38.586204 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m08:56:38.590690 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m08:56:38.595759 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m08:56:38.596429 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m08:56:38.602548 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m08:56:38.603044 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m08:56:38.654244 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m08:56:38.656696 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m08:56:38.653131 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m08:56:38.660356 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m08:56:38.990697 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m08:56:38.992945 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m08:56:38.995333 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m08:56:39.000711 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m08:56:39.001440 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m08:56:39.003956 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m08:56:39.022546 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m08:56:39.029154 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m08:56:39.282700 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:9f247d4a-a3ab-4302-a720-0801068d56fd&page=queryresults
[0m08:56:39.283500 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:e915f94f-3f29-4276-8eb7-c4e10acde79c&page=queryresults
[0m08:56:39.287758 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:f277dad6-f617-4119-90e8-a0ba4e5b3237&page=queryresults
[0m08:56:39.294222 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:06882a6c-d326-497a-ac38-022998f26bf4&page=queryresults
[0m08:56:40.889973 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '10e61d19-2db3-439d-ab0d-a54b9522f181', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f67016f4510>]}
[0m08:56:40.891294 [info ] [Thread-3 (]: 3 of 4 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 20.6 KiB processed)[0m in 2.33s]
[0m08:56:40.892474 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m08:56:41.129433 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '10e61d19-2db3-439d-ab0d-a54b9522f181', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6701a43f50>]}
[0m08:56:41.129990 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '10e61d19-2db3-439d-ab0d-a54b9522f181', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f670189ead0>]}
[0m08:56:41.131103 [info ] [Thread-4 (]: 4 of 4 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 12.8 KiB processed)[0m in 2.57s]
[0m08:56:41.133291 [info ] [Thread-1 (]: 1 of 4 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 15.7 KiB processed)[0m in 2.58s]
[0m08:56:41.134522 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m08:56:41.135654 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m08:56:41.147377 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '10e61d19-2db3-439d-ab0d-a54b9522f181', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6701a1ce90>]}
[0m08:56:41.148573 [info ] [Thread-2 (]: 2 of 4 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 15.6 KiB processed)[0m in 2.59s]
[0m08:56:41.150052 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m08:56:41.152622 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m08:56:41.155547 [debug] [MainThread]: Connection 'master' was properly closed.
[0m08:56:41.156283 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m08:56:41.157056 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m08:56:41.157665 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m08:56:41.158329 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m08:56:41.159825 [info ] [MainThread]: 
[0m08:56:41.160769 [info ] [MainThread]: Finished running 4 incremental models in 0 hours 0 minutes and 4.61 seconds (4.61s).
[0m08:56:41.162249 [debug] [MainThread]: Command end result
[0m08:56:41.196100 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt/target/manifest.json
[0m08:56:41.200573 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt/target/semantic_manifest.json
[0m08:56:41.209496 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt/target/run_results.json
[0m08:56:41.210316 [info ] [MainThread]: 
[0m08:56:41.211279 [info ] [MainThread]: [32mCompleted successfully[0m
[0m08:56:41.212255 [info ] [MainThread]: 
[0m08:56:41.213215 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m08:56:41.214915 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 5.902148, "process_in_blocks": "0", "process_kernel_time": 0.247711, "process_mem_max_rss": "220704", "process_out_blocks": "0", "process_user_time": 3.517508}
[0m08:56:41.216151 [debug] [MainThread]: Command `dbt run` succeeded at 08:56:41.216038 after 5.90 seconds
[0m08:56:41.217035 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6733180c90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6733210c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6733210c50>]}
[0m08:56:41.217854 [debug] [MainThread]: Flushing usage events
[0m08:56:42.449537 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m08:56:44.383027 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6da60c7a10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6da60c7d50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6da88b61d0>]}


============================== 08:56:44.385728 | 4b60a33f-aaab-4a78-830c-6e572661a1eb ==============================
[0m08:56:44.385728 [info ] [MainThread]: Running with dbt=1.9.0
[0m08:56:44.386843 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/usr/app/dbt/logs', 'version_check': 'True', 'profiles_dir': '/usr/app/dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt run --project-dir /usr/app/dbt --profiles-dir /usr/app/dbt --select facts', 'send_anonymous_usage_stats': 'True'}
[0m08:56:45.039211 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '4b60a33f-aaab-4a78-830c-6e572661a1eb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6d7c21a510>]}
[0m08:56:45.094613 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '4b60a33f-aaab-4a78-830c-6e572661a1eb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6d7c2f7f10>]}
[0m08:56:45.095934 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m08:56:45.169690 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m08:56:45.420239 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m08:56:45.434658 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m08:56:45.465392 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4b60a33f-aaab-4a78-830c-6e572661a1eb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6d77fd8790>]}
[0m08:56:45.608913 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt/target/manifest.json
[0m08:56:45.614562 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt/target/semantic_manifest.json
[0m08:56:45.632943 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4b60a33f-aaab-4a78-830c-6e572661a1eb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6da6e64750>]}
[0m08:56:45.634139 [info ] [MainThread]: Found 9 models, 8 sources, 489 macros
[0m08:56:45.635230 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4b60a33f-aaab-4a78-830c-6e572661a1eb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6d77faf590>]}
[0m08:56:45.638297 [info ] [MainThread]: 
[0m08:56:45.640212 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m08:56:45.641274 [info ] [MainThread]: 
[0m08:56:45.642623 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m08:56:45.647127 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m08:56:45.648016 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:56:47.278129 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_marts)
[0m08:56:47.279083 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_facts'
[0m08:56:47.279843 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_staging'
[0m08:56:47.280891 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:56:47.282067 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:56:47.283136 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:56:47.588500 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4b60a33f-aaab-4a78-830c-6e572661a1eb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6da6e64750>]}
[0m08:56:47.589602 [debug] [MainThread]: Opening a new connection, currently in state init
[0m08:56:47.595329 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m08:56:47.595694 [debug] [Thread-2 (]: Began running node model.hailing_project.dim_driver
[0m08:56:47.596446 [info ] [Thread-1 (]: 1 of 3 START sql incremental model rizky_dwh_hailing_facts.dim_customer ........ [RUN]
[0m08:56:47.597864 [info ] [Thread-2 (]: 2 of 3 START sql incremental model rizky_dwh_hailing_facts.dim_driver .......... [RUN]
[0m08:56:47.599631 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_staging, now model.hailing_project.dim_customer)
[0m08:56:47.600907 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_facts, now model.hailing_project.dim_driver)
[0m08:56:47.601999 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m08:56:47.602915 [debug] [Thread-2 (]: Began compiling node model.hailing_project.dim_driver
[0m08:56:47.620503 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m08:56:47.625323 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.dim_driver"
[0m08:56:47.631442 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m08:56:47.632251 [debug] [Thread-2 (]: Began executing node model.hailing_project.dim_driver
[0m08:56:47.687373 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m08:56:47.689206 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m08:56:48.024353 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m08:56:48.024846 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.dim_driver"
[0m08:56:48.030652 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
)

SELECT * FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m08:56:48.031468 [debug] [Thread-2 (]: On model.hailing_project.dim_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver` as DBT_INTERNAL_DEST
        using (


WITH driver AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver` --pakai ref untuk buat dependency

),

vehicle AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle`
)

SELECT
    driver.driver_id,
    vehicle.vehicle_id,
    driver.name AS driver_name,
    driver.phone_number AS phone_number,
    driver.email AS email,
    vehicle.vehicle_type,
    vehicle.brand AS vehicle_brand,
    vehicle.year AS vehicle_production_year,
    vehicle.license_plate,
    driver.created_at
FROM driver
LEFT JOIN vehicle
on driver.driver_id = vehicle.driver_id


    WHERE driver.created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_name` = DBT_INTERNAL_SOURCE.`driver_name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`vehicle_brand` = DBT_INTERNAL_SOURCE.`vehicle_brand`,`vehicle_production_year` = DBT_INTERNAL_SOURCE.`vehicle_production_year`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `vehicle_id`, `driver_name`, `phone_number`, `email`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)
    values
        (`driver_id`, `vehicle_id`, `driver_name`, `phone_number`, `email`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)


    
[0m08:56:48.295810 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:cccf7691-9c58-4edc-83c7-b07e10b56316&page=queryresults
[0m08:56:48.307700 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:721ce483-b6f0-44a2-9720-6c306b92f409&page=queryresults
[0m08:56:49.934206 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4b60a33f-aaab-4a78-830c-6e572661a1eb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6d77fafc50>]}
[0m08:56:49.935334 [info ] [Thread-1 (]: 1 of 3 OK created sql incremental model rizky_dwh_hailing_facts.dim_customer ... [[32mMERGE (0.0 rows, 15.5 KiB processed)[0m in 2.33s]
[0m08:56:49.936515 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m08:56:50.432752 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4b60a33f-aaab-4a78-830c-6e572661a1eb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6d74406cd0>]}
[0m08:56:50.433819 [info ] [Thread-2 (]: 2 of 3 OK created sql incremental model rizky_dwh_hailing_facts.dim_driver ..... [[32mMERGE (0.0 rows, 25.5 KiB processed)[0m in 2.83s]
[0m08:56:50.435055 [debug] [Thread-2 (]: Finished running node model.hailing_project.dim_driver
[0m08:56:50.436529 [debug] [Thread-4 (]: Began running node model.hailing_project.fact_hailing_rides
[0m08:56:50.437336 [info ] [Thread-4 (]: 3 of 3 START sql incremental model rizky_dwh_hailing_facts.fact_hailing_rides .. [RUN]
[0m08:56:50.439037 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.fact_hailing_rides'
[0m08:56:50.439985 [debug] [Thread-4 (]: Began compiling node model.hailing_project.fact_hailing_rides
[0m08:56:50.446007 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.fact_hailing_rides"
[0m08:56:50.453233 [debug] [Thread-4 (]: Began executing node model.hailing_project.fact_hailing_rides
[0m08:56:50.456602 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m08:56:50.741782 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.fact_hailing_rides"
[0m08:56:50.750104 [debug] [Thread-4 (]: On model.hailing_project.fact_hailing_rides: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.fact_hailing_rides"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides` as DBT_INTERNAL_DEST
        using (

WITH dim_driver AS (

    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
),

dim_customer AS (

    SELECT * 
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer`
),

ride_staging AS (

    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride`
)

SELECT
ride_staging.ride_id,
ride_staging.start_time AS ride_start_time,
ride_staging.end_time AS ride_end_time,
ride_staging.distance_km,
ride_staging.fare,
ride_staging.ride_status,
dim_customer.cust_id,
dim_customer.name AS cust_name,
dim_customer.phone_number AS cust_phone_number,
dim_customer.email AS cust_email,
dim_driver.driver_id,
dim_driver.driver_name,
dim_driver.phone_number AS driver_phone_number,
dim_driver.email AS driver_email,
dim_driver.vehicle_id,
dim_driver.vehicle_type,
dim_driver.vehicle_brand,
dim_driver.vehicle_production_year,
dim_driver.license_plate,
ride_staging.created_at

FROM ride_staging

LEFT JOIN dim_customer
on ride_staging.cust_id = dim_customer.cust_id

LEFT JOIN dim_driver
on ride_staging.driver_id = dim_driver.driver_id


    WHERE ride_staging.created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`ride_start_time` = DBT_INTERNAL_SOURCE.`ride_start_time`,`ride_end_time` = DBT_INTERNAL_SOURCE.`ride_end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`cust_name` = DBT_INTERNAL_SOURCE.`cust_name`,`cust_phone_number` = DBT_INTERNAL_SOURCE.`cust_phone_number`,`cust_email` = DBT_INTERNAL_SOURCE.`cust_email`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`driver_name` = DBT_INTERNAL_SOURCE.`driver_name`,`driver_phone_number` = DBT_INTERNAL_SOURCE.`driver_phone_number`,`driver_email` = DBT_INTERNAL_SOURCE.`driver_email`,`vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`vehicle_brand` = DBT_INTERNAL_SOURCE.`vehicle_brand`,`vehicle_production_year` = DBT_INTERNAL_SOURCE.`vehicle_production_year`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `ride_start_time`, `ride_end_time`, `distance_km`, `fare`, `ride_status`, `cust_id`, `cust_name`, `cust_phone_number`, `cust_email`, `driver_id`, `driver_name`, `driver_phone_number`, `driver_email`, `vehicle_id`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)
    values
        (`ride_id`, `ride_start_time`, `ride_end_time`, `distance_km`, `fare`, `ride_status`, `cust_id`, `cust_name`, `cust_phone_number`, `cust_email`, `driver_id`, `driver_name`, `driver_phone_number`, `driver_email`, `vehicle_id`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)


    
[0m08:56:51.006061 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:82159a01-9694-4939-a9d2-ca7117ff054e&page=queryresults
[0m08:56:52.838852 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4b60a33f-aaab-4a78-830c-6e572661a1eb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6d7417a410>]}
[0m08:56:52.839829 [info ] [Thread-4 (]: 3 of 3 OK created sql incremental model rizky_dwh_hailing_facts.fact_hailing_rides  [[32mMERGE (0.0 rows, 55.2 KiB processed)[0m in 2.40s]
[0m08:56:52.841632 [debug] [Thread-4 (]: Finished running node model.hailing_project.fact_hailing_rides
[0m08:56:52.844301 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m08:56:52.846947 [debug] [MainThread]: Connection 'master' was properly closed.
[0m08:56:52.847950 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_marts' was properly closed.
[0m08:56:52.849421 [debug] [MainThread]: Connection 'model.hailing_project.dim_driver' was properly closed.
[0m08:56:52.850428 [debug] [MainThread]: Connection 'model.hailing_project.dim_customer' was properly closed.
[0m08:56:52.851277 [debug] [MainThread]: Connection 'model.hailing_project.fact_hailing_rides' was properly closed.
[0m08:56:52.852152 [info ] [MainThread]: 
[0m08:56:52.853058 [info ] [MainThread]: Finished running 3 incremental models in 0 hours 0 minutes and 7.21 seconds (7.21s).
[0m08:56:52.854656 [debug] [MainThread]: Command end result
[0m08:56:52.890662 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt/target/manifest.json
[0m08:56:52.895632 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt/target/semantic_manifest.json
[0m08:56:52.904301 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt/target/run_results.json
[0m08:56:52.905235 [info ] [MainThread]: 
[0m08:56:52.906236 [info ] [MainThread]: [32mCompleted successfully[0m
[0m08:56:52.907278 [info ] [MainThread]: 
[0m08:56:52.908388 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
[0m08:56:52.909993 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 8.590965, "process_in_blocks": "0", "process_kernel_time": 0.23085, "process_mem_max_rss": "224560", "process_out_blocks": "0", "process_user_time": 3.452724}
[0m08:56:52.911908 [debug] [MainThread]: Command `dbt run` succeeded at 08:56:52.911726 after 8.59 seconds
[0m08:56:52.912797 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6da60c8bd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6da9838c90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6da99bd790>]}
[0m08:56:52.913609 [debug] [MainThread]: Flushing usage events
[0m08:56:53.913723 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m08:56:56.587116 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0697ab2590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f069879be10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0697ab3950>]}


============================== 08:56:56.590261 | 6c4bb9f5-8fb8-4d22-a466-b04f98f737df ==============================
[0m08:56:56.590261 [info ] [MainThread]: Running with dbt=1.9.0
[0m08:56:56.591862 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/usr/app/dbt/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt run --project-dir /usr/app/dbt --profiles-dir /usr/app/dbt --select marts', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m08:56:57.224430 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '6c4bb9f5-8fb8-4d22-a466-b04f98f737df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0669c87850>]}
[0m08:56:57.271238 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '6c4bb9f5-8fb8-4d22-a466-b04f98f737df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0699d30b90>]}
[0m08:56:57.272997 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m08:56:57.339478 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m08:56:57.554236 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m08:56:57.555156 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m08:56:57.584372 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '6c4bb9f5-8fb8-4d22-a466-b04f98f737df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f066997a890>]}
[0m08:56:57.722452 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt/target/manifest.json
[0m08:56:57.728296 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt/target/semantic_manifest.json
[0m08:56:57.744397 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '6c4bb9f5-8fb8-4d22-a466-b04f98f737df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0669d7c150>]}
[0m08:56:57.745878 [info ] [MainThread]: Found 9 models, 8 sources, 489 macros
[0m08:56:57.747001 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6c4bb9f5-8fb8-4d22-a466-b04f98f737df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f06699a3250>]}
[0m08:56:57.749195 [info ] [MainThread]: 
[0m08:56:57.750375 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m08:56:57.751959 [info ] [MainThread]: 
[0m08:56:57.753338 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m08:56:57.758394 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m08:56:57.759286 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:56:58.373705 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_staging)
[0m08:56:58.374431 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_facts'
[0m08:56:58.374989 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_marts'
[0m08:56:58.375598 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:56:58.377509 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:56:58.378517 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:56:58.727054 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6c4bb9f5-8fb8-4d22-a466-b04f98f737df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0669c5cc10>]}
[0m08:56:58.728009 [debug] [MainThread]: Opening a new connection, currently in state init
[0m08:56:58.732767 [debug] [Thread-1 (]: Began running node model.hailing_project.mart_cust_rides_daily
[0m08:56:58.733112 [debug] [Thread-2 (]: Began running node model.hailing_project.mart_driver_loyalty_mgmt
[0m08:56:58.733969 [info ] [Thread-1 (]: 1 of 2 START sql incremental model rizky_dwh_hailing_marts.mart_cust_rides_daily  [RUN]
[0m08:56:58.735052 [info ] [Thread-2 (]: 2 of 2 START sql incremental model rizky_dwh_hailing_marts.mart_driver_loyalty_mgmt  [RUN]
[0m08:56:58.736480 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_facts, now model.hailing_project.mart_cust_rides_daily)
[0m08:56:58.738096 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_staging, now model.hailing_project.mart_driver_loyalty_mgmt)
[0m08:56:58.738970 [debug] [Thread-1 (]: Began compiling node model.hailing_project.mart_cust_rides_daily
[0m08:56:58.739899 [debug] [Thread-2 (]: Began compiling node model.hailing_project.mart_driver_loyalty_mgmt
[0m08:56:58.749261 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.mart_cust_rides_daily"
[0m08:56:58.752523 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.mart_driver_loyalty_mgmt"
[0m08:56:58.756768 [debug] [Thread-1 (]: Began executing node model.hailing_project.mart_cust_rides_daily
[0m08:56:58.758720 [debug] [Thread-2 (]: Began executing node model.hailing_project.mart_driver_loyalty_mgmt
[0m08:56:58.803525 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m08:56:58.806062 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m08:56:59.122388 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.mart_cust_rides_daily"
[0m08:56:59.122934 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.mart_driver_loyalty_mgmt"
[0m08:56:59.127459 [debug] [Thread-1 (]: On model.hailing_project.mart_cust_rides_daily: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.mart_cust_rides_daily"} */
-- back compat for old kwarg name
  
  
        
            
                
                
            
                
                
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_marts`.`mart_cust_rides_daily` as DBT_INTERNAL_DEST
        using (


WITH fact_rides AS(

    SELECT * 
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
)

SELECT 

    fact_rides.cust_id,
    DATE(fact_rides.created_at) AS ride_date,
    fact_rides.cust_name,
    fact_rides.cust_email,
    fact_rides.cust_phone_number,
    COUNT(fact_rides.ride_id) AS no_of_rides,
    SUM(TIMESTAMP_DIFF(fact_rides.ride_end_time, fact_rides.ride_start_time, MINUTE)) AS total_ride_duration_min,
    SUM(fact_rides.fare) AS total_fare,
    SUM(fact_rides.distance_km) as total_distance_km,
    SUM(fact_rides.distance_km)-SUM(fact_rides.fare) AS rev_opportunity_loss,

FROM fact_rides
GROUP BY cust_name, cust_id, ride_date, cust_email, cust_phone_number
        ) as DBT_INTERNAL_SOURCE
        on (
                    DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
                ) and (
                    DBT_INTERNAL_SOURCE.ride_date = DBT_INTERNAL_DEST.ride_date
                )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`ride_date` = DBT_INTERNAL_SOURCE.`ride_date`,`cust_name` = DBT_INTERNAL_SOURCE.`cust_name`,`cust_email` = DBT_INTERNAL_SOURCE.`cust_email`,`cust_phone_number` = DBT_INTERNAL_SOURCE.`cust_phone_number`,`no_of_rides` = DBT_INTERNAL_SOURCE.`no_of_rides`,`total_ride_duration_min` = DBT_INTERNAL_SOURCE.`total_ride_duration_min`,`total_fare` = DBT_INTERNAL_SOURCE.`total_fare`,`total_distance_km` = DBT_INTERNAL_SOURCE.`total_distance_km`,`rev_opportunity_loss` = DBT_INTERNAL_SOURCE.`rev_opportunity_loss`
    

    when not matched then insert
        (`cust_id`, `ride_date`, `cust_name`, `cust_email`, `cust_phone_number`, `no_of_rides`, `total_ride_duration_min`, `total_fare`, `total_distance_km`, `rev_opportunity_loss`)
    values
        (`cust_id`, `ride_date`, `cust_name`, `cust_email`, `cust_phone_number`, `no_of_rides`, `total_ride_duration_min`, `total_fare`, `total_distance_km`, `rev_opportunity_loss`)


    
[0m08:56:59.129673 [debug] [Thread-2 (]: On model.hailing_project.mart_driver_loyalty_mgmt: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.mart_driver_loyalty_mgmt"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_marts`.`mart_driver_loyalty_mgmt` as DBT_INTERNAL_DEST
        using (

WITH dim_driver AS(
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
),

fact_rides AS(
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
)

SELECT 
dim_driver.driver_id,
dim_driver.driver_name,
dim_driver.phone_number,
dim_driver.email,
dim_driver.vehicle_type,
COUNT(fact_rides.ride_id) AS no_of_rides,
SUM(TIMESTAMP_DIFF(fact_rides.ride_end_time, fact_rides.ride_start_time, MINUTE)) AS total_ride_duration_min,
SUM(fact_rides.fare) AS total_fare,
SUM(fact_rides.distance_km) as total_distance_km,
SUM(fact_rides.distance_km)-SUM(fact_rides.fare) AS rev_opportunity_loss,
FROM dim_driver
LEFT JOIN fact_rides
ON dim_driver.driver_id = fact_rides.driver_id

GROUP BY driver_id,driver_name,phone_number,email,vehicle_type
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`driver_name` = DBT_INTERNAL_SOURCE.`driver_name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`no_of_rides` = DBT_INTERNAL_SOURCE.`no_of_rides`,`total_ride_duration_min` = DBT_INTERNAL_SOURCE.`total_ride_duration_min`,`total_fare` = DBT_INTERNAL_SOURCE.`total_fare`,`total_distance_km` = DBT_INTERNAL_SOURCE.`total_distance_km`,`rev_opportunity_loss` = DBT_INTERNAL_SOURCE.`rev_opportunity_loss`
    

    when not matched then insert
        (`driver_id`, `driver_name`, `phone_number`, `email`, `vehicle_type`, `no_of_rides`, `total_ride_duration_min`, `total_fare`, `total_distance_km`, `rev_opportunity_loss`)
    values
        (`driver_id`, `driver_name`, `phone_number`, `email`, `vehicle_type`, `no_of_rides`, `total_ride_duration_min`, `total_fare`, `total_distance_km`, `rev_opportunity_loss`)


    
[0m08:56:59.373881 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:c961c54d-cea1-4006-af4b-365d5ce8f795&page=queryresults
[0m08:56:59.427012 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:2f7ef60a-39f6-4900-8c77-88726cc159b7&page=queryresults
[0m08:57:01.277905 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6c4bb9f5-8fb8-4d22-a466-b04f98f737df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0669930350>]}
[0m08:57:01.280215 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6c4bb9f5-8fb8-4d22-a466-b04f98f737df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0669c483d0>]}
[0m08:57:01.280931 [info ] [Thread-1 (]: 1 of 2 OK created sql incremental model rizky_dwh_hailing_marts.mart_cust_rides_daily  [[32mMERGE (97.0 rows, 26.5 KiB processed)[0m in 2.54s]
[0m08:57:01.282140 [info ] [Thread-2 (]: 2 of 2 OK created sql incremental model rizky_dwh_hailing_marts.mart_driver_loyalty_mgmt  [[32mMERGE (116.0 rows, 26.8 KiB processed)[0m in 2.54s]
[0m08:57:01.283202 [debug] [Thread-1 (]: Finished running node model.hailing_project.mart_cust_rides_daily
[0m08:57:01.284161 [debug] [Thread-2 (]: Finished running node model.hailing_project.mart_driver_loyalty_mgmt
[0m08:57:01.287184 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m08:57:01.289760 [debug] [MainThread]: Connection 'master' was properly closed.
[0m08:57:01.290542 [debug] [MainThread]: Connection 'model.hailing_project.mart_driver_loyalty_mgmt' was properly closed.
[0m08:57:01.291208 [debug] [MainThread]: Connection 'model.hailing_project.mart_cust_rides_daily' was properly closed.
[0m08:57:01.292178 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_marts' was properly closed.
[0m08:57:01.293396 [info ] [MainThread]: 
[0m08:57:01.294327 [info ] [MainThread]: Finished running 2 incremental models in 0 hours 0 minutes and 3.54 seconds (3.54s).
[0m08:57:01.296082 [debug] [MainThread]: Command end result
[0m08:57:01.332402 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt/target/manifest.json
[0m08:57:01.336638 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt/target/semantic_manifest.json
[0m08:57:01.344606 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt/target/run_results.json
[0m08:57:01.345362 [info ] [MainThread]: 
[0m08:57:01.346282 [info ] [MainThread]: [32mCompleted successfully[0m
[0m08:57:01.347764 [info ] [MainThread]: 
[0m08:57:01.348946 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m08:57:01.350787 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 4.819095, "process_in_blocks": "0", "process_kernel_time": 0.168502, "process_mem_max_rss": "220824", "process_out_blocks": "0", "process_user_time": 3.488988}
[0m08:57:01.351842 [debug] [MainThread]: Command `dbt run` succeeded at 08:57:01.351725 after 4.82 seconds
[0m08:57:01.352756 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0697b0bf10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f069b5a59d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f069b2d4f10>]}
[0m08:57:01.353837 [debug] [MainThread]: Flushing usage events
[0m08:57:02.323137 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m10:48:21.293138 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f59c8bff750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f59c8c57e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f59c8c57d50>]}


============================== 10:48:21.296657 | fe0fa1e9-02ec-469a-8d22-593182e924f1 ==============================
[0m10:48:21.296657 [info ] [MainThread]: Running with dbt=1.9.0
[0m10:48:21.298116 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt', 'debug': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt/logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'invocation_command': 'dbt run --project-dir /usr/app/dbt --profiles-dir /usr/app/dbt --select staging', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m10:48:21.316777 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa7ae925a10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa7af60f890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa7ae97fe10>]}


============================== 10:48:21.319953 | 6a1b38c8-4321-4b77-b735-8da6ca667538 ==============================
[0m10:48:21.319953 [info ] [MainThread]: Running with dbt=1.9.0
[0m10:48:21.321359 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/usr/app/dbt/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run --project-dir /usr/app/dbt --profiles-dir /usr/app/dbt --select staging', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m10:48:21.983222 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'fe0fa1e9-02ec-469a-8d22-593182e924f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f599af703d0>]}
[0m10:48:22.016999 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '6a1b38c8-4321-4b77-b735-8da6ca667538', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa784b3d590>]}
[0m10:48:22.034327 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'fe0fa1e9-02ec-469a-8d22-593182e924f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f59a79dec90>]}
[0m10:48:22.035957 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m10:48:22.067166 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '6a1b38c8-4321-4b77-b735-8da6ca667538', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa784c37490>]}
[0m10:48:22.068295 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m10:48:22.112590 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m10:48:22.142469 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m10:48:22.322849 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m10:48:22.324371 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m10:48:22.333356 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m10:48:22.334137 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m10:48:22.357698 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'fe0fa1e9-02ec-469a-8d22-593182e924f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f599ab01290>]}
[0m10:48:22.362986 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '6a1b38c8-4321-4b77-b735-8da6ca667538', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa78482dd10>]}
[0m10:48:22.520944 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt/target/manifest.json
[0m10:48:22.527155 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt/target/semantic_manifest.json
[0m10:48:22.528073 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt/target/manifest.json
[0m10:48:22.538019 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt/target/semantic_manifest.json
[0m10:48:22.550070 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'fe0fa1e9-02ec-469a-8d22-593182e924f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f599a9d5ed0>]}
[0m10:48:22.551702 [info ] [MainThread]: Found 9 models, 8 sources, 489 macros
[0m10:48:22.555105 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'fe0fa1e9-02ec-469a-8d22-593182e924f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f599ac4d250>]}
[0m10:48:22.558160 [info ] [MainThread]: 
[0m10:48:22.559502 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m10:48:22.561631 [info ] [MainThread]: 
[0m10:48:22.563258 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m10:48:22.567152 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '6a1b38c8-4321-4b77-b735-8da6ca667538', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa7849673d0>]}
[0m10:48:22.569385 [info ] [MainThread]: Found 9 models, 8 sources, 489 macros
[0m10:48:22.570787 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m10:48:22.570815 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6a1b38c8-4321-4b77-b735-8da6ca667538', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa7847d7ad0>]}
[0m10:48:22.572179 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:48:22.574481 [info ] [MainThread]: 
[0m10:48:22.576027 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m10:48:22.577143 [info ] [MainThread]: 
[0m10:48:22.578481 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m10:48:22.583990 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m10:48:22.584874 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:48:23.087736 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_marts)
[0m10:48:23.088846 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_facts'
[0m10:48:23.089644 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_staging'
[0m10:48:23.090566 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:48:23.091458 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:48:23.092309 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:48:23.370634 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'fe0fa1e9-02ec-469a-8d22-593182e924f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f599aada3d0>]}
[0m10:48:23.372144 [debug] [MainThread]: Opening a new connection, currently in state init
[0m10:48:23.378140 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m10:48:23.378600 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m10:48:23.379064 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m10:48:23.379565 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m10:48:23.380726 [info ] [Thread-1 (]: 1 of 4 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [RUN]
[0m10:48:23.381929 [info ] [Thread-2 (]: 2 of 4 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [RUN]
[0m10:48:23.383134 [info ] [Thread-3 (]: 3 of 4 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [RUN]
[0m10:48:23.384231 [info ] [Thread-4 (]: 4 of 4 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [RUN]
[0m10:48:23.385470 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_facts, now model.hailing_project.production_hailing_staging_customer)
[0m10:48:23.387161 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_staging, now model.hailing_project.production_hailing_staging_driver)
[0m10:48:23.388345 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_marts, now model.hailing_project.production_hailing_staging_ride)
[0m10:48:23.389532 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_vehicle'
[0m10:48:23.390458 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m10:48:23.409803 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_facts)
[0m10:48:23.391467 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m10:48:23.410601 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_marts'
[0m10:48:23.411368 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_staging'
[0m10:48:23.412047 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:48:23.413047 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:48:23.392580 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m10:48:23.394430 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m10:48:23.411467 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m10:48:23.417230 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m10:48:23.421973 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m10:48:23.426327 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m10:48:23.432684 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m10:48:23.414376 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:48:23.433213 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m10:48:23.439370 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m10:48:23.449734 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m10:48:23.513310 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m10:48:23.513765 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m10:48:23.514139 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m10:48:23.517671 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m10:48:23.688996 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6a1b38c8-4321-4b77-b735-8da6ca667538', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa786ecb290>]}
[0m10:48:23.690314 [debug] [MainThread]: Opening a new connection, currently in state init
[0m10:48:23.699082 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m10:48:23.699815 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m10:48:23.700416 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m10:48:23.700837 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m10:48:23.711521 [info ] [Thread-1 (]: 1 of 4 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [RUN]
[0m10:48:23.716092 [info ] [Thread-2 (]: 2 of 4 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [RUN]
[0m10:48:23.724200 [info ] [Thread-3 (]: 3 of 4 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [RUN]
[0m10:48:23.730040 [info ] [Thread-4 (]: 4 of 4 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [RUN]
[0m10:48:23.734413 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_marts, now model.hailing_project.production_hailing_staging_customer)
[0m10:48:23.736168 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_staging, now model.hailing_project.production_hailing_staging_driver)
[0m10:48:23.737904 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_facts, now model.hailing_project.production_hailing_staging_ride)
[0m10:48:23.739561 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_vehicle'
[0m10:48:23.741816 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m10:48:23.750766 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m10:48:23.752443 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m10:48:23.753792 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m10:48:23.773594 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m10:48:23.778506 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m10:48:23.785025 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m10:48:23.792760 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m10:48:23.801755 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m10:48:23.802268 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m10:48:23.857000 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m10:48:23.858527 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m10:48:23.862511 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m10:48:23.803583 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m10:48:23.863789 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m10:48:23.870158 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m10:48:23.809353 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m10:48:23.870834 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m10:48:23.874027 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m10:48:23.874888 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m10:48:23.866221 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m10:48:23.870118 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m10:48:23.874256 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m10:48:23.880616 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m10:48:24.116306 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:3360f3f7-48ed-4db0-b970-1fedf660a1c5&page=queryresults
[0m10:48:24.135242 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:d3c9619a-ea05-4ad5-932d-22aebdbc6e03&page=queryresults
[0m10:48:24.137021 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:98044565-1549-4b6e-8b00-9ec449829b4d&page=queryresults
[0m10:48:24.190195 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:03cc84f4-7968-4499-9614-c9237c1b9967&page=queryresults
[0m10:48:24.208909 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m10:48:24.210351 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m10:48:24.210946 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m10:48:24.212579 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m10:48:24.217401 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m10:48:24.218599 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m10:48:24.219190 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m10:48:24.221316 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m10:48:24.437917 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:ef323e47-d13e-452e-9975-b1bb543c5617&page=queryresults
[0m10:48:24.442099 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:2c772ce8-6f43-4137-998f-c7d210c035a0&page=queryresults
[0m10:48:24.451134 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:3eae627b-e085-4e83-a3c2-17696fe31678&page=queryresults
[0m10:48:24.462511 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:a4807f59-4655-4475-81ac-5ecfa24a9326&page=queryresults
[0m10:48:25.950361 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fe0fa1e9-02ec-469a-8d22-593182e924f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f599add0a10>]}
[0m10:48:25.950769 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fe0fa1e9-02ec-469a-8d22-593182e924f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f599bd1e6d0>]}
[0m10:48:25.952111 [info ] [Thread-4 (]: 4 of 4 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [[32mMERGE (5.0 rows, 13.1 KiB processed)[0m in 2.56s]
[0m10:48:25.953427 [info ] [Thread-2 (]: 2 of 4 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [[32mMERGE (5.0 rows, 16.0 KiB processed)[0m in 2.56s]
[0m10:48:25.954674 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m10:48:25.958074 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m10:48:26.200958 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fe0fa1e9-02ec-469a-8d22-593182e924f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f599af8ad90>]}
[0m10:48:26.202336 [info ] [Thread-3 (]: 3 of 4 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [[32mMERGE (5.0 rows, 21.1 KiB processed)[0m in 2.81s]
[0m10:48:26.203580 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m10:48:26.241484 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6a1b38c8-4321-4b77-b735-8da6ca667538', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa784435ad0>]}
[0m10:48:26.241970 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6a1b38c8-4321-4b77-b735-8da6ca667538', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa7af771f10>]}
[0m10:48:26.244472 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6a1b38c8-4321-4b77-b735-8da6ca667538', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa784368910>]}
[0m10:48:26.245290 [info ] [Thread-4 (]: 4 of 4 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [[32mMERGE (5.0 rows, 13.1 KiB processed)[0m in 2.50s]
[0m10:48:26.246422 [info ] [Thread-1 (]: 1 of 4 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [[32mMERGE (5.0 rows, 16.0 KiB processed)[0m in 2.51s]
[0m10:48:26.247887 [info ] [Thread-2 (]: 2 of 4 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [[32mMERGE (5.0 rows, 16.0 KiB processed)[0m in 2.51s]
[0m10:48:26.249422 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m10:48:26.250458 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m10:48:26.251400 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m10:48:26.507047 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6a1b38c8-4321-4b77-b735-8da6ca667538', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa784c37190>]}
[0m10:48:26.508099 [info ] [Thread-3 (]: 3 of 4 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [[32mMERGE (5.0 rows, 21.1 KiB processed)[0m in 2.77s]
[0m10:48:26.509169 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m10:48:26.511414 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m10:48:26.514610 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:48:26.515545 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m10:48:26.516288 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m10:48:26.517022 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m10:48:26.517659 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m10:48:26.518928 [info ] [MainThread]: 
[0m10:48:26.520353 [info ] [MainThread]: Finished running 4 incremental models in 0 hours 0 minutes and 3.94 seconds (3.94s).
[0m10:48:26.522626 [debug] [MainThread]: Command end result
[0m10:48:26.531084 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fe0fa1e9-02ec-469a-8d22-593182e924f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f599af8be10>]}
[0m10:48:26.532814 [info ] [Thread-1 (]: 1 of 4 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [[32mMERGE (5.0 rows, 16.0 KiB processed)[0m in 3.15s]
[0m10:48:26.535063 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m10:48:26.537843 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m10:48:26.542159 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:48:26.543123 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m10:48:26.544020 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m10:48:26.544930 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m10:48:26.545736 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m10:48:26.547018 [info ] [MainThread]: 
[0m10:48:26.548042 [info ] [MainThread]: Finished running 4 incremental models in 0 hours 0 minutes and 3.98 seconds (3.98s).
[0m10:48:26.549888 [debug] [MainThread]: Command end result
[0m10:48:26.562636 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt/target/manifest.json
[0m10:48:26.566412 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt/target/semantic_manifest.json
[0m10:48:26.576245 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt/target/run_results.json
[0m10:48:26.577197 [info ] [MainThread]: 
[0m10:48:26.578252 [info ] [MainThread]: [32mCompleted successfully[0m
[0m10:48:26.579219 [info ] [MainThread]: 
[0m10:48:26.580316 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m10:48:26.582838 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 5.3260093, "process_in_blocks": "8", "process_kernel_time": 0.344743, "process_mem_max_rss": "221248", "process_out_blocks": "0", "process_user_time": 3.193949}
[0m10:48:26.583824 [debug] [MainThread]: Command `dbt run` succeeded at 10:48:26.583702 after 5.33 seconds
[0m10:48:26.584796 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa7ae985750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa7b2214c90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa7b22a5690>]}
[0m10:48:26.584761 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt/target/manifest.json
[0m10:48:26.585962 [debug] [MainThread]: Flushing usage events
[0m10:48:26.590275 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt/target/semantic_manifest.json
[0m10:48:26.598683 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt/target/run_results.json
[0m10:48:26.599473 [info ] [MainThread]: 
[0m10:48:26.600612 [info ] [MainThread]: [32mCompleted successfully[0m
[0m10:48:26.602144 [info ] [MainThread]: 
[0m10:48:26.603506 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m10:48:26.605132 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 5.36755, "process_in_blocks": "120", "process_kernel_time": 0.393472, "process_mem_max_rss": "222204", "process_out_blocks": "0", "process_user_time": 3.216635}
[0m10:48:26.606123 [debug] [MainThread]: Command `dbt run` succeeded at 10:48:26.605999 after 5.37 seconds
[0m10:48:26.606951 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f59c90dfa10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f59c8c57e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f59c8c57f90>]}
[0m10:48:26.607714 [debug] [MainThread]: Flushing usage events
[0m10:48:27.675844 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m10:48:27.878539 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m10:48:30.272869 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa93548fa90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa93548df90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa93548f310>]}


============================== 10:48:30.276050 | 1302924c-edb5-486c-b366-2a2642d3b92a ==============================
[0m10:48:30.276050 [info ] [MainThread]: Running with dbt=1.9.0
[0m10:48:30.277533 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/usr/app/dbt/logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --project-dir /usr/app/dbt --profiles-dir /usr/app/dbt --select facts', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m10:48:30.299041 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efc8cdd2910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efc8ce2bc10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efc8ce2bdd0>]}


============================== 10:48:30.301902 | 3cadde02-f099-477d-80d2-bd6003f71849 ==============================
[0m10:48:30.301902 [info ] [MainThread]: Running with dbt=1.9.0
[0m10:48:30.303075 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/usr/app/dbt/logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run --project-dir /usr/app/dbt --profiles-dir /usr/app/dbt --select facts', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m10:48:30.987515 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1302924c-edb5-486c-b366-2a2642d3b92a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa9077a8610>]}
[0m10:48:30.988225 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '3cadde02-f099-477d-80d2-bd6003f71849', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efc5ff79d90>]}
[0m10:48:31.039434 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '1302924c-edb5-486c-b366-2a2642d3b92a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa93773ce90>]}
[0m10:48:31.041689 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m10:48:31.043428 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '3cadde02-f099-477d-80d2-bd6003f71849', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efc8db624d0>]}
[0m10:48:31.044712 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m10:48:31.119202 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m10:48:31.119241 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m10:48:31.281192 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m10:48:31.282479 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m10:48:31.285479 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m10:48:31.286260 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m10:48:31.314041 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3cadde02-f099-477d-80d2-bd6003f71849', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efc5ec7d850>]}
[0m10:48:31.319026 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1302924c-edb5-486c-b366-2a2642d3b92a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa907493490>]}
[0m10:48:31.451539 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt/target/manifest.json
[0m10:48:31.457833 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt/target/semantic_manifest.json
[0m10:48:31.473678 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt/target/manifest.json
[0m10:48:31.479408 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt/target/semantic_manifest.json
[0m10:48:31.479359 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3cadde02-f099-477d-80d2-bd6003f71849', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efc5f097810>]}
[0m10:48:31.480845 [info ] [MainThread]: Found 9 models, 8 sources, 489 macros
[0m10:48:31.482007 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3cadde02-f099-477d-80d2-bd6003f71849', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efc5f061f10>]}
[0m10:48:31.485685 [info ] [MainThread]: 
[0m10:48:31.486947 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m10:48:31.487922 [info ] [MainThread]: 
[0m10:48:31.489296 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m10:48:31.494387 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m10:48:31.495247 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:48:31.501203 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1302924c-edb5-486c-b366-2a2642d3b92a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa9073bc250>]}
[0m10:48:31.502125 [info ] [MainThread]: Found 9 models, 8 sources, 489 macros
[0m10:48:31.503103 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1302924c-edb5-486c-b366-2a2642d3b92a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa907325c90>]}
[0m10:48:31.506012 [info ] [MainThread]: 
[0m10:48:31.507140 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m10:48:31.508101 [info ] [MainThread]: 
[0m10:48:31.509265 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m10:48:31.514905 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m10:48:31.516051 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:48:32.004354 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_staging)
[0m10:48:32.005109 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_facts'
[0m10:48:32.005808 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_marts'
[0m10:48:32.006359 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:48:32.007151 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:48:32.008161 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:48:32.261863 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3cadde02-f099-477d-80d2-bd6003f71849', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efc645dfcd0>]}
[0m10:48:32.263078 [debug] [MainThread]: Opening a new connection, currently in state init
[0m10:48:32.269426 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m10:48:32.269855 [debug] [Thread-2 (]: Began running node model.hailing_project.dim_driver
[0m10:48:32.270702 [info ] [Thread-1 (]: 1 of 3 START sql incremental model rizky_dwh_hailing_facts.dim_customer ........ [RUN]
[0m10:48:32.271758 [info ] [Thread-2 (]: 2 of 3 START sql incremental model rizky_dwh_hailing_facts.dim_driver .......... [RUN]
[0m10:48:32.272807 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_marts, now model.hailing_project.dim_customer)
[0m10:48:32.273679 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_facts, now model.hailing_project.dim_driver)
[0m10:48:32.274393 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m10:48:32.275790 [debug] [Thread-2 (]: Began compiling node model.hailing_project.dim_driver
[0m10:48:32.290488 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m10:48:32.294322 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.dim_driver"
[0m10:48:32.299808 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m10:48:32.300313 [debug] [Thread-2 (]: Began executing node model.hailing_project.dim_driver
[0m10:48:32.325834 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_marts)
[0m10:48:32.326699 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_staging'
[0m10:48:32.327602 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_facts'
[0m10:48:32.328585 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:48:32.329399 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:48:32.330746 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:48:32.357932 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m10:48:32.360191 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m10:48:32.585811 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1302924c-edb5-486c-b366-2a2642d3b92a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa907ddde90>]}
[0m10:48:32.586756 [debug] [MainThread]: Opening a new connection, currently in state init
[0m10:48:32.592494 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m10:48:32.592928 [debug] [Thread-2 (]: Began running node model.hailing_project.dim_driver
[0m10:48:32.593871 [info ] [Thread-1 (]: 1 of 3 START sql incremental model rizky_dwh_hailing_facts.dim_customer ........ [RUN]
[0m10:48:32.595214 [info ] [Thread-2 (]: 2 of 3 START sql incremental model rizky_dwh_hailing_facts.dim_driver .......... [RUN]
[0m10:48:32.596796 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_facts, now model.hailing_project.dim_customer)
[0m10:48:32.598066 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_marts, now model.hailing_project.dim_driver)
[0m10:48:32.598926 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m10:48:32.599936 [debug] [Thread-2 (]: Began compiling node model.hailing_project.dim_driver
[0m10:48:32.617458 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m10:48:32.621230 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.dim_driver"
[0m10:48:32.627371 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m10:48:32.627947 [debug] [Thread-2 (]: Began executing node model.hailing_project.dim_driver
[0m10:48:32.654298 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m10:48:32.656212 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.dim_driver"
[0m10:48:32.661777 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
)

SELECT * FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m10:48:32.662441 [debug] [Thread-2 (]: On model.hailing_project.dim_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver` as DBT_INTERNAL_DEST
        using (


WITH driver AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver` --pakai ref untuk buat dependency

),

vehicle AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle`
)

SELECT
    driver.driver_id,
    vehicle.vehicle_id,
    driver.name AS driver_name,
    driver.phone_number AS phone_number,
    driver.email AS email,
    vehicle.vehicle_type,
    vehicle.brand AS vehicle_brand,
    vehicle.year AS vehicle_production_year,
    vehicle.license_plate,
    driver.created_at
FROM driver
LEFT JOIN vehicle
on driver.driver_id = vehicle.driver_id


    WHERE driver.created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_name` = DBT_INTERNAL_SOURCE.`driver_name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`vehicle_brand` = DBT_INTERNAL_SOURCE.`vehicle_brand`,`vehicle_production_year` = DBT_INTERNAL_SOURCE.`vehicle_production_year`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `vehicle_id`, `driver_name`, `phone_number`, `email`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)
    values
        (`driver_id`, `vehicle_id`, `driver_name`, `phone_number`, `email`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)


    
[0m10:48:32.693008 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m10:48:32.693511 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m10:48:32.909431 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:8c3de222-76b8-4b0b-a731-e747f56b0c84&page=queryresults
[0m10:48:32.910055 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:18b8dabf-e6e9-4d15-8442-d98b62c1922f&page=queryresults
[0m10:48:32.982452 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m10:48:32.981109 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.dim_driver"
[0m10:48:32.988199 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
)

SELECT * FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m10:48:32.991091 [debug] [Thread-2 (]: On model.hailing_project.dim_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver` as DBT_INTERNAL_DEST
        using (


WITH driver AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver` --pakai ref untuk buat dependency

),

vehicle AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle`
)

SELECT
    driver.driver_id,
    vehicle.vehicle_id,
    driver.name AS driver_name,
    driver.phone_number AS phone_number,
    driver.email AS email,
    vehicle.vehicle_type,
    vehicle.brand AS vehicle_brand,
    vehicle.year AS vehicle_production_year,
    vehicle.license_plate,
    driver.created_at
FROM driver
LEFT JOIN vehicle
on driver.driver_id = vehicle.driver_id


    WHERE driver.created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_name` = DBT_INTERNAL_SOURCE.`driver_name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`vehicle_brand` = DBT_INTERNAL_SOURCE.`vehicle_brand`,`vehicle_production_year` = DBT_INTERNAL_SOURCE.`vehicle_production_year`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `vehicle_id`, `driver_name`, `phone_number`, `email`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)
    values
        (`driver_id`, `vehicle_id`, `driver_name`, `phone_number`, `email`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)


    
[0m10:48:33.196984 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:2f85e00f-4f94-4780-b648-fdc37a4ebd58&page=queryresults
[0m10:48:33.205851 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:f40298f9-3a85-4550-bb3b-16f37f46d6a5&page=queryresults
[0m10:48:34.523814 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3cadde02-f099-477d-80d2-bd6003f71849', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efc46ec5f90>]}
[0m10:48:34.525080 [info ] [Thread-1 (]: 1 of 3 OK created sql incremental model rizky_dwh_hailing_facts.dim_customer ... [[32mMERGE (10.0 rows, 16.2 KiB processed)[0m in 2.25s]
[0m10:48:34.527260 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m10:48:34.646866 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3cadde02-f099-477d-80d2-bd6003f71849', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efc5edfe810>]}
[0m10:48:34.648182 [info ] [Thread-2 (]: 2 of 3 OK created sql incremental model rizky_dwh_hailing_facts.dim_driver ..... [[32mMERGE (20.0 rows, 26.6 KiB processed)[0m in 2.37s]
[0m10:48:34.649925 [debug] [Thread-2 (]: Finished running node model.hailing_project.dim_driver
[0m10:48:34.652527 [debug] [Thread-4 (]: Began running node model.hailing_project.fact_hailing_rides
[0m10:48:34.653816 [info ] [Thread-4 (]: 3 of 3 START sql incremental model rizky_dwh_hailing_facts.fact_hailing_rides .. [RUN]
[0m10:48:34.655057 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.fact_hailing_rides'
[0m10:48:34.655891 [debug] [Thread-4 (]: Began compiling node model.hailing_project.fact_hailing_rides
[0m10:48:34.660841 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.fact_hailing_rides"
[0m10:48:34.666973 [debug] [Thread-4 (]: Began executing node model.hailing_project.fact_hailing_rides
[0m10:48:34.670243 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m10:48:34.910701 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.fact_hailing_rides"
[0m10:48:34.917025 [debug] [Thread-4 (]: On model.hailing_project.fact_hailing_rides: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.fact_hailing_rides"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides` as DBT_INTERNAL_DEST
        using (

WITH dim_driver AS (

    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
),

dim_customer AS (

    SELECT * 
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer`
),

ride_staging AS (

    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride`
)

SELECT
ride_staging.ride_id,
ride_staging.start_time AS ride_start_time,
ride_staging.end_time AS ride_end_time,
ride_staging.distance_km,
ride_staging.fare,
ride_staging.ride_status,
dim_customer.cust_id,
dim_customer.name AS cust_name,
dim_customer.phone_number AS cust_phone_number,
dim_customer.email AS cust_email,
dim_driver.driver_id,
dim_driver.driver_name,
dim_driver.phone_number AS driver_phone_number,
dim_driver.email AS driver_email,
dim_driver.vehicle_id,
dim_driver.vehicle_type,
dim_driver.vehicle_brand,
dim_driver.vehicle_production_year,
dim_driver.license_plate,
ride_staging.created_at

FROM ride_staging

LEFT JOIN dim_customer
on ride_staging.cust_id = dim_customer.cust_id

LEFT JOIN dim_driver
on ride_staging.driver_id = dim_driver.driver_id


    WHERE ride_staging.created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`ride_start_time` = DBT_INTERNAL_SOURCE.`ride_start_time`,`ride_end_time` = DBT_INTERNAL_SOURCE.`ride_end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`cust_name` = DBT_INTERNAL_SOURCE.`cust_name`,`cust_phone_number` = DBT_INTERNAL_SOURCE.`cust_phone_number`,`cust_email` = DBT_INTERNAL_SOURCE.`cust_email`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`driver_name` = DBT_INTERNAL_SOURCE.`driver_name`,`driver_phone_number` = DBT_INTERNAL_SOURCE.`driver_phone_number`,`driver_email` = DBT_INTERNAL_SOURCE.`driver_email`,`vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`vehicle_brand` = DBT_INTERNAL_SOURCE.`vehicle_brand`,`vehicle_production_year` = DBT_INTERNAL_SOURCE.`vehicle_production_year`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `ride_start_time`, `ride_end_time`, `distance_km`, `fare`, `ride_status`, `cust_id`, `cust_name`, `cust_phone_number`, `cust_email`, `driver_id`, `driver_name`, `driver_phone_number`, `driver_email`, `vehicle_id`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)
    values
        (`ride_id`, `ride_start_time`, `ride_end_time`, `distance_km`, `fare`, `ride_status`, `cust_id`, `cust_name`, `cust_phone_number`, `cust_email`, `driver_id`, `driver_name`, `driver_phone_number`, `driver_email`, `vehicle_id`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)


    
[0m10:48:34.990073 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1302924c-edb5-486c-b366-2a2642d3b92a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa935496c10>]}
[0m10:48:34.990548 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1302924c-edb5-486c-b366-2a2642d3b92a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa907267290>]}
[0m10:48:34.992342 [info ] [Thread-1 (]: 1 of 3 OK created sql incremental model rizky_dwh_hailing_facts.dim_customer ... [[32mMERGE (10.0 rows, 16.2 KiB processed)[0m in 2.39s]
[0m10:48:34.993798 [info ] [Thread-2 (]: 2 of 3 OK created sql incremental model rizky_dwh_hailing_facts.dim_driver ..... [[32mMERGE (20.0 rows, 26.6 KiB processed)[0m in 2.39s]
[0m10:48:34.995093 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m10:48:34.996343 [debug] [Thread-2 (]: Finished running node model.hailing_project.dim_driver
[0m10:48:34.999081 [debug] [Thread-4 (]: Began running node model.hailing_project.fact_hailing_rides
[0m10:48:35.000044 [info ] [Thread-4 (]: 3 of 3 START sql incremental model rizky_dwh_hailing_facts.fact_hailing_rides .. [RUN]
[0m10:48:35.001204 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.fact_hailing_rides'
[0m10:48:35.002043 [debug] [Thread-4 (]: Began compiling node model.hailing_project.fact_hailing_rides
[0m10:48:35.008404 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.fact_hailing_rides"
[0m10:48:35.015523 [debug] [Thread-4 (]: Began executing node model.hailing_project.fact_hailing_rides
[0m10:48:35.020160 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m10:48:35.168695 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:db55b0fd-bcfd-435a-b2c0-25ad58d01507&page=queryresults
[0m10:48:35.241649 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.fact_hailing_rides"
[0m10:48:35.248078 [debug] [Thread-4 (]: On model.hailing_project.fact_hailing_rides: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.fact_hailing_rides"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides` as DBT_INTERNAL_DEST
        using (

WITH dim_driver AS (

    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
),

dim_customer AS (

    SELECT * 
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer`
),

ride_staging AS (

    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride`
)

SELECT
ride_staging.ride_id,
ride_staging.start_time AS ride_start_time,
ride_staging.end_time AS ride_end_time,
ride_staging.distance_km,
ride_staging.fare,
ride_staging.ride_status,
dim_customer.cust_id,
dim_customer.name AS cust_name,
dim_customer.phone_number AS cust_phone_number,
dim_customer.email AS cust_email,
dim_driver.driver_id,
dim_driver.driver_name,
dim_driver.phone_number AS driver_phone_number,
dim_driver.email AS driver_email,
dim_driver.vehicle_id,
dim_driver.vehicle_type,
dim_driver.vehicle_brand,
dim_driver.vehicle_production_year,
dim_driver.license_plate,
ride_staging.created_at

FROM ride_staging

LEFT JOIN dim_customer
on ride_staging.cust_id = dim_customer.cust_id

LEFT JOIN dim_driver
on ride_staging.driver_id = dim_driver.driver_id


    WHERE ride_staging.created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`ride_start_time` = DBT_INTERNAL_SOURCE.`ride_start_time`,`ride_end_time` = DBT_INTERNAL_SOURCE.`ride_end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`cust_name` = DBT_INTERNAL_SOURCE.`cust_name`,`cust_phone_number` = DBT_INTERNAL_SOURCE.`cust_phone_number`,`cust_email` = DBT_INTERNAL_SOURCE.`cust_email`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`driver_name` = DBT_INTERNAL_SOURCE.`driver_name`,`driver_phone_number` = DBT_INTERNAL_SOURCE.`driver_phone_number`,`driver_email` = DBT_INTERNAL_SOURCE.`driver_email`,`vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`vehicle_brand` = DBT_INTERNAL_SOURCE.`vehicle_brand`,`vehicle_production_year` = DBT_INTERNAL_SOURCE.`vehicle_production_year`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `ride_start_time`, `ride_end_time`, `distance_km`, `fare`, `ride_status`, `cust_id`, `cust_name`, `cust_phone_number`, `cust_email`, `driver_id`, `driver_name`, `driver_phone_number`, `driver_email`, `vehicle_id`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)
    values
        (`ride_id`, `ride_start_time`, `ride_end_time`, `distance_km`, `fare`, `ride_status`, `cust_id`, `cust_name`, `cust_phone_number`, `cust_email`, `driver_id`, `driver_name`, `driver_phone_number`, `driver_email`, `vehicle_id`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)


    
[0m10:48:35.464021 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:d2a2129b-9f15-400f-a462-d7eb0c0bb382&page=queryresults
[0m10:48:36.920095 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3cadde02-f099-477d-80d2-bd6003f71849', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efc5f0df510>]}
[0m10:48:36.921801 [info ] [Thread-4 (]: 3 of 3 OK created sql incremental model rizky_dwh_hailing_facts.fact_hailing_rides  [[32mMERGE (10.0 rows, 61.1 KiB processed)[0m in 2.27s]
[0m10:48:36.923230 [debug] [Thread-4 (]: Finished running node model.hailing_project.fact_hailing_rides
[0m10:48:36.925549 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m10:48:36.928350 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:48:36.929302 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_staging' was properly closed.
[0m10:48:36.930102 [debug] [MainThread]: Connection 'model.hailing_project.dim_driver' was properly closed.
[0m10:48:36.930769 [debug] [MainThread]: Connection 'model.hailing_project.dim_customer' was properly closed.
[0m10:48:36.931359 [debug] [MainThread]: Connection 'model.hailing_project.fact_hailing_rides' was properly closed.
[0m10:48:36.932049 [info ] [MainThread]: 
[0m10:48:36.932887 [info ] [MainThread]: Finished running 3 incremental models in 0 hours 0 minutes and 5.44 seconds (5.44s).
[0m10:48:36.934614 [debug] [MainThread]: Command end result
[0m10:48:36.969156 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt/target/manifest.json
[0m10:48:36.973857 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt/target/semantic_manifest.json
[0m10:48:36.982529 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt/target/run_results.json
[0m10:48:36.983477 [info ] [MainThread]: 
[0m10:48:36.984842 [info ] [MainThread]: [32mCompleted successfully[0m
[0m10:48:36.986046 [info ] [MainThread]: 
[0m10:48:36.987029 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
[0m10:48:36.988520 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 6.745951, "process_in_blocks": "688", "process_kernel_time": 0.148261, "process_mem_max_rss": "222028", "process_out_blocks": "0", "process_user_time": 3.271629}
[0m10:48:36.989512 [debug] [MainThread]: Command `dbt run` succeeded at 10:48:36.989384 after 6.75 seconds
[0m10:48:36.990728 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efc8ce26410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efc8ce24790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efc90721510>]}
[0m10:48:36.992209 [debug] [MainThread]: Flushing usage events
[0m10:48:37.222498 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1302924c-edb5-486c-b366-2a2642d3b92a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa9354d1990>]}
[0m10:48:37.225108 [info ] [Thread-4 (]: 3 of 3 OK created sql incremental model rizky_dwh_hailing_facts.fact_hailing_rides  [[32mMERGE (10.0 rows, 61.1 KiB processed)[0m in 2.22s]
[0m10:48:37.227099 [debug] [Thread-4 (]: Finished running node model.hailing_project.fact_hailing_rides
[0m10:48:37.229943 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m10:48:37.233326 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:48:37.234672 [debug] [MainThread]: Connection 'model.hailing_project.dim_driver' was properly closed.
[0m10:48:37.235768 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_staging' was properly closed.
[0m10:48:37.236721 [debug] [MainThread]: Connection 'model.hailing_project.dim_customer' was properly closed.
[0m10:48:37.237781 [debug] [MainThread]: Connection 'model.hailing_project.fact_hailing_rides' was properly closed.
[0m10:48:37.238737 [info ] [MainThread]: 
[0m10:48:37.239659 [info ] [MainThread]: Finished running 3 incremental models in 0 hours 0 minutes and 5.73 seconds (5.73s).
[0m10:48:37.242091 [debug] [MainThread]: Command end result
[0m10:48:37.277595 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt/target/manifest.json
[0m10:48:37.281350 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt/target/semantic_manifest.json
[0m10:48:37.291455 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt/target/run_results.json
[0m10:48:37.292288 [info ] [MainThread]: 
[0m10:48:37.293459 [info ] [MainThread]: [32mCompleted successfully[0m
[0m10:48:37.294413 [info ] [MainThread]: 
[0m10:48:37.295458 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
[0m10:48:37.297834 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 7.0809045, "process_in_blocks": "1224", "process_kernel_time": 0.208463, "process_mem_max_rss": "221840", "process_out_blocks": "0", "process_user_time": 3.285777}
[0m10:48:37.298945 [debug] [MainThread]: Command `dbt run` succeeded at 10:48:37.298790 after 7.08 seconds
[0m10:48:37.299873 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa935599d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa938db4c90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa938e44c50>]}
[0m10:48:37.300947 [debug] [MainThread]: Flushing usage events
[0m10:48:37.948234 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m10:48:38.295752 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m10:48:40.385101 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd8efbac50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd8f013b10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd8efbb3d0>]}


============================== 10:48:40.389600 | 53405e91-94d0-4342-8fa3-1fe2743d5605 ==============================
[0m10:48:40.389600 [info ] [MainThread]: Running with dbt=1.9.0
[0m10:48:40.390873 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/usr/app/dbt/logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt run --project-dir /usr/app/dbt --profiles-dir /usr/app/dbt --select marts', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m10:48:40.417592 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdde641f850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdde6477c50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdde641fbd0>]}


============================== 10:48:40.421778 | dabadbff-ad14-49db-bb63-86ec7737c564 ==============================
[0m10:48:40.421778 [info ] [MainThread]: Running with dbt=1.9.0
[0m10:48:40.423193 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/usr/app/dbt/logs', 'profiles_dir': '/usr/app/dbt', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt run --project-dir /usr/app/dbt --profiles-dir /usr/app/dbt --select marts', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m10:48:41.257450 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '53405e91-94d0-4342-8fa3-1fe2743d5605', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd61197fd0>]}
[0m10:48:41.318377 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'dabadbff-ad14-49db-bb63-86ec7737c564', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fddbc5eb6d0>]}
[0m10:48:41.321596 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '53405e91-94d0-4342-8fa3-1fe2743d5605', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd9126a710>]}
[0m10:48:41.323018 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m10:48:41.376205 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'dabadbff-ad14-49db-bb63-86ec7737c564', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdde86a2850>]}
[0m10:48:41.377539 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m10:48:41.405438 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m10:48:41.461894 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m10:48:41.632532 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m10:48:41.633748 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m10:48:41.666242 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '53405e91-94d0-4342-8fa3-1fe2743d5605', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd6105e490>]}
[0m10:48:41.683423 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m10:48:41.684440 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m10:48:41.716506 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'dabadbff-ad14-49db-bb63-86ec7737c564', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fddbcd4b450>]}
[0m10:48:41.812625 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt/target/manifest.json
[0m10:48:41.820374 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt/target/semantic_manifest.json
[0m10:48:41.837434 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '53405e91-94d0-4342-8fa3-1fe2743d5605', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd60f7c310>]}
[0m10:48:41.839354 [info ] [MainThread]: Found 9 models, 8 sources, 489 macros
[0m10:48:41.840696 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '53405e91-94d0-4342-8fa3-1fe2743d5605', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd60fd6290>]}
[0m10:48:41.843768 [info ] [MainThread]: 
[0m10:48:41.844969 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m10:48:41.846296 [info ] [MainThread]: 
[0m10:48:41.847859 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m10:48:41.851931 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m10:48:41.853102 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:48:41.865757 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt/target/manifest.json
[0m10:48:41.871099 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt/target/semantic_manifest.json
[0m10:48:41.889900 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'dabadbff-ad14-49db-bb63-86ec7737c564', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fddbc1e4c50>]}
[0m10:48:41.893237 [info ] [MainThread]: Found 9 models, 8 sources, 489 macros
[0m10:48:41.894958 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'dabadbff-ad14-49db-bb63-86ec7737c564', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fddbc67e7d0>]}
[0m10:48:41.897446 [info ] [MainThread]: 
[0m10:48:41.898586 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m10:48:41.899659 [info ] [MainThread]: 
[0m10:48:41.901269 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m10:48:41.906116 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m10:48:41.906865 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:48:42.333626 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_staging)
[0m10:48:42.334658 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_marts'
[0m10:48:42.335266 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_facts'
[0m10:48:42.335706 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:48:42.336634 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:48:42.337419 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:48:42.590717 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '53405e91-94d0-4342-8fa3-1fe2743d5605', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd6116b050>]}
[0m10:48:42.591588 [debug] [MainThread]: Opening a new connection, currently in state init
[0m10:48:42.596078 [debug] [Thread-1 (]: Began running node model.hailing_project.mart_cust_rides_daily
[0m10:48:42.596465 [debug] [Thread-2 (]: Began running node model.hailing_project.mart_driver_loyalty_mgmt
[0m10:48:42.597170 [info ] [Thread-1 (]: 1 of 2 START sql incremental model rizky_dwh_hailing_marts.mart_cust_rides_daily  [RUN]
[0m10:48:42.598198 [info ] [Thread-2 (]: 2 of 2 START sql incremental model rizky_dwh_hailing_marts.mart_driver_loyalty_mgmt  [RUN]
[0m10:48:42.599142 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_facts, now model.hailing_project.mart_cust_rides_daily)
[0m10:48:42.600021 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_marts, now model.hailing_project.mart_driver_loyalty_mgmt)
[0m10:48:42.600795 [debug] [Thread-1 (]: Began compiling node model.hailing_project.mart_cust_rides_daily
[0m10:48:42.601469 [debug] [Thread-2 (]: Began compiling node model.hailing_project.mart_driver_loyalty_mgmt
[0m10:48:42.611665 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.mart_cust_rides_daily"
[0m10:48:42.614886 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.mart_driver_loyalty_mgmt"
[0m10:48:42.619621 [debug] [Thread-1 (]: Began executing node model.hailing_project.mart_cust_rides_daily
[0m10:48:42.625883 [debug] [Thread-2 (]: Began executing node model.hailing_project.mart_driver_loyalty_mgmt
[0m10:48:42.652973 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_staging)
[0m10:48:42.653607 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_marts'
[0m10:48:42.654137 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_facts'
[0m10:48:42.654899 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:48:42.655823 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:48:42.656695 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:48:42.667901 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m10:48:42.669124 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m10:48:42.919622 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'dabadbff-ad14-49db-bb63-86ec7737c564', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdde71ea650>]}
[0m10:48:42.920550 [debug] [MainThread]: Opening a new connection, currently in state init
[0m10:48:42.926697 [debug] [Thread-1 (]: Began running node model.hailing_project.mart_cust_rides_daily
[0m10:48:42.927084 [debug] [Thread-2 (]: Began running node model.hailing_project.mart_driver_loyalty_mgmt
[0m10:48:42.927930 [info ] [Thread-1 (]: 1 of 2 START sql incremental model rizky_dwh_hailing_marts.mart_cust_rides_daily  [RUN]
[0m10:48:42.929279 [info ] [Thread-2 (]: 2 of 2 START sql incremental model rizky_dwh_hailing_marts.mart_driver_loyalty_mgmt  [RUN]
[0m10:48:42.930615 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_facts, now model.hailing_project.mart_cust_rides_daily)
[0m10:48:42.931661 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_marts, now model.hailing_project.mart_driver_loyalty_mgmt)
[0m10:48:42.932431 [debug] [Thread-1 (]: Began compiling node model.hailing_project.mart_cust_rides_daily
[0m10:48:42.933147 [debug] [Thread-2 (]: Began compiling node model.hailing_project.mart_driver_loyalty_mgmt
[0m10:48:42.942352 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.mart_cust_rides_daily"
[0m10:48:42.946197 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.mart_driver_loyalty_mgmt"
[0m10:48:42.951332 [debug] [Thread-1 (]: Began executing node model.hailing_project.mart_cust_rides_daily
[0m10:48:42.966109 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.mart_cust_rides_daily"
[0m10:48:42.966620 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.mart_driver_loyalty_mgmt"
[0m10:48:42.957765 [debug] [Thread-2 (]: Began executing node model.hailing_project.mart_driver_loyalty_mgmt
[0m10:48:42.971956 [debug] [Thread-1 (]: On model.hailing_project.mart_cust_rides_daily: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.mart_cust_rides_daily"} */
-- back compat for old kwarg name
  
  
        
            
                
                
            
                
                
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_marts`.`mart_cust_rides_daily` as DBT_INTERNAL_DEST
        using (


WITH fact_rides AS(

    SELECT * 
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
)

SELECT 

    fact_rides.cust_id,
    DATE(fact_rides.created_at) AS ride_date,
    fact_rides.cust_name,
    fact_rides.cust_email,
    fact_rides.cust_phone_number,
    COUNT(fact_rides.ride_id) AS no_of_rides,
    SUM(TIMESTAMP_DIFF(fact_rides.ride_end_time, fact_rides.ride_start_time, MINUTE)) AS total_ride_duration_min,
    SUM(fact_rides.fare) AS total_fare,
    SUM(fact_rides.distance_km) as total_distance_km,
    SUM(fact_rides.distance_km)-SUM(fact_rides.fare) AS rev_opportunity_loss,

FROM fact_rides
GROUP BY cust_name, cust_id, ride_date, cust_email, cust_phone_number
        ) as DBT_INTERNAL_SOURCE
        on (
                    DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
                ) and (
                    DBT_INTERNAL_SOURCE.ride_date = DBT_INTERNAL_DEST.ride_date
                )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`ride_date` = DBT_INTERNAL_SOURCE.`ride_date`,`cust_name` = DBT_INTERNAL_SOURCE.`cust_name`,`cust_email` = DBT_INTERNAL_SOURCE.`cust_email`,`cust_phone_number` = DBT_INTERNAL_SOURCE.`cust_phone_number`,`no_of_rides` = DBT_INTERNAL_SOURCE.`no_of_rides`,`total_ride_duration_min` = DBT_INTERNAL_SOURCE.`total_ride_duration_min`,`total_fare` = DBT_INTERNAL_SOURCE.`total_fare`,`total_distance_km` = DBT_INTERNAL_SOURCE.`total_distance_km`,`rev_opportunity_loss` = DBT_INTERNAL_SOURCE.`rev_opportunity_loss`
    

    when not matched then insert
        (`cust_id`, `ride_date`, `cust_name`, `cust_email`, `cust_phone_number`, `no_of_rides`, `total_ride_duration_min`, `total_fare`, `total_distance_km`, `rev_opportunity_loss`)
    values
        (`cust_id`, `ride_date`, `cust_name`, `cust_email`, `cust_phone_number`, `no_of_rides`, `total_ride_duration_min`, `total_fare`, `total_distance_km`, `rev_opportunity_loss`)


    
[0m10:48:42.974372 [debug] [Thread-2 (]: On model.hailing_project.mart_driver_loyalty_mgmt: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.mart_driver_loyalty_mgmt"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_marts`.`mart_driver_loyalty_mgmt` as DBT_INTERNAL_DEST
        using (

WITH dim_driver AS(
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
),

fact_rides AS(
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
)

SELECT 
dim_driver.driver_id,
dim_driver.driver_name,
dim_driver.phone_number,
dim_driver.email,
dim_driver.vehicle_type,
COUNT(fact_rides.ride_id) AS no_of_rides,
SUM(TIMESTAMP_DIFF(fact_rides.ride_end_time, fact_rides.ride_start_time, MINUTE)) AS total_ride_duration_min,
SUM(fact_rides.fare) AS total_fare,
SUM(fact_rides.distance_km) as total_distance_km,
SUM(fact_rides.distance_km)-SUM(fact_rides.fare) AS rev_opportunity_loss,
FROM dim_driver
LEFT JOIN fact_rides
ON dim_driver.driver_id = fact_rides.driver_id

GROUP BY driver_id,driver_name,phone_number,email,vehicle_type
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`driver_name` = DBT_INTERNAL_SOURCE.`driver_name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`no_of_rides` = DBT_INTERNAL_SOURCE.`no_of_rides`,`total_ride_duration_min` = DBT_INTERNAL_SOURCE.`total_ride_duration_min`,`total_fare` = DBT_INTERNAL_SOURCE.`total_fare`,`total_distance_km` = DBT_INTERNAL_SOURCE.`total_distance_km`,`rev_opportunity_loss` = DBT_INTERNAL_SOURCE.`rev_opportunity_loss`
    

    when not matched then insert
        (`driver_id`, `driver_name`, `phone_number`, `email`, `vehicle_type`, `no_of_rides`, `total_ride_duration_min`, `total_fare`, `total_distance_km`, `rev_opportunity_loss`)
    values
        (`driver_id`, `driver_name`, `phone_number`, `email`, `vehicle_type`, `no_of_rides`, `total_ride_duration_min`, `total_fare`, `total_distance_km`, `rev_opportunity_loss`)


    
[0m10:48:42.999284 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m10:48:43.003046 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m10:48:43.413146 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:e103d948-adee-48ee-b981-e999bc433f34&page=queryresults
[0m10:48:43.413922 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:4bc91208-1e00-4269-9ebd-3098b55a3c92&page=queryresults
[0m10:48:43.567177 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.mart_driver_loyalty_mgmt"
[0m10:48:43.570548 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.mart_cust_rides_daily"
[0m10:48:43.576407 [debug] [Thread-2 (]: On model.hailing_project.mart_driver_loyalty_mgmt: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.mart_driver_loyalty_mgmt"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_marts`.`mart_driver_loyalty_mgmt` as DBT_INTERNAL_DEST
        using (

WITH dim_driver AS(
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
),

fact_rides AS(
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
)

SELECT 
dim_driver.driver_id,
dim_driver.driver_name,
dim_driver.phone_number,
dim_driver.email,
dim_driver.vehicle_type,
COUNT(fact_rides.ride_id) AS no_of_rides,
SUM(TIMESTAMP_DIFF(fact_rides.ride_end_time, fact_rides.ride_start_time, MINUTE)) AS total_ride_duration_min,
SUM(fact_rides.fare) AS total_fare,
SUM(fact_rides.distance_km) as total_distance_km,
SUM(fact_rides.distance_km)-SUM(fact_rides.fare) AS rev_opportunity_loss,
FROM dim_driver
LEFT JOIN fact_rides
ON dim_driver.driver_id = fact_rides.driver_id

GROUP BY driver_id,driver_name,phone_number,email,vehicle_type
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`driver_name` = DBT_INTERNAL_SOURCE.`driver_name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`no_of_rides` = DBT_INTERNAL_SOURCE.`no_of_rides`,`total_ride_duration_min` = DBT_INTERNAL_SOURCE.`total_ride_duration_min`,`total_fare` = DBT_INTERNAL_SOURCE.`total_fare`,`total_distance_km` = DBT_INTERNAL_SOURCE.`total_distance_km`,`rev_opportunity_loss` = DBT_INTERNAL_SOURCE.`rev_opportunity_loss`
    

    when not matched then insert
        (`driver_id`, `driver_name`, `phone_number`, `email`, `vehicle_type`, `no_of_rides`, `total_ride_duration_min`, `total_fare`, `total_distance_km`, `rev_opportunity_loss`)
    values
        (`driver_id`, `driver_name`, `phone_number`, `email`, `vehicle_type`, `no_of_rides`, `total_ride_duration_min`, `total_fare`, `total_distance_km`, `rev_opportunity_loss`)


    
[0m10:48:43.577243 [debug] [Thread-1 (]: On model.hailing_project.mart_cust_rides_daily: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.mart_cust_rides_daily"} */
-- back compat for old kwarg name
  
  
        
            
                
                
            
                
                
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_marts`.`mart_cust_rides_daily` as DBT_INTERNAL_DEST
        using (


WITH fact_rides AS(

    SELECT * 
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
)

SELECT 

    fact_rides.cust_id,
    DATE(fact_rides.created_at) AS ride_date,
    fact_rides.cust_name,
    fact_rides.cust_email,
    fact_rides.cust_phone_number,
    COUNT(fact_rides.ride_id) AS no_of_rides,
    SUM(TIMESTAMP_DIFF(fact_rides.ride_end_time, fact_rides.ride_start_time, MINUTE)) AS total_ride_duration_min,
    SUM(fact_rides.fare) AS total_fare,
    SUM(fact_rides.distance_km) as total_distance_km,
    SUM(fact_rides.distance_km)-SUM(fact_rides.fare) AS rev_opportunity_loss,

FROM fact_rides
GROUP BY cust_name, cust_id, ride_date, cust_email, cust_phone_number
        ) as DBT_INTERNAL_SOURCE
        on (
                    DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
                ) and (
                    DBT_INTERNAL_SOURCE.ride_date = DBT_INTERNAL_DEST.ride_date
                )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`ride_date` = DBT_INTERNAL_SOURCE.`ride_date`,`cust_name` = DBT_INTERNAL_SOURCE.`cust_name`,`cust_email` = DBT_INTERNAL_SOURCE.`cust_email`,`cust_phone_number` = DBT_INTERNAL_SOURCE.`cust_phone_number`,`no_of_rides` = DBT_INTERNAL_SOURCE.`no_of_rides`,`total_ride_duration_min` = DBT_INTERNAL_SOURCE.`total_ride_duration_min`,`total_fare` = DBT_INTERNAL_SOURCE.`total_fare`,`total_distance_km` = DBT_INTERNAL_SOURCE.`total_distance_km`,`rev_opportunity_loss` = DBT_INTERNAL_SOURCE.`rev_opportunity_loss`
    

    when not matched then insert
        (`cust_id`, `ride_date`, `cust_name`, `cust_email`, `cust_phone_number`, `no_of_rides`, `total_ride_duration_min`, `total_fare`, `total_distance_km`, `rev_opportunity_loss`)
    values
        (`cust_id`, `ride_date`, `cust_name`, `cust_email`, `cust_phone_number`, `no_of_rides`, `total_ride_duration_min`, `total_fare`, `total_distance_km`, `rev_opportunity_loss`)


    
[0m10:48:43.808806 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:4f28de2f-b97c-46c0-985a-8e18c5ad99f2&page=queryresults
[0m10:48:43.821245 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:2f456bf4-887a-49b3-b92b-e1df7a602e93&page=queryresults
[0m10:48:44.945693 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '53405e91-94d0-4342-8fa3-1fe2743d5605', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd62e7fa50>]}
[0m10:48:44.947250 [info ] [Thread-2 (]: 2 of 2 OK created sql incremental model rizky_dwh_hailing_marts.mart_driver_loyalty_mgmt  [[32mMERGE (121.0 rows, 30.7 KiB processed)[0m in 2.34s]
[0m10:48:44.949091 [debug] [Thread-2 (]: Finished running node model.hailing_project.mart_driver_loyalty_mgmt
[0m10:48:45.673187 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dabadbff-ad14-49db-bb63-86ec7737c564', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fddbc7b3a90>]}
[0m10:48:45.674321 [info ] [Thread-1 (]: 1 of 2 OK created sql incremental model rizky_dwh_hailing_marts.mart_cust_rides_daily  [[32mMERGE (100.0 rows, 28.9 KiB processed)[0m in 2.74s]
[0m10:48:45.676023 [debug] [Thread-1 (]: Finished running node model.hailing_project.mart_cust_rides_daily
[0m10:48:50.854577 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dabadbff-ad14-49db-bb63-86ec7737c564', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fddbc27bb90>]}
[0m10:48:50.855679 [info ] [Thread-2 (]: 2 of 2 OK created sql incremental model rizky_dwh_hailing_marts.mart_driver_loyalty_mgmt  [[32mMERGE (121.0 rows, 31.2 KiB processed)[0m in 7.92s]
[0m10:48:50.856925 [debug] [Thread-2 (]: Finished running node model.hailing_project.mart_driver_loyalty_mgmt
[0m10:48:50.859250 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m10:48:50.863239 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:48:50.864037 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_staging' was properly closed.
[0m10:48:50.864857 [debug] [MainThread]: Connection 'model.hailing_project.mart_driver_loyalty_mgmt' was properly closed.
[0m10:48:50.865492 [debug] [MainThread]: Connection 'model.hailing_project.mart_cust_rides_daily' was properly closed.
[0m10:48:50.866307 [info ] [MainThread]: 
[0m10:48:50.867787 [info ] [MainThread]: Finished running 2 incremental models in 0 hours 0 minutes and 8.97 seconds (8.97s).
[0m10:48:50.869430 [debug] [MainThread]: Command end result
[0m10:48:50.904761 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt/target/manifest.json
[0m10:48:50.909317 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt/target/semantic_manifest.json
[0m10:48:50.917578 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt/target/run_results.json
[0m10:48:50.918386 [info ] [MainThread]: 
[0m10:48:50.919379 [info ] [MainThread]: [32mCompleted successfully[0m
[0m10:48:50.920462 [info ] [MainThread]: 
[0m10:48:50.921491 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m10:48:50.923789 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 10.572881, "process_in_blocks": "0", "process_kernel_time": 0.233926, "process_mem_max_rss": "219812", "process_out_blocks": "0", "process_user_time": 3.45805}
[0m10:48:50.924901 [debug] [MainThread]: Command `dbt run` succeeded at 10:48:50.924760 after 10.57 seconds
[0m10:48:50.925826 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdde9cfea10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fddb45d2450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdde9c18d10>]}
[0m10:48:50.926609 [debug] [MainThread]: Flushing usage events
[0m10:48:51.249433 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '53405e91-94d0-4342-8fa3-1fe2743d5605', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd61215a10>]}
[0m10:48:51.252006 [info ] [Thread-1 (]: 1 of 2 OK created sql incremental model rizky_dwh_hailing_marts.mart_cust_rides_daily  [[32mMERGE (100.0 rows, 29.2 KiB processed)[0m in 8.65s]
[0m10:48:51.253985 [debug] [Thread-1 (]: Finished running node model.hailing_project.mart_cust_rides_daily
[0m10:48:51.256346 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m10:48:51.259218 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:48:51.259954 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_staging' was properly closed.
[0m10:48:51.260629 [debug] [MainThread]: Connection 'model.hailing_project.mart_driver_loyalty_mgmt' was properly closed.
[0m10:48:51.261198 [debug] [MainThread]: Connection 'model.hailing_project.mart_cust_rides_daily' was properly closed.
[0m10:48:51.261936 [info ] [MainThread]: 
[0m10:48:51.262905 [info ] [MainThread]: Finished running 2 incremental models in 0 hours 0 minutes and 9.41 seconds (9.41s).
[0m10:48:51.264730 [debug] [MainThread]: Command end result
[0m10:48:51.299467 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt/target/manifest.json
[0m10:48:51.303742 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt/target/semantic_manifest.json
[0m10:48:51.312544 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt/target/run_results.json
[0m10:48:51.313356 [info ] [MainThread]: 
[0m10:48:51.314402 [info ] [MainThread]: [32mCompleted successfully[0m
[0m10:48:51.315394 [info ] [MainThread]: 
[0m10:48:51.316421 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m10:48:51.318719 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 11.003638, "process_in_blocks": "0", "process_kernel_time": 0.265427, "process_mem_max_rss": "220484", "process_out_blocks": "0", "process_user_time": 3.480053}
[0m10:48:51.320753 [debug] [MainThread]: Command `dbt run` succeeded at 10:48:51.320466 after 11.01 seconds
[0m10:48:51.321793 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd8efed510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd8efee050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd8efeea50>]}
[0m10:48:51.322672 [debug] [MainThread]: Flushing usage events
[0m10:48:51.906860 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m10:48:52.283141 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m10:51:33.956966 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5b1e70fb50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5b1eab24d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5b1e6b7510>]}


============================== 10:51:33.959742 | 4aabd740-7a3b-4170-91d3-a4242966fd75 ==============================
[0m10:51:33.959742 [info ] [MainThread]: Running with dbt=1.9.0
[0m10:51:33.960879 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt', 'log_path': '/usr/app/dbt/logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt run --project-dir /usr/app/dbt --profiles-dir /usr/app/dbt --select staging', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m10:51:34.573874 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '4aabd740-7a3b-4170-91d3-a4242966fd75', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5af49885d0>]}
[0m10:51:34.620910 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '4aabd740-7a3b-4170-91d3-a4242966fd75', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5b1f44a3d0>]}
[0m10:51:34.622974 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m10:51:34.693223 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m10:51:34.904455 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m10:51:34.906837 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m10:51:34.941139 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4aabd740-7a3b-4170-91d3-a4242966fd75', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5af48a18d0>]}
[0m10:51:35.080027 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt/target/manifest.json
[0m10:51:35.085979 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt/target/semantic_manifest.json
[0m10:51:35.105464 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4aabd740-7a3b-4170-91d3-a4242966fd75', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5af46516d0>]}
[0m10:51:35.106468 [info ] [MainThread]: Found 9 models, 8 sources, 489 macros
[0m10:51:35.107609 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4aabd740-7a3b-4170-91d3-a4242966fd75', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5af472fc90>]}
[0m10:51:35.110093 [info ] [MainThread]: 
[0m10:51:35.111003 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m10:51:35.111865 [info ] [MainThread]: 
[0m10:51:35.112920 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m10:51:35.117478 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m10:51:35.118411 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:51:35.585386 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_marts)
[0m10:51:35.586050 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_staging'
[0m10:51:35.586587 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_facts'
[0m10:51:35.587509 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:51:35.588454 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:51:35.589308 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:51:35.819807 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4aabd740-7a3b-4170-91d3-a4242966fd75', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5af48a1c90>]}
[0m10:51:35.821248 [debug] [MainThread]: Opening a new connection, currently in state init
[0m10:51:35.827786 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m10:51:35.828231 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m10:51:35.828676 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m10:51:35.829147 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m10:51:35.829970 [info ] [Thread-1 (]: 1 of 4 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [RUN]
[0m10:51:35.831682 [info ] [Thread-2 (]: 2 of 4 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [RUN]
[0m10:51:35.833156 [info ] [Thread-3 (]: 3 of 4 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [RUN]
[0m10:51:35.834369 [info ] [Thread-4 (]: 4 of 4 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [RUN]
[0m10:51:35.835574 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_marts, now model.hailing_project.production_hailing_staging_customer)
[0m10:51:35.836614 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_facts, now model.hailing_project.production_hailing_staging_driver)
[0m10:51:35.838419 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_staging, now model.hailing_project.production_hailing_staging_ride)
[0m10:51:35.839366 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_vehicle'
[0m10:51:35.840243 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m10:51:35.841086 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m10:51:35.841956 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m10:51:35.842841 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m10:51:35.856778 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m10:51:35.860704 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m10:51:35.865027 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m10:51:35.869498 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m10:51:35.875816 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m10:51:35.876306 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m10:51:35.876804 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m10:51:35.883003 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m10:51:35.982446 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m10:51:35.985426 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m10:51:35.988335 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m10:51:35.992670 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m10:51:35.999178 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    );
  
[0m10:51:36.000031 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    );
  
[0m10:51:36.001000 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m10:51:36.001597 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    );
  
[0m10:51:36.002067 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    );
  
[0m10:51:36.003000 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m10:51:36.005737 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m10:51:36.007093 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m10:51:36.387549 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:db7f2fd0-6696-4bff-8a29-ce8104000dfa&page=queryresults
[0m10:51:36.399771 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:34eca9c2-07e4-4bf3-a784-e25a70cf7cb0&page=queryresults
[0m10:51:36.422580 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:fcc294cd-b971-4d76-84f9-9e6ba36c527a&page=queryresults
[0m10:51:36.426579 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:66ba78cb-47e9-41c8-986d-388578ae6c82&page=queryresults
[0m10:51:38.541056 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4aabd740-7a3b-4170-91d3-a4242966fd75', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5af4afd650>]}
[0m10:51:38.541436 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4aabd740-7a3b-4170-91d3-a4242966fd75', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5af434ca10>]}
[0m10:51:38.542462 [info ] [Thread-1 (]: 1 of 4 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [[32mCREATE TABLE (121.0 rows, 8.3 KiB processed)[0m in 2.70s]
[0m10:51:38.543715 [info ] [Thread-4 (]: 4 of 4 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [[32mCREATE TABLE (121.0 rows, 6.7 KiB processed)[0m in 2.70s]
[0m10:51:38.544832 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m10:51:38.546460 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m10:51:38.619803 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4aabd740-7a3b-4170-91d3-a4242966fd75', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5af4524c50>]}
[0m10:51:38.620865 [info ] [Thread-3 (]: 3 of 4 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [[32mCREATE TABLE (121.0 rows, 10.8 KiB processed)[0m in 2.78s]
[0m10:51:38.622033 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m10:51:38.935766 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4aabd740-7a3b-4170-91d3-a4242966fd75', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5af4348390>]}
[0m10:51:38.937132 [info ] [Thread-2 (]: 2 of 4 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [[32mCREATE TABLE (121.0 rows, 8.2 KiB processed)[0m in 3.10s]
[0m10:51:38.938697 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m10:51:38.940997 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m10:51:38.945016 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:51:38.945741 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m10:51:38.946536 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m10:51:38.947257 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m10:51:38.948035 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m10:51:38.949375 [info ] [MainThread]: 
[0m10:51:38.950268 [info ] [MainThread]: Finished running 4 incremental models in 0 hours 0 minutes and 3.84 seconds (3.84s).
[0m10:51:38.952125 [debug] [MainThread]: Command end result
[0m10:51:38.987198 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt/target/manifest.json
[0m10:51:38.991940 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt/target/semantic_manifest.json
[0m10:51:39.000313 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt/target/run_results.json
[0m10:51:39.001130 [info ] [MainThread]: 
[0m10:51:39.002210 [info ] [MainThread]: [32mCompleted successfully[0m
[0m10:51:39.003197 [info ] [MainThread]: 
[0m10:51:39.005133 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m10:51:39.006861 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 5.105269, "process_in_blocks": "0", "process_kernel_time": 0.253309, "process_mem_max_rss": "220512", "process_out_blocks": "0", "process_user_time": 3.546329}
[0m10:51:39.007977 [debug] [MainThread]: Command `dbt run` succeeded at 10:51:39.007832 after 5.11 seconds
[0m10:51:39.008865 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5b1e712750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5b1e711690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5b1e710c90>]}
[0m10:51:39.009847 [debug] [MainThread]: Flushing usage events
[0m10:51:40.000667 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m10:51:41.921462 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f454b837c50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f454ab538d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f454ab526d0>]}


============================== 10:51:41.924724 | b59cd200-0dd3-4367-8c76-3ab9e106a8e6 ==============================
[0m10:51:41.924724 [info ] [MainThread]: Running with dbt=1.9.0
[0m10:51:41.925785 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/usr/app/dbt/logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run --project-dir /usr/app/dbt --profiles-dir /usr/app/dbt --select facts', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m10:51:42.605682 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b59cd200-0dd3-4367-8c76-3ab9e106a8e6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f454ab5b150>]}
[0m10:51:42.661313 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b59cd200-0dd3-4367-8c76-3ab9e106a8e6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4520e65550>]}
[0m10:51:42.662739 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m10:51:42.737008 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m10:51:42.981233 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m10:51:42.982220 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m10:51:43.017874 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b59cd200-0dd3-4367-8c76-3ab9e106a8e6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4520ba0910>]}
[0m10:51:43.156333 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt/target/manifest.json
[0m10:51:43.161583 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt/target/semantic_manifest.json
[0m10:51:43.178633 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b59cd200-0dd3-4367-8c76-3ab9e106a8e6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4520929990>]}
[0m10:51:43.180086 [info ] [MainThread]: Found 9 models, 8 sources, 489 macros
[0m10:51:43.181196 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b59cd200-0dd3-4367-8c76-3ab9e106a8e6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f454cdce810>]}
[0m10:51:43.183708 [info ] [MainThread]: 
[0m10:51:43.184824 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m10:51:43.186289 [info ] [MainThread]: 
[0m10:51:43.188002 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m10:51:43.192677 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m10:51:43.193798 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:51:43.660827 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_facts)
[0m10:51:43.661752 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_marts'
[0m10:51:43.662344 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_staging'
[0m10:51:43.662851 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:51:43.663642 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:51:43.664999 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:51:43.906729 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b59cd200-0dd3-4367-8c76-3ab9e106a8e6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f45212ffe90>]}
[0m10:51:43.908088 [debug] [MainThread]: Opening a new connection, currently in state init
[0m10:51:43.912578 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m10:51:43.912916 [debug] [Thread-2 (]: Began running node model.hailing_project.dim_driver
[0m10:51:43.913765 [info ] [Thread-1 (]: 1 of 3 START sql incremental model rizky_dwh_hailing_facts.dim_customer ........ [RUN]
[0m10:51:43.915790 [info ] [Thread-2 (]: 2 of 3 START sql incremental model rizky_dwh_hailing_facts.dim_driver .......... [RUN]
[0m10:51:43.916871 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_staging, now model.hailing_project.dim_customer)
[0m10:51:43.917985 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_marts, now model.hailing_project.dim_driver)
[0m10:51:43.919027 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m10:51:43.919928 [debug] [Thread-2 (]: Began compiling node model.hailing_project.dim_driver
[0m10:51:43.936532 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m10:51:43.941800 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.dim_driver"
[0m10:51:43.948152 [debug] [Thread-2 (]: Began executing node model.hailing_project.dim_driver
[0m10:51:43.955496 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m10:51:44.049714 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m10:51:44.050227 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.dim_driver"
[0m10:51:44.056288 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
)

SELECT * FROM source

    );
  
[0m10:51:44.057430 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m10:51:44.057943 [debug] [Thread-2 (]: On model.hailing_project.dim_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_driver"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      


WITH driver AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver` --pakai ref untuk buat dependency

),

vehicle AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle`
)

SELECT
    driver.driver_id,
    vehicle.vehicle_id,
    driver.name AS driver_name,
    driver.phone_number AS phone_number,
    driver.email AS email,
    vehicle.vehicle_type,
    vehicle.brand AS vehicle_brand,
    vehicle.year AS vehicle_production_year,
    vehicle.license_plate,
    driver.created_at
FROM driver
LEFT JOIN vehicle
on driver.driver_id = vehicle.driver_id


    );
  
[0m10:51:44.059627 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m10:51:44.406681 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:34a1bca1-24d4-4266-bcec-93387ff19323&page=queryresults
[0m10:51:44.454920 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:b9612944-c961-4b4c-9eba-869d86970c6e&page=queryresults
[0m10:51:46.295212 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b59cd200-0dd3-4367-8c76-3ab9e106a8e6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4520e43350>]}
[0m10:51:46.296382 [info ] [Thread-1 (]: 1 of 3 OK created sql incremental model rizky_dwh_hailing_facts.dim_customer ... [[32mCREATE TABLE (121.0 rows, 8.1 KiB processed)[0m in 2.38s]
[0m10:51:46.298144 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m10:51:46.301492 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b59cd200-0dd3-4367-8c76-3ab9e106a8e6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4520fb87d0>]}
[0m10:51:46.302465 [info ] [Thread-2 (]: 2 of 3 OK created sql incremental model rizky_dwh_hailing_facts.dim_driver ..... [[32mCREATE TABLE (121.0 rows, 13.8 KiB processed)[0m in 2.38s]
[0m10:51:46.304500 [debug] [Thread-2 (]: Finished running node model.hailing_project.dim_driver
[0m10:51:46.306346 [debug] [Thread-4 (]: Began running node model.hailing_project.fact_hailing_rides
[0m10:51:46.307297 [info ] [Thread-4 (]: 3 of 3 START sql incremental model rizky_dwh_hailing_facts.fact_hailing_rides .. [RUN]
[0m10:51:46.308470 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.fact_hailing_rides'
[0m10:51:46.309307 [debug] [Thread-4 (]: Began compiling node model.hailing_project.fact_hailing_rides
[0m10:51:46.314824 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.fact_hailing_rides"
[0m10:51:46.321133 [debug] [Thread-4 (]: Began executing node model.hailing_project.fact_hailing_rides
[0m10:51:46.325950 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.fact_hailing_rides"
[0m10:51:46.332423 [debug] [Thread-4 (]: On model.hailing_project.fact_hailing_rides: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.fact_hailing_rides"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH dim_driver AS (

    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
),

dim_customer AS (

    SELECT * 
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer`
),

ride_staging AS (

    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride`
)

SELECT
ride_staging.ride_id,
ride_staging.start_time AS ride_start_time,
ride_staging.end_time AS ride_end_time,
ride_staging.distance_km,
ride_staging.fare,
ride_staging.ride_status,
dim_customer.cust_id,
dim_customer.name AS cust_name,
dim_customer.phone_number AS cust_phone_number,
dim_customer.email AS cust_email,
dim_driver.driver_id,
dim_driver.driver_name,
dim_driver.phone_number AS driver_phone_number,
dim_driver.email AS driver_email,
dim_driver.vehicle_id,
dim_driver.vehicle_type,
dim_driver.vehicle_brand,
dim_driver.vehicle_production_year,
dim_driver.license_plate,
ride_staging.created_at

FROM ride_staging

LEFT JOIN dim_customer
on ride_staging.cust_id = dim_customer.cust_id

LEFT JOIN dim_driver
on ride_staging.driver_id = dim_driver.driver_id


    );
  
[0m10:51:46.333733 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m10:51:46.686848 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:48d04c7b-bb92-4e46-aed6-a9359f7561bb&page=queryresults
[0m10:51:48.868458 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b59cd200-0dd3-4367-8c76-3ab9e106a8e6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4520e67290>]}
[0m10:51:48.869462 [info ] [Thread-4 (]: 3 of 3 OK created sql incremental model rizky_dwh_hailing_facts.fact_hailing_rides  [[32mCREATE TABLE (121.0 rows, 29.8 KiB processed)[0m in 2.56s]
[0m10:51:48.870619 [debug] [Thread-4 (]: Finished running node model.hailing_project.fact_hailing_rides
[0m10:51:48.874130 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m10:51:48.877691 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:51:48.878426 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_facts' was properly closed.
[0m10:51:48.879477 [debug] [MainThread]: Connection 'model.hailing_project.dim_driver' was properly closed.
[0m10:51:48.880830 [debug] [MainThread]: Connection 'model.hailing_project.dim_customer' was properly closed.
[0m10:51:48.881812 [debug] [MainThread]: Connection 'model.hailing_project.fact_hailing_rides' was properly closed.
[0m10:51:48.882651 [info ] [MainThread]: 
[0m10:51:48.883529 [info ] [MainThread]: Finished running 3 incremental models in 0 hours 0 minutes and 5.70 seconds (5.70s).
[0m10:51:48.885075 [debug] [MainThread]: Command end result
[0m10:51:48.920331 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt/target/manifest.json
[0m10:51:48.924879 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt/target/semantic_manifest.json
[0m10:51:48.932541 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt/target/run_results.json
[0m10:51:48.933329 [info ] [MainThread]: 
[0m10:51:48.934540 [info ] [MainThread]: [32mCompleted successfully[0m
[0m10:51:48.935917 [info ] [MainThread]: 
[0m10:51:48.937142 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
[0m10:51:48.938761 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 7.076183, "process_in_blocks": "0", "process_kernel_time": 0.16338, "process_mem_max_rss": "220488", "process_out_blocks": "0", "process_user_time": 3.686277}
[0m10:51:48.939804 [debug] [MainThread]: Command `dbt run` succeeded at 10:51:48.939646 after 7.08 seconds
[0m10:51:48.940686 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f454e43cc90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f454e4ccc10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4518d2edd0>]}
[0m10:51:48.941765 [debug] [MainThread]: Flushing usage events
[0m10:51:50.356464 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m10:51:52.917541 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbd31e537d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbd31e53410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbd31e53b50>]}


============================== 10:51:52.920246 | cf6e04a9-02b6-43ba-8695-968fdd6995ee ==============================
[0m10:51:52.920246 [info ] [MainThread]: Running with dbt=1.9.0
[0m10:51:52.921314 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt run --project-dir /usr/app/dbt --profiles-dir /usr/app/dbt --select marts', 'send_anonymous_usage_stats': 'True'}
[0m10:51:53.548304 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'cf6e04a9-02b6-43ba-8695-968fdd6995ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbd339c8d90>]}
[0m10:51:53.597049 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'cf6e04a9-02b6-43ba-8695-968fdd6995ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbd340aa2d0>]}
[0m10:51:53.598437 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m10:51:53.666923 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m10:51:53.872464 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m10:51:53.873260 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m10:51:53.904393 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'cf6e04a9-02b6-43ba-8695-968fdd6995ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbd03ddc390>]}
[0m10:51:54.036249 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt/target/manifest.json
[0m10:51:54.042924 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt/target/semantic_manifest.json
[0m10:51:54.060232 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'cf6e04a9-02b6-43ba-8695-968fdd6995ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbd03c30b50>]}
[0m10:51:54.061940 [info ] [MainThread]: Found 9 models, 8 sources, 489 macros
[0m10:51:54.063342 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'cf6e04a9-02b6-43ba-8695-968fdd6995ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbd03cc4ed0>]}
[0m10:51:54.065986 [info ] [MainThread]: 
[0m10:51:54.067125 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m10:51:54.068401 [info ] [MainThread]: 
[0m10:51:54.070231 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m10:51:54.074049 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m10:51:54.074838 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:51:54.509072 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_facts)
[0m10:51:54.509676 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_staging'
[0m10:51:54.510201 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_marts'
[0m10:51:54.510646 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:51:54.511488 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:51:54.512287 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:51:54.749488 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'cf6e04a9-02b6-43ba-8695-968fdd6995ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbd09656a50>]}
[0m10:51:54.750721 [debug] [MainThread]: Opening a new connection, currently in state init
[0m10:51:54.754996 [debug] [Thread-1 (]: Began running node model.hailing_project.mart_cust_rides_daily
[0m10:51:54.755402 [debug] [Thread-2 (]: Began running node model.hailing_project.mart_driver_loyalty_mgmt
[0m10:51:54.756564 [info ] [Thread-1 (]: 1 of 2 START sql incremental model rizky_dwh_hailing_marts.mart_cust_rides_daily  [RUN]
[0m10:51:54.757683 [info ] [Thread-2 (]: 2 of 2 START sql incremental model rizky_dwh_hailing_marts.mart_driver_loyalty_mgmt  [RUN]
[0m10:51:54.758807 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_marts, now model.hailing_project.mart_cust_rides_daily)
[0m10:51:54.759796 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_facts, now model.hailing_project.mart_driver_loyalty_mgmt)
[0m10:51:54.760622 [debug] [Thread-1 (]: Began compiling node model.hailing_project.mart_cust_rides_daily
[0m10:51:54.761545 [debug] [Thread-2 (]: Began compiling node model.hailing_project.mart_driver_loyalty_mgmt
[0m10:51:54.771259 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.mart_cust_rides_daily"
[0m10:51:54.774536 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.mart_driver_loyalty_mgmt"
[0m10:51:54.779416 [debug] [Thread-1 (]: Began executing node model.hailing_project.mart_cust_rides_daily
[0m10:51:54.779981 [debug] [Thread-2 (]: Began executing node model.hailing_project.mart_driver_loyalty_mgmt
[0m10:51:54.870503 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.mart_driver_loyalty_mgmt"
[0m10:51:54.871676 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.mart_cust_rides_daily"
[0m10:51:54.877390 [debug] [Thread-2 (]: On model.hailing_project.mart_driver_loyalty_mgmt: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.mart_driver_loyalty_mgmt"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_marts`.`mart_driver_loyalty_mgmt`
      
    
    

    OPTIONS()
    as (
      

WITH dim_driver AS(
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
),

fact_rides AS(
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
)

SELECT 
dim_driver.driver_id,
dim_driver.driver_name,
dim_driver.phone_number,
dim_driver.email,
dim_driver.vehicle_type,
COUNT(fact_rides.ride_id) AS no_of_rides,
SUM(TIMESTAMP_DIFF(fact_rides.ride_end_time, fact_rides.ride_start_time, MINUTE)) AS total_ride_duration_min,
SUM(fact_rides.fare) AS total_fare,
SUM(fact_rides.distance_km) as total_distance_km,
SUM(fact_rides.distance_km)-SUM(fact_rides.fare) AS rev_opportunity_loss,
FROM dim_driver
LEFT JOIN fact_rides
ON dim_driver.driver_id = fact_rides.driver_id

GROUP BY driver_id,driver_name,phone_number,email,vehicle_type
    );
  
[0m10:51:54.878400 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m10:51:54.878842 [debug] [Thread-1 (]: On model.hailing_project.mart_cust_rides_daily: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.mart_cust_rides_daily"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_marts`.`mart_cust_rides_daily`
      
    partition by ride_date
    

    OPTIONS()
    as (
      


WITH fact_rides AS(

    SELECT * 
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
)

SELECT 

    fact_rides.cust_id,
    DATE(fact_rides.created_at) AS ride_date,
    fact_rides.cust_name,
    fact_rides.cust_email,
    fact_rides.cust_phone_number,
    COUNT(fact_rides.ride_id) AS no_of_rides,
    SUM(TIMESTAMP_DIFF(fact_rides.ride_end_time, fact_rides.ride_start_time, MINUTE)) AS total_ride_duration_min,
    SUM(fact_rides.fare) AS total_fare,
    SUM(fact_rides.distance_km) as total_distance_km,
    SUM(fact_rides.distance_km)-SUM(fact_rides.fare) AS rev_opportunity_loss,

FROM fact_rides
GROUP BY cust_name, cust_id, ride_date, cust_email, cust_phone_number
    );
  
[0m10:51:54.880188 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m10:51:55.219309 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:3d5e45db-c491-480d-a221-241bd57b7ede&page=queryresults
[0m10:51:55.223833 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:82566730-ac7a-4314-a9b2-2c628f05b797&page=queryresults
[0m10:51:56.785537 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cf6e04a9-02b6-43ba-8695-968fdd6995ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbd08143a90>]}
[0m10:51:56.786865 [info ] [Thread-2 (]: 2 of 2 OK created sql incremental model rizky_dwh_hailing_marts.mart_driver_loyalty_mgmt  [[32mCREATE TABLE (121.0 rows, 15.7 KiB processed)[0m in 2.02s]
[0m10:51:56.788378 [debug] [Thread-2 (]: Finished running node model.hailing_project.mart_driver_loyalty_mgmt
[0m10:51:57.069147 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cf6e04a9-02b6-43ba-8695-968fdd6995ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbd03f37390>]}
[0m10:51:57.071527 [info ] [Thread-1 (]: 1 of 2 OK created sql incremental model rizky_dwh_hailing_marts.mart_cust_rides_daily  [[32mCREATE TABLE (100.0 rows, 14.6 KiB processed)[0m in 2.31s]
[0m10:51:57.073651 [debug] [Thread-1 (]: Finished running node model.hailing_project.mart_cust_rides_daily
[0m10:51:57.077196 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m10:51:57.082539 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:51:57.084082 [debug] [MainThread]: Connection 'model.hailing_project.mart_driver_loyalty_mgmt' was properly closed.
[0m10:51:57.085511 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_staging' was properly closed.
[0m10:51:57.086850 [debug] [MainThread]: Connection 'model.hailing_project.mart_cust_rides_daily' was properly closed.
[0m10:51:57.087952 [info ] [MainThread]: 
[0m10:51:57.088957 [info ] [MainThread]: Finished running 2 incremental models in 0 hours 0 minutes and 3.02 seconds (3.02s).
[0m10:51:57.091412 [debug] [MainThread]: Command end result
[0m10:51:57.130364 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt/target/manifest.json
[0m10:51:57.136506 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt/target/semantic_manifest.json
[0m10:51:57.147504 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt/target/run_results.json
[0m10:51:57.148659 [info ] [MainThread]: 
[0m10:51:57.149903 [info ] [MainThread]: [32mCompleted successfully[0m
[0m10:51:57.151670 [info ] [MainThread]: 
[0m10:51:57.153779 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m10:51:57.155679 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 4.289834, "process_in_blocks": "0", "process_kernel_time": 0.181294, "process_mem_max_rss": "222148", "process_out_blocks": "0", "process_user_time": 3.353952}
[0m10:51:57.156663 [debug] [MainThread]: Command `dbt run` succeeded at 10:51:57.156538 after 4.29 seconds
[0m10:51:57.157527 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbd32246210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbd32246590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbd356fe910>]}
[0m10:51:57.158383 [debug] [MainThread]: Flushing usage events
[0m10:51:58.124839 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:26:16.009382 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4d495c3550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4d49ad8e90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4d4961bfd0>]}


============================== 12:26:16.012722 | cdd75389-443d-48ab-903d-4bf052c1a1f9 ==============================
[0m12:26:16.012722 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:26:16.013838 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt/logs', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt run --project-dir /usr/app/dbt --profiles-dir /usr/app/dbt --select staging', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m12:26:16.631100 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'cdd75389-443d-48ab-903d-4bf052c1a1f9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4d1b8917d0>]}
[0m12:26:16.678311 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'cdd75389-443d-48ab-903d-4bf052c1a1f9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4d1bef0610>]}
[0m12:26:16.679824 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m12:26:16.756185 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m12:26:16.982071 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m12:26:16.983231 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m12:26:17.014140 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'cdd75389-443d-48ab-903d-4bf052c1a1f9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4d1b441b90>]}
[0m12:26:17.143106 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt/target/manifest.json
[0m12:26:17.150477 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt/target/semantic_manifest.json
[0m12:26:17.176660 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'cdd75389-443d-48ab-903d-4bf052c1a1f9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4d1b443dd0>]}
[0m12:26:17.178085 [info ] [MainThread]: Found 9 models, 8 sources, 489 macros
[0m12:26:17.179312 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'cdd75389-443d-48ab-903d-4bf052c1a1f9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4d2099d6d0>]}
[0m12:26:17.182235 [info ] [MainThread]: 
[0m12:26:17.183395 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m12:26:17.184378 [info ] [MainThread]: 
[0m12:26:17.185737 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m12:26:17.190419 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m12:26:17.191463 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:26:17.822023 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_facts)
[0m12:26:17.822615 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_staging'
[0m12:26:17.823113 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_marts'
[0m12:26:17.823741 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:26:17.824704 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:26:17.825618 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:26:18.140739 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'cdd75389-443d-48ab-903d-4bf052c1a1f9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4d1b6f9d10>]}
[0m12:26:18.141796 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:26:18.146445 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m12:26:18.146953 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m12:26:18.147388 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m12:26:18.147680 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m12:26:18.148231 [info ] [Thread-1 (]: 1 of 4 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [RUN]
[0m12:26:18.149824 [info ] [Thread-2 (]: 2 of 4 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [RUN]
[0m12:26:18.151214 [info ] [Thread-3 (]: 3 of 4 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [RUN]
[0m12:26:18.152241 [info ] [Thread-4 (]: 4 of 4 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [RUN]
[0m12:26:18.153779 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_marts, now model.hailing_project.production_hailing_staging_customer)
[0m12:26:18.154773 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_staging, now model.hailing_project.production_hailing_staging_driver)
[0m12:26:18.155751 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_facts, now model.hailing_project.production_hailing_staging_ride)
[0m12:26:18.156671 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_vehicle'
[0m12:26:18.157516 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m12:26:18.158289 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m12:26:18.159076 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m12:26:18.159800 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m12:26:18.176982 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m12:26:18.180526 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m12:26:18.184780 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m12:26:18.188711 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m12:26:18.194108 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m12:26:18.196463 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m12:26:18.213107 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m12:26:18.239606 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m12:26:18.248536 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m12:26:18.250806 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m12:26:18.254626 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m12:26:18.258684 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:26:18.599940 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m12:26:18.601327 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m12:26:18.607815 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m12:26:18.609170 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m12:26:18.610166 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m12:26:18.616799 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m12:26:18.618161 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m12:26:18.623816 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m12:26:18.852791 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:10f04fcf-13f3-4935-b402-a90c09567a69&page=queryresults
[0m12:26:18.855163 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:e6bdf663-4b17-4f58-917f-2dd0259b67fa&page=queryresults
[0m12:26:18.867725 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:e6f11074-1822-418e-bc51-22fffc667ef0&page=queryresults
[0m12:26:18.870210 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:1078a17c-3116-475d-b781-4a9b01ca25fa&page=queryresults
[0m12:26:20.725556 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cdd75389-443d-48ab-903d-4bf052c1a1f9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4d037c51d0>]}
[0m12:26:20.725873 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cdd75389-443d-48ab-903d-4bf052c1a1f9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4d181e9bd0>]}
[0m12:26:20.726160 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cdd75389-443d-48ab-903d-4bf052c1a1f9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4d181e9c50>]}
[0m12:26:20.726424 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cdd75389-443d-48ab-903d-4bf052c1a1f9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4d037c5390>]}
[0m12:26:20.727140 [info ] [Thread-2 (]: 2 of 4 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [[32mMERGE (2.0 rows, 16.4 KiB processed)[0m in 2.57s]
[0m12:26:20.728363 [info ] [Thread-3 (]: 3 of 4 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [[32mMERGE (2.0 rows, 21.7 KiB processed)[0m in 2.57s]
[0m12:26:20.729586 [info ] [Thread-4 (]: 4 of 4 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [[32mMERGE (2.0 rows, 13.5 KiB processed)[0m in 2.57s]
[0m12:26:20.731539 [info ] [Thread-1 (]: 1 of 4 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [[32mMERGE (2.0 rows, 16.5 KiB processed)[0m in 2.57s]
[0m12:26:20.733014 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m12:26:20.734130 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m12:26:20.735078 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m12:26:20.736007 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m12:26:20.741473 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m12:26:20.744626 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:26:20.745523 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m12:26:20.746227 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m12:26:20.746888 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m12:26:20.747681 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m12:26:20.748438 [info ] [MainThread]: 
[0m12:26:20.749231 [info ] [MainThread]: Finished running 4 incremental models in 0 hours 0 minutes and 3.56 seconds (3.56s).
[0m12:26:20.750670 [debug] [MainThread]: Command end result
[0m12:26:20.783180 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt/target/manifest.json
[0m12:26:20.787875 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt/target/semantic_manifest.json
[0m12:26:20.798140 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt/target/run_results.json
[0m12:26:20.798953 [info ] [MainThread]: 
[0m12:26:20.800464 [info ] [MainThread]: [32mCompleted successfully[0m
[0m12:26:20.801882 [info ] [MainThread]: 
[0m12:26:20.802921 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m12:26:20.804512 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 4.8544807, "process_in_blocks": "56", "process_kernel_time": 0.281204, "process_mem_max_rss": "222628", "process_out_blocks": "0", "process_user_time": 3.561924}
[0m12:26:20.805461 [debug] [MainThread]: Command `dbt run` succeeded at 12:26:20.805351 after 4.86 seconds
[0m12:26:20.806267 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4d4961c150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4d4d0b1a50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4d037fb0d0>]}
[0m12:26:20.807628 [debug] [MainThread]: Flushing usage events
[0m12:26:21.840798 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:26:23.851774 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f78d32a3b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f78d3f57a10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f78d3768e90>]}


============================== 12:26:23.854285 | a455dd63-bbf7-4313-8116-c1cf35eb66b8 ==============================
[0m12:26:23.854285 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:26:23.855537 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt', 'debug': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt/logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --project-dir /usr/app/dbt --profiles-dir /usr/app/dbt --select facts', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m12:26:24.444107 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a455dd63-bbf7-4313-8116-c1cf35eb66b8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f78a5614550>]}
[0m12:26:24.501060 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a455dd63-bbf7-4313-8116-c1cf35eb66b8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f78d54fe550>]}
[0m12:26:24.502927 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m12:26:24.586865 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m12:26:24.800009 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m12:26:24.801178 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m12:26:24.829818 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a455dd63-bbf7-4313-8116-c1cf35eb66b8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f78a5c15450>]}
[0m12:26:24.966090 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt/target/manifest.json
[0m12:26:24.972852 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt/target/semantic_manifest.json
[0m12:26:24.992887 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a455dd63-bbf7-4313-8116-c1cf35eb66b8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f78a5024cd0>]}
[0m12:26:24.993975 [info ] [MainThread]: Found 9 models, 8 sources, 489 macros
[0m12:26:24.995988 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a455dd63-bbf7-4313-8116-c1cf35eb66b8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f78a5307490>]}
[0m12:26:24.999137 [info ] [MainThread]: 
[0m12:26:25.000389 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m12:26:25.002326 [info ] [MainThread]: 
[0m12:26:25.004185 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m12:26:25.008713 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m12:26:25.009969 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:26:25.584054 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_staging)
[0m12:26:25.585075 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_marts'
[0m12:26:25.585975 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_facts'
[0m12:26:25.586353 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:26:25.587249 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:26:25.588302 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:26:25.903938 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a455dd63-bbf7-4313-8116-c1cf35eb66b8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f78b1e7fb50>]}
[0m12:26:25.905319 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:26:25.909932 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m12:26:25.910285 [debug] [Thread-2 (]: Began running node model.hailing_project.dim_driver
[0m12:26:25.911339 [info ] [Thread-1 (]: 1 of 3 START sql incremental model rizky_dwh_hailing_facts.dim_customer ........ [RUN]
[0m12:26:25.912970 [info ] [Thread-2 (]: 2 of 3 START sql incremental model rizky_dwh_hailing_facts.dim_driver .......... [RUN]
[0m12:26:25.914106 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_facts, now model.hailing_project.dim_customer)
[0m12:26:25.915008 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_staging, now model.hailing_project.dim_driver)
[0m12:26:25.915831 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m12:26:25.916689 [debug] [Thread-2 (]: Began compiling node model.hailing_project.dim_driver
[0m12:26:25.931994 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m12:26:25.936311 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.dim_driver"
[0m12:26:25.942283 [debug] [Thread-2 (]: Began executing node model.hailing_project.dim_driver
[0m12:26:25.949546 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m12:26:26.016063 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m12:26:26.016748 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:26:26.308395 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.dim_driver"
[0m12:26:26.315585 [debug] [Thread-2 (]: On model.hailing_project.dim_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver` as DBT_INTERNAL_DEST
        using (


WITH driver AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver` --pakai ref untuk buat dependency

),

vehicle AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle`
)

SELECT
    driver.driver_id,
    vehicle.vehicle_id,
    driver.name AS driver_name,
    driver.phone_number AS phone_number,
    driver.email AS email,
    vehicle.vehicle_type,
    vehicle.brand AS vehicle_brand,
    vehicle.year AS vehicle_production_year,
    vehicle.license_plate,
    driver.created_at
FROM driver
LEFT JOIN vehicle
on driver.driver_id = vehicle.driver_id


    WHERE driver.created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_name` = DBT_INTERNAL_SOURCE.`driver_name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`vehicle_brand` = DBT_INTERNAL_SOURCE.`vehicle_brand`,`vehicle_production_year` = DBT_INTERNAL_SOURCE.`vehicle_production_year`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `vehicle_id`, `driver_name`, `phone_number`, `email`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)
    values
        (`driver_id`, `vehicle_id`, `driver_name`, `phone_number`, `email`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)


    
[0m12:26:26.318479 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m12:26:26.327153 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
)

SELECT * FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m12:26:26.559885 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:054c9b5a-2702-491e-b41d-d5e1970b0616&page=queryresults
[0m12:26:26.575652 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:5e219255-4d12-4f90-a3b1-2f256eae21eb&page=queryresults
[0m12:26:28.410995 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a455dd63-bbf7-4313-8116-c1cf35eb66b8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f78a51f5650>]}
[0m12:26:28.411292 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a455dd63-bbf7-4313-8116-c1cf35eb66b8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f78a50d3e90>]}
[0m12:26:28.412531 [info ] [Thread-1 (]: 1 of 3 OK created sql incremental model rizky_dwh_hailing_facts.dim_customer ... [[32mMERGE (2.0 rows, 16.3 KiB processed)[0m in 2.50s]
[0m12:26:28.413862 [info ] [Thread-2 (]: 2 of 3 OK created sql incremental model rizky_dwh_hailing_facts.dim_driver ..... [[32mMERGE (2.0 rows, 26.8 KiB processed)[0m in 2.50s]
[0m12:26:28.415000 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m12:26:28.416100 [debug] [Thread-2 (]: Finished running node model.hailing_project.dim_driver
[0m12:26:28.417865 [debug] [Thread-4 (]: Began running node model.hailing_project.fact_hailing_rides
[0m12:26:28.419019 [info ] [Thread-4 (]: 3 of 3 START sql incremental model rizky_dwh_hailing_facts.fact_hailing_rides .. [RUN]
[0m12:26:28.420478 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.fact_hailing_rides'
[0m12:26:28.421279 [debug] [Thread-4 (]: Began compiling node model.hailing_project.fact_hailing_rides
[0m12:26:28.427079 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.fact_hailing_rides"
[0m12:26:28.432974 [debug] [Thread-4 (]: Began executing node model.hailing_project.fact_hailing_rides
[0m12:26:28.436544 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m12:26:28.709315 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.fact_hailing_rides"
[0m12:26:28.716793 [debug] [Thread-4 (]: On model.hailing_project.fact_hailing_rides: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.fact_hailing_rides"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides` as DBT_INTERNAL_DEST
        using (

WITH dim_driver AS (

    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
),

dim_customer AS (

    SELECT * 
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer`
),

ride_staging AS (

    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride`
)

SELECT
ride_staging.ride_id,
ride_staging.start_time AS ride_start_time,
ride_staging.end_time AS ride_end_time,
ride_staging.distance_km,
ride_staging.fare,
ride_staging.ride_status,
dim_customer.cust_id,
dim_customer.name AS cust_name,
dim_customer.phone_number AS cust_phone_number,
dim_customer.email AS cust_email,
dim_driver.driver_id,
dim_driver.driver_name,
dim_driver.phone_number AS driver_phone_number,
dim_driver.email AS driver_email,
dim_driver.vehicle_id,
dim_driver.vehicle_type,
dim_driver.vehicle_brand,
dim_driver.vehicle_production_year,
dim_driver.license_plate,
ride_staging.created_at

FROM ride_staging

LEFT JOIN dim_customer
on ride_staging.cust_id = dim_customer.cust_id

LEFT JOIN dim_driver
on ride_staging.driver_id = dim_driver.driver_id


    WHERE ride_staging.created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`ride_start_time` = DBT_INTERNAL_SOURCE.`ride_start_time`,`ride_end_time` = DBT_INTERNAL_SOURCE.`ride_end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`cust_name` = DBT_INTERNAL_SOURCE.`cust_name`,`cust_phone_number` = DBT_INTERNAL_SOURCE.`cust_phone_number`,`cust_email` = DBT_INTERNAL_SOURCE.`cust_email`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`driver_name` = DBT_INTERNAL_SOURCE.`driver_name`,`driver_phone_number` = DBT_INTERNAL_SOURCE.`driver_phone_number`,`driver_email` = DBT_INTERNAL_SOURCE.`driver_email`,`vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`vehicle_brand` = DBT_INTERNAL_SOURCE.`vehicle_brand`,`vehicle_production_year` = DBT_INTERNAL_SOURCE.`vehicle_production_year`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `ride_start_time`, `ride_end_time`, `distance_km`, `fare`, `ride_status`, `cust_id`, `cust_name`, `cust_phone_number`, `cust_email`, `driver_id`, `driver_name`, `driver_phone_number`, `driver_email`, `vehicle_id`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)
    values
        (`ride_id`, `ride_start_time`, `ride_end_time`, `distance_km`, `fare`, `ride_status`, `cust_id`, `cust_name`, `cust_phone_number`, `cust_email`, `driver_id`, `driver_name`, `driver_phone_number`, `driver_email`, `vehicle_id`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)


    
[0m12:26:28.996462 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:7741411c-f6b1-4674-8caf-d13a14812421&page=queryresults
[0m12:26:30.841672 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a455dd63-bbf7-4313-8116-c1cf35eb66b8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f78a45cf2d0>]}
[0m12:26:30.843335 [info ] [Thread-4 (]: 3 of 3 OK created sql incremental model rizky_dwh_hailing_facts.fact_hailing_rides  [[32mMERGE (2.0 rows, 58.0 KiB processed)[0m in 2.42s]
[0m12:26:30.844970 [debug] [Thread-4 (]: Finished running node model.hailing_project.fact_hailing_rides
[0m12:26:30.847529 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m12:26:30.851372 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:26:30.852381 [debug] [MainThread]: Connection 'model.hailing_project.dim_driver' was properly closed.
[0m12:26:30.853557 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_marts' was properly closed.
[0m12:26:30.854499 [debug] [MainThread]: Connection 'model.hailing_project.dim_customer' was properly closed.
[0m12:26:30.855409 [debug] [MainThread]: Connection 'model.hailing_project.fact_hailing_rides' was properly closed.
[0m12:26:30.856929 [info ] [MainThread]: 
[0m12:26:30.858272 [info ] [MainThread]: Finished running 3 incremental models in 0 hours 0 minutes and 5.85 seconds (5.85s).
[0m12:26:30.860608 [debug] [MainThread]: Command end result
[0m12:26:30.901679 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt/target/manifest.json
[0m12:26:30.907101 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt/target/semantic_manifest.json
[0m12:26:30.915216 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt/target/run_results.json
[0m12:26:30.916014 [info ] [MainThread]: 
[0m12:26:30.917296 [info ] [MainThread]: [32mCompleted successfully[0m
[0m12:26:30.918873 [info ] [MainThread]: 
[0m12:26:30.920507 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
[0m12:26:30.922517 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 7.1200595, "process_in_blocks": "0", "process_kernel_time": 0.229528, "process_mem_max_rss": "222084", "process_out_blocks": "0", "process_user_time": 3.422972}
[0m12:26:30.923578 [debug] [MainThread]: Command `dbt run` succeeded at 12:26:30.923447 after 7.12 seconds
[0m12:26:30.924440 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f78a52e6f50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f78d32a9890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f78d6c05690>]}
[0m12:26:30.925941 [debug] [MainThread]: Flushing usage events
[0m12:26:32.113333 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:26:34.046699 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4389699e10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f43896eff10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f438969bb50>]}


============================== 12:26:34.049604 | 22246cf3-7b95-4171-9a5d-4ad559892c57 ==============================
[0m12:26:34.049604 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:26:34.051108 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt', 'log_path': '/usr/app/dbt/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'invocation_command': 'dbt run --project-dir /usr/app/dbt --profiles-dir /usr/app/dbt --select marts', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m12:26:34.687364 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '22246cf3-7b95-4171-9a5d-4ad559892c57', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f435b9b26d0>]}
[0m12:26:34.734634 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '22246cf3-7b95-4171-9a5d-4ad559892c57', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f438b94a790>]}
[0m12:26:34.735765 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m12:26:34.813512 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m12:26:35.128515 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m12:26:35.129296 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m12:26:35.161898 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '22246cf3-7b95-4171-9a5d-4ad559892c57', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f435b80de10>]}
[0m12:26:35.296025 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt/target/manifest.json
[0m12:26:35.302409 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt/target/semantic_manifest.json
[0m12:26:35.321618 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '22246cf3-7b95-4171-9a5d-4ad559892c57', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f435b5bc110>]}
[0m12:26:35.323393 [info ] [MainThread]: Found 9 models, 8 sources, 489 macros
[0m12:26:35.324631 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '22246cf3-7b95-4171-9a5d-4ad559892c57', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f435b6a3450>]}
[0m12:26:35.327437 [info ] [MainThread]: 
[0m12:26:35.328926 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m12:26:35.330381 [info ] [MainThread]: 
[0m12:26:35.332177 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m12:26:35.336765 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m12:26:35.337820 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:26:35.890086 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_facts)
[0m12:26:35.891071 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_marts'
[0m12:26:35.891756 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_staging'
[0m12:26:35.893035 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:26:35.895215 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:26:35.896073 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:26:36.195447 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '22246cf3-7b95-4171-9a5d-4ad559892c57', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4363945610>]}
[0m12:26:36.196782 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:26:36.201175 [debug] [Thread-1 (]: Began running node model.hailing_project.mart_cust_rides_daily
[0m12:26:36.201563 [debug] [Thread-2 (]: Began running node model.hailing_project.mart_driver_loyalty_mgmt
[0m12:26:36.202297 [info ] [Thread-1 (]: 1 of 2 START sql incremental model rizky_dwh_hailing_marts.mart_cust_rides_daily  [RUN]
[0m12:26:36.203908 [info ] [Thread-2 (]: 2 of 2 START sql incremental model rizky_dwh_hailing_marts.mart_driver_loyalty_mgmt  [RUN]
[0m12:26:36.205454 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_marts, now model.hailing_project.mart_cust_rides_daily)
[0m12:26:36.206496 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_staging, now model.hailing_project.mart_driver_loyalty_mgmt)
[0m12:26:36.207209 [debug] [Thread-1 (]: Began compiling node model.hailing_project.mart_cust_rides_daily
[0m12:26:36.207948 [debug] [Thread-2 (]: Began compiling node model.hailing_project.mart_driver_loyalty_mgmt
[0m12:26:36.216736 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.mart_cust_rides_daily"
[0m12:26:36.220339 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.mart_driver_loyalty_mgmt"
[0m12:26:36.225504 [debug] [Thread-2 (]: Began executing node model.hailing_project.mart_driver_loyalty_mgmt
[0m12:26:36.232123 [debug] [Thread-1 (]: Began executing node model.hailing_project.mart_cust_rides_daily
[0m12:26:36.271975 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:26:36.270593 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m12:26:36.587597 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.mart_cust_rides_daily"
[0m12:26:36.588801 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.mart_driver_loyalty_mgmt"
[0m12:26:36.594838 [debug] [Thread-2 (]: On model.hailing_project.mart_driver_loyalty_mgmt: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.mart_driver_loyalty_mgmt"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_marts`.`mart_driver_loyalty_mgmt` as DBT_INTERNAL_DEST
        using (

WITH dim_driver AS(
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
),

fact_rides AS(
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
)

SELECT 
dim_driver.driver_id,
dim_driver.driver_name,
dim_driver.phone_number,
dim_driver.email,
dim_driver.vehicle_type,
COUNT(fact_rides.ride_id) AS no_of_rides,
SUM(TIMESTAMP_DIFF(fact_rides.ride_end_time, fact_rides.ride_start_time, MINUTE)) AS total_ride_duration_min,
SUM(fact_rides.fare) AS total_fare,
SUM(fact_rides.distance_km) as total_distance_km,
SUM(fact_rides.distance_km)-SUM(fact_rides.fare) AS rev_opportunity_loss,
FROM dim_driver
LEFT JOIN fact_rides
ON dim_driver.driver_id = fact_rides.driver_id

GROUP BY driver_id,driver_name,phone_number,email,vehicle_type
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`driver_name` = DBT_INTERNAL_SOURCE.`driver_name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`no_of_rides` = DBT_INTERNAL_SOURCE.`no_of_rides`,`total_ride_duration_min` = DBT_INTERNAL_SOURCE.`total_ride_duration_min`,`total_fare` = DBT_INTERNAL_SOURCE.`total_fare`,`total_distance_km` = DBT_INTERNAL_SOURCE.`total_distance_km`,`rev_opportunity_loss` = DBT_INTERNAL_SOURCE.`rev_opportunity_loss`
    

    when not matched then insert
        (`driver_id`, `driver_name`, `phone_number`, `email`, `vehicle_type`, `no_of_rides`, `total_ride_duration_min`, `total_fare`, `total_distance_km`, `rev_opportunity_loss`)
    values
        (`driver_id`, `driver_name`, `phone_number`, `email`, `vehicle_type`, `no_of_rides`, `total_ride_duration_min`, `total_fare`, `total_distance_km`, `rev_opportunity_loss`)


    
[0m12:26:36.596590 [debug] [Thread-1 (]: On model.hailing_project.mart_cust_rides_daily: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.mart_cust_rides_daily"} */
-- back compat for old kwarg name
  
  
        
            
                
                
            
                
                
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_marts`.`mart_cust_rides_daily` as DBT_INTERNAL_DEST
        using (


WITH fact_rides AS(

    SELECT * 
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
)

SELECT 

    fact_rides.cust_id,
    DATE(fact_rides.created_at) AS ride_date,
    fact_rides.cust_name,
    fact_rides.cust_email,
    fact_rides.cust_phone_number,
    COUNT(fact_rides.ride_id) AS no_of_rides,
    SUM(TIMESTAMP_DIFF(fact_rides.ride_end_time, fact_rides.ride_start_time, MINUTE)) AS total_ride_duration_min,
    SUM(fact_rides.fare) AS total_fare,
    SUM(fact_rides.distance_km) as total_distance_km,
    SUM(fact_rides.distance_km)-SUM(fact_rides.fare) AS rev_opportunity_loss,

FROM fact_rides
GROUP BY cust_name, cust_id, ride_date, cust_email, cust_phone_number
        ) as DBT_INTERNAL_SOURCE
        on (
                    DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
                ) and (
                    DBT_INTERNAL_SOURCE.ride_date = DBT_INTERNAL_DEST.ride_date
                )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`ride_date` = DBT_INTERNAL_SOURCE.`ride_date`,`cust_name` = DBT_INTERNAL_SOURCE.`cust_name`,`cust_email` = DBT_INTERNAL_SOURCE.`cust_email`,`cust_phone_number` = DBT_INTERNAL_SOURCE.`cust_phone_number`,`no_of_rides` = DBT_INTERNAL_SOURCE.`no_of_rides`,`total_ride_duration_min` = DBT_INTERNAL_SOURCE.`total_ride_duration_min`,`total_fare` = DBT_INTERNAL_SOURCE.`total_fare`,`total_distance_km` = DBT_INTERNAL_SOURCE.`total_distance_km`,`rev_opportunity_loss` = DBT_INTERNAL_SOURCE.`rev_opportunity_loss`
    

    when not matched then insert
        (`cust_id`, `ride_date`, `cust_name`, `cust_email`, `cust_phone_number`, `no_of_rides`, `total_ride_duration_min`, `total_fare`, `total_distance_km`, `rev_opportunity_loss`)
    values
        (`cust_id`, `ride_date`, `cust_name`, `cust_email`, `cust_phone_number`, `no_of_rides`, `total_ride_duration_min`, `total_fare`, `total_distance_km`, `rev_opportunity_loss`)


    
[0m12:26:36.837469 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:182b7fa2-41ef-47ff-84ed-e9476b8bb0fe&page=queryresults
[0m12:26:36.850528 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:675f08c6-9a2a-4169-b7aa-378ae39d9dc7&page=queryresults
[0m12:26:38.409686 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '22246cf3-7b95-4171-9a5d-4ad559892c57', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f435b478450>]}
[0m12:26:38.411269 [info ] [Thread-2 (]: 2 of 2 OK created sql incremental model rizky_dwh_hailing_marts.mart_driver_loyalty_mgmt  [[32mMERGE (123.0 rows, 28.3 KiB processed)[0m in 2.20s]
[0m12:26:38.412836 [debug] [Thread-2 (]: Finished running node model.hailing_project.mart_driver_loyalty_mgmt
[0m12:26:38.639362 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '22246cf3-7b95-4171-9a5d-4ad559892c57', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f435b81dcd0>]}
[0m12:26:38.640778 [info ] [Thread-1 (]: 1 of 2 OK created sql incremental model rizky_dwh_hailing_marts.mart_cust_rides_daily  [[32mMERGE (101.0 rows, 27.7 KiB processed)[0m in 2.43s]
[0m12:26:38.642504 [debug] [Thread-1 (]: Finished running node model.hailing_project.mart_cust_rides_daily
[0m12:26:38.644459 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m12:26:38.647431 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:26:38.648267 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_facts' was properly closed.
[0m12:26:38.649563 [debug] [MainThread]: Connection 'model.hailing_project.mart_cust_rides_daily' was properly closed.
[0m12:26:38.650440 [debug] [MainThread]: Connection 'model.hailing_project.mart_driver_loyalty_mgmt' was properly closed.
[0m12:26:38.651332 [info ] [MainThread]: 
[0m12:26:38.652177 [info ] [MainThread]: Finished running 2 incremental models in 0 hours 0 minutes and 3.32 seconds (3.32s).
[0m12:26:38.653518 [debug] [MainThread]: Command end result
[0m12:26:38.690083 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt/target/manifest.json
[0m12:26:38.696132 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt/target/semantic_manifest.json
[0m12:26:38.706064 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt/target/run_results.json
[0m12:26:38.707143 [info ] [MainThread]: 
[0m12:26:38.708396 [info ] [MainThread]: [32mCompleted successfully[0m
[0m12:26:38.709479 [info ] [MainThread]: 
[0m12:26:38.710886 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m12:26:38.713766 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 4.7203207, "process_in_blocks": "0", "process_kernel_time": 0.242241, "process_mem_max_rss": "221824", "process_out_blocks": "0", "process_user_time": 3.361105}
[0m12:26:38.714929 [debug] [MainThread]: Command `dbt run` succeeded at 12:26:38.714802 after 4.72 seconds
[0m12:26:38.715764 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4389717790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4389717690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f438cfc0c90>]}
[0m12:26:38.716681 [debug] [MainThread]: Flushing usage events
[0m12:26:39.915413 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:06:29.312853 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f02a8ca3610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f02a8cf7b10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f02a8dae250>]}


============================== 13:06:29.315909 | 08091b1b-6ea0-40b2-9e1e-b62a6fe34d30 ==============================
[0m13:06:29.315909 [info ] [MainThread]: Running with dbt=1.9.0
[0m13:06:29.317205 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': '/usr/app/dbt', 'log_path': '/usr/app/dbt/logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run --project-dir /usr/app/dbt --profiles-dir /usr/app/dbt --select staging', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m13:06:29.921864 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '08091b1b-6ea0-40b2-9e1e-b62a6fe34d30', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f02808cdf90>]}
[0m13:06:29.978922 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '08091b1b-6ea0-40b2-9e1e-b62a6fe34d30', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f02aaf1cc50>]}
[0m13:06:29.980868 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m13:06:30.061996 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m13:06:30.309267 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m13:06:30.310336 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m13:06:30.342732 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '08091b1b-6ea0-40b2-9e1e-b62a6fe34d30', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f027ab7ad50>]}
[0m13:06:30.473366 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt/target/manifest.json
[0m13:06:30.479680 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt/target/semantic_manifest.json
[0m13:06:30.511478 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '08091b1b-6ea0-40b2-9e1e-b62a6fe34d30', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f027aa68050>]}
[0m13:06:30.512520 [info ] [MainThread]: Found 9 models, 8 sources, 489 macros
[0m13:06:30.513524 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '08091b1b-6ea0-40b2-9e1e-b62a6fe34d30', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f027b46f390>]}
[0m13:06:30.515788 [info ] [MainThread]: 
[0m13:06:30.517225 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m13:06:30.518407 [info ] [MainThread]: 
[0m13:06:30.519712 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m13:06:30.524151 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m13:06:30.525419 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:06:31.121688 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_marts)
[0m13:06:31.123218 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_facts'
[0m13:06:31.124577 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_staging'
[0m13:06:31.125642 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:06:31.126840 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:06:31.128025 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:06:31.453128 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '08091b1b-6ea0-40b2-9e1e-b62a6fe34d30', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f02aaf1a910>]}
[0m13:06:31.454155 [debug] [MainThread]: Opening a new connection, currently in state init
[0m13:06:31.460317 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m13:06:31.460748 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m13:06:31.461133 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m13:06:31.461521 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m13:06:31.462315 [info ] [Thread-1 (]: 1 of 4 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [RUN]
[0m13:06:31.463815 [info ] [Thread-2 (]: 2 of 4 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [RUN]
[0m13:06:31.465090 [info ] [Thread-3 (]: 3 of 4 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [RUN]
[0m13:06:31.466329 [info ] [Thread-4 (]: 4 of 4 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [RUN]
[0m13:06:31.467539 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_marts, now model.hailing_project.production_hailing_staging_customer)
[0m13:06:31.469520 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_staging, now model.hailing_project.production_hailing_staging_driver)
[0m13:06:31.470865 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_facts, now model.hailing_project.production_hailing_staging_ride)
[0m13:06:31.472135 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_vehicle'
[0m13:06:31.473053 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m13:06:31.474053 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m13:06:31.475044 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m13:06:31.476561 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m13:06:31.493346 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m13:06:31.498067 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m13:06:31.502606 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m13:06:31.507732 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m13:06:31.514097 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m13:06:31.520564 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m13:06:31.547859 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m13:06:31.564393 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m13:06:31.585523 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m13:06:31.587823 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:06:31.590812 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m13:06:31.595571 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m13:06:31.918758 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m13:06:31.920636 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m13:06:31.922186 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m13:06:31.923304 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m13:06:31.927564 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m13:06:31.928410 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m13:06:31.931309 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m13:06:31.936928 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m13:06:32.169848 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:a3155f12-3551-4e98-9c55-731ffa6a6aa4&page=queryresults
[0m13:06:32.185545 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:e9ce6dc8-1cf6-4cd1-8c61-90679b21dc59&page=queryresults
[0m13:06:32.203523 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:18b66d50-b700-4e3c-9b22-f3db0c883fe3&page=queryresults
[0m13:06:32.210261 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:186160bb-db2e-4dfd-b422-94f8b642af3a&page=queryresults
[0m13:06:33.775942 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '08091b1b-6ea0-40b2-9e1e-b62a6fe34d30', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f027ac8f210>]}
[0m13:06:33.777198 [info ] [Thread-4 (]: 4 of 4 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [[32mMERGE (3.0 rows, 13.7 KiB processed)[0m in 2.30s]
[0m13:06:33.779012 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m13:06:33.987011 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '08091b1b-6ea0-40b2-9e1e-b62a6fe34d30', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f02a9210890>]}
[0m13:06:33.988202 [info ] [Thread-3 (]: 3 of 4 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [[32mMERGE (3.0 rows, 22.1 KiB processed)[0m in 2.52s]
[0m13:06:33.989701 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m13:06:34.028977 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '08091b1b-6ea0-40b2-9e1e-b62a6fe34d30', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f027ac5b5d0>]}
[0m13:06:34.032331 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '08091b1b-6ea0-40b2-9e1e-b62a6fe34d30', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f02a9aa42d0>]}
[0m13:06:34.033131 [info ] [Thread-1 (]: 1 of 4 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [[32mMERGE (3.0 rows, 16.8 KiB processed)[0m in 2.56s]
[0m13:06:34.034326 [info ] [Thread-2 (]: 2 of 4 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [[32mMERGE (3.0 rows, 16.8 KiB processed)[0m in 2.56s]
[0m13:06:34.035558 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m13:06:34.036661 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m13:06:34.040251 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m13:06:34.043442 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:06:34.044240 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m13:06:34.045421 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m13:06:34.047017 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m13:06:34.048119 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m13:06:34.049173 [info ] [MainThread]: 
[0m13:06:34.050204 [info ] [MainThread]: Finished running 4 incremental models in 0 hours 0 minutes and 3.53 seconds (3.53s).
[0m13:06:34.051786 [debug] [MainThread]: Command end result
[0m13:06:34.085117 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt/target/manifest.json
[0m13:06:34.090072 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt/target/semantic_manifest.json
[0m13:06:34.099259 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt/target/run_results.json
[0m13:06:34.099978 [info ] [MainThread]: 
[0m13:06:34.101855 [info ] [MainThread]: [32mCompleted successfully[0m
[0m13:06:34.102823 [info ] [MainThread]: 
[0m13:06:34.103736 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m13:06:34.105305 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 4.8562155, "process_in_blocks": "96", "process_kernel_time": 0.219311, "process_mem_max_rss": "225132", "process_out_blocks": "144", "process_user_time": 3.618642}
[0m13:06:34.106165 [debug] [MainThread]: Command `dbt run` succeeded at 13:06:34.106046 after 4.86 seconds
[0m13:06:34.106983 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f02ac4c0f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f02ac61cc10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f02ac61d550>]}
[0m13:06:34.108042 [debug] [MainThread]: Flushing usage events
[0m13:06:35.175202 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:06:38.002996 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f856df63710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f856df60090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f856df63410>]}


============================== 13:06:38.006068 | a7980f94-fe28-4b69-8d5b-e53c6c80cdbe ==============================
[0m13:06:38.006068 [info ] [MainThread]: Running with dbt=1.9.0
[0m13:06:38.007194 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/usr/app/dbt/logs', 'version_check': 'True', 'profiles_dir': '/usr/app/dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt run --project-dir /usr/app/dbt --profiles-dir /usr/app/dbt --select facts', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m13:06:38.654136 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a7980f94-fe28-4b69-8d5b-e53c6c80cdbe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8544265e10>]}
[0m13:06:38.704753 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a7980f94-fe28-4b69-8d5b-e53c6c80cdbe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f85701b5350>]}
[0m13:06:38.706821 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m13:06:38.775566 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m13:06:38.966125 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m13:06:38.967473 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m13:06:38.996478 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a7980f94-fe28-4b69-8d5b-e53c6c80cdbe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f853fec4510>]}
[0m13:06:39.123217 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt/target/manifest.json
[0m13:06:39.128356 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt/target/semantic_manifest.json
[0m13:06:39.145647 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a7980f94-fe28-4b69-8d5b-e53c6c80cdbe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f853fc447d0>]}
[0m13:06:39.146740 [info ] [MainThread]: Found 9 models, 8 sources, 489 macros
[0m13:06:39.147874 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a7980f94-fe28-4b69-8d5b-e53c6c80cdbe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f85441a9e90>]}
[0m13:06:39.150753 [info ] [MainThread]: 
[0m13:06:39.152463 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m13:06:39.153539 [info ] [MainThread]: 
[0m13:06:39.154824 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m13:06:39.159614 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m13:06:39.160967 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:06:39.689333 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_facts)
[0m13:06:39.690027 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_staging'
[0m13:06:39.690584 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_marts'
[0m13:06:39.691145 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:06:39.692276 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:06:39.693395 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:06:39.999359 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a7980f94-fe28-4b69-8d5b-e53c6c80cdbe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f853fe2b350>]}
[0m13:06:40.000263 [debug] [MainThread]: Opening a new connection, currently in state init
[0m13:06:40.005006 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m13:06:40.005693 [debug] [Thread-2 (]: Began running node model.hailing_project.dim_driver
[0m13:06:40.006677 [info ] [Thread-1 (]: 1 of 3 START sql incremental model rizky_dwh_hailing_facts.dim_customer ........ [RUN]
[0m13:06:40.007760 [info ] [Thread-2 (]: 2 of 3 START sql incremental model rizky_dwh_hailing_facts.dim_driver .......... [RUN]
[0m13:06:40.008952 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_marts, now model.hailing_project.dim_customer)
[0m13:06:40.009861 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_staging, now model.hailing_project.dim_driver)
[0m13:06:40.010653 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m13:06:40.011623 [debug] [Thread-2 (]: Began compiling node model.hailing_project.dim_driver
[0m13:06:40.026956 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m13:06:40.030754 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.dim_driver"
[0m13:06:40.036511 [debug] [Thread-2 (]: Began executing node model.hailing_project.dim_driver
[0m13:06:40.037076 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m13:06:40.097913 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m13:06:40.098470 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:06:40.384973 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.dim_driver"
[0m13:06:40.386964 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m13:06:40.391732 [debug] [Thread-2 (]: On model.hailing_project.dim_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver` as DBT_INTERNAL_DEST
        using (


WITH driver AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver` --pakai ref untuk buat dependency

),

vehicle AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle`
)

SELECT
    driver.driver_id,
    vehicle.vehicle_id,
    driver.name AS driver_name,
    driver.phone_number AS phone_number,
    driver.email AS email,
    vehicle.vehicle_type,
    vehicle.brand AS vehicle_brand,
    vehicle.year AS vehicle_production_year,
    vehicle.license_plate,
    driver.created_at
FROM driver
LEFT JOIN vehicle
on driver.driver_id = vehicle.driver_id


    WHERE driver.created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_name` = DBT_INTERNAL_SOURCE.`driver_name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`vehicle_brand` = DBT_INTERNAL_SOURCE.`vehicle_brand`,`vehicle_production_year` = DBT_INTERNAL_SOURCE.`vehicle_production_year`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `vehicle_id`, `driver_name`, `phone_number`, `email`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)
    values
        (`driver_id`, `vehicle_id`, `driver_name`, `phone_number`, `email`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)


    
[0m13:06:40.394888 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
)

SELECT * FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m13:06:40.659372 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:0bbed52e-f0bb-4265-ac4c-3cc8f9672b18&page=queryresults
[0m13:06:40.697966 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:8c93ac1a-b4c2-4496-8b28-2bcabb0e9f85&page=queryresults
[0m13:06:42.524207 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a7980f94-fe28-4b69-8d5b-e53c6c80cdbe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f853fce2910>]}
[0m13:06:42.525865 [info ] [Thread-1 (]: 1 of 3 OK created sql incremental model rizky_dwh_hailing_facts.dim_customer ... [[32mMERGE (3.0 rows, 16.6 KiB processed)[0m in 2.51s]
[0m13:06:42.527583 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m13:06:42.534514 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a7980f94-fe28-4b69-8d5b-e53c6c80cdbe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f853fcf15d0>]}
[0m13:06:42.535534 [info ] [Thread-2 (]: 2 of 3 OK created sql incremental model rizky_dwh_hailing_facts.dim_driver ..... [[32mMERGE (3.0 rows, 27.4 KiB processed)[0m in 2.52s]
[0m13:06:42.536935 [debug] [Thread-2 (]: Finished running node model.hailing_project.dim_driver
[0m13:06:42.538268 [debug] [Thread-4 (]: Began running node model.hailing_project.fact_hailing_rides
[0m13:06:42.539722 [info ] [Thread-4 (]: 3 of 3 START sql incremental model rizky_dwh_hailing_facts.fact_hailing_rides .. [RUN]
[0m13:06:42.541457 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.fact_hailing_rides'
[0m13:06:42.542270 [debug] [Thread-4 (]: Began compiling node model.hailing_project.fact_hailing_rides
[0m13:06:42.547243 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.fact_hailing_rides"
[0m13:06:42.552728 [debug] [Thread-4 (]: Began executing node model.hailing_project.fact_hailing_rides
[0m13:06:42.557994 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m13:06:42.801457 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.fact_hailing_rides"
[0m13:06:42.809113 [debug] [Thread-4 (]: On model.hailing_project.fact_hailing_rides: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.fact_hailing_rides"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides` as DBT_INTERNAL_DEST
        using (

WITH dim_driver AS (

    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
),

dim_customer AS (

    SELECT * 
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer`
),

ride_staging AS (

    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride`
)

SELECT
ride_staging.ride_id,
ride_staging.start_time AS ride_start_time,
ride_staging.end_time AS ride_end_time,
ride_staging.distance_km,
ride_staging.fare,
ride_staging.ride_status,
dim_customer.cust_id,
dim_customer.name AS cust_name,
dim_customer.phone_number AS cust_phone_number,
dim_customer.email AS cust_email,
dim_driver.driver_id,
dim_driver.driver_name,
dim_driver.phone_number AS driver_phone_number,
dim_driver.email AS driver_email,
dim_driver.vehicle_id,
dim_driver.vehicle_type,
dim_driver.vehicle_brand,
dim_driver.vehicle_production_year,
dim_driver.license_plate,
ride_staging.created_at

FROM ride_staging

LEFT JOIN dim_customer
on ride_staging.cust_id = dim_customer.cust_id

LEFT JOIN dim_driver
on ride_staging.driver_id = dim_driver.driver_id


    WHERE ride_staging.created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`ride_start_time` = DBT_INTERNAL_SOURCE.`ride_start_time`,`ride_end_time` = DBT_INTERNAL_SOURCE.`ride_end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`cust_name` = DBT_INTERNAL_SOURCE.`cust_name`,`cust_phone_number` = DBT_INTERNAL_SOURCE.`cust_phone_number`,`cust_email` = DBT_INTERNAL_SOURCE.`cust_email`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`driver_name` = DBT_INTERNAL_SOURCE.`driver_name`,`driver_phone_number` = DBT_INTERNAL_SOURCE.`driver_phone_number`,`driver_email` = DBT_INTERNAL_SOURCE.`driver_email`,`vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`vehicle_brand` = DBT_INTERNAL_SOURCE.`vehicle_brand`,`vehicle_production_year` = DBT_INTERNAL_SOURCE.`vehicle_production_year`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `ride_start_time`, `ride_end_time`, `distance_km`, `fare`, `ride_status`, `cust_id`, `cust_name`, `cust_phone_number`, `cust_email`, `driver_id`, `driver_name`, `driver_phone_number`, `driver_email`, `vehicle_id`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)
    values
        (`ride_id`, `ride_start_time`, `ride_end_time`, `distance_km`, `fare`, `ride_status`, `cust_id`, `cust_name`, `cust_phone_number`, `cust_email`, `driver_id`, `driver_name`, `driver_phone_number`, `driver_email`, `vehicle_id`, `vehicle_type`, `vehicle_brand`, `vehicle_production_year`, `license_plate`, `created_at`)


    
[0m13:06:43.077811 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:4649ff78-48d9-43da-b3c3-964bd1559d9d&page=queryresults
[0m13:06:45.262882 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a7980f94-fe28-4b69-8d5b-e53c6c80cdbe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f851ff73090>]}
[0m13:06:45.264270 [info ] [Thread-4 (]: 3 of 3 OK created sql incremental model rizky_dwh_hailing_facts.fact_hailing_rides  [[32mMERGE (3.0 rows, 59.2 KiB processed)[0m in 2.72s]
[0m13:06:45.265653 [debug] [Thread-4 (]: Finished running node model.hailing_project.fact_hailing_rides
[0m13:06:45.267864 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m13:06:45.271628 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:06:45.272781 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_facts' was properly closed.
[0m13:06:45.273812 [debug] [MainThread]: Connection 'model.hailing_project.dim_driver' was properly closed.
[0m13:06:45.274893 [debug] [MainThread]: Connection 'model.hailing_project.dim_customer' was properly closed.
[0m13:06:45.276393 [debug] [MainThread]: Connection 'model.hailing_project.fact_hailing_rides' was properly closed.
[0m13:06:45.277646 [info ] [MainThread]: 
[0m13:06:45.279135 [info ] [MainThread]: Finished running 3 incremental models in 0 hours 0 minutes and 6.12 seconds (6.12s).
[0m13:06:45.281201 [debug] [MainThread]: Command end result
[0m13:06:45.320897 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt/target/manifest.json
[0m13:06:45.326986 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt/target/semantic_manifest.json
[0m13:06:45.336580 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt/target/run_results.json
[0m13:06:45.337501 [info ] [MainThread]: 
[0m13:06:45.339126 [info ] [MainThread]: [32mCompleted successfully[0m
[0m13:06:45.340601 [info ] [MainThread]: 
[0m13:06:45.341774 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
[0m13:06:45.343750 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 7.3927755, "process_in_blocks": "0", "process_kernel_time": 0.258537, "process_mem_max_rss": "220556", "process_out_blocks": "0", "process_user_time": 3.45048}
[0m13:06:45.345038 [debug] [MainThread]: Command `dbt run` succeeded at 13:06:45.344853 after 7.39 seconds
[0m13:06:45.346677 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8571750f90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8571751010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f85718ada10>]}
[0m13:06:45.348106 [debug] [MainThread]: Flushing usage events
[0m13:06:46.352823 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:06:49.407138 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f41471eae10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4147ec7bd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f41471eaa90>]}


============================== 13:06:49.410119 | 558121b6-e87d-4ef2-890f-2fc5cfd9fff1 ==============================
[0m13:06:49.410119 [info ] [MainThread]: Running with dbt=1.9.0
[0m13:06:49.411448 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/usr/app/dbt/logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt run --project-dir /usr/app/dbt --profiles-dir /usr/app/dbt --select marts', 'send_anonymous_usage_stats': 'True'}
[0m13:06:50.037350 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '558121b6-e87d-4ef2-890f-2fc5cfd9fff1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f411a9e5b50>]}
[0m13:06:50.083379 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '558121b6-e87d-4ef2-890f-2fc5cfd9fff1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4149440bd0>]}
[0m13:06:50.084692 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m13:06:50.154965 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m13:06:50.366301 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m13:06:50.367618 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m13:06:50.402671 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '558121b6-e87d-4ef2-890f-2fc5cfd9fff1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f41193fda50>]}
[0m13:06:50.536191 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt/target/manifest.json
[0m13:06:50.542808 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt/target/semantic_manifest.json
[0m13:06:50.559950 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '558121b6-e87d-4ef2-890f-2fc5cfd9fff1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4118fa8210>]}
[0m13:06:50.561358 [info ] [MainThread]: Found 9 models, 8 sources, 489 macros
[0m13:06:50.562725 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '558121b6-e87d-4ef2-890f-2fc5cfd9fff1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4119396dd0>]}
[0m13:06:50.565252 [info ] [MainThread]: 
[0m13:06:50.566425 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m13:06:50.567519 [info ] [MainThread]: 
[0m13:06:50.569013 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m13:06:50.573204 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m13:06:50.574070 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:06:51.169259 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_marts)
[0m13:06:51.170336 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_facts'
[0m13:06:51.171027 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_staging'
[0m13:06:51.171419 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:06:51.172674 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:06:51.173584 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:06:51.451489 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '558121b6-e87d-4ef2-890f-2fc5cfd9fff1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f411908e310>]}
[0m13:06:51.452403 [debug] [MainThread]: Opening a new connection, currently in state init
[0m13:06:51.456914 [debug] [Thread-1 (]: Began running node model.hailing_project.mart_cust_rides_daily
[0m13:06:51.457531 [debug] [Thread-2 (]: Began running node model.hailing_project.mart_driver_loyalty_mgmt
[0m13:06:51.458308 [info ] [Thread-1 (]: 1 of 2 START sql incremental model rizky_dwh_hailing_marts.mart_cust_rides_daily  [RUN]
[0m13:06:51.459662 [info ] [Thread-2 (]: 2 of 2 START sql incremental model rizky_dwh_hailing_marts.mart_driver_loyalty_mgmt  [RUN]
[0m13:06:51.460766 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_marts, now model.hailing_project.mart_cust_rides_daily)
[0m13:06:51.461917 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_staging, now model.hailing_project.mart_driver_loyalty_mgmt)
[0m13:06:51.463130 [debug] [Thread-1 (]: Began compiling node model.hailing_project.mart_cust_rides_daily
[0m13:06:51.464858 [debug] [Thread-2 (]: Began compiling node model.hailing_project.mart_driver_loyalty_mgmt
[0m13:06:51.474881 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.mart_cust_rides_daily"
[0m13:06:51.478581 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.mart_driver_loyalty_mgmt"
[0m13:06:51.484345 [debug] [Thread-1 (]: Began executing node model.hailing_project.mart_cust_rides_daily
[0m13:06:51.485622 [debug] [Thread-2 (]: Began executing node model.hailing_project.mart_driver_loyalty_mgmt
[0m13:06:51.531417 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m13:06:51.534438 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:06:51.862905 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.mart_driver_loyalty_mgmt"
[0m13:06:51.866037 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.mart_cust_rides_daily"
[0m13:06:51.872979 [debug] [Thread-1 (]: On model.hailing_project.mart_cust_rides_daily: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.mart_cust_rides_daily"} */
-- back compat for old kwarg name
  
  
        
            
                
                
            
                
                
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_marts`.`mart_cust_rides_daily` as DBT_INTERNAL_DEST
        using (


WITH fact_rides AS(

    SELECT * 
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
)

SELECT 

    fact_rides.cust_id,
    DATE(fact_rides.created_at) AS ride_date,
    fact_rides.cust_name,
    fact_rides.cust_email,
    fact_rides.cust_phone_number,
    COUNT(fact_rides.ride_id) AS no_of_rides,
    SUM(TIMESTAMP_DIFF(fact_rides.ride_end_time, fact_rides.ride_start_time, MINUTE)) AS total_ride_duration_min,
    SUM(fact_rides.fare) AS total_fare,
    SUM(fact_rides.distance_km) as total_distance_km,
    SUM(fact_rides.distance_km)-SUM(fact_rides.fare) AS rev_opportunity_loss,

FROM fact_rides
GROUP BY cust_name, cust_id, ride_date, cust_email, cust_phone_number
        ) as DBT_INTERNAL_SOURCE
        on (
                    DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
                ) and (
                    DBT_INTERNAL_SOURCE.ride_date = DBT_INTERNAL_DEST.ride_date
                )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`ride_date` = DBT_INTERNAL_SOURCE.`ride_date`,`cust_name` = DBT_INTERNAL_SOURCE.`cust_name`,`cust_email` = DBT_INTERNAL_SOURCE.`cust_email`,`cust_phone_number` = DBT_INTERNAL_SOURCE.`cust_phone_number`,`no_of_rides` = DBT_INTERNAL_SOURCE.`no_of_rides`,`total_ride_duration_min` = DBT_INTERNAL_SOURCE.`total_ride_duration_min`,`total_fare` = DBT_INTERNAL_SOURCE.`total_fare`,`total_distance_km` = DBT_INTERNAL_SOURCE.`total_distance_km`,`rev_opportunity_loss` = DBT_INTERNAL_SOURCE.`rev_opportunity_loss`
    

    when not matched then insert
        (`cust_id`, `ride_date`, `cust_name`, `cust_email`, `cust_phone_number`, `no_of_rides`, `total_ride_duration_min`, `total_fare`, `total_distance_km`, `rev_opportunity_loss`)
    values
        (`cust_id`, `ride_date`, `cust_name`, `cust_email`, `cust_phone_number`, `no_of_rides`, `total_ride_duration_min`, `total_fare`, `total_distance_km`, `rev_opportunity_loss`)


    
[0m13:06:51.876998 [debug] [Thread-2 (]: On model.hailing_project.mart_driver_loyalty_mgmt: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.mart_driver_loyalty_mgmt"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_marts`.`mart_driver_loyalty_mgmt` as DBT_INTERNAL_DEST
        using (

WITH dim_driver AS(
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_driver`
),

fact_rides AS(
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`fact_hailing_rides`
)

SELECT 
dim_driver.driver_id,
dim_driver.driver_name,
dim_driver.phone_number,
dim_driver.email,
dim_driver.vehicle_type,
COUNT(fact_rides.ride_id) AS no_of_rides,
SUM(TIMESTAMP_DIFF(fact_rides.ride_end_time, fact_rides.ride_start_time, MINUTE)) AS total_ride_duration_min,
SUM(fact_rides.fare) AS total_fare,
SUM(fact_rides.distance_km) as total_distance_km,
SUM(fact_rides.distance_km)-SUM(fact_rides.fare) AS rev_opportunity_loss,
FROM dim_driver
LEFT JOIN fact_rides
ON dim_driver.driver_id = fact_rides.driver_id

GROUP BY driver_id,driver_name,phone_number,email,vehicle_type
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`driver_name` = DBT_INTERNAL_SOURCE.`driver_name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`no_of_rides` = DBT_INTERNAL_SOURCE.`no_of_rides`,`total_ride_duration_min` = DBT_INTERNAL_SOURCE.`total_ride_duration_min`,`total_fare` = DBT_INTERNAL_SOURCE.`total_fare`,`total_distance_km` = DBT_INTERNAL_SOURCE.`total_distance_km`,`rev_opportunity_loss` = DBT_INTERNAL_SOURCE.`rev_opportunity_loss`
    

    when not matched then insert
        (`driver_id`, `driver_name`, `phone_number`, `email`, `vehicle_type`, `no_of_rides`, `total_ride_duration_min`, `total_fare`, `total_distance_km`, `rev_opportunity_loss`)
    values
        (`driver_id`, `driver_name`, `phone_number`, `email`, `vehicle_type`, `no_of_rides`, `total_ride_duration_min`, `total_fare`, `total_distance_km`, `rev_opportunity_loss`)


    
[0m13:06:52.115172 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:fa321ea7-6b5d-495c-bfaf-7d98f5cc5706&page=queryresults
[0m13:06:52.127157 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:f8d8d0d1-18ba-4a91-b25b-eb8058e9405e&page=queryresults
[0m13:06:53.665312 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '558121b6-e87d-4ef2-890f-2fc5cfd9fff1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4118672b50>]}
[0m13:06:53.666688 [info ] [Thread-2 (]: 2 of 2 OK created sql incremental model rizky_dwh_hailing_marts.mart_driver_loyalty_mgmt  [[32mMERGE (126.0 rows, 28.9 KiB processed)[0m in 2.20s]
[0m13:06:53.668254 [debug] [Thread-2 (]: Finished running node model.hailing_project.mart_driver_loyalty_mgmt
[0m13:06:53.914218 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '558121b6-e87d-4ef2-890f-2fc5cfd9fff1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f411936b790>]}
[0m13:06:53.915514 [info ] [Thread-1 (]: 1 of 2 OK created sql incremental model rizky_dwh_hailing_marts.mart_cust_rides_daily  [[32mMERGE (104.0 rows, 28.2 KiB processed)[0m in 2.45s]
[0m13:06:53.917129 [debug] [Thread-1 (]: Finished running node model.hailing_project.mart_cust_rides_daily
[0m13:06:53.919135 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m13:06:53.922407 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:06:53.923401 [debug] [MainThread]: Connection 'model.hailing_project.mart_cust_rides_daily' was properly closed.
[0m13:06:53.924206 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_facts' was properly closed.
[0m13:06:53.924987 [debug] [MainThread]: Connection 'model.hailing_project.mart_driver_loyalty_mgmt' was properly closed.
[0m13:06:53.925865 [info ] [MainThread]: 
[0m13:06:53.926821 [info ] [MainThread]: Finished running 2 incremental models in 0 hours 0 minutes and 3.36 seconds (3.36s).
[0m13:06:53.928102 [debug] [MainThread]: Command end result
[0m13:06:53.962687 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt/target/manifest.json
[0m13:06:53.967255 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt/target/semantic_manifest.json
[0m13:06:53.974959 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt/target/run_results.json
[0m13:06:53.975746 [info ] [MainThread]: 
[0m13:06:53.976870 [info ] [MainThread]: [32mCompleted successfully[0m
[0m13:06:53.978450 [info ] [MainThread]: 
[0m13:06:53.979750 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m13:06:53.981698 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 4.6251965, "process_in_blocks": "0", "process_kernel_time": 0.265822, "process_mem_max_rss": "219696", "process_out_blocks": "0", "process_user_time": 3.406466}
[0m13:06:53.982699 [debug] [MainThread]: Command `dbt run` succeeded at 13:06:53.982570 after 4.63 seconds
[0m13:06:53.983508 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4147238c90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f41472395d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f414a9d8f90>]}
[0m13:06:53.984355 [debug] [MainThread]: Flushing usage events
[0m13:06:54.989422 [debug] [MainThread]: An error was encountered while trying to flush usage events
